{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of HIERENC is unclear and suggests that it might introduce noise due to the averaging of multiple contextual representations. However, it does not provide explicit guidance on how to clarify the description or address the issue of noise. The authors are left to infer that they need to clarify the description and possibly reconsider the averaging approach. While the comment identifies a potential problem, it lacks concrete instructions on how to resolve it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, pointing out that the averaging of multiple contextual representations might introduce noise and suggesting that only one instantiation is likely correct. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and suggests that averaging multiple contextual representations might introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is likely correct and that averaging multiple representations could lead to noise. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning and potential consequences to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of HIERENC, noting that the averaging of multiple contextual representations might introduce noise. It provides a logical reasoning that only one instantiation is likely correct, which could lead to noise. This feedback is clear and actionable, as it points out a potential weakness in the description and suggests a possible improvement. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or address the issue of noise. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, and it recommends correcting the wording. However, the comment does not provide specific guidance on how to rephrase the sentence or what alternative phrasing would be more appropriate. While the action is implicit, as the authors can infer that they need to revise the wording, the lack of concrete details makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.791,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting that the authors should correct the phrase \"on par or better\" to avoid a cognitive bias among NLP researchers. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a general cognitive bias among NLP researchers to phrase results in a certain way, specifically by mapping instances where they perform worse to \"on par\" and the rest to \"better.\" The reviewer suggests that the wording in the paper should be corrected, but does not provide specific examples or references to support this claim. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. The authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It points out a potential cognitive bias among NLP researchers to phrase results in a certain way, which could lead to misinterpretation. The reviewer suggests correcting the wording to avoid this bias, but does not provide specific suggestions or examples of alternative phrasing. While the comment highlights an important area for improvement, it lacks detailed guidance on how to address the issue, making it somewhat helpful. The authors are given a clear direction but may need to infer more detailed guidance to fully resolve the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOS-V. While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to clarify or explain these points, but without concrete guidance, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues being raised, which are the interpretations of the results for Chinese MOS-Q and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOS-V. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions about the interpretation of results in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOS-V. While the comment identifies areas of confusion, it does not provide any actionable feedback or suggestions for clarification or improvement. The authors are left with a vague understanding of what needs to be addressed, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include an ablation study to evaluate the importance of the post-processing steps proposed to filter out \"false-positive\" neurons. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable. The authors can infer that they need to conduct an ablation study but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of integrated gradients to measure attribution and the proposed post-processing steps to filter out \"false-positive\" neurons. It also suggests an ablation study, providing clear guidance on what needs to be addressed. However, the comment does not specify which part of the paper should include the ablation study, making it fully grounded but under-specific. Therefore, this comment aligns with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that using integrated gradients to measure attribution has been studied in existing papers and suggests that an ablation study may be needed to evaluate the importance of the post-processing steps proposed to filter out \"false-positive\" neurons. However, the comment lacks specific references to these existing studies or detailed reasoning to support the claim that an ablation study is necessary. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that could be improved by suggesting an ablation study to evaluate the importance of the post-processing steps proposed to filter out \"false-positive\" neurons. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance their work. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would benefit the paper. Despite this, the suggestion is valuable and provides a clear direction for the authors to improve their draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it suggests a method of matching the head of noun phrases. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the method. The comment lacks concrete instructions or detailed suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about identifying antecedents in the context of a prediction being a pronoun. It suggests a method of matching the head of noun phrases, but does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. It is specific in its question about the handling of a head word that is not a pronoun, but without clear grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about identifying antecedents in the context of a prediction being a pronoun. It suggests a method of matching the head of noun phrases, but does not provide any supporting evidence, reasoning, or references to justify the claim. The comment lacks detailed explanation or examples, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the identification of antecedents in the context of a prediction being a pronoun. It suggests a method of matching the head of noun phrases, which could be a useful approach. However, the comment lacks clarity and does not provide specific guidance on how to implement this method or address the issue of handling situations where the head word is not a pronoun. While it identifies a potential area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It implies that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to incorporate these baselines or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed models\" and the \"MST baseline,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison between the proposed models and models that only consider different senses but not sememes. The comment suggests that the paper would be stronger with the inclusion of more baselines based on related work. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. The comment provides a logical reasoning by pointing out the potential comparison between the proposed models and existing models that only consider different senses. However, it lacks specific examples or references to support the claim that the MST baseline is an example of such a model. Additionally, it does not provide detailed guidance on how to incorporate more baselines or what specific aspects of the comparison should be addressed. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper regarding the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including additional comparisons and references. By addressing this point, the authors can improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific examples of related work or baselines that should be considered. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect of their work. The comment lacks actionable details, such as recommending specific ways to present the selection process or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the selection of frame similarity factors and attributes similarity factors is unclear, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or sections need clarification, making the comment weakly grounded. However, it is specific in detailing what needs to be addressed regarding the selection process. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. It points out that the explanation of these choices is unclear, which is a valid observation that could help the authors improve the clarity and transparency of their work. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the selection process. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely low-resource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the experiments or demonstrate the method's applicability. The action is implicit and somewhat vague, as the authors can infer that they need to expand the scope of their experiments and demonstrate the method's applicability to other NLP tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the main weaknesses of the paper, specifically the experiments, which are limited to an extremely low-resource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the potential of the proposed method, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are the main weakness of the paper, as they are limited to an extremely low-resource regime and sentence classification, which are not the only cases for data augmentation in real-world applications. The reviewer also suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. The comment provides some logical reasoning by pointing out the limitations of the experiments and the potential of the proposed method, but it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a general critique but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely low-resource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. The comment highlights the need for the paper to showcase the method's applicability to a broader range of tasks. While the feedback points out specific areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these weaknesses or expand the scope of their experiments. The comment is somewhat helpful as it provides insight into potential areas for improvement, but it could be more beneficial with additional guidance or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether concept map extraction should be treated as a separate task, considering that generic summarization systems often build knowledge graphs and generate summaries accordingly. The reviewer suggests that with the increase in node numbers, concept maps become harder to distinguish, making general summaries more readable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they might need to reconsider their approach to concept map extraction, but the comment lacks concrete details on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether concept map extraction should be treated as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion that general summaries should be more readable due to the difficulty in distinguishing concept maps. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether concept map extraction should be treated as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. The comment provides a logical reasoning by comparing it to generic summarization systems that build knowledge graphs and generate summaries accordingly. However, it lacks specific examples or references to support the claim that general summaries should be more readable due to the difficulty in distinguishing concept maps. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the necessity of treating concept map extraction as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. It suggests that general summaries might be more readable due to these challenges. While the comment identifies a potential issue with the current approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider the trade-offs between treating concept map extraction as a separate task versus incorporating it into general summarization systems. However, it could be more helpful if it provided actionable steps or examples to enhance the clarity or feasibility of the proposed solution. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that lines 102-106 are misleading, as they refer to a \"such distribution\" that cannot be related to the discussion in the previous section. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific changes or clarifications to be made to the text. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 102-106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the misleading statement regarding \"such distribution\" and its relation to the discussion in the previous section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 102-106 are misleading, specifically mentioning that \"such distribution\" cannot refer to the discussion in the previous section. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text, noting that lines 102-106 are misleading due to the use of \"such distribution.\" It points out that this phrase cannot refer to the discussion in the previous section, which is a valuable observation that can help the authors improve the clarity of their writing. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the clarity of the text. While it highlights a potential problem, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without answers to these questions, it is difficult to understand what the model is capturing. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns. It lacks concrete steps or specific actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, the comment is somewhat actionable, as it identifies an area for consideration but does not offer detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the choice of datasets and the duration of four years for studying style shifts. However, it does not specify which part of the paper these questions pertain to, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment highlights a potential issue with the study, it lacks specificity in identifying where the authors should address these concerns. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the choice of datasets and the duration of four years for studying style shifts, suggesting that it may not be sufficient to capture all style shifts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of datasets and the duration of four years for studying style shifts. It questions whether four years is sufficient to capture all style shifts and suggests that the authors should provide more information on what kind of style shifts occur during this period. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their dataset choice and the potential impact on the model\\'s performance. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or what additional information might be needed. Therefore, it aligns with a score of 3, as it provides some guidance but lacks depth and actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the claim of \"no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This feedback is clear and directs the authors to review the references mentioned to understand the tools available in the reinforcement learning setting. The action is explicit and concrete, as the authors know exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim of \"no corresponding set of tools for the reinforcement learning setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides references to support the claim, which helps the authors understand the context and the basis of the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. However, the comment does not specify which references are being referred to or how they support the claim. This lack of detailed explanation or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks the necessary detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment challenges a claim made in the paper regarding the availability of tools for the reinforcement learning setting. It provides a specific rebuttal by referencing external sources, which is a valuable contribution to the discussion. This feedback helps the authors clarify and potentially correct an inaccurate statement in their work, ensuring that the paper accurately reflects the state of the field. However, the comment could be more helpful if it provided additional context or explanation about why the references are relevant or how they support the claim. Overall, the comment is mostly helpful as it directs the authors to a specific area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of a reference to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. While the comment identifies a missing link, it does not explicitly instruct the authors to include these references or provide guidance on how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to enhance their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works, \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of references to similar work that shares a similar structure and inference capabilities with the CRF. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the relevance or significance of these references. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a missing link by pointing out the absence of references to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. This feedback is somewhat helpful as it highlights a potential gap in the literature review that could enhance the authors\\' understanding and comparison of their work. However, the comment could be more helpful if it provided specific examples or references to these similar works, which would guide the authors on how to incorporate them into their analysis. Overall, the comment is somewhat helpful as it directs the authors to explore additional literature, but it lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 could benefit from a slower development to improve readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need more development. The comment lacks concrete details on how to implement this suggestion, such as recommending additional content or a different structure. As a result, the authors are left without clear instructions on how to enhance the readability of the section. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the section is \"very tersely written\" and could benefit from a slower development for easier readability. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 4 is \"very tersely written\" and could benefit from a slower development to improve readability. However, the comment does not provide any specific reasoning or examples to support this claim. It lacks detailed justification or references to similar works that might have addressed this issue, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the writing style of Section 4, noting that it is \"very tersely written\" and could benefit from a slower development to improve readability. While it highlights a potential problem, it lacks specific suggestions or guidance on how to achieve this improvement. The feedback is somewhat helpful as it points out an area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, making it highly actionable. The comment is specific about what needs to be included and explained, giving the authors a clear path to improve their draft. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the distribution of videos of different lengths within the benchmark and the explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide relevant explanations regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This claim is somewhat verifiable as it logically points out a gap in the paper\\'s explanation and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or references to support the importance of this explanation or the impact of the distribution on the assessment of reasoning ability and robustness. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of explanation regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the draft. By addressing this issue, the authors can enhance the transparency and clarity of their work, which is valuable for improving the paper\\'s comprehensibility and credibility. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue, such as suggesting ways to make the dataset more accessible or how to mitigate the potential impact of this delay. As a result, the authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the dataset\\'s availability, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the promised dataset has not yet been made publicly available, suggesting that a cautious approach should be taken regarding the contribution until the dataset is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a potential issue with the paper\\'s contribution, specifically the availability of the promised dataset. It suggests that a cautious approach should be taken until the dataset is publicly accessible, which is a valid concern. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or mitigate the potential impact of the delay. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing [A]. This direct suggestion provides a clear and concrete action for the authors to take, ensuring they are aware of the relevant literature and can incorporate it into their discussion. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section discussing related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of related work on modular networks for VQA, such as [A]. This provides clear guidance on how to improve the introduction by acknowledging existing work in the field. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is crucial to mention related work on modular networks for VQA, such as [A], to avoid the impression that no one does modular architectures for VQA. However, the comment does not provide specific examples or references to support this claim, nor does it explain why this omission is problematic. Without additional context or evidence, the authors may find it challenging to understand the significance of this claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion of related work in the paper, noting that the introduction seems to imply that no one does modular architectures for VQA. It provides a clear and actionable suggestion by recommending the inclusion of related work on modular networks for VQA, such as [A]. This feedback is valuable as it guides the authors to enhance their literature review and ensure that their work is properly contextualized within the existing body of research. However, the comment could be more helpful if it explained why this omission is problematic or how it affects the overall understanding of the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the tables. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or correct the results, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance without reinforcement learning (RL) dropped lower than without dependency tree, and that the tables do not list the cases where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance without reinforcement learning (RL) dropped lower than without dependency tree in the ablation experiment. However, it does not provide any supporting evidence, such as data or comparisons, to substantiate this claim. Additionally, the comment mentions that the two tables do not list the cases where dependency tree and RL are not used, but it does not explain why this is a concern or how it affects the results. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the results of the ablation experiment, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is somewhat helpful as it highlights an area where the authors need to clarify or correct their results. However, the comment lacks specific suggestions on how to address the discrepancy or what additional information should be included in the tables. While it provides some direction, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, it does not provide explicit guidance on what additional information is needed or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors uncertain about how to improve the clarity of their notation. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it is confusing. However, it does not specify which part of the paper this notation is used in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its critique of the notation but lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, the comment does not provide any specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the confusion or how to address it. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the notation used to separate \"static\" and temporal features into two variables, noting that it requires more information than is provided in the paper. This feedback is somewhat helpful as it points out a potential issue with the clarity of the paper, which could be improved by providing additional information or explanation. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional explanations or examples. While it highlights an area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be more detailed, particularly in the definitions of the resistance distance and explanations of Algorithm 1. While it implies that more details should be provided, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper deals with many graph notions and is somewhat hard to understand, but the writing is generally good. It provides specific feedback by mentioning the need for more detailed explanations, particularly in the definition of the resistance distance and the explanations of Algorithm 1. The authors can infer that these are areas that need attention, but the comment does not explicitly mention which sections or parts of the paper these issues pertain to. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in identifying the need for more detailed explanations. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is difficult to understand due to its focus on graph notions, but it also acknowledges that the writing is generally good. The comment provides a specific suggestion for improvement by recommending more detailed explanations, particularly in the definition of the resistance distance and the explanations of Algorithm 1. This feedback is somewhat verifiable as it identifies areas where the paper could be more accessible, but it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it deals with many graph notions and is somewhat hard to understand. It acknowledges that the writing is generally good but suggests that more detailed explanations could be provided, particularly in the definition of the resistance distance and the explanations of Algorithm 1. This feedback is somewhat helpful as it points out areas where the paper could be improved, but it lacks specific suggestions or guidance on how to enhance these explanations. The authors are given a direction for improvement but are not provided with detailed instructions or examples on how to address the identified issues. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to consider introducing specific aspects of their model that are relevant to the example model. It provides a clear and concrete action for the authors to take, specifying that they should clarify the model's specificity in relation to the infinite subdivisions and bounded parameters. This guidance is direct and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of specific aspects of the model that are relevant to the example model. The comment provides guidance on what should be clarified, such as the setting with infinite subdivisions and bounded parameters. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should introduce specific aspects of their model that are relevant to the example model, such as clarifying the setting with infinite subdivisions and bounded parameters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors introduce specific aspects of their model that are relevant to the example model. It highlights the need to clarify the setting with infinite subdivisions and bounded parameters, which are crucial for understanding the model's applicability. This guidance is clear and constructive, as it directs the authors to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the transparency and accessibility of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. The reviewer suggests that this condition is not realistic and may lead to unreasonably large learning rates when learning on large-scale datasets. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on whether the authors should adjust the condition, provide a rationale for its necessity, or explore alternative approaches. As a result, the authors are left without actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. It provides a clear rationale for why this condition is not realistic and may lead to unreasonably large learning rates when learning on large-scale datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the learning rate condition and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the condition on the learning rate is not scalable, as it does not grow with the number of samples in practice. The reviewer provides a logical reasoning by explaining that this condition leads to unreasonably large learning rates when learning on large-scale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not realistic. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. This is a critical observation, as it highlights a potential flaw in the methodology that could lead to unreasonably large learning rates when learning on large-scale datasets. The reviewer provides a logical reasoning for why this condition is not realistic and suggests that the authors need a way to precisely characterize the benefit of large learning rates. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or explore alternative approaches. While it provides valuable insights, the lack of actionable guidance limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a more convincing setting for training, similar to what was done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. It provides a specific reference to the paper by He et al. (EMNLP 2018) as an example of a convincing setting. This feedback is explicit and provides a clear action for the authors to take, which is to adopt a more convincing training approach. The suggestion is concrete and provides a specific method to implement the change, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)\" and suggests that the data is perfectly balanced, which is impractical in real-world applications. It also references a specific paper, \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018,\" which suggests using a more convincing setting for training. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the perfectly balanced unlabeled data from the preprocessed Amazon review dataset is impractical in real-world applications. It suggests that the authors should use a more convincing setting, like the one described in the referenced paper \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018.\" The comment provides a specific reference to the paper, which supports the claim by offering a concrete example of a more convincing setting. This makes the claim mostly verifiable, as it provides a clear rationale and evidence for the suggestion. However, the comment could be strengthened by explaining why the current setting is impractical or how the suggested setting would improve the results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the perfectly balanced unlabeled data from the preprocessed Amazon review dataset, noting that this is impractical in real-world applications. It suggests that the authors should use a more convincing setting, like the one described in the referenced paper \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018.\" This feedback is clear and actionable, providing the authors with a concrete suggestion for improving their approach. By referencing a specific paper, the comment offers a practical solution that could enhance the applicability and robustness of their work. However, it could be more helpful if it explained why the current setting is impractical or how the suggested setting would benefit the authors\\' work. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding how to sample from the DPP when the eigenfunctions e_n are inaccessible, as described in Equation (10) line 130. It also mentions a similar issue with sampling from the leverage score in [3]. The reviewer questions whether sampling from the DPP is easier than sampling from the leverage score. While the comment identifies a potential problem, it does not provide explicit guidance on how to address it or suggest specific actions for the authors to take. The authors are left to infer that they need to clarify the sampling process, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of how to sample from the DPP when the eigenfunctions e_n are inaccessible, and it references a similar issue in [3]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how to sample from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar issue in [3]. However, the comment does not provide specific examples or detailed reasoning to support the claim that sampling from the DPP is more difficult than sampling from the leverage score. The lack of detailed justification or references makes it challenging for the authors to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper regarding how to sample from the DPP when the eigenfunctions e_n are inaccessible, as described in Equation (10) line 130. It also references a similar issue in [3] and questions whether sampling from the DPP is easier than sampling from the leverage score. This feedback is somewhat helpful as it points out a potential gap in the explanation, but it lacks depth and does not provide specific suggestions or guidance on how to address the issue. The authors are left with a general understanding of the problem but without actionable steps to improve the clarity of their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the evaluation of the generalizability of observations to few-shot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the submission's contributions regarding understanding the properties of episodic training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation to include other few-shot learners, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of evaluation on the generalizability of observations to few-shot learners beyond Prototypical Networks. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the evaluation section. However, the comment is not specific as it does not detail what specific aspects of the evaluation are missing or how the authors could address this issue. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the observations presented do not evaluate the generalizability to few-shot learners beyond Prototypical Networks, which may limit the scope of the paper\\'s contributions regarding understanding the properties of episodic training. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the significance of the issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the lack of evaluation on the generalizability of observations to few-shot learners beyond Prototypical Networks. This feedback highlights a potential limitation in the scope of the paper\\'s contributions regarding understanding the properties of episodic training. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or what specific aspects of the evaluation should be expanded. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address this issue, specifically asking for guidance on how to deal with the problem. However, the comment does not provide explicit instructions or concrete suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the contribution of different modalities and address the problem, but the comment lacks detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the contribution of different modalities of different instances, specifically mentioning modalities A and B and their performance in different instances. It raises a question about how to deal with the problem of removing the modal subset of all instances, as described in Equation 3. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the discussion of modalities and their contribution. The comment is also specific because it details the issue of removing the modal subset and asks for guidance on how to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address the problem of removing the modal subset of all instances, as described in Equation 3. However, the comment lacks specific examples or references to support the claim that the contribution of different modalities is different. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the contribution of different modalities of different instances. It points out that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer raises a question about how to address the problem of removing the modal subset of all instances, as described in Equation 3. This feedback is somewhat helpful as it highlights a potential weakness in the paper and prompts the authors to consider how to handle this issue. However, the comment could be more helpful if it provided suggestions or examples on how to address this problem or how to incorporate this information into the paper. Overall, the comment is somewhat helpful as it directs the authors to consider a specific aspect of their work but lacks detailed guidance or actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed objective in Eq. 2 in line 128 requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S. It also notes that the effect on the number of parameters versus prior work, such as AlignFlow, has not been discussed clearly. While the comment identifies a specific issue with the discussion of parameters and prior work, it does not provide explicit guidance on how to address this issue or what specific aspects of the discussion need clarification. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about the number of parameters and their comparison to prior work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 128\" and \"Eq. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the objective requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S, and that the effect on the number of parameters versus prior work, such as AlignFlow, has not been discussed clearly. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed objective in Eq. 2 in line 128 requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S, and that the effect on the number of parameters versus prior work, such as AlignFlow, has not been discussed clearly. However, the comment lacks specific examples or references to support the claim about the number of parameters or the comparison to prior work. The reasoning is based on logical reasoning and common knowledge, but it does not provide detailed evidence or references to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks specific examples or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed objective in Eq. 2 in line 128, noting that it requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S. It also points out that the effect on the number of parameters versus prior work, such as AlignFlow, has not been discussed clearly. This feedback is somewhat helpful as it highlights a potential gap in the discussion of the number of parameters and their comparison to prior work. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific aspects of the discussion need clarification. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the implications of Eq. 4 and potentially improve the results in Table 5, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the implications of Eq. 4 and noting the lack of significant improvement in the designed solutions in Table 5, particularly on the OfficeHome dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This claim is somewhat verifiable as it provides some logical reasoning and examples to support the suggestion that the improvement is not significant. However, it could be strengthened by providing more detailed analysis or references to similar studies that demonstrate the expected behavior of u^l in this context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This feedback is somewhat helpful as it points out a potential issue with the results and suggests that the authors might need to reconsider their approach. However, the comment could be more helpful if it provided more detailed guidance on how to address the issue or what specific aspects of the results need further examination. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"VolumeDeform [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the issue is: the use of a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform [1]. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, the comment does not provide specific details or references to VolumeDeform to support the claim that this idea is not novel. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any constructive feedback or suggestions for improvement. It lacks depth and actionable guidance, leaving the authors without a clear understanding of how to address the issue or enhance their work. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, it does not explicitly instruct the authors to average over subword representations or provide guidance on how to implement this suggestion. The action is implied and somewhat vague, as the authors need to infer that they should consider averaging over subword representations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, as done by Hewitt and Manning (2019, footnote 4). This feedback is actionable and provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, the comment does not provide specific examples or detailed reasoning to support why this is a common practice or how it would benefit the current work. While it references a specific work, the lack of detailed explanation or justification makes the claim somewhat verifiable. The authors would need to infer the importance of this suggestion and might find it challenging to understand the full implications without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in the paper, noting that it is common in similar cases to average over subword representations. It provides a reference to a specific work by Hewitt and Manning (2019, footnote 4) to support this suggestion. This feedback is somewhat helpful as it points out a potential improvement in the language used, but it lacks detailed guidance or suggestions on how to implement this change effectively. The authors are given a direction to consider, but the comment could be more actionable with additional details or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear action to take, it lacks specific guidance on how to conduct the calibration curves or what aspects of the difference between the traditional method and the proposed method should be discussed. The authors are left with a general direction but may need to infer the exact steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the model AUC and its ability to assess model discriminant ability, as well as the consistency between predicted scores and actual risks. It suggests conducting calibration curves to demonstrate this consistency, which is crucial for the clinical scoring system. The comment also mentions the difference between the traditional method and the proposed method, which could be discussed in the paper. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as conducting calibration curves and discussing the difference between traditional and proposed methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model AUC can assess the model discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It suggests that this consistency is crucial for the clinical scoring system and recommends conducting calibration curves to show the agreement. The comment also mentions the importance of discussing the difference between the traditional method and the proposed method. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim about the importance of calibration curves. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of demonstrating consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. The comment suggests conducting calibration curves to show this consistency, offering a specific and concrete step for the authors to take. Additionally, it encourages the authors to discuss the difference between their method and traditional methods, providing a direction for further exploration and comparison. While the comment could be more helpful by offering examples or guidance on how to conduct the calibration curves, it still provides valuable insights and actionable advice. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues related to the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the strength and fairness of the experiments, questioning the use of position kernels and the absence of certain baselines. It also suggests that the paper lacks discussion on limitations and societal impacts. While the comment identifies specific issues, it does not provide detailed reasoning or evidence to support these claims. The authors are left to infer the basis of the reviewer\\'s concerns, making the comment somewhat verifiable. The authors would need to further explore the rationale behind these claims to fully address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. It provides specific suggestions for addressing these issues, such as using default settings of baselines in the literature and comparing the proposed approach with other baselines. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful as it provides clear and actionable feedback, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of insight into the performance of sparsity patterns and questions whether this is unique to the sparsity detection problem or applies to GNNs in general. It suggests that the authors should provide more insight into this observation. However, the comment does not specify what kind of insight is needed or how the authors should present it. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or analysis but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of sparsity patterns and asking for more insight into whether this is unique to the sparsity detection problem or applies to GNNs in general. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the performance of sparsity patterns and whether this is unique to the sparsity detection problem or applies to GNNs in general. It suggests that the authors should provide more insight into this observation. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the performance is unexpected or noteworthy. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a direction for further exploration but lacks sufficient justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance of sparsity patterns, noting that they seem to perform equally well across different patterns. It questions whether this is unique to the sparsity detection problem or applies to GNNs in general. The comment suggests that the authors should provide more insight into this observation, which could be a valuable contribution to the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide the requested insight. While it points out an area for improvement, it does not offer detailed advice on how to achieve it, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 needs this comparison or what aspects of the prior efforts should be compared. This makes it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the prior efforts should be compared or how this comparison would enhance the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in Section 6 by suggesting that the manuscript could benefit from comparing the perspective taken in the present work to the contributions of prior efforts. This feedback is somewhat helpful as it points out a specific area where the manuscript could enhance its analysis and comparison with existing literature. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but not detailed steps for implementation. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact change needed (examining performance with different numbers of scenarios), but it is somewhat vague because it does not provide detailed guidance on how to conduct the experiment or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the training process or results, but this inference is not direct. The comment is specific in its suggestion to examine performance with different scenarios, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion or how it could be tested. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential relationship between the performance and the number of scenarios used for training, suggesting that examining performance with different numbers of scenarios could be interesting. This is a valuable observation that could lead to a meaningful experiment or analysis. However, the comment lacks specific guidance on how to conduct this experiment or what aspects of the performance to focus on. While it points out a potential area for improvement, it does not provide detailed instructions or suggestions for the authors to follow. Therefore, the comment is somewhat helpful, as it highlights an interesting area for exploration but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model's ability to predict it. It suggests that disturbances in the training data might affect the model's ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or test their model under such disturbances. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between generating a quality label and the model\\'s ability to predict it, suggesting that disturbances in the training data might affect the model\\'s ability to generate the correct quality label. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue is discussed. The authors can infer that it relates to the model evaluation or training process, but this inference is not direct. The comment is specific in its inquiry about the model\\'s ability to predict quality labels, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model\\'s ability to predict it. It suggests that disturbances in the training data might affect the model\\'s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relationship between generating a quality label and the model\\'s ability to predict it, suggesting that disturbances in the training data might affect the model\\'s ability to generate the correct quality label, potentially indicating a decrease in quality. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or test their model under disturbances. The feedback is somewhat helpful as it prompts the authors to consider the robustness of their model, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the bounded noise assumption in the context of stochastic optimization literature, noting its restrictiveness and suggesting that it has been extended in recent literature. It provides specific references to papers by A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou, which discuss better theory for stochastic gradient descent (SGD) in the nonconvex world. However, the comment does not explicitly instruct the authors to consider these references or incorporate the extended noise conditions into their work. While the references provide a clear direction for further exploration, the action is implicit and lacks concrete guidance on how to apply this information. Therefore, the comment is somewhat actionable, as it points to a potential area for improvement but does not provide explicit instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the bounded noise assumption, which allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by pointing out that this assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The comment provides specific references to relevant literature, which further clarifies the need for addressing this issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The reviewer provides specific references to external works, such as A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou, which support the claim by citing relevant literature. This provides a robust foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by further explaining why the bounded noise assumption is restrictive or how these extensions have impacted the literature. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the bounded noise assumption, which is common in stochastic optimization literature. It suggests that this assumption is somewhat restrictive and points out that there have been efforts to extend these noise conditions. The comment provides specific references to relevant literature, which could be beneficial for the authors to explore and potentially incorporate into their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or integrated the references into the paper. Overall, the comment provides some actionable feedback but could be more comprehensive, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to improve their writing quality, but without concrete steps or examples, they may struggle to know where to focus their efforts. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in detailing what exactly is unclear or needs improvement in the writing. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address them effectively. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies significant writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights these problems, it does not provide specific examples or guidance on how to address them. The comment lacks actionable advice or suggestions for improvement, leaving the authors without a clear path to enhance the clarity and quality of their writing. As a result, the feedback is not helpful, as it does not offer constructive guidance for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the potential of exploring energy models for image generation and suggests that it is less explored compared to GANs and VAEs. However, it also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. While the comment implies that the authors should consider this similarity and potentially address it in their work, it does not provide explicit guidance on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should address the similarity to the prior work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it acknowledges that the motivation and goals of the model are similar to a prior VAE paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the comparison to the prior work. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the comparison and potentially conduct additional research to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the potential of exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This feedback is somewhat helpful as it highlights an area of potential interest and a similarity to prior work, providing the authors with a direction for further exploration or clarification. However, the comment could be more helpful if it offered specific suggestions on how to address the similarity or how to differentiate the model from prior work. Overall, the comment provides some insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should conduct experiments to explore these aspects, but it lacks concrete guidance on what specific experiments to conduct or how to analyze the results. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the need for experiments on data acquisition and performance changes. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that obtaining labeled data is necessary for imitation learning and suggests that experiments should be conducted to explore difficulties in data acquisition and performance changes with data size. However, the comment lacks specific examples or references to support the claim that obtaining labeled data is necessary or that difficulties in data acquisition are significant. Without such evidence or detailed reasoning, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. It highlights the importance of conducting experiments to explore these aspects, which could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks specific suggestions on how to conduct these experiments or what specific aspects to focus on. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the use of the terminology \"certificate\" in the paper, as it has a strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider the use of the term \"certificate\" and possibly make a change. Without concrete instructions or examples, the authors may find it challenging to implement the suggested action effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the terminology \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of the terminology \"certificate\" in some contexts could be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of terminology in the paper, specifically the term \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This is a valuable observation that could help the authors avoid confusion or misunderstanding in their work. However, the comment lacks specific guidance on how to address this issue, such as suggesting alternative terminology or explaining the context in which the term is used. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment implies that additional experiments are necessary, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions on how to implement the suggested experiments. The action is implicit and somewhat vague, as the authors need to infer the specific details of how to proceed with the additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. The references provided are relevant but do not directly address the comment. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. The comment provides references to relevant works, which supports the claim that these experiments could enhance the paper. However, the comment lacks detailed reasoning or specific examples of how these additional experiments would benefit the paper. While the references provide some context, the claim could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides some support but lacks full clarity and depth.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions or suggestions for the authors. Therefore, the comment is somewhat helpful as it points out a potential area for improvement but does not provide actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer implies that this makes the motivation for Algorithm 1 unclear. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. It lacks actionable details, such as suggesting how to clarify the motivation or how to incorporate this insight into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem can be reformulated using the conjugate function, making the motivation unclear. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is somewhat verifiable as it provides a logical reasoning based on the conjugate function, which is a common mathematical concept. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation could lead to a significant improvement in the clarity and coherence of the paper. However, the comment lacks specific guidance on how the authors might address this issue or what changes they should make to improve the motivation. While it points out a potential problem, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the paper. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the intuitive benefit of using multiple local prompts but notes that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the differences in features and positions across categories, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the intuitive benefit of using multiple local prompts but notes that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it affects the paper\\'s conclusions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the intuitive benefit of using multiple local prompts but points out that the features and their positions differ across categories. This observation highlights a potential limitation in the study, which could impact the generalizability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path for improvement. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide enough detail for the authors to effectively address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCT-pair) and what about the ablation studies of MCT without the adaptive metrics. While these questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to clarify the discrepancy in the results and potentially include ablation studies, but the comment lacks specific details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCT-pair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the alignment of results and asking about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that are relevant to the paper\\'s content and methodology. First, it questions the alignment of results between Table 6 and Table 1 (MCT-pair), which could indicate a discrepancy or inconsistency in the data. Second, it asks about the ablation studies of MCT without the adaptive metrics, suggesting that this could provide valuable insights into the model\\'s performance. While the comment identifies areas for clarification and potential enhancement, it does not offer specific guidance or suggestions on how to address these issues. The authors are left with a general sense of what needs to be improved but without detailed instructions on how to do so. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works that have already explored these topics, such as RobustBench and [A, B]. The comment suggests that the authors should consider these existing works and potentially expand their analysis to include other models or datasets. However, it does not provide explicit instructions on how to incorporate these references or what specific aspects of the prior work should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific analyses and prior works, such as RobustBench and [A, B], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses have been conducted in prior works, which may not be surprising due to the limited scale of the current work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works, such as RobustBench and [A, B], which have explored these topics. The comment also mentions that the results are not particularly surprising, as they align with prior work. This provides a logical reasoning and references to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and surprise of the current work, noting that similar analyses have been conducted in prior works. It specifically references existing studies, such as RobustBench and [A, B], which have explored the robustness of CIFAR-10 models on distribution shifts. The comment suggests that the current work may not provide new insights or surprising results due to the overlap with prior work. While it highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing studies. The feedback is somewhat helpful as it points out a potential limitation, but it could be more beneficial with additional guidance on how to enhance the novelty or impact of the work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the 10 sub-tasks are simplistic for bAbi and that more discussions are required. However, it does not provide any specific guidance on what kind of discussions are needed or how the authors should address this issue. The comment lacks actionable details, such as recommending additional analyses or discussions that could be included to enhance the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the 10 sub-tasks are simplistic for bAbi and that more discussions are required. However, it does not specify which part of the paper these sub-tasks are discussed in or where the discussions are lacking. Without explicit references to sections or specific sub-tasks, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what kind of discussions are needed or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the 10 sub-tasks are simplistic for bAbi and suggests that more discussions are required. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of how the sub-tasks are simplistic or how they could be improved with additional discussions. Without such support, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the 10 sub-tasks being considered simplistic for bAbi, suggesting that they could solve all the sub-tasks with their final model. However, it lacks specificity and does not provide actionable guidance on how the authors could address this issue or what kind of discussions are needed. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it points out a potential weakness but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper and suggests that related work might be relevant but not necessarily detrimental to the novelty of the paper. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sequence of episodes\" and suggesting that related work might be relevant but not detrimental to the novelty of the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about the definition of \"sequence of episodes\" and the relevance of related work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper, which is a relevant point for clarity. It also suggests that related work might be relevant but not detrimental to the novelty of the paper. While the comment identifies a potential area for improvement by suggesting the inclusion of related work, it lacks specific guidance or suggestions on how to address this issue or incorporate related work. The feedback is somewhat helpful as it points out a potential gap in the paper, but it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes should be made to the study. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the study\\'s classification but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. While the comment identifies a potential issue with the study\\'s designation, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or reframe their study. The feedback is somewhat helpful as it points out a potential misclassification, but it does not offer actionable advice or detailed critique to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm (TN) architecture to similar competitors like AutoDial and AdaBN. This feedback provides a clear and explicit action for the authors to take, which is to extend the evaluation to include these additional competitors. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation\" and the \"comparing several base DA methods with and without the proposed TransferNorm architecture.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN, which are direct competitors to the TransferNorm architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN, which are direct competitors to the TransferNorm architecture. However, the comment does not provide specific reasoning or evidence to support why these additional comparisons would enhance the evaluation. While it highlights a potential area for improvement, the lack of detailed justification or examples makes the claim somewhat verifiable. The authors would need to infer the importance of including these comparisons themselves, which may not be immediately clear. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the evaluation section by suggesting that the base DA methods should be evaluated with and without the proposed TransferNorm (TN) architecture, as well as with other architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation by including additional comparisons that could strengthen their analysis. By addressing this suggestion, the authors can improve the comprehensiveness and rigor of their evaluation, which is valuable for the paper\\'s overall quality. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify how the attention module is attached to the backbone ResNet-20 architecture, including the number of attention modules used, their placement (after each block or stage), and how they are integrated into the overall architecture. This feedback provides clear and specific guidance on what the authors need to address to improve the clarity of their draft. The action is concrete, as it details the exact information that needs to be clarified, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attention module attached to the backbone ResNet-20 architecture\" and the need to clarify how many attention modules are used, where they are placed, and after which stages. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules, their placement, and how they are integrated into the architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how the attention module is attached to the backbone ResNet-20 architecture, specifically asking about the number of attention modules, their placement, and how they are integrated into the overall architecture. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the integration of the attention module with the backbone ResNet-20 architecture. It asks for clarification on the number of attention modules used, their placement, and how they are integrated into the overall architecture. This feedback is clear and actionable, as it provides the authors with specific questions to address in order to improve the clarity of their draft. By addressing these points, the authors can enhance the understandability and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information in the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the proof or relocate Theorem 8 to a more accessible location, but it lacks specific instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the proof more accessible. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the linear convergence rates relying on Theorem 8, which is buried in the appendix and whose proof is unclear. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This claim is somewhat verifiable as it provides a specific reference to Theorem 8 and the appendix, allowing the authors to understand the issue. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the proof is unclear or how it affects the paper\\'s conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This is a clear and actionable point that the authors can address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the proof or relocate Theorem 8 to a more prominent location in the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis on BRP-NAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This feedback implies that the authors should expand their analysis to include more comparisons and consider additional NAS approaches. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on which NAS approaches to include or how to conduct the analysis. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis on BRP-NAS, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis on BRP-NAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. However, the comment does not provide specific examples or references to these other NAS approaches, nor does it explain why these comparisons are necessary or how they would enhance the analysis. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the analysis section of the paper, specifically noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This feedback highlights an area where the authors could expand their analysis to provide a more comprehensive understanding of the BRP-NAS. However, the comment does not offer specific suggestions on how to address this issue or which NAS approaches to consider. While it points out a potential weakness, it lacks actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this question. The authors can infer that they need to consider the applicability of their method to natural images, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its question about the applicability of the method to natural images, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, the comment lacks any supporting evidence, reasoning, or references to justify why this limitation is a concern or how it affects the method\\'s applicability. Without such information, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. This is an important consideration for the broader applicability of the method in real-world scenarios. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or expand the method\\'s applicability. While it identifies a potential limitation, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that if FFNs are omitted due to a linear decomposition issue, the authors should consider whether there is existing work that offers a way around this limitation. If not, the comment recommends adding a line or two acknowledging the lack of a solution and describing it as an open (hard) problem. This feedback provides a clear and explicit action for the authors to take, ensuring they know exactly what steps to consider to improve their draft. The suggestion is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of FFNs being omitted due to a linear decomposition problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering existing work for a way around the issue and proposes adding a line or two to acknowledge the problem as an open (hard) problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that FFNs are omitted due to a linear decomposition issue and questions whether there is existing work that offers a way around this limitation. The comment suggests that if not, a line or two should be added acknowledging the problem as an open (hard) problem. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. The authors might need to conduct additional research to verify the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the omission of FFNs due to a linear decomposition problem. It suggests that the authors should consider whether there is existing work that offers a way around this limitation or if it is an open (hard) problem. The comment provides a clear and actionable suggestion for improving the paper by acknowledging the issue and offering a potential solution. This feedback is valuable as it guides the authors in enhancing the clarity and completeness of their work. However, it could be more helpful if it included specific references or examples of existing work that addresses this issue. Overall, the comment is mostly helpful as it provides a constructive direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the use of perplexity as a measure of semantic information retention after fine-tuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to control domain drift. The comment lacks actionable details, such as recommending specific methods or experiments to explore, making it difficult for the authors to know how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of perplexity as a measure of semantic information retention after fine-tuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the use of perplexity and the need to control domain drift, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of perplexity as a measure of semantic information retention after fine-tuning, noting that there are also factors such as domain drift that need to be controlled. However, the comment does not provide specific examples or references to support the claim that perplexity is an inappropriate measure or that domain drift is a significant issue. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of perplexity as a measure of semantic information retention after fine-tuning, noting that there are also factors such as domain drift that need to be controlled. This is an important point that could impact the validity and reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or control domain drift. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work only uses binary features and questions whether the method is applicable to real and categorical features. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to consider real and categorical features. The comment lacks concrete details on how to incorporate these features or what specific modifications are needed. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of binary features in the work and questions whether the method is applicable to real and categorical features. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of binary features and suggesting that the method may not be applicable to real and categorical features. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work only uses binary features, which is a factual observation. However, it questions whether the method is applicable to real and categorical features, suggesting that this limitation needs to be addressed. The comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors may need to infer the importance of considering real and categorical features, but the lack of detailed evidence or reasoning makes the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the work, noting that it only uses binary features while real-world data typically includes a mix of binary, real, and categorical features. This is a relevant observation that could impact the applicability and generalizability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate real and categorical features into their analysis. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not provide any guidance on how the authors should address this issue or what specific changes could be made to enhance the novelty of their work. The comment lacks explicit or implicit actions, leaving the authors without direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"algorithm for construction of coresets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, stating that the algorithm is not novel because it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the algorithm for constructing coresets is not novel because it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the novelty of the paper, noting that the algorithm for constructing coresets is not novel as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This feedback is clear and actionable, as it points out a weakness in the paper\\'s originality and suggests that the authors should consider how to enhance the novelty of their work. However, the comment could be more helpful if it provided suggestions on how to differentiate the algorithm or how to address this issue in the context of the paper. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this methodology is discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. This feedback prompts the authors to reconsider their experimental setup and potentially explore alternative methods for data selection. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what potential improvements could be made. While it identifies a relevant area for consideration, the feedback could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should generate instances with more constraints and variables, as the paper currently has few instances with more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a clear and explicit action. The comment also raises a concern about LLMs' ability to model problems with large instance sizes, providing a specific direction for improvement. However, it does not offer detailed guidance on how to implement this suggestion or what specific constraints and variables should be included. While the action is clear, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a specific suggestion for improvement. However, the comment does not explicitly mention which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for more variables and constraints, but without clear grounding, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks instances with more constraints and variables, as few instances have more than 7 variables. This claim is based on the observation that the paper currently has few instances with large instance sizes, which raises concerns about LLMs\\' ability to model such problems. However, the comment does not provide specific examples or references to support the claim that larger instances are necessary or how they would impact the model\\'s performance. The reasoning is somewhat verifiable, as it highlights a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that few instances have more than 7 variables, which raises concerns about LLMs\\' ability to model problems with large instance sizes. This feedback is valuable as it highlights an area where the paper could be strengthened by expanding the dataset to include more instances with larger variable counts. However, the comment could be more helpful if it provided specific suggestions on how to generate these instances or what constraints and variables should be considered. While it points out a relevant issue, the lack of detailed guidance limits its utility for the authors. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It seeks clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment implies that the authors should provide more information or clarification on this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implications of this statement, including whether the base node affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what aspects need clarification or further exploration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the implications of a statement regarding \"NodeSort differentially sorting nodes depending on the base node.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node,\" seeking clarification on whether the base node affects the ordering, key nodes for attention, and model performance. This is a relevant question that could help the authors better understand the potential impact of their method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. This question implies that the authors should clarify or correct the arrow direction to better align with the intended purpose of the figure. While the comment does not explicitly instruct the authors to make a change, it provides a clear direction for improvement by pointing out a potential inconsistency in the figure. The action is implicit but concrete, as the authors can infer the need to adjust the arrow direction to better align with the intended purpose. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the direction of the arrow in the figure, which is a clear indication of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer expresses confusion about the purpose of the figure, which is to influence n^(i). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim or clarify the confusion. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the direction of the arrow in Figure 2, specifically questioning why it goes from a Gaussian space into the latent space rather than the other way around. This feedback highlights a potential inconsistency in the figure, which could be confusing for readers. By pointing out this issue, the comment prompts the authors to clarify or correct the figure to better align with the intended purpose. However, the comment does not provide specific suggestions or guidance on how to address this issue, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a potential problem but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. It provides a clear and specific action for the authors to take, which is to define these abbreviations in the text or provide a glossary. This guidance is direct and concrete, leaving no ambiguity about what needs to be done to improve the clarity of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviation \"AR\" in Table 5, noting that it stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definitions and cause confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This claim is somewhat verifiable as it highlights a specific issue with the paper\\'s clarity, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to infer the significance of this issue and how it affects the overall understanding of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that many abbreviations lack definitions and cause confusion. It provides a clear example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is actionable as it directs the authors to clarify these abbreviations to improve the clarity and accessibility of their work. However, the comment could be more helpful if it suggested ways to standardize the use of abbreviations throughout the paper or provided examples of how to define them. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an issue with the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This implies that the comparison is unfair and suggests that the authors should address this issue to ensure fairness in their evaluation. However, the comment does not provide explicit guidance on how to rectify this issue or what specific changes should be made to the evaluation process. While the action is implied, it is not detailed enough for the authors to know exactly how to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the performance comparison, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights while most baselines use a uniform weight of 1. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness, but it lacks specific examples or references to support the assertion that this difference significantly impacts the comparison. The authors would need to further investigate and analyze the impact of these sample weights to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This is a relevant observation that could impact the fairness and validity of the comparison. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending a standardized weighting scheme or explaining the potential impact of this difference. While it points out a relevant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the time complexity of the system if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the time complexity or suggestions for adjusting the buffer size. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"reply buffer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of high time complexity if the buffer is too large, providing clear guidance on what needs to be addressed. However, the comment could be more specific by suggesting ways to mitigate the time complexity or providing examples of how other similar systems have handled this issue. Therefore, the comment is fully grounded and under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the system if the reply buffer is too large. This is a relevant concern that could impact the performance and scalability of the system. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue. It does not offer actionable advice or examples of how to mitigate the time complexity, leaving the authors without a clear path forward. Therefore, the comment is somewhat helpful as it points out a potential problem but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that a brief conclusion and a summary of the article\\'s contributions are needed. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact content that needs to be included in the conclusion and summary. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need for a brief conclusion and a summary of the article\\'s contributions, providing full grounding as it clearly identifies the parts of the paper being addressed. It is specific because it clearly specifies what needs to be included in the conclusion and summary, such as a brief overview of the paper\\'s contributions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a brief conclusion and a summary of the article\\'s contributions are needed. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of a brief conclusion and a summary of the article\\'s contributions. This feedback is clear and actionable, as it directly guides the authors on how to enhance the final section of their paper. By providing a concrete suggestion for improving the paper\\'s conclusion, the comment offers valuable insight that can help the authors improve the clarity and impact of their work. However, the comment could be more helpful if it included specific examples or suggestions on what elements should be included in the conclusion and summary. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. This feedback implies that the authors should include this comparison in their paper to enhance the results\\' meaningfulness. While the action is implicit, it is clear that the authors need to make this addition to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what specific aspects of the framework should be compared. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment highlights an area for improvement, it lacks specificity and grounding, making it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such a comparison would be beneficial. The absence of detailed reasoning or evidence makes it difficult for the authors to fully understand the basis of the suggestion. Therefore, the comment is somewhat verifiable, as it provides a logical suggestion but lacks the necessary evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for improving the paper by recommending a comparison with a method designed to defend against multiple attacks. This feedback is actionable as it points out a specific area where the authors could enhance their study, which could lead to more meaningful results. However, the comment could be more helpful if it provided examples of such methods or detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it identifies a clear area for improvement and offers a direction for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the plan-based method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with pre-defined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to improve the generalizability of their method. The authors are left to infer that they need to consider this issue and find ways to improve their method, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not provide explicit instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the plan-based method, specifically mentioning the requirement for manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also compares the learned plan methods to those with pre-defined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. However, the comment does not specify which part of the paper discusses the plan-based method or where the comparison to Table 2 is made. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue with the plan-based method and the comparison to pre-defined plans, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plan-based method is unrealistic in real-world scenarios due to the requirement for manually designing a plan based on the ground truth in advance. It also compares the learned plan methods to those with pre-defined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the plan-based method is unrealistic or that the learned plan methods are not comparable to those with pre-defined plans. This makes the claim somewhat verifiable, as it provides some logical reasoning but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the plan-based method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also highlights a limitation in the learned plan methods compared to those with pre-defined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. This feedback is somewhat helpful as it points out a critical issue that the authors need to address to improve the real-world applicability of their method. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how other methods have successfully overcome similar challenges. Overall, the comment offers valuable insights but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce what the section is about, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests adding a first sentence to introduce what Section 3.2 is about. However, it does not provide any reasoning, evidence, or examples to support why this addition is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their paper. By providing a specific and direct recommendation, the comment offers a straightforward way for the authors to enhance the organization and flow of their content. However, the comment could be more helpful if it explained why this introduction is important or how it would benefit the reader. Overall, the comment is mostly helpful as it provides a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide explicit guidance on what the authors should do to address this issue or how to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of the term, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this statement is problematic or unclear. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback highlights a potential inconsistency or confusion in the paper, which could be clarified to improve the clarity and coherence of the text. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes might be necessary to clarify the statement. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. The reviewer provides a clear and specific suggestion for how to rephrase the statement to improve clarity. This feedback is explicit and concrete, as it directly instructs the authors on how to revise their draft to better convey the concept of uncertainty. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper where the uncertainty is defined, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion for clarifying the definition of uncertainty by suggesting that the epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. This provides a clear and actionable step for the authors to take to improve the clarity of their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. The reviewer provides a logical explanation of how this process works, which is based on common knowledge in the field. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further develop the explanation to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This feedback is clear and constructive, as it offers a precise way to enhance the explanation of the concept of uncertainty. By following this suggestion, the authors can significantly improve the clarity and accessibility of their draft, making it more understandable to readers. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors experimented with using domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for clarification on the number of questions created for the zero-shot intent classifier and its accuracy. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the usage of domain ontologies to avoid placeholder generation and asks for clarification on the number of questions created for the zero-shot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the usage of domain ontologies to avoid placeholder generation in the evaluated responses and seeks clarification on the number of questions created for the zero-shot intent classifier and its accuracy. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these questions are important or how they relate to the paper\\'s content. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the usage of domain ontologies to avoid placeholder generation in the evaluated responses, which is a relevant and potentially valuable aspect to explore. It also seeks clarification on the number of questions created for the zero-shot intent classifier and its accuracy, which could provide valuable insights into the performance of the system. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for potential enhancement, it does not provide actionable feedback or detailed advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare their work with a chain-of-thought prompting approach, which is a specific and concrete suggestion for improvement. This feedback provides clear guidance on what the authors need to do to enhance their comparisons and make their work more robust. The explicit nature of the suggestion and the concrete example of a potential baseline make the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of meaningful baselines and the suggestion to compare with a chain-of-thought prompting approach. This provides clear guidance on what the authors need to improve in their comparisons. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors should compare their work with a chain-of-thought prompting approach. While the comment identifies a potential issue with the baselines, it does not provide specific examples or detailed reasoning to support the claim that the current baselines are insufficient. The suggestion to compare with a chain-of-thought prompting approach is a logical suggestion, but the comment lacks the necessary evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the lack of meaningful baselines limits the comparisons made in the paper. It suggests that the authors should consider using a chain-of-thought prompting approach as a more meaningful baseline. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the robustness and credibility of the paper. By addressing this point, the authors can significantly improve the quality of their comparisons and demonstrate the effectiveness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important experimental details in the main text and the lack of explanations or interpretations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8 as examples of missing information. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text and Appendix, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the missing information, such as the lack of explanations or interpretations for the PCA experiments in these figures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. The reviewer provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This provides a clear and specific basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that highlight the importance of including such explanations. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it highlights specific areas where the authors need to improve the clarity and completeness of their experimental details. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending a specific structure or approach for presenting the experimental details in the main text. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, it does not provide explicit guidance on how to resolve this issue or suggest alternative notations. The action is implicit and vague, as the authors are left to infer that they need to clarify or change the notation to avoid confusion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L166\" and \"L176,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"K,\" which is being used for both a known kernel function and the number of layers, causing confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"K,\" noting that it is being used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176), which can cause confusion. This feedback is clear and actionable, as it points out a potential source of confusion in the paper and suggests a way to clarify the notation. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a different notation or explaining the context in which \"K\" is used. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the connection to human cognition, questioning the relevance of the authors\\' suggestion that cognitively basic adaptation mechanisms might have a significant impact on self-organization. It suggests that the authors should provide more evidence or references to support their claim. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on how to present this evidence or what kind of references would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should provide more evidence or references to support their claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the connection to human cognition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the connection to human cognition and suggests that the authors should provide more evidence or references to support their claim. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of the connection to human cognition, suggesting that the problem is reductionist and does not involve mechanisms like bargaining and negotiation that humans use. The reviewer argues that it would be surprising for a behavioral economist to ignore these factors and suggests that more evidence or references are needed to support the claim. However, the comment lacks specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to further develop the reasoning or provide additional evidence to fully support the claim, which would elevate the comment to a higher verifiability level. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the relevance of the connection to human cognition, questioning whether it makes sense to bring such connections into the discussion. It points out that the problem is reductionist and does not involve mechanisms like bargaining and negotiation that humans use, which could affect the authors\\' claims about the impact of cognitively basic adaptation mechanisms on self-organization. The comment suggests that the authors need to provide more evidence or references to support their claim, which is a constructive suggestion that could help the authors strengthen their argument. However, the comment could be more helpful if it provided specific examples or references to support the claim or offered suggestions on how to address the issue. Overall, the comment is somewhat helpful as it identifies a potential weakness and provides a direction for improvement, but it lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, it does not provide specific guidance on how to tone down the language or suggest alternative phrasing. The comment lacks explicit instructions or concrete examples of what constitutes overly exaggerated or flamboyant language, making it difficult for the authors to know exactly how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, describing it as overly exaggerated and flamboyant. This provides clear guidance on what needs to be addressed in the conclusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or references to overly exaggerated or flamboyant language, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant in multiple places. This feedback is somewhat helpful as it points out a potential problem with the language used in the paper, which could be revised to be more appropriate and professional. However, the comment lacks specific examples or suggestions on how to tone down the language or what alternative phrasing might be more appropriate. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to compare against or detailing the expected utility measure. The comment lacks concrete steps for the authors to take, leaving them uncertain about how to improve their draft. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for comparison to baselines. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility or some other measure, which is a significant weakness. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific examples or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure to prove the effectiveness of the proposed approach. This is a critical oversight that could impact the credibility and impact of the paper. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting which baselines to compare against or how to implement the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the introduction of multi-granularity and multi-scale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the introduction of multi-granularity and multi-scale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what is considered a common approach and what is lacking in the paper, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks, and that merely migrating this approach to the field of MLMs is not innovative. The reviewer supports this claim by referencing the article itself, which implies that the authors should have known this. However, the comment lacks specific examples or references to support the claim that merely migrating this approach is not innovative. This makes the claim somewhat verifiable, as it provides some evidence but could be strengthened with more detailed examples or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the introduction of multi-granularity and multi-scale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. While the comment identifies a potential weakness in the paper\\'s contribution, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is somewhat helpful as it highlights a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to address the concerns raised. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarity-aware positive sample selection or the transfer performance of the model. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the concerns about the model's generalization and suggesting additional experiments, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment is somewhat verifiable as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments to validate the claim, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment also highlights the need for additional experiments across different downstream tasks and domains to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these additional experiments or what specific downstream tasks should be considered. This limits the comment\\'s helpfulness, as it provides insight but does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that there should be more discussion on the power of different architectures. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and vague, as the authors are left to infer that they need to provide more discussion on the power of different architectures. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that there should be more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the architectures should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the expressiveness of fast SMP compared to SMP. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that there should be more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the discussion should be expanded. The comment is somewhat helpful as it points out a potential gap in the paper, but it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of train-val-test, rather than simply different initialisation seeds. This feedback provides a clear and explicit action for the authors to take, which is to consider using different splits of the training, validation, and testing datasets to test the robustness of their methods. The comment is specific in detailing what needs to be done to improve the robustness of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of train-val-test, rather than simply different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the evaluation or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that evaluating methods across different splits of train-val-test would be more robust than simply using different initialisation seeds. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be more robust. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of train-val-test, rather than simply different initialisation seeds. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the robustness of their results. By suggesting a more comprehensive evaluation approach, the comment offers a concrete way to enhance the quality and reliability of the paper. However, it could be more helpful if it provided additional guidance on how to implement this change or what specific metrics or analyses should be considered. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a clear path for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the clarity of the symbols or the explanation of the process. The authors are left to infer that they need to clarify the symbols and provide more information on the process, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process. This provides clear guidance on what needs to be addressed in the figure and the process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support the claim of ambiguity or the need for clarification. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process. This feedback is somewhat helpful as it points out a potential area for improvement in the clarity and comprehensibility of the figure. However, it lacks depth and does not provide specific suggestions or guidance on how to address the ambiguity or improve the explanation of the symbols. While it highlights an issue, the comment could be more helpful with additional details or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the paper regarding the assumption that the spectrum of a kernel is sub-gaussian. It acknowledges that this assumption is reasonable for Gaussian kernels but points out that it may be restrictive for other popular classes of kernels, such as Matern kernels. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or expand their results to include other kernel classes. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of this limitation and potentially explore other kernel classes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the assumption of the spectrum of a kernel being sub-gaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results could be restrictive due to the exclusion of popular classes of kernels, such as Matern kernels. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assumption of the spectrum of a kernel being sub-gaussian is a limitation, as it excludes popular classes of kernels like Matern kernels. The comment provides a logical reasoning by pointing out that the results could be restrictive due to this assumption. However, it lacks specific examples or references to Matern kernels or other classes of kernels to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the assumption that the spectrum of a kernel is sub-gaussian, which could restrict the applicability of the results. It acknowledges that this assumption is reasonable for Gaussian kernels but points out that it excludes popular classes of kernels like Matern kernels, whose spectrum only decays polynomially. This feedback is valuable as it highlights a potential limitation in the scope of the results and suggests that the authors should consider expanding their analysis to include other kernel classes. However, the comment could be more helpful if it provided specific suggestions on how to address this limitation or how to incorporate other kernel classes into the analysis. Overall, the comment is mostly helpful as it directs the authors to consider a broader range of kernel classes, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain. While the comment explicitly states the action to take, it lacks concrete details on how to implement this suggestion. It does not provide specific guidance on what aspects of the pretraining method should be discussed or how to integrate it into the main paper. The authors are left with a general idea of what to do but without detailed instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"unsupervised pretraining,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detailed discussion on the unsupervised pretraining method in the main paper. The comment suggests focusing more on the pretraining method in the main paper, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unsupervised pretraining is a key factor in performance gain, based on data from Table 4. However, it does not provide specific evidence or detailed reasoning to support this claim, such as specific data points or comparisons with other methods. The suggestion to focus more on the pretraining method is logical, but without detailed justification or examples, the claim remains somewhat verifiable. The authors would need to further explore the data and make a case for the importance of the unsupervised pretraining themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the unsupervised pretraining is a key factor in performance gain but is not discussed in detail in the main paper. It suggests that the authors should focus more on the pretraining method in the main paper. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it included specific examples or insights into why the unsupervised pretraining is so important or how it could be integrated more effectively into the main paper. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is implicit, it is clear that the authors need to expand their testing to include more datasets. The comment provides a specific suggestion for improvement, which is to test on additional datasets. However, it does not offer detailed guidance on which datasets to use or how to conduct the additional testing. Therefore, the action is somewhat actionable, as it provides a clear direction but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the testing and evaluation of the method, but this inference is not direct. The comment is specific in suggesting the need for additional testing, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any supporting evidence, reasoning, or references to justify why testing on more datasets would be beneficial or necessary. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. This is a clear and actionable suggestion that could significantly improve the robustness and generalizability of the method. However, the comment lacks depth and does not provide specific guidance on which datasets to use or how to conduct the additional testing. While it identifies a potential area for improvement, it could be more helpful with additional details. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. While the comment identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the domain of the inputs, but it is vague because it lacks specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the inputs are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed regarding the domain of the inputs. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\\'s validity. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the domain of the inputs. While it points out a potential weakness, it does not provide actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and the independence of x and y given W. The reviewer suggests that taking Z\u00e2\u0080\u0099 to be the empty set would lead to a contradiction with Eq. (7), which states otherwise. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to resolve the conflict. While the action is implied, it is not detailed enough for the authors to know exactly how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, particularly regarding the definition of Z\\u0027 and the independence of x and y given W. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\\u0027 and the independence of x and y given W. The reviewer provides a logical explanation by taking Z\\u0027 to be the empty set, which would lead to a contradiction with Eq. (7). However, the comment lacks specific references or examples to support the claim, making it somewhat verifiable. The authors would need to further explore the issue to fully understand and address the conflict. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\\u0027 and the independence of x and y given W. By taking Z\\u0027 to be the empty set, the reviewer demonstrates a logical contradiction that could be addressed. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this issue or improve the clarity of the paper. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify their explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the problem of gradient bias in Batch Normalization and the potential of Online Normalization. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the difference between Online Normalization and Batch Normalization, asking why Online Normalization is unbiased while Batch Normalization is biased. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that Online Normalization is unbiased and Batch Normalization is biased, suggesting that the authors have not adequately explained this difference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. This is a relevant point that could help the authors clarify their explanation or provide additional context to readers. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the concept of local interactions, asking whether it refers to interactions within a time window or within the same modality. While the comment identifies an area of confusion, it does not provide explicit guidance on how the authors should clarify this concept in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer definition or explanation of the concept. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its questioning of the concept, as it seeks clarification on the definition of local interactions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the confusion. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is somewhat helpful as it identifies a potential area of confusion that the authors may need to address to improve the clarity of their work. However, the comment lacks specific suggestions or guidance on how to clarify this concept, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims better results in the Molecule generation experiment but notes that adding the proposed constrained method actually yields lower validity and diversity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment, as stated in Table.3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claims regarding the Molecule generation experiment, specifically noting that the addition of the proposed constrained method actually yields lower validity and diversity. This is a critical observation that could impact the paper\\'s conclusions and credibility. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their results. While it points out a potential problem, it does not provide actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so or provide specific guidance on what details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about the environment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this information should be included in, nor does it provide detailed guidance on what aspects of the environment should be described. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not provide any reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without such justification, the claim is unverifiable, as it lacks the necessary evidence or explanation to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing additional context or background information. However, the comment lacks depth and does not offer specific suggestions on what aspects of the environment should be described or how this information could enhance the paper. While it points out a potential area for improvement, it does not provide actionable guidance or detailed advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of domain adaptation methods that are not novel. It suggests that the authors should consider using more recent domain adaptation methods to improve performance. While the comment implies that the authors should explore other methods, it does not provide specific guidance on which methods to use or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore other domain adaptation methods to enhance their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of domain adaptation methods that are not novel. It suggests that the authors should consider using more recent domain adaptation methods to improve performance. However, the comment does not specify which parts of the paper these critiques pertain to, such as sections or specific techniques. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the use of existing methods, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors combine two existing techniques without innovation, specifically mentioning the use of domain adaptation methods that are not novel. The reviewer supports this claim by pointing out that the domain adaptation method used by the authors is old and simple, suggesting that there are more effective methods available in recent years. However, the comment lacks specific examples or references to these more recent methods, which would strengthen the verifiability. The reasoning is logical and based on common knowledge, but the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of domain adaptation methods that are not novel. It suggests that the authors should consider using more recent domain adaptation methods to improve performance. While the comment identifies a potential weakness in the paper\\'s innovation, it lacks specific suggestions or guidance on which domain adaptation methods to consider or how to implement them. The feedback is somewhat helpful as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments are limited to one game environment and suggests that more experiments are necessary. This provides a clear and direct action for the authors to take, which is to expand their experimental scope to include additional game environments. The comment is specific in its request for additional experiments, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to conduct more experiments, but without clear references to specific sections or experiments, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are conducted on only one game environment. It suggests that more experiments are necessary to provide a broader perspective. While this feedback highlights an area for improvement, it lacks specific guidance on which additional environments should be considered or how to conduct these experiments. The comment is somewhat helpful as it points out a potential weakness but does not offer detailed suggestions for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the authors\\' claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific information about the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet-18, as well as the accuracy, which is around 70%. This explicit comparison and concrete data provide the authors with a clear action to take: they need to address the issue of slow speed and low accuracy by improving their implementation. The comment is explicit and provides concrete details on how to apply the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the implementation of ImageNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of slow speed and low accuracy, providing specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet-18, as well as the accuracy, which is around 70%. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' implementation of ImageNet is slow and has low accuracy, citing specific examples of time and accuracy. However, the comment does not provide any supporting evidence or references to substantiate these claims. Without additional context or detailed analysis, the authors may find it challenging to understand the basis of these claims and address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet-18, as well as the accuracy, which is around 70%. This feedback is clear and actionable, as it highlights a critical issue that the authors need to address to improve the credibility and effectiveness of their work. By addressing these points, the authors can enhance the robustness and reliability of their implementation. However, the comment could be more helpful if it offered suggestions on how to improve the speed and accuracy, such as potential optimizations or alternative approaches. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. It also requests theoretical justifications, if possible. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should report the classification accuracy and provide theoretical justifications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed classification network, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. Additionally, it requests theoretical justifications, if possible, which provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. The comment suggests that building a new model for detecting out-of-distribution samples could lead to loss of classification accuracy. However, the comment lacks specific evidence or references to support the claim that the proposed network's classification error is universally inferior to the standard softmax network. Without such evidence or detailed reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to address the concern without additional information. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the classification error of the proposed network and its potential impact on detecting out-of-distribution samples. It suggests reporting the classification accuracy on ImageNet data and requests theoretical justifications, if possible. This feedback is somewhat helpful as it prompts the authors to provide additional information that could strengthen their claims about the performance of the proposed network. However, the comment could be more helpful if it offered specific suggestions on how to address the concerns or provided examples of theoretical justifications that might be relevant. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. It points out that if not, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly re-run experiments with different initialization methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the initialization of the proposed method before the fine-tuning stage. The comment suggests that if the compared methods were not initialized with the same or similar pre-trained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. The reviewer supports this claim by referencing Table 1, which shows the inferior performance of the proposed method without SSL compared to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential issue in the experimental setup that could affect the results. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have addressed this issue. Overall, the claim is mostly verifiable, as it is supported by a reference to Table 1 and logical reasoning, but it could be further substantiated with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method before the fine-tuning stage. It suggests that if the compared methods were not initialized with the same or similar pre-trained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This feedback is somewhat helpful as it points out a potential weakness in the experimental setup that could affect the results. However, it lacks specific suggestions on how to address this issue or improve the experimental design. To be more helpful, the comment could provide guidance on how to ensure fairness in the comparison or suggest alternative initialization methods to test. Overall, the comment identifies a relevant concern but could be more actionable with additional details. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information that CD captures on top of Predictive Uncertainty. It also questions why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" (line 115). The reviewer does not provide specific guidance on how to implement these suggestions, leaving the authors to infer the actions needed. The feedback is explicit in identifying the need for clarification and alternate formulations, but it lacks concrete details on how to achieve these improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the additional information captured by Confidence Diversity (CD) and the appropriateness of entropy as a measure. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the additional information captured by Confidence Diversity (CD) and the appropriateness of entropy as a measure. It suggests that the paper should describe possible alternate formulations for CD. However, the comment lacks specific examples or references to support the claim that entropy is not a good measure or that CD captures additional information beyond Predictive Uncertainty. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claims themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by asking the authors to describe possible alternate formulations for Confidence Diversity (CD). It also questions the additional information captured by CD beyond Predictive Uncertainty and challenges the appropriateness of entropy as a measure. This feedback is valuable as it prompts the authors to clarify and potentially expand their work, which could enhance the understanding and impact of their findings. However, the comment could be more helpful if it provided specific examples or references to alternate formulations or entropy measures that might be considered. Overall, the comment is mostly helpful as it guides the authors toward a clearer and more comprehensive presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. The reviewer points out that this is a problem, especially considering the other factors mentioned in Section 4.1 that contribute to the human baseline's weakness. Additionally, the comment notes that the abstract statement about beating a human who learned Kalamang is misleading due to the limited duration of the human baseline. While the comment identifies a clear issue, it does not provide explicit guidance on how the authors should address this problem or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the duration of the human baseline and possibly revise the abstract statement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the human baseline, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. Additionally, the comment highlights the misleading statement in the abstract regarding the human baseline beating a human who learned Kalamang from the same resources. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the human baseline is considerably weaker than the model baseline due to the limited duration of the human recordings. The reviewer supports this claim by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, which is a significant difference compared to the model baseline. Additionally, the comment highlights that the abstract statement about beating a human who learned Kalamang is misleading due to the limited duration of the human baseline. This provides a logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar studies that demonstrate the impact of limited human data on performance. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. This is a critical observation that could impact the validity and applicability of the human baseline. The comment also points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited duration of the human baseline. This feedback is valuable as it highlights a potential weakness in the study that the authors should address to ensure the robustness and credibility of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the human baseline. Overall, the comment is somewhat helpful as it identifies a critical issue and offers a direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This implies that the authors should consider using these methods as a baseline in their work. However, the comment does not provide specific guidance on how to implement this suggestion or which methods to use. The action is implicit and somewhat vague, as the authors need to infer that they should consider using these methods as a baseline. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This provides clear guidance on what needs to be addressed in the paper, namely the inclusion of these methods as a baseline. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the related work section, noting that it discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s analysis, which could be addressed by including these methods as a baseline. However, the comment lacks specific suggestions on how to incorporate these methods or which ones to consider. While it highlights an area for improvement, it does not provide detailed guidance on how to address the issue, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. It also mentions that the authors might have missed this in the appendix. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the resilience of the metric to the choice of random projection. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the chosen random projection matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. The comment also mentions that the authors might have missed this in the appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the variability in results with the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but suggests investigating the resilience of the metric to the choice of random projection. The comment is somewhat verifiable as it provides a logical reasoning for the need to test the resilience of the metric, but it lacks specific examples or references to support the claim about pathological projection matrices. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results obtained using the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. It raises a valid point about the resilience of the metric to the choice of random projection and suggests that the authors might have missed this in the appendix. While the comment highlights an important area for investigation, it lacks specific guidance or suggestions on how to address this issue or what specific tests could be conducted. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed guidance on how to resolve it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. While the comment implies that the authors should expand the evaluation to include additional comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden the evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited use of FGT for evaluating the performance of the proposed method and comparative methods. This provides clear guidance on how to improve the evaluation section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of FGT is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the paper\\'s conclusions. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of FGT, noting that it is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for expanding the evaluation to include additional comparisons. By addressing this point, the authors can enhance the robustness and comprehensiveness of their evaluation, which is valuable for improving the draft. However, the comment could be more helpful if it provided specific examples of comparative methods or detailed guidance on how to conduct these additional evaluations. Overall, the comment is mostly helpful as it effectively directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the scope of the work or how to demonstrate its broader impact. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the work are considered narrow or how the authors might address this issue to enhance its broader impact. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and how it affects the paper\\'s impact. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. While this observation highlights a potential limitation, it does not provide specific guidance or suggestions on how the authors might address this issue or broaden the scope of their work. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward to enhance the impact and relevance of their research. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what changes they should make to their draft. The action is implicit and vague, as the authors are left to infer that they should consider whether the distinction is necessary or beneficial. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not specify which part of the paper discusses these distances or where the distinction is made. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its suggestion to consider whether the distinction is necessary, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is unnecessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. While it identifies a potential redundancy or lack of clarity in the paper, it does not provide any specific guidance or suggestions on how the authors might address this issue or why it might be important to distinguish between the two distances. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. While the comment implies that the authors should consider expanding their evaluation to include more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that understanding the criteria behind the selection and exploring other tasks or datasets might yield different insights. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. However, the comment does not provide specific examples or references to support the claim that the current evaluation is limited in scope. While it logically points out a potential issue, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. This feedback is somewhat helpful as it prompts the authors to consider the broader implications of their evaluation approach and how it might impact the generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional tasks or datasets might be relevant to include. Overall, the comment offers a valuable direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of detail in the experimental description, suggesting that increased clarity would be beneficial. It explicitly states that the current state of the manuscript makes it difficult for readers to judge the results. The reviewer provides a reference to \"Questions\" for further details, which implies that the authors should refer to this section for guidance on how to improve the clarity of their experimental description. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental details\" and the \"Questions\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the experimental description and the need for increased detail to better judge the results. This provides clear guidance on what the authors need to improve in their manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental description lacks detail, which makes it difficult for readers to judge the results. This claim is somewhat verifiable as it highlights a specific issue with the manuscript, but it does not provide detailed examples or references to support the claim. The mention of \"Questions\" suggests that further details are available elsewhere, but this does not fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, namely the lack of detail in the experimental description. It suggests that increased clarity in this area would significantly benefit the reader's ability to understand and judge the results. The reviewer provides a reference to \"Questions\" for further details, which is helpful as it points the authors in the right direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to enhance the clarity of the experimental description. Overall, the feedback is somewhat helpful as it highlights an important area for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the paper is not self-contained and suggests that the supplementary material is necessary to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment identifies a specific issue with the self-containment and provides a clear action for the authors to take, it does not offer detailed guidance on how to improve the self-containment or what specific aspects of the supplementary material should be included. The action is explicit but somewhat vague, as the authors need to determine which parts of the supplementary material are most critical for self-containment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"supplementary\" material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the self-containment issue and the request for the release of the source code for reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not self-contained and suggests that the supplementary material is necessary for understanding the main paper and enabling reproducibility. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or examples to substantiate the claim, making it somewhat verifiable. The authors may find it challenging to understand the exact issues without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the self-containment of the paper, noting that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. It also requests the authors to release the source code of their experiments to allow for reproduction of their results. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their paper that affects its accessibility and reproducibility. However, the comment could be more helpful if it provided specific suggestions on how to improve the self-containment or what aspects of the supplementary material should be prioritized. Overall, the comment is mostly helpful as it highlights a key area for improvement and offers a concrete request for additional materials.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. It implies that the authors should clarify the reasoning behind these choices, specifically mentioning the attention model paper that the algorithm iterates on. While the comment does not explicitly instruct the authors to provide this rationale, it clearly points out what needs to be added to improve the draft. The action is explicit and concrete, as it specifies the need for clarification and provides a clear direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"REINFORCE algorithm\" and \"PPO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the rationale behind certain choices, such as the use of REINFORCE versus PPO. The comment provides a clear direction for improvement by suggesting that the authors should clarify the reasoning behind these choices, which is important for understanding the methodology. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. The reviewer implies that this choice might be related to the attention model paper that the algorithm iterates on, but does not provide specific evidence or references to support this claim. While the suggestion is logical, it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the draft. It points out that the authors should provide a rationale for the choices made, specifically regarding the use of the REINFORCE algorithm versus PPO. By doing so, the authors can clarify the reasoning behind these choices, which is important for understanding the methodology and its basis. The comment is specific and constructive, offering a direct way for the authors to enhance the clarity and transparency of their work. Therefore, it is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of a discussion about Set Transformer and other related works that use summary tokens. This provides a clear and direct action for the authors to take, which is to include a discussion on these topics. The comment is specific in identifying the missing content and provides a concrete action for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Set Transformer\" and \"other related works that also use summary tokens,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the use of summary tokens and related works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there is a missing discussion about Set Transformer and other related works that use summary tokens. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of a discussion about Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to expand their literature review to include relevant works that could enhance their understanding and analysis. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the paper. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of details regarding how the network fits the residual instead of directly learning the input-output mapping. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information about the network's training process, but it lacks concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of detail regarding how the network fits the residual instead of directly learning the input-output mapping. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking details regarding the network's training process, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the lack of details regarding how the network fits the residual instead of directly learning the input-output mapping. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this is a significant issue or a problem that needs to be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of details on how the network fits the residual instead of directly learning the input-output mapping. This is a relevant point that could impact the understanding and effectiveness of the network. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details might be needed. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. While the comment implies that the authors should provide more details about these aspects, it does not explicitly instruct them to do so. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides some context but does not offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the experiment setup. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for details about the experiment setup, such as data augmentation methods and learning rate, and provides a reference to a related paper for context. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is helpful in providing context but does not offer actionable advice. Overall, the comment is somewhat helpful as it points out a potential area for improvement but lacks depth and specificity in its guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors conducted statistical significance tests for the numbers presented in the paper. While it implies that the authors should consider conducting such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is presented in, making it weakly grounded. The comment is specific in its request for statistical significance tests, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is relevant or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. This is a valuable point as it highlights a potential area for improvement in the paper, which could enhance the credibility and robustness of the results. However, the comment lacks specific guidance on how to conduct statistical significance tests or what aspects of the comparison should be analyzed. While it identifies a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the choice of significance testing method used in the paper, suggesting that a paired test setting like the Wilcoxon signed-ranked test might be more appropriate. While the comment implies that the authors should consider using a different test, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of significance testing method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the choice of significance testing method used in the paper, specifically questioning the appropriateness of the current method. However, it does not specify which part of the paper discusses this choice, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this discussion is located, the comment lacks full grounding. It is specific in suggesting a different test method, the Wilcoxon signed-ranked test, but without detailed guidance on why this change would be beneficial or how to implement it, the comment remains under-specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed justification or examples to explain why the current test might be inappropriate or how the suggested test would be more suitable. As a result, the claim is not verifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. While it identifies a potential issue with the current choice, it does not provide specific guidance or examples of alternative tests that could be used. The comment lacks depth and does not offer actionable steps for the authors to address the concern, such as suggesting specific tests or explaining why the current choice might be inappropriate. As a result, the feedback is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the background knowledge and literature description. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, such as providing more background knowledge and literature description. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the paper. Without concrete evidence or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s organization, suggesting that it could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. This feedback is somewhat helpful as it points out a specific area for improvement, but it lacks depth and does not provide detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specific steps to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it identifies a potential gap in the comparison, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific models, \"PanopticFPN\" and \"Mask2Former,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these models in the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these models should be included in the comparison. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper\\'s contribution. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is valuable as it highlights an area where the paper could be expanded to include more comprehensive comparisons. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these models into the comparison or what aspects to focus on. While it points out a potential weakness, it does not offer actionable guidance for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds in the paper, specifically mentioning that the independence number may be a better bound for some graphs. It also provides additional remarks about the results on the adaptive adversary and counterfactual feedback. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this gap or improve the paper. The authors are left to infer that they should investigate the independence number and its potential impact on the bounds, but the comment lacks concrete steps or suggestions for implementation. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the gap between the lower and upper bounds, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3} and the results on the adaptive adversary and counterfactual feedback. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the gap between the lower and upper bounds and the potential impact of the independence number on these bounds. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a gap between the lower and upper bounds in the paper, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3}. The reviewer also suggests that the independence number may be a better bound for some graphs, and provides examples of the results on the adaptive adversary and counterfactual feedback. However, the comment lacks specific examples or detailed reasoning to support the claim that the independence number is a better bound. While it identifies a potential issue, the lack of detailed evidence or explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap between the lower and upper bounds in the paper, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3}. It also points out that the independence number may be a better bound for some graphs, and provides examples of the results on the adaptive adversary and counterfactual feedback. This feedback is somewhat helpful as it highlights a potential issue with the bounds and suggests an area for improvement. However, the comment could be more helpful if it provided specific suggestions on how to address the gap or improve the bounds. Overall, the comment offers some insight but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. It also provides a rationale for why expected test loss might not be as meaningful for language-related tasks. However, the comment does not explicitly instruct the authors to include these results or provide guidance on how to incorporate them into the paper. While the suggestion is clear, the lack of concrete steps or detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, specifically mentioning language-related tasks. It also provides a rationale for why expected test loss might not be as meaningful for language-related tasks. However, the comment does not specify which part of the paper should include these results or how they should be integrated. While the authors might have an idea of where to include these results, the lack of explicit guidance makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. The comment provides a rationale for why expected test loss might not be as meaningful for language-related tasks, suggesting that people care more about OOD performance. However, the comment lacks specific examples or references to support the claim that expected test loss is not as relevant for language-related tasks. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. It provides a rationale for why expected test loss might not be as meaningful for language-related tasks, suggesting that people care more about OOD performance. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a logical basis for the suggestion. However, the comment could be more helpful if it offered specific guidance on how to incorporate these results or what aspects of OOD performance should be prioritized. Overall, the comment provides a clear direction for improvement but lacks detailed instructions, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the recent related work, CoCoOp, should be compared in the experiments. It provides a clear and direct action for the authors to take, specifying that they should include a comparison with CoCoOp in their experiments. The comment is specific and provides concrete guidance on what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the recent work \"CoCoOp\" and its relation to the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with CoCoOp in the experiments. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recent work CoCoOp, which is a CVPR\\'22 work, should be compared in the experiments. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the recent work CoCoOp, which is a CVPR\\'22 work, is not compared in the experiments. This is a relevant point as it is an extension of CoOp and could provide valuable insights for comparison. However, the comment does not offer suggestions on how to incorporate this comparison or what specific aspects of CoCoOp should be compared. While it highlights an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for testing on more complex games, but it is somewhat vague in detailing how to implement this additional testing. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically mentioning that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as testing on more complex games, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems, specifically mentioning the issue of input size for value and policy functions. However, the comment lacks specific examples or references to support the claim that these complex problems are necessary for testing ReBeL. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. This feedback is somewhat helpful as it points out a potential gap in the experimental setup and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples of complex games or detailed guidance on how to implement the additional testing. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it does not specify what aspects of the discussion should be included or how it should be structured. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspects of the theoretical guarantee are missing or how the authors should address this issue. The comment is specific in identifying the lack of discussion but lacks detailed guidance on how to improve it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, specifically the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a relevant point that could enhance the paper\\'s theoretical foundation and provide additional insights to readers. However, the comment does not offer suggestions or guidance on how the authors might address this gap in the discussion. While it highlights an important area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate quantitative measures or what specific metrics could be used. The action is implicit and somewhat vague, as the authors need to infer that they should include quantitative measures but are not given concrete suggestions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a quantitative measure to evaluate the generated VCEs, and suggests that evaluation is mainly performed with visual inspection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of quantitative measures to evaluate the generated VCEs. It notes that evaluation is mainly performed with visual inspection, which is a relevant observation. However, the comment does not provide detailed guidance on how to incorporate quantitative measures or what specific metrics could be used. While it highlights an important area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the generated videos, specifically noting significant artifacts and questioning the action recognition performance compared to state-of-the-art methods. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it guide the authors on how to address the issues or improve the quality of the videos. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generated videos, specifically mentioning artifacts and the action recognition performance on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment does provide some specificity by questioning the action recognition performance compared to state-of-the-art methods, which suggests that the authors should address this aspect. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and questions the action recognition performance compared to state-of-the-art methods. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed analysis to substantiate the claims, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the generated videos, noting significant artifacts and questioning the action recognition performance compared to state-of-the-art methods. It highlights the need for improvement in the quality of the videos and suggests that the current action recognition performance is below par. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the quality of their videos. While it points out a critical area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017). While it does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it implies that the authors should consider the relevance of the term in the context of their work. The action is implicit but clear, as the authors can infer that they need to evaluate the relevance of the term and potentially revise their work accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017), providing a clear direction for the authors to consider the applicability of this term in their context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017). While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, it is rated as barely helpful, as it points out a potential weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the experiments are limited to MNIST and a single real-world dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, it does not provide specific guidance on which datasets to include or how to conduct the additional experiments. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment points out that the experiments are limited to MNIST and a single real-world dataset, but it does not specify which part of the paper this limitation is discussed in. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying the issue of limited datasets being used for experiments. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to MNIST and a single real-world dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the validity of the experiments. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a limitation in the experiments, specifically noting that they are limited to MNIST and a single real-world dataset. This feedback highlights an area where the authors could potentially expand their experiments to include a broader range of datasets, which could enhance the generalizability and robustness of their findings. However, the comment lacks specific suggestions on which datasets to include or how to conduct the additional experiments. While it points out a potential weakness, it does not provide actionable guidance for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep at the time, to provide context. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim. While it implies that the authors should provide more detailed information or examples, it lacks concrete guidance on what specific aspects to address or how to present the information. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks.\" It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting that quantifying and clarifying the claim could be beneficial. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling. This reference provides some context for the claim, but it does not offer specific examples or detailed reasoning to fully substantiate the claim. The comment is somewhat verifiable, as it provides a logical connection to the original work but lacks detailed evidence or examples to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be beneficial. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling. This reference provides some context for the claim, but the comment lacks specific guidance on how to quantify or clarify the claim. While it points out a potential area for improvement, it does not offer detailed suggestions or examples on how to address the issue. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more explanations on the consistency between training and inference, specifically mentioning lines 95-97 and 308-310. While the comment implies that the authors should elaborate on the smoothness of neural models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanations. However, the comment does provide a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the lack of explanation regarding the consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks explanations regarding the consistency between training and inference due to the smoothness of neural models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it claims consistency between training and inference due to the smoothness of neural models but lacks adequate explanations. It suggests that the authors should provide more detailed explanations on this topic. While the comment highlights an area for improvement, it does not offer specific guidance or examples on how to enhance the explanation. This limits its helpfulness, as the authors are given a direction but not detailed steps to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It asks for clarification on whether the proposed model improves with larger word embedding and LSTM parameters. While the comment implies that the authors should provide evidence or experiments to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional experiments or evidence to substantiate their claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about superior performance with fewer parameters, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have tested the model with standard parameter settings in the baseline model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. The reviewer requests evidence or experiments to support the claim, indicating a need for further clarification. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional information or experiments to fully substantiate their claim, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It questions whether the proposed model actually improves with larger word embedding and LSTM parameters, which is a crucial aspect of the paper\\'s contribution. By asking for evidence or experiments to support the claim, the comment provides a clear and actionable suggestion for the authors to further substantiate their findings. This feedback is somewhat helpful as it prompts the authors to provide additional data or analysis to strengthen their argument, but it could be more helpful if it offered specific guidance on how to conduct these experiments. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the availability of the environment or a good OPE method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these hyperparameters are introduced, the comment lacks full grounding. It is specific about the issue of finetuning and the dependence on the environment or OPE method, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains unverifiable, as it does not provide sufficient justification for the authors to make improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. This feedback is somewhat helpful as it points out a potential problem that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to ensure the availability of the environment or a good OPE method. Without actionable advice or detailed explanation, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a typographical error in the first \"f\" in \"we fixed the form of\" and an extra period in a sentence. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. While the comment provides specific corrections and a question, it does not offer guidance on how to address the question or improve the paper. The action is clear but lacks detailed instructions on how to implement the corrections or respond to the question. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"line 108\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the typographical error in the first \"f\" in \"we fixed the form of\" and the extra period in a sentence. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This question is specific and provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual corrections and a question about the baseline MCL with deep learning. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies specific typographical errors in the manuscript, which are important to correct for accuracy and professionalism. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This question is relevant and could prompt the authors to provide more detailed explanations or evidence regarding the robustness of their baseline. However, the comment could be more helpful if it offered suggestions on how to address the issue of early learning cutoff or how to ensure that each network has converged to reasonable results. Overall, the comment is mostly helpful as it provides actionable feedback on errors and a relevant question for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the limitations of FedPCL due to its reliance on pre-trained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pre-trained models. However, the comment does not provide explicit guidance on how the authors should further improve their work or what specific aspects of the framework should be refined. It lacks actionable details, such as suggestions for additional experiments or modifications to the framework. As a result, the authors are left without clear direction on how to enhance their draft based on this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the sensitivity of the model accuracy to pre-trained models and how the authors addressed this limitation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedPCL heavily relies on the selection of different pre-trained models, which limits its applications to more wide areas. The reviewer supports this claim by referencing Table 4, which shows the model accuracy is sensitive to pre-trained models. However, the comment does not provide further details or examples to substantiate the claim or suggest improvements. While the reference to Table 4 provides some support, the lack of additional context or explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the limitations of FedPCL due to its reliance on pre-trained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pre-trained models for prototyping. However, the comment lacks specific suggestions or guidance on how the authors could further improve their work or what aspects of the framework should be refined. While it provides some insight into the limitations and potential solutions, it does not offer actionable feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a limitation but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include tentative attention maps in the qualitative figures to provide a more comprehensive understanding of the attention mechanism. While the comment implies that the authors should add these maps, it does not explicitly instruct them to do so. The action is concrete, as it specifies what additional information should be included, but it is somewhat vague because it does not provide detailed guidance on how to present these maps. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including tentative attention maps in the qualitative figures, which implies that it relates to the visualization or discussion of the attention mechanism. However, it does not explicitly mention a specific section or figure where these maps should be included, making it weakly grounded. The comment is specific in suggesting what additional information should be included, such as the retrieved and final attentions, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including tentative attention maps in the qualitative figures would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the understanding of the attention mechanism. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including tentative attention maps in the qualitative figures would enhance the understanding of the attention mechanism. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending the inclusion of additional visual information. However, the comment lacks depth and does not provide specific guidance on how to present these maps or why they are important. Without further explanation or examples, the authors may find it challenging to fully understand and implement the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the understanding of Figure 5 or the labels being incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific steps to take to improve the figure or labels. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper, such as Figure 5, is being addressed. It lacks specificity because it does not provide details on what is unclear or incorrect about the figure or labels. Without explicit references or detailed feedback, the authors cannot effectively identify the issues or make improvements. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that either the reviewer does not understand Figure 5 or the labels are incorrect. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the clarity or accuracy of Figure 5 or the labels used in the figure. However, it does not provide any specific guidance or suggestions on how to address this issue or improve the figure. Without detailed feedback or actionable advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' derivation is based on classical learning theory-based bounds, which are not realistic without Bayesian considerations. It suggests that the authors should consider Bayesian-PAC-based bounds to make their derivation more realistic. While the comment implies that the authors should incorporate Bayesian considerations, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to understand the implications of the suggestion and determine how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, specifically mentioning that it is based on classical learning theory-based bounds. However, it does not specify which part of the paper this critique pertains to, such as a particular section or equation. The authors can infer that it relates to the derivation or theoretical framework, but this inference is not direct. The comment also suggests that Bayesian considerations should be taken into account, but it does not provide specific examples or guidance on how to incorporate these considerations. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is under-specific in terms of what needs to be addressed.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors\\' derivation is based on classical learning theory-based bounds, which are not realistic without Bayesian considerations. The reviewer supports this claim by suggesting that Bayesian-PAC-based bounds are more realistic. However, the comment lacks specific examples or references to classical learning theory-based bounds or Bayesian-PAC-based bounds, making it somewhat verifiable. The authors would need to infer the relevance of these concepts and explore them further to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' derivation, noting that it is based on classical learning theory-based bounds that are not realistic without Bayesian considerations. The reviewer suggests that the authors should consider Bayesian-PAC-based bounds to make their derivation more realistic. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a particular approach to enhance the theoretical foundation of the work. However, the comment could be more helpful if it included examples or references to Bayesian-PAC-based bounds or explained why these are more realistic. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the use of suboptimally weight decay across all layers is expected to result in a large training loss and suboptimal cosine similarities, especially for large weight decay parameters. It also notes that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the cosine similarities. The action is implicit and somewhat vague, as the authors can infer that they need to report cosine similarities for larger weight decay strengths and possibly adjust the weight decay parameters. However, without concrete instructions or detailed suggestions, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of suboptimally weight decay across all layers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that cosine similarities for large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of suboptimally weight decay across all layers is expected to result in a large training loss and suboptimal cosine similarities, especially for large weight decay parameters. The reviewer supports this claim by noting that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed evidence or references to similar studies that have observed similar effects. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the application of weight decay across all layers, which is expected to result in a large training loss and suboptimal cosine similarities, especially for large weight decay parameters. It points out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is somewhat helpful as it highlights a potential weakness in the paper that could impact the validity of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional experiments or analyses to verify the cosine similarities. Overall, the comment offers some insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. It suggests that this omission could lead to incorrect conclusions by casual readers. The reviewer implies that the authors should fix this issue, but does not provide specific guidance on how to do so. The comment is explicit in identifying the problem but lacks concrete details on how to address it. Therefore, the action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of not explaining that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment suggests that this must be fixed for publication, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This omission could lead to incorrect conclusions by casual readers. The reviewer suggests that this is a serious issue and implies that it should be addressed before publication. However, the comment does not provide specific examples or references to support the claim that this omission is a significant problem. While the claim is logical and somewhat supported by the mention of unsupervised random forests, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires more detailed evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This is a critical issue that could lead to incorrect conclusions by casual readers. The reviewer suggests that this omission must be addressed before publication, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to clarify this point in the paper, such as recommending specific sections to include this information or suggesting alternative phrasing. Despite this, the comment is mostly helpful as it highlights a critical oversight and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. While the comment implies that additional analysis is needed, it does not specify what kind of evidence or analysis is required or how it should be presented. The authors are left to infer that they need to provide more detailed information, but the comment lacks concrete guidance on what exactly is needed. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in its request for additional evidence or analysis, but it lacks full grounding as it does not explicitly mention the sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of evidence or analysis supporting the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide more detailed evidence or analysis to strengthen their claims. However, the comment could be more helpful if it suggested specific types of evidence or analysis that would be beneficial, such as comparisons with other datasets or detailed performance metrics. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s claim that the student distillation improves the teacher\\'s performance. It suggests that the improvements could be due to regularization effects rather than distillation, given the lack of early-stopping and the long fine-tuning process. The reviewer implies that proper ablation studies are needed to verify the claim. While the comment identifies a potential issue, it does not provide explicit instructions on how to conduct these studies or what specific aspects should be analyzed. The action is implicit and somewhat vague, as the authors need to infer the need for ablation studies and determine how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that the student distillation improves the teacher\\'s performance, suggesting that the improvements could be due to regularization effects rather than distillation. It points out the lack of early-stopping and the long fine-tuning process, which could lead to high variances. The comment implies that proper ablation studies are needed to verify the claim. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the claim and the need for ablation studies, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the student distillation improves the teacher\\'s performance, suggesting that the improvements could be due to regularization effects rather than distillation. The reviewer provides a logical reasoning by pointing out the lack of early-stopping and the long fine-tuning process, which could lead to high variances. However, the comment lacks specific examples or references to support the claim that regularization effects are more likely to be responsible for the observed improvements. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that student distillation improves the teacher\\'s performance. It suggests that the improvements could be due to regularization effects rather than distillation, given the lack of early-stopping and the long fine-tuning process. The reviewer points out that the fine-tuning on GLUE without validation early-stopping usually has high variances, implying that proper ablation studies are needed to verify the claim. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s analysis and suggests a direction for further investigation. However, it could be more helpful if it provided specific guidance on how to conduct the ablation studies or what aspects to focus on. Overall, the comment offers some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes should be made to include the 1-shot setting. The comment lacks actionable details, such as recommending specific experiments or modifications to the paper, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its critique of the absence of the 1-shot setting in the experiment part, but it lacks grounding as it does not pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\\'s conclusions. The claim is based on a logical observation but lacks detailed justification or examples, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the absence of the 1-shot setting in the experiment part of the paper, noting that related works like RALE have included this setting. This feedback highlights a potential gap in the paper\\'s experimental evaluation, which could impact the authors\\' conclusions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate the 1-shot setting into their experiments. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the formula in the text, specifically mentioning $\\\\ell_{BCE}$. This is a clear and direct action for the authors to take, as it specifies the exact information that needs to be added. The comment is specific and provides concrete guidance on how to enhance the clarity of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the formula \"\\\\ell_{BCE},\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing more details about the formula in the text. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more details about the formula in the text, specifically mentioning $\\\\ell_{BCE}$. However, the comment does not provide any reasoning or evidence to support why this additional detail is necessary or how it would improve the clarity of the paper. Without further explanation or examples, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement by suggesting that the authors provide more details about the formula in the text, specifically mentioning $\\\\ell_{BCE}$. This feedback is clear and actionable, as it directs the authors to enhance the clarity of their work by including specific details about the formula. However, the comment could be more helpful if it provided examples of what kind of details would be beneficial or explained why these details are important for understanding the formula. Overall, the comment offers a clear direction for improvement, but it could be more comprehensive to fully support the authors in making these changes. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. While the comment implies that additional discussions are needed, it does not provide specific guidance on what aspects of these discussions should be included or how to structure them. The authors are left to infer that they need to expand on the existing discussions, but without concrete instructions on what to focus on or how to implement these changes, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. The authors can infer that it relates to the discussion of LLMs, but this inference is not direct. The comment is specific in its suggestion to include more discussions, but it lacks grounding as it does not pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically regarding the limitations and challenges of LLMs. However, the comment lacks specific guidance on what aspects of these discussions should be included or how to structure them. While it points out a gap in the paper, it does not provide detailed suggestions or examples on how to address the issue, which would make the feedback more actionable. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of insight into the rationale behind the need for self-supervised learning on 360 video data with spatial audio. It implies that the authors should provide more detailed explanations or justifications for this approach. However, the comment does not explicitly instruct the authors to add this information or specify what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but may not be entirely sure of the exact details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results and suggests that while the proposed approach is valuable for self-supervised learning on 360 video data with spatial audio, it lacks insights into why this approach is needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of insight into the rationale behind the need for self-supervised learning on this kind of data. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results suggest the proposed approach is valuable for self-supervised learning on 360 video data with spatial audio but lacks insights into why this approach is needed. The comment provides a logical reasoning by pointing out the absence of detailed explanations for the rationale behind the approach. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors may need to infer the need for more detailed explanations themselves, which could lead to some confusion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the rationale behind the need for self-supervised learning on 360 video data with spatial audio. It highlights that while the experimental results suggest the approach's value, the paper lacks insights into why this approach is necessary. This feedback is somewhat helpful as it points out an area where the authors could provide more context or explanation to enhance the paper\\'s clarity and comprehensiveness. However, the comment could be more helpful if it suggested specific insights or examples to consider, which would guide the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the paper, noting that it only covers the SimCLR case and lacks analysis of the projection head, which is considered important. However, it does not provide explicit guidance on what specific analysis should be conducted or how the authors should address this issue. The comment implies that the authors should include analysis of the projection head, but it does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the projection head, which is a critical component of the SimCLR approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only covers the SimCLR case and lacks analysis of the projection head, which is considered important. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why the projection head is crucial or how it relates to the SimCLR case. Without this additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, noting that it only covers the SimCLR case and lacks analysis of the projection head, which is considered important. This feedback is somewhat helpful as it points out a gap in the paper that could be addressed to enhance its comprehensiveness and relevance. However, the comment does not provide specific suggestions or guidance on how to incorporate analysis of the projection head or what aspects of this analysis would be most valuable. While it highlights an area for improvement, the lack of detailed guidance limits its utility for the authors. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern about the use of approximations in the paper, specifically mentioning lines 107-110. It suggests that the authors should expand on the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what additional information should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (107-110) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should expand on the possible vulnerability of the approximations, particularly regarding the assumption of attacks being in the feasible set only in those lines. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of approximations in the paper leaves \"loose ends\" and suggests that the possible vulnerability of these approximations needs to be expanded to reassure readers. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the concern about the vulnerability of the approximations. As a result, the claim is somewhat verifiable, as it requires further elaboration to be fully understood and actionable by the authors. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of approximations in the paper, specifically mentioning lines 107-110. It points out that while approximations are necessary, the paper does not adequately address the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. The comment suggests that the authors should expand on this issue to reassure readers that it is not a real concern. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address it. However, it could be more helpful if it included suggestions on how to present this information or what additional details should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the experimental results, noting that the proposed method does not show any advantage without prior information, but only when using prior knowledge. It suggests that this comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. While the comment identifies an issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors can infer that they need to consider the extra complexity and cost of using prior knowledge in their method. However, the comment lacks concrete details on how to implement this consideration, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not show any advantage without prior information but only when using prior knowledge. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not show any advantage without prior information but only when using prior knowledge. The reviewer supports this claim by explaining that the method essentially requires two separate representation models, which adds complexity and cost. This reasoning is logical and based on the experimental results, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the experimental setup or results that support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, noting that the proposed method does not show any advantage without prior information but only when using prior knowledge. It highlights that this comparison is unfair because the proposed method essentially requires two separate representation models, which adds complexity and cost. This feedback is valuable as it points out a potential weakness in the experimental setup and suggests that the authors consider the impact of prior knowledge on the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or how to design a more fair comparison. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the dimensionality problem or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the proposed model, specifically that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\\'s dimensionality, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a relevant observation that could impact the applicability and scalability of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate its impact on the model. Without actionable advice or additional context, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. However, the comment does not offer explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"prediction of homo-lumo gap\" and the \"QM9 in downstream experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the Transformer-M model performs poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as evidenced by Transformer-M\\'s poor performance on most tasks except for homo, lumo, and gap. The reviewer provides an example from QM9 in downstream experiments, which supports the claim. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have observed negative transfer in similar contexts. Despite this, the claim is mostly verifiable due to the provided example and logical reasoning.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. This feedback is somewhat helpful as it highlights a specific area of concern that the authors should address to improve the clarity and accuracy of their claims. However, the comment could be more helpful if it offered suggestions on how to mitigate this issue or how to better align the description of the model with its performance. Overall, the comment provides valuable insights but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the theoretical contribution as \"ok but not particularly strong\" and points out that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It does not suggest specific ways to strengthen the theoretical contribution or offer guidance on how to make the proof more novel. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical contribution of the paper, specifically mentioning that it is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the weaknesses of the theoretical contribution and the proof, but without clear grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical contribution is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the theoretical contribution as \"ok but not particularly strong,\" which is a subjective assessment. It also points out that the theoretical result is a weak, unpractical bound and that the proof lacks mathematical novelty. While the comment identifies some weaknesses in the paper, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the theoretical contribution. The feedback is somewhat helpful as it highlights areas for improvement, but it lacks actionable advice or detailed critique to fully support the authors in enhancing their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with lines L240 and L428, questioning the phrase \"is sufficient\" and suggesting that the authors might want to clarify what is meant by \"the sum of the optimistic hoped for rewards is close to the expected actual rewards.\" While the comment identifies a potential area for clarification, it does not provide explicit instructions on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of the phrase. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the phrase \"is sufficient\" and suggests that the authors might want to clarify what is meant by the sum of the \"optimistic\" hoped-for rewards being close to the expected actual rewards. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrase \"is sufficient\" in lines L240 and L428, suggesting that the authors might want to clarify what is meant by the sum of the \"optimistic\" hoped-for rewards being close to the expected actual rewards. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the phrasing in lines L240 and L428, questioning whether \"is sufficient\" is clear and suggesting that the authors might want to clarify what is meant by the sum of the \"optimistic\" hoped-for rewards being close to the expected actual rewards. While the comment highlights a potential area for clarification, it does not provide detailed guidance or suggestions on how to improve the clarity or what specific changes should be made. The feedback is somewhat helpful as it points out a potential issue, but it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of the trade-off and possibly explore ways to mitigate it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"ancestral graphs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. The comment further raises a question about the information encoded in the ancestral graph compared to the DAGs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the reduction in search space results in a loss of information. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a relevant consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the trade-off. While it points out a relevant concern, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of the VAD is puzzling and suggests that the authors should clarify what they mean by \"discarding TF bins with a magnitude of less than epsilon.\" It also notes that this approach is not consistent with a VAD, which is supposed to look for speech presence and is unlikely to be defined over frequency. The comment implies that the authors should reconsider their definition and approach to VAD. While the action is implicit, it is clear and provides a direction for the authors to take, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic with the VAD description, namely that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The comment further explains that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the VAD description is puzzling and suggests that the authors are discarding TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer argues that a VAD should look for speech presence and is unlikely to be defined over frequency, which is a common understanding in the field. The comment provides a logical reasoning and references common knowledge about VADs, making it mostly verifiable. However, it could be strengthened by providing specific references or examples to support the claim about VADs and their definition. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the description of the VAD, noting that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. It points out that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear and actionable suggestion for improvement. The comment highlights a critical misunderstanding in the paper that could lead to incorrect conclusions, making it highly helpful for the authors to address this issue. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network's performance may be improved by training them simultaneously. The reviewer explicitly requests KID/FID metrics for the teacher network, providing a clear and concrete action for the authors to take. This guidance is explicit and specific, leaving no ambiguity about what the authors need to do to address the concern. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the training of the student and refinement networks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of the comparison and requests KID/FID metrics for the teacher network. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network's performance may be improved by training them simultaneously. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. It explicitly requests KID/FID metrics for the teacher network, which is a clear and actionable request that can help the authors validate their claims and improve the paper. However, the comment could be more helpful if it provided additional context or reasoning for why this comparison is important or how it might impact the overall contribution of the work. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement and provides a concrete action to take. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide model-specific insights by investigating how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a clear action to take, it does not specify how to conduct the investigation or what specific aspects of the models should be analyzed. The authors are given a general direction but may need to infer the details of how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Model-Specific Insights\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the investigation into how specific models behave differently when ReGuide is applied and the presentation of differences in false positive rates (FPR) between models with and without ReGuide. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper focuses on generic findings across models and recommends a deeper investigation into how specific models behave differently when ReGuide is applied. The reviewer provides a specific example of GPT-4o and InternVL2, suggesting that differences in false positive rates (FPR) should be presented for a better comparison. This claim is somewhat verifiable as it provides a logical suggestion for enhancing the paper\\'s analysis, but it lacks detailed evidence or references to support the claim that these specific models behave differently. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the current focus on generic findings across models and recommends a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. The comment suggests presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is valuable as it directs the authors to a specific area for enhancing their analysis and conclusions, which could provide more nuanced insights into the models\\' behavior. However, the comment could be more helpful if it included examples or guidance on how to conduct the investigation or present the results. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer requests clarification on the rationale for considering these factors as separate evaluations. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their evaluation criteria. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the traditional DCI framework and questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The comment is specific in its critique of the evaluation criteria and provides a logical explanation of how they might be entangled. However, it does not explicitly mention which part of the paper discusses these evaluation criteria, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific examples or references to support the claim that these factors are already considered within the framework. This makes the claim somewhat verifiable, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their motivation for considering these factors as separate evaluations. While it identifies a potential area for clarification, the feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not provide specific guidance on how to assess or address these concerns. The authors are left to infer that they need to consider practicality and safety, but without concrete steps or examples on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not specify which part of the paper this issue pertains to, such as the intervention section or the results section. The authors can infer that it relates to the intervention or querying aspects, but this inference is not direct. The comment is specific in its suggestion to consider practicality and safety, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why these considerations are necessary or how they would impact the paper\\'s findings. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that while the types of interventions included are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. This feedback is somewhat helpful as it highlights an area that the authors should address to ensure their work is applicable and relevant in practical settings. However, the comment could be more helpful if it provided specific examples or suggestions on how to assess and improve the practicality and safety of the interventions. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. While the comment implies that the authors should reconsider their approach, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their methodology and potentially revise the paper to include more automated disentangling. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the manual disentangling process in the paper, suggesting that it could be more interesting if the paper did not involve manual disentangling and instead demonstrated everything being learned. However, the comment lacks specific reasoning or evidence to support why manual disentangling is problematic or how automating the process would improve the paper. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the manual disentangling process in the paper, questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it demonstrated everything being learned without manual disentangling. This feedback is somewhat helpful as it prompts the authors to consider alternative approaches or methods for automating the disentangling process. However, the comment lacks specific suggestions or guidance on how to achieve this, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of connection between the theoretical analysis and the proposed method, specifically regarding the use of self-attention mechanisms in the context of graph neural networks (GNNs). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to strengthen the connection between the theoretical analysis and the proposed method, or how to enhance the generalization for distant nodes. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical analysis and the proposed method, specifically mentioning the derivation of PAC-Bayesian bounds for GNNs in the transductive setting and the interplay between training and testing sets. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing the lack of a strong connection between the theoretical analysis and the proposed method, as well as the issue of adopting the self-attention mechanism from transformers. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical analysis does not have a strong connection to the proposed method, which seems to simply adopt the self-attention mechanism from transformers. The reviewer questions how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of a strong connection between the theoretical analysis and the proposed method. It points out that the proposed method seems to simply adopt the self-attention mechanism from transformers and apply it to graphs, without explaining how it enhances generalization for distant nodes. This feedback is valuable as it highlights a critical gap in the paper that the authors need to address to strengthen their work. However, the comment could be more helpful if it provided specific suggestions on how to bridge this gap or what aspects of the theoretical analysis should be expanded to better support the proposed method. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement, but it lacks detailed guidance on how to address the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not provide any specific guidance or suggestions on how the authors could improve the contribution or make it more novel. The comment lacks actionable details, such as recommending new approaches or improvements to the pipeline. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not specify which part of the paper this assessment is based on, such as the methodology, results, or discussion sections. Without explicit references to specific sections, the authors cannot confidently determine which parts need revision. The comment is specific in its critique of the contribution being incremental, but it lacks grounding as it does not point to a particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. It implies that the pipeline is a collection of tricks to improve defense evaluation, which is a somewhat helpful observation. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors could enhance the contribution or make it more novel. Without detailed guidance or examples, the authors are left without a clear understanding of what improvements could be made to strengthen their work. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the eta_ri term is not clearly explained as a non-central chi-squared distribution. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to clarify this point. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the eta_ri term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the eta_ri term being a non-central chi-squared distribution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the eta_ri term being a non-central chi-squared distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this term should be considered unclear or how it could be clarified. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the eta_ri term being a non-central chi-squared distribution. This is a clear and actionable point that the authors can address to improve the understanding of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the implications of this clarification. Overall, the comment is somewhat helpful as it directs the authors to a specific area for improvement but lacks depth and detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on the vagueness of certain RNNs and suggests that the reinforcement learning/agent analogy is out of place. It also points to specific lines in the paper where generalization capabilities are better illustrated. While the comment identifies areas for improvement, it does not provide concrete guidance on how to address the vagueness or suggest specific changes to the analogy or examples. The authors are left with a general idea of what needs to be improved but without detailed instructions on how to implement these improvements. Therefore, the comment is somewhat actionable, as it provides a direction but lacks specificity in execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L15\" and \"L16-18,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the vagueness of certain RNNs and the reinforcement learning/agent analogy, providing clear guidance on what needs to be addressed. The comment is specific in detailing the problem with the vagueness and suggesting that the examples later in the paper better illustrate generalization capabilities. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the vagueness of certain RNNs and the reinforcement learning/agent analogy are out of place in the context of the paper. The reviewer provides a specific reference to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to support the claim that certain RNNs work well for certain natural language reasoning tasks. However, the comment lacks detailed reasoning or examples from the paper itself to fully substantiate the claim. While the reference provides some support, the comment could be strengthened by further elaboration on why the analogy is inappropriate or how it detracts from the paper. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed justification or examples from the paper.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the vagueness of certain RNNs and the reinforcement learning/agent analogy in the paper. It suggests that the examples later in the paper better illustrate generalization capabilities, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided specific suggestions on how to address the vagueness or how to better integrate the examples into the paper. While it identifies areas for improvement, the feedback lacks detailed guidance, making it somewhat helpful but not comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of speed analysis in the experiments, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. It suggests that the improvement on inference speed would be more interesting than reducing FLOPs. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include speed analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of speed analysis and the comparison of inference speed between the proposed network and prior work. It specifies the issue by pointing out the absence of such comparisons, which allows the authors to identify the exact part of the paper being addressed. The comment is also specific because it clearly articulates the need for comparisons of inference speed and why this would be more interesting than reducing FLOPs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of speed analysis is a significant issue, as the experiments have compared GFLOPs of different segmentation networks but not the inference speed between the proposed network and prior work. The reviewer suggests that the improvement on inference speed would be more interesting than reducing FLOPs. This claim is somewhat verifiable as it logically points out the importance of speed analysis in evaluating the performance of the proposed network. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of speed analysis in the experiments. It highlights the importance of comparing inference speed between the proposed network and prior work, suggesting that this would be more interesting than simply reducing FLOPs. This feedback is clear and actionable, as it directs the authors to include speed analysis in their experiments. However, it could be more helpful if it provided specific guidance on how to conduct these comparisons or what metrics to use. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It suggests that the authors should conduct a thorough literature review to identify other works that use this property. While the comment explicitly states the need for a literature review, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of originality in the proposed method and the need for a thorough literature review to identify other works that use the same property. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and score-interpolation, which have used this property. This provides a clear and robust justification for the claim, making it fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known in the literature. It provides specific examples of existing works that use this property, such as the original denoising score matching objective and score-interpolation. This feedback is valuable as it highlights a potential gap in originality and suggests a thorough literature review to address it. However, the comment could be more helpful if it offered guidance on how to conduct the literature review or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides actionable feedback on a critical aspect of the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if the authors have the resources, they should compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This is an explicit action that the authors can directly take, as it provides a clear direction for further exploration and analysis. The comment is specific in its request for comparison, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion for comparison, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be valuable or how it would contribute to the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, which could provide valuable insights into the performance of the proposed method. This feedback is actionable and offers a specific direction for further exploration and analysis, potentially enhancing the robustness and generalizability of the results. However, the comment lacks depth and does not explain why this comparison is important or how it might impact the paper\\'s conclusions. To be more helpful, the comment could provide additional context or suggestions on how to conduct the comparison or interpret the results. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. While the comment identifies an issue, it does not provide explicit guidance on how to address it or what specific experiments should be conducted. The authors are left to infer that they need to clarify this point and potentially conduct additional experiments, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the resolution of a debate left open in the paper. The comment questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the resolution of a debate left open in the paper and suggests that the distribution cannot be considered a factor in the results. It also questions whether experiments disentangle changes in distribution from the removal of information. While the comment raises valid points, it lacks specific examples or references to support the claim that the distribution is a significant factor. The reasoning is somewhat verifiable, as it highlights a potential issue but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is somewhat helpful as it points out a potential weakness in the paper that could be clarified or addressed. However, the comment lacks specific suggestions or guidance on how to resolve this issue or what experiments might be needed. While it highlights an area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects to focus on. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section or experiment where this combination is discussed. Without explicit references or clear indications, the authors cannot confidently determine which part of the paper should be addressed. Additionally, the comment lacks specificity regarding what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it identifies an area of interest, it lacks specificity and actionable guidance for the authors. It does not provide details on how to conduct this analysis or what aspects to focus on, nor does it offer suggestions for potential improvements or insights. Without clear direction or context, the comment does not offer much value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the plots are terrible, providing specific issues with the plot quality. It mentions that the plots are too small, colors are hard to distinguish, axis labels are poorly labeled, and labels are visually similar. The reviewer also points out that these issues are the main presentation of the experimental results, which should be clearer. This feedback is clear and provides concrete actions for the authors to take, such as improving plot size, color contrast, and label clarity. The comment is highly actionable as it directly instructs the authors on how to enhance the clarity and quality of their plots, ensuring that they are more effective in communicating their results.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"plots\" and \"plots are terrible,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the plots, such as their small size, color difficulty, and poorly labeled axis. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are terrible, with specific issues such as small size, color difficulty, and poorly labeled axis. The reviewer also mentions that the labels are visually similar, which contributes to the overall clarity issue. While the comment provides some specific examples of problems with the plots, it lacks detailed reasoning or references to support the claim that the plots are \"terrible.\" This makes the claim somewhat verifiable, as the authors would need to address the specific issues mentioned but may not fully understand the severity of the problem without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies issues such as the small size of the plots, difficulty in distinguishing colors, poorly labeled axis, and visually similar labels. This feedback is clear and constructive, offering the authors a clear path to improve the clarity and effectiveness of their plots. By addressing these issues, the authors can significantly enhance the presentation of their results, which is crucial for the success of their paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to address the issue of low performance gains. As a result, the comment lacks actionability, leaving the authors without any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance gains of the paper, specifically mentioning that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not specify which metrics or parts of the paper this analysis is based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the performance gains, but it lacks grounding as it does not reference specific sections or metrics. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a specific issue with the performance gains of the paper, noting that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). This is a clear and actionable observation that can guide the authors in understanding the limitations of their work. However, the comment could be more helpful if it provided suggestions on how to improve the performance gains or addressed potential sources of variability in the results. Overall, the comment is somewhat helpful as it identifies a specific area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. However, it does not provide explicit guidance or suggestions on how the authors should address this question or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific tables (1, 2, and 3) and the addition of parameters in LinearTop and NLTop, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the question about the performance boost due to additional parameters and raises a question about the use of a better Unary baseline. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. The comment references the use of a different neural network in [14], which provides some basis for the claim that a better Unary baseline could improve performance. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the question, the lack of detailed evidence or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. It highlights the potential issue of using a different neural network in [14] and suggests that a better Unary baseline could improve performance. While the comment identifies a potential weakness in the analysis, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it prompts the authors to consider the impact of different baselines on performance, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback implies that the authors should expand their discussion of related work to include a comparison with their own work. While the action is implicit, it is clear that the authors need to include a more detailed discussion of related work, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this discussion should be included in, such as the introduction, literature review, or results section. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a more detailed discussion of related work, but without explicit references to sections or elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This claim is somewhat verifiable as it provides a logical reasoning for expanding the discussion of related work. However, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors would need to infer the specific aspects of the related work that should be discussed and the differences to the presented work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their literature review section. By including a comparison with other works, the authors can better situate their research within the existing context and highlight the unique contributions of their study. However, the comment could be more helpful if it provided examples of specific related works or aspects to focus on for comparison. Overall, the comment is mostly helpful as it offers a concrete suggestion for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include experiments on other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which architectures or tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be expanded to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper these experiments should be added to or which specific architectures or tasks should be considered. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas that need revision. The suggestion is specific in terms of what additional experiments could be conducted, but without clear grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends expanding to other architectures and classification tasks. However, the comment does not provide any supporting evidence, examples, or references to justify why this expansion is necessary or beneficial. Without additional context or reasoning, the authors may find it challenging to understand the basis of the suggestion and how it could improve their work. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the experiments in the paper are limited to neural networks and image classification tasks and recommends expanding to other architectures and classification tasks. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting that the authors explore the performance of attacks on a broader range of systems. However, the comment lacks specific guidance on which architectures or tasks to consider or how to implement these changes. While it points out a gap in the current work, it does not provide detailed instructions or examples to help the authors effectively address the suggestion. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the output from the algorithm depends on the order in which the data is processed and suggests that this should be clarified. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to clarify this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the order of data processing. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the output from the algorithm depends on the order in which the data is processed and recommends clarifying this point. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of the algorithm's dependence on data order, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output from the algorithm depends on the order in which the data is processed, suggesting that this should be clarified. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the algorithm's output, suggesting that it depends on the order in which the data is processed. This is a clear and actionable point that the authors should address to improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify this aspect or offered examples of how other studies have addressed similar issues. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the sampling method used to obtain different initializations x_0, noting that it is important for convergence to the optimum. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their sampling method. The comment suggests that the sampling should be evaluated more thoroughly, but it does not specify which benchmarks should be used or how the evaluation should be conducted. The lack of concrete details makes it difficult for the authors to know exactly how to implement the suggested improvement. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sampling method used to obtain different initializations x_0, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the sampling is not evaluated carefully on the proposed benchmarks, except for Table 1 in the supplementary material. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sampling method used to obtain different initializations x_0 is important for convergence to the optimum, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the sampling is not evaluated carefully on the proposed benchmarks, except for Table 1 in the supplementary material, where it is compared to sampling from a uniform distribution. However, this reference does not provide sufficient detail or analysis to substantiate the claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the sampling method used to obtain different initializations x_0, noting that it is important for convergence to the optimum. However, it points out that this aspect has not been evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what additional experiments could be conducted. The feedback is somewhat helpful as it directs the authors to consider evaluating the sampling method more thoroughly, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions why the authors compare the proposed method with [9] first and then [16], and why they only compare the computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies areas for clarification and potential issues, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The authors can infer that they need to provide a clearer explanation of the method's logic and comparisons, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific papers, \"[9]\" and \"16,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the logic behind the comparisons, the computational cost, and its relevance in a practical scenario. The comment provides clear guidance on what needs to be addressed, namely the rationale behind the comparisons and the significance of the computational cost. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. The reviewer questions why the authors compare the proposed method with [9] first and then [16], and why they only compare the computational cost with [9]. The comment also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims. The authors are left to infer the basis of the reviewer\\'s concerns, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several pertinent questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions why the authors compare the proposed method with [9] first and then [16], and why they only compare the computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. These questions highlight areas where the authors need to provide more clarity and justification for their methodology and comparisons. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues, such as suggesting alternative comparisons or discussing the practical implications of the computational cost. While it identifies important areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting but not necessary to explore how the model works with tabular data, specifically by considering each attribute dimension as a modality. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore tabular data but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this exploration could be discussed. The authors can infer that it relates to the model evaluation or methodology sections, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality, would be interesting but not necessary. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exploration would be beneficial or necessary. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. This is a valuable suggestion as it could provide insights into the model's applicability to different forms of data. However, the comment lacks specific guidance on how to implement this exploration or what aspects of the model should be considered. While it identifies a potential area for improvement, the lack of detailed instructions or examples limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but requires more detailed guidance for the authors to fully address the suggestion.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This provides a clear and explicit action for the authors to take, which is to include additional details on using attention in an appendix. The suggestion is concrete, as it specifies the exact location where the additional information should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, it does not specify which part of the paper discusses attention or where the additional details should be added. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting an additional appendix, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why additional details on attention are necessary or how they would benefit the paper. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by adding more details on a particular aspect. However, the comment could be more helpful if it included specific questions or areas where the authors could elaborate on the use of attention. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific reason for the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. While the comment implies that the authors should address this issue by providing a rationale or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the choice of Gaussian noise. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the model's ability to work well for various image noise types, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of Gaussian noise in the experiments and asks for a rationale or explanation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of Gaussian noise in the experiments, suggesting that there might be a particular reason for this choice. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or justification to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. This is an important point as it highlights a potential limitation in the scope of the experiments. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional noise types could be considered. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While the comment implies that the authors should consider moving this information to the supplementary materials, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider moving the information to the supplementary materials. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific, as it clearly identifies a potential improvement by recommending the inclusion of supplementary materials. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. The comment lacks specificity and does not offer a detailed explanation or references to support the claim. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While it provides a specific suggestion for improvement, it lacks depth and does not explain why this change would be beneficial or how it would enhance the paper. The comment does not offer detailed guidance or examples on how to implement this suggestion, leaving the authors with a general idea but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not provide comprehensive guidance for implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific line in the paper (ln. 180--182) and highlights a potential issue with the claim made in Corollary 10. It notes that the corollary only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss but does not necessarily imply that it is minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors should clarify or rephrase their claim, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ln. 180--182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made in Corollary 10, noting that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss but does not necessarily imply that it is minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out that the corollary does not directly address the minimization of the expected convex surrogate. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors may need to further explore the implications of the corollary to fully understand and address the reviewer\\'s point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim made in Corollary 10, noting that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This is a clear and actionable point that the authors can address to improve the clarity and accuracy of their claims. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the claim to better align with the evidence presented. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there are missing details about the division to train and test sets, including numbers and the method used for division (random or other considerations). It clearly instructs the authors to add these details, providing a direct action for improvement. The comment is specific and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for details about the division to train and test sets, including numbers and the method used for division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, such as details about the division method and numbers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are missing details about the division to train and test sets, including numbers and the method used for division. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of details about the division to train and test sets, including numbers and the method used for division. It clearly instructs the authors to add these details, providing a direct and actionable suggestion for improvement. This feedback is valuable as it helps the authors clarify and strengthen their methodology section, ensuring that their experimental results are robust and transparent. However, the comment could be more helpful if it provided additional context or examples of how these details might be presented or discussed in the paper. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the model was only tested on a single supporting fact dataset for the bAbI task. It implies that the authors should consider testing the model on other tasks in the bAbI dataset. However, the comment does not provide explicit instructions or concrete guidance on how to address this issue, such as suggesting specific tasks to test or recommending additional datasets. The action is implicit and somewhat vague, as the authors can infer that they need to test the model on more tasks but may not be entirely sure which ones to prioritize. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the model was only tested on a single supporting fact dataset for Task 1. However, it does not provide specific guidance on what additional tasks should be tested or how to address this issue. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the model testing on bAbI. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the model testing for bAbI, specifically asking whether the model was only tested on a single supporting fact dataset for Task 1. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what additional testing might be needed. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment acknowledges that the dataset used in the experiments is small but suggests that results on larger datasets like ImageNet would be more convincing. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to include results on larger datasets. The action is implied, as the authors can infer that they should consider running experiments on larger datasets, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the dataset used in the experiments being small, suggesting that results on larger datasets like ImageNet would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to include results on larger datasets, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why larger datasets are necessary or how they would impact the paper\\'s conclusions. Without specific examples or detailed explanations, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the issue of using small datasets in the experiments and suggests that results on larger datasets like ImageNet would be more convincing. However, it does not provide specific guidance or suggestions on how to address this issue, such as recommending additional datasets or methods for scaling up the experiments. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims a unique contribution regarding the number of points and apriori knowledge needed for its algorithm, but it suggests that empirical justification would be beneficial. However, it does not provide specific guidance on how to conduct this empirical justification or what kind of evidence would be sufficient. The action is implicit and somewhat vague, as the authors can infer that they need to provide empirical evidence but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first claimed contribution\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper lacks empirical justification for the claim about the number of points and apriori knowledge needed for the algorithm. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s first contribution is unique because it does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment suggests that empirical justification would be beneficial. While the claim is logical, it lacks specific examples or references to support the assertion that empirical justification is necessary. The reasoning is somewhat verifiable, as it provides a general idea of what could be improved, but it does not offer detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of empirical justification for the claim about the algorithm\\'s unique contribution. It suggests that providing empirical evidence would strengthen the paper\\'s argument. While the comment highlights an important point, it does not offer specific guidance on how to conduct the empirical justification or what kind of evidence would be sufficient. This limits the comment\\'s helpfulness, as it provides a direction for improvement but lacks detailed guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015) and suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and provides a concrete action for the authors to take, which is to include a discussion on the comparison with RMED. The comment is specific in detailing what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed S1DB-ED algorithm\" and \"RMED (Komiyama et al. 2015),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion on the comparison with RMED. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed S1DB-ED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is somewhat helpful as it points out a specific area where the paper could be improved by addressing the comparison with an existing work. However, the comment could be more helpful if it provided suggestions on how to conduct this discussion or what aspects to focus on. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a comparison of GCG with other LLMs could be included, as it demonstrated the transferability of its approach. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs. While the comment implies that the authors should include this comparison and address the jailbreaking issue, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"their approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a comparison with other LLMs and the issue of low jailbreaking percentages for certain LLMs. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a comparison with other LLMs could be included, as it demonstrated the transferability of the GCG approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Additionally, the mention of the low jailbreaking percentage for certain LLMs is not further elaborated on or explained. This lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the importance of the comparison and the jailbreaking issue without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the inclusion of a comparison with other LLMs, which could demonstrate the transferability of the GCG approach. This is a clear and actionable piece of feedback that could enhance the paper\\'s contribution and relevance. Additionally, the comment points out a minor issue with the jailbreaking percentage for certain LLMs, which could be addressed to improve the paper\\'s thoroughness. However, the comment could be more helpful if it provided additional context or examples of how such a comparison might be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. While it implies that the authors should address this limitation, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations of the framework, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the framework is limited in this way. Without such information, the authors may find it challenging to address the question or understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. This is a relevant point that could help the authors identify potential areas for improvement or expansion in their work. However, the comment lacks specific guidance or suggestions on how to address these limitations, such as suggesting specific experiments or analyses that could be conducted. While it points out an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is well-studied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\\' dataset can be considered extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use the Kialo dataset rather than being directly told to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters, and that it is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in suggesting that the Kialo dataset could be used as an alternative, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. The reviewer claims that the Kialo dataset provides pairs of short claims and their counters and is cleaner than the dataset created by the authors. However, the comment lacks specific examples or references to support the claim that the Kialo dataset is cleaner or that it provides exactly what the authors need. While the suggestion to use the Kialo dataset is logical, the lack of detailed evidence or comparisons makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community and provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner than the one created by the authors and suggests that the authors\\' dataset can be considered extra data to learn from. While the comment identifies a potential source of data for the authors to consider, it lacks detailed guidance on how to incorporate this data or why it would be beneficial. The feedback is somewhat helpful as it points out a potential alternative dataset, but it could be more helpful with additional suggestions or explanations on how to integrate it into the paper. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the limited number of tasks in the experiments and suggests that the authors should include more tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. However, it does not provide specific guidance on how to implement these changes or what aspects of the experiments should be improved. The comment implies that the authors should address the weaknesses mentioned, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the limited number of tasks and suggests that the authors should include more tasks and sequential results in terms of tasks learned rather than epochs. The comment also asks the authors to address the weaknesses mentioned above, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the number of tasks in the experiments is limited and recommends including more tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning or evidence to support why the current number of tasks is insufficient or how adding more tasks would improve the experiments. The suggestion is based on a general expectation, but without detailed justification or examples, it lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, specifically the limited number of tasks used. It suggests that the authors should include more tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, as it provides a specific direction for improvement that could enhance the robustness and comprehensiveness of the experiments. However, the comment could be more helpful if it explained why the current number of tasks is insufficient or how adding more tasks would benefit the analysis. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. While the comment raises a valid point, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their motivation. The authors are left to infer that they need to provide a clearer explanation or justification for their choice, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this analysis is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity in detailing what needs to be clarified or improved regarding the motivation for analyzing only the last convolutional layer. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the motivation for analyzing only the last convolutional layer, specifically questioning why numerosity would not appear in earlier layers. This is an important point that could impact the clarity and justification of the paper\\'s analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide a clearer explanation. While it identifies a potential weakness, it does not offer actionable steps or examples for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the parameter S remains a problem, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps the authors should consider to improve the parameter setting. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the issue of setting the parameter S, but it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the parameter S setting is problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The comment states that \"How to set the parameter S remains a problem,\" but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the parameter S, indicating that it remains a problem. However, it lacks any further explanation or guidance on how to address this issue or what aspects of the parameter setting are problematic. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful, as it does not provide the authors with any meaningful insights or direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the introduction claims that shape constraints do not require tuning a free parameter, the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be considered a hyperparameter that needs to be chosen or tuned. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that shape constraints do not require tuning a free parameter. The comment points out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction statement about shape constraints not requiring tuning is technically true but misleading. The reviewer provides a logical reasoning by pointing out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This reasoning is based on a logical distinction between constraints and hyperparameters, which is a common understanding in the field. However, the comment could be strengthened by providing specific examples or references to support the claim that these choices should be considered hyperparameters. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential misconception in the introduction regarding the claim that shape constraints do not require tuning a free parameter. It points out that the choice of convex or concave constraints, and increasing or decreasing constraints, can be considered hyperparameters that need to be chosen or tuned. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By clarifying the distinction between constraints and hyperparameters, the comment offers a constructive suggestion that can help the authors improve the clarity and accuracy of their introduction. However, the comment could be more helpful if it provided additional guidance on how to present this information or suggested specific language to use in the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: the limited scope of datasets and models used in the study and the lack of assessment of other important biases and datasets. It also mentions the absence of assessments on state-of-the-art generative models like GPT. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand their dataset and model selection and consider additional biases and generative models. However, the lack of concrete suggestions or detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of the datasets and models used in the study, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on state-of-the-art generative models like GPT. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where datasets and models are discussed. The comment is specific in detailing what is missing or inadequate in the study, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the datasets and models used in the study are limited, specifically mentioning that the bias benchmarks only assess gender, race, and religion. It also notes the absence of assessments on state-of-the-art generative models like GPT. While the comment identifies a limitation, it lacks specific examples or references to support the claim that other important biases and datasets are not measured. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the study, noting that the datasets and models used are limited and do not assess important biases or state-of-the-art generative models like GPT. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should expand their dataset and model selection to include a broader range of biases and generative models. However, the comment could be more helpful if it provided specific suggestions on how to address this limitation or examples of other datasets or models that could be considered. Overall, the comment is mostly helpful as it directs the authors to a significant area for improvement, but it lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies issues with Figure 3, including the unclear workflow and captions, as well as the confusing representation of communication modes on the left side. This provides clear and direct guidance on what needs to be improved, namely the clarity and comprehensibility of the figure. The authors are given specific actions to take, such as revising the captions and the representation of communication modes, to enhance the figure\\'s understandability. The feedback is concrete and provides a clear path for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as the representation of communication modes on the left side. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks specific references or examples to clarify the issues, making it difficult for the authors to address the feedback effectively. Therefore, the claim is considered borderline verifiable, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and the representation of communication modes on the left side is confusing. This feedback is actionable as it provides the authors with a clear understanding of what needs to be improved in the figure, namely the clarity and comprehensibility of the captions and the representation of communication modes. By addressing these issues, the authors can enhance the figure\\'s utility and accessibility to readers. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar figures have been effectively communicated. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly encourages the authors to conduct error analysis and provide detailed explanations of the model's performance under different scenarios. This guidance is clear and specific, giving the authors a direct action to take. The comment also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the importance of error analysis and its role in evaluating model performance and identifying potential issues. It also encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it details the importance of error analysis and its role in guiding subsequent improvements and expansions of the ERC research. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. This claim is somewhat verifiable as it logically supports the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. However, the comment lacks specific examples or references to substantiate the claim fully. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. This feedback is valuable as it highlights the importance of error analysis in evaluating model performance and identifying potential issues, which is crucial for guiding subsequent improvements and expansions of the ERC research. By following this advice, the authors can enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or guidance on how to conduct error analysis or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim their work as preliminary but question the NLP-specific aspects of their approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be revised to better align with an NLP-specific focus. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim made by the authors regarding their work being preliminary and discusses the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspect of the approach is lacking in being NLP-specific. Without clear guidance on where the issue is located or what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors claim their work as preliminary but question the NLP-specific aspects of their approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a discrepancy between the authors\\' claim of their work as preliminary and the lack of NLP-specific aspects in their approach. However, it does not provide any constructive feedback or suggestions on how the authors might address this issue or improve their work. Without actionable advice or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that at least one NCE-based method should be included for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, as it specifies the exact action the authors need to take by including a specific method for comparison. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper should include this comparison or which section would benefit from it. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention the sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including at least one NCE-based method for comparison. It provides a reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This reference supports the claim that including such a method would be beneficial. However, the comment does not provide detailed reasoning or explanation of why this specific method is relevant or how it would enhance the paper. While the reference is a useful starting point, the comment lacks the depth and justification needed to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but not enough detail for the authors to fully understand and act upon the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include at least one NCE-based method for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is somewhat helpful as it identifies a potential gap in the comparison section of the paper. However, the comment lacks depth and does not explain why this inclusion is necessary or how it would enhance the paper. Additionally, it does not provide specific guidance on how to integrate this method into the paper or what aspects to focus on. While the suggestion is actionable, the comment could be more helpful with additional context or explanation. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a clear direction for improvement, it does not specify which specific tests should be conducted or how to conduct them. Additionally, it does not mention which recent LLMs should be compared. While the action is explicit, the lack of concrete details on how to implement the suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the experiment section, specifically mentioning the need for significance tests on human evaluation results and comparing the proposed method with recent LLMs. However, it does not specify which part of the experiment section needs improvement or which specific LLMs should be compared. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting improvements, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these changes would significantly enhance the experiment section. The absence of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and implement the suggested improvements.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiment section, specifically suggesting the inclusion of significance tests on human evaluation results and the comparison of the proposed method with recent LLMs. While the comment provides a clear direction for enhancing the experiment section, it lacks specific guidance on how to conduct these tests or which recent LLMs should be compared. This limits the comment\\'s helpfulness, as it offers actionable suggestions but does not provide detailed instructions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the comparison with SOTA methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the larger-scale datasets. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors can infer that they should consider the impact of dataset size on performance and potentially adjust the comparison with SOTA methods. However, the comment lacks concrete steps or suggestions on how to conduct this adjustment or what specific aspects of the comparison should be revised. Therefore, the comment is somewhat actionable, as it points out an issue but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with SOTA methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison with SOTA methods. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison with SOTA methods may be unfair due to the difference in dataset size. The reviewer provides a logical reasoning by noting that the superiority of the proposed method may be attributed to the larger-scale datasets. However, the comment lacks specific examples or references to support the claim that the dataset size significantly impacts the accuracy. While the reasoning is sound, the absence of detailed evidence or references makes the claim somewhat verifiable. The authors would need to further explore the impact of dataset size on performance to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the paper\\'s performance against SOTA methods. It points out that the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets, such as GEM\\'s 20M unlabeled data. This observation highlights a potential bias in the comparison, as the larger dataset may contribute to the superiority of the proposed method. The comment suggests that the superiority may be due to the larger-scale datasets, which is a relevant consideration for the authors to address. However, the comment could be more helpful by providing specific suggestions on how to adjust the comparison or what aspects of the dataset size should be considered in the analysis. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts, noting that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. However, the comment does not explicitly instruct the authors on how to address this issue or what specific information should be included to clarify the generalizability of these examples. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or examples to address the concern, but the comment lacks concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of the examples of biases and prediction shifts presented in these sections. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents specific examples of biases and prediction shifts but does not provide sufficient information on their generalizability. The comment suggests that while the authors mention the possibility of bias, they do not clarify how general these situations are. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique to address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the presentation of examples of biases and prediction shifts in the paper. It points out that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. This feedback is clear and actionable, as it directs the authors to clarify the generalizability of these examples to enhance the comprehensiveness and applicability of their work. However, the comment could be more helpful if it suggested specific ways to address this issue, such as providing additional context or examples to illustrate the generalizability. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify whether there is any additional novel effort in the section on 3D Gaussians generation, specifically mentioning the previous work by Luciddreamer. This request is clear and provides a direct action for the authors to take, which is to address the issue by either explaining the novelty or providing evidence of additional effort. The comment is specific and provides concrete guidance on what the authors need to do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether there is any additional novel effort in this section. This provides clear guidance on what the authors need to clarify or improve in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the section on 3D Gaussians generation is merely a repetition of previous work, specifically mentioning \"Luciddreamer.\" However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the section on 3D Gaussians generation, specifically questioning whether it is a repetition of previous work. This is a valid point that could help the authors clarify their contribution and differentiate their work from existing literature. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or what additional effort could be made to differentiate their work. While it identifies a potential weakness, it does not offer actionable suggestions or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the focus on DNNs is not relevant to the paper's core focus on detecting drift types and magnitude. The comment implies that the authors should reconsider the content and relevance of this paragraph, but it does not provide specific guidance on how to revise it or what alternative content could be included. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper\\'s focus. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is somewhat verifiable as it logically argues that the introduction of DNNs is not relevant to the paper\\'s core focus on detecting drift types and magnitude. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors may need to infer the relevance of the DNN introduction themselves, which could lead to some confusion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the paper\\'s core focus. This feedback is clear and actionable, as it suggests that the authors should reconsider the relevance and content of this paragraph to ensure it aligns with the paper\\'s central theme. By addressing this issue, the authors can improve the clarity and focus of their introduction, making the paper more effective for its intended audience. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. While the comment implies that the authors should create a simplified version, it does not provide specific guidance on how to achieve this or what aspects of Theorem 2 should be simplified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests presenting a simplified version of Theorem 2, similar to Theorem 1, to make it more accessible to the general audience. However, it does not specify which part of the paper contains Theorem 2 or where the simplified version should be placed. The authors can infer that it relates to the section containing the theorem, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. However, the comment does not provide any reasoning, examples, or references to support why this simplification is necessary or how it would benefit the paper. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. This feedback is somewhat helpful as it identifies a potential issue with the presentation of the theorem, which could improve the clarity and comprehensibility of the paper. However, the comment lacks specific guidance on how to achieve this simplification or what aspects of Theorem 2 should be simplified. While it points out a potential area for improvement, the authors are left with a general suggestion without detailed instructions on how to implement it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of their model. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to implement this suggestion or what aspects of the model might be affected by the change in resolution. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine how to conduct them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by using a larger image resolution, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. This is a valuable suggestion that could provide insights into how the model might perform with different image resolutions. However, the comment lacks depth and does not explain why this change might be beneficial or how it could impact the results. Additionally, it does not offer specific guidance on how to implement this suggestion or what aspects of the model might be affected by the change in resolution. While the suggestion is somewhat helpful, it could be more actionable and comprehensive with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While the comment implies that the authors should add this information, it does not explicitly instruct them to do so or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include this detail. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section, figure, or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting what needs to be added, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While it identifies a potential area for clarification, it lacks specificity and does not provide guidance on how to address this issue or why it is important. The comment is somewhat helpful as it points out a potential gap in the explanation, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that additional experiments on larger datasets would be beneficial but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the concerns were addressed. However, the comment does not explicitly instruct the authors to conduct these additional experiments or provide guidance on how to manage the compute issue. The action is implicit and somewhat vague, as the authors can infer that they should consider conducting additional experiments but are not given specific steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on larger datasets, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment also acknowledges the issue of compute and thanks the authors for their response, but does not provide further details or specificity regarding the compute issue. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting additional experiments and acknowledging the compute issue. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments on larger datasets, which is a suggestion for improvement. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. The comment does not provide specific reasoning or evidence to support why maintaining probabilities might be an issue or how it could be addressed. While it acknowledges the concern, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on larger datasets, which could provide valuable insights into the model's performance and robustness. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address the compute issue or how to design the additional experiments. The feedback is somewhat helpful as it points out a potential area for improvement but lacks detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or specify how this explanation should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation of the bounds. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be provided. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the bounds need explanation or how they should be presented. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this additional explanation is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to effectively explain the bounds or what aspects should be clarified. The comment is somewhat helpful as it points out a potential weakness, but it does not offer actionable advice or detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a specific suggestion to consider using more datasets to ensure rigor. However, the comment does not provide explicit guidance on how to select additional datasets or which datasets to prioritize. While the action is implied, it lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment is specific in its concern about the number and choice of datasets, but it does not explicitly mention which part of the paper this issue pertains to. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a logical reasoning by pointing out that having a limited number of datasets could impact the evaluation's thoroughness. However, the comment lacks specific examples or references to support the claim that some datasets are too large for all algorithms. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment provides a logical reasoning for this concern and highlights the potential impact on the thoroughness of the evaluation. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or methods for evaluating the algorithms. While the comment identifies a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of results with larger models like ResNet101/152, which is a specific action for the authors to take. However, it does not provide guidance on how to conduct these experiments or what specific aspects to focus on. The comment implies that the authors should include results with larger models, but it lacks concrete details on how to implement this action. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of ResNet models on imageNet classification, specifically mentioning ResNet50/34/18 and noting the absence of results with larger models like ResNet101/152. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in identifying the issue of not including results with larger models, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results with larger models like ResNet101/152, but it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to previous studies or benchmarks, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of results with larger models like ResNet101/152. This feedback highlights a potential gap in the paper\\'s evaluation, which could be addressed by including results with these models. However, the comment lacks depth and does not provide suggestions on how to conduct these experiments or what specific aspects to focus on. While it identifies a potential weakness, it does not offer actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the method addresses sparse reward problems and questions whether it can solve sparse-reward tasks as well as other methods (Qmix). However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, or suggesting ways to improve the method's performance in sparse-reward scenarios. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the method and the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the method addresses sparse reward problems and whether it can solve sparse-reward tasks as well as other methods (Qmix). The comment provides a clear direction for improvement by asking for clarification on the method's performance in sparse-reward scenarios. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the method\\'s ability to address sparse reward problems and suggests that the experiments do not support this claim. The reviewer provides a logical reasoning by comparing the proposed method to dense reward signals and sub-task-specific rewards, which could be seen as a way to address sparse reward issues. However, the comment lacks specific examples or references to support the claim that the method does not address sparse reward problems effectively. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the method\\'s ability to address sparse reward problems effectively, based on the experiments presented. It suggests that the proposed method requires sub-task-specific rewards, which is similar to dense reward signals, and questions whether it can solve sparse-reward tasks as well as other methods (Qmix). The comment also includes minor comments that suggest specific areas for improvement. However, the feedback lacks detailed guidance or suggestions on how the authors might address these issues or improve their method. While it identifies potential weaknesses, the comment could be more helpful by providing actionable steps or examples to enhance the draft. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or discussion are confusing. It lacks concrete details on how to improve the clarity or depth of the paper. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies specific issues with the proof of the main results, suggesting that there are confusing mistakes. However, it does not specify which part of the proof is confusing or where the mistakes are located. Additionally, it mentions the lack of a detailed discussion and comparison with previous work, but again does not specify which sections or aspects are missing. The comment also suggests that the paper lacks new insights, but does not provide specific examples or details to support this claim. Overall, the comment is not grounded and lacks specificity, making it difficult for the authors to understand and address the issues. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there are confusing mistakes in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of specific examples or references makes the claim unverifiable, as it does not provide sufficient evidence or justification to support the claims. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed guidance on how to address these issues or what aspects of the proof or discussion are confusing. Without actionable feedback or suggestions for improvement, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique and does not offer constructive feedback for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several issues related to the motivation, experimental results, and comparison of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment does provide some specificity by mentioning the addition of CAT and GAN, which could be used to guide the authors in identifying the relevant sections. Overall, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in detailing the issues. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for using an adversarial network is unclear and that the experimental results are unfair. It also suggests that the proposed model is equipped with a larger CAT and GAN, which could be considered an unfair comparison. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. While it highlights these areas for improvement, the comment does not provide specific suggestions or guidance on how the authors might address these issues. It lacks actionable advice or detailed feedback that could help the authors improve their draft. As a result, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific techniques or approaches to incorporate adversarial loss or explaining why it is necessary. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where this is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the adversarial loss are missing or how it could be incorporated. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is no adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting the absence of adversarial loss to ensure that perturbed data is similar to authentic data. This is a relevant point that could impact the validity and reliability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate adversarial loss. Without actionable advice or detailed explanation, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific methods for tuning hyperparameters or discussing potential strategies for managing variation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameters that need to be tuned, specifically mentioning step size, N, and $\\\\delta t$. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the optimization process, specifically the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample basis. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the potential variation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a concern but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The reviewer is open to changing their rating based on feedback from the authors and comments from other reviewers. While the comment implies that the authors should provide additional analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific analysis required. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the issue of limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for additional analysis, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The comment provides a logical reasoning by pointing out the limited comparison and the need for additional analysis to justify the results. However, it lacks specific examples or references to support the claim that the results violate the motivation. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. This feedback is clear and actionable, as it points out a specific area where the authors need to improve their work. However, the comment could be more helpful if it provided examples of the analysis that should be conducted or suggested specific methods for evaluating the results. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the use of a Jaccard index. This provides a clear and explicit action for the authors to take, as it specifies a specific method for evaluating the support of their solution. The suggestion is concrete, as it directly instructs the authors on how to conduct the comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the use of a Jaccard index. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table where the results are presented. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a comparison using a Jaccard index. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the use of a Jaccard index. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the use of a Jaccard index. This is a clear and actionable suggestion that could provide valuable insights into the effectiveness of the proposed solution. By including this comparison, the authors could demonstrate the strengths and limitations of their approach relative to existing methods. However, the comment could be more helpful if it explained why the Jaccard index is an appropriate metric for this comparison or how it would enhance the paper\\'s contribution. Overall, the comment is mostly helpful as it provides a specific direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the originality of the paper, noting similarities to a previous study. It implies that the authors should address this issue by either explaining how their work differs from the previous study or demonstrating novel contributions. However, the comment does not provide specific guidance on how to do this, such as suggesting ways to differentiate the work or highlighting areas where novelty is present. The action is implicit and somewhat vague, as the authors need to infer that they should address the originality concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the paper, specifically mentioning a previous study, \"How Do Nonlinear Transformers Learn and Generalize in In-Context Learning.\" This provides some grounding by referencing a specific work, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what aspects of the paper are similar to the previous study or how the authors can address the originality concerns. The lack of specificity regarding the issues or suggestions for improvement makes it weakly grounded but specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's originality is questionable due to similarities with a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The mention of a specific study, \"How Do Nonlinear Transformers Learn and Generalize in In-Context Learning,\" suggests that the authors should address the issue of originality, but without further elaboration or evidence, the claim remains somewhat verifiable. The authors would need to conduct their own analysis to fully understand and address the originality concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the paper, noting similarities to a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address the originality concerns. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the very-long-term forecasting task is of limited practical significance and that the discussion requires improvement. It provides a specific action for the authors to take, which is to conduct experiments on more datasets and train the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is explicit and provides concrete steps for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of the very-long-term forecasting task being of limited practical significance and suggests that the discussion requires improvement. However, it does not specify which part of the paper discusses this task or the specific aspects that need improvement. The authors can infer that it relates to the discussion section, but the comment lacks full grounding as it does not explicitly mention the section. Additionally, while it suggests conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon, it does not provide detailed guidance on how to implement these improvements. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the very-long-term forecasting task is of limited practical significance and suggests that the discussion requires improvement. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the limited practical significance of the very-long-term forecasting task. It suggests that the discussion requires improvement by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in context. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the discussion section of their paper. However, the comment could be more helpful if it elaborated on why the current discussion is insufficient or how the suggested improvements would enhance the paper\\'s contribution. Overall, the comment is mostly helpful as it guides the authors toward a meaningful revision of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these analyses to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"strong empirical results\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the potential contribution of finding out the reasons behind the empirical results through theoretical analyses or experiments. However, the comment lacks specificity regarding what kind of theoretical analyses or experiments would be needed to address the issues raised. It suggests exploring the reasons behind the outperformance of simple greedy selection and deterministic MLP predictors, but does not provide detailed guidance on how to conduct these analyses or what specific aspects to focus on. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. The comment provides a logical reasoning that these analyses could be beneficial, but it lacks specific examples or references to support the claim that these analyses are missing from the paper. The suggestion is somewhat verifiable, as it provides a rationale for the need for these analyses but does not fully substantiate the claim with detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is clear and actionable, as it points out a specific gap in the paper that could enhance its contribution and rigor. However, the comment could be more helpful if it provided examples of what kind of analyses or experiments would be beneficial or how they could be conducted. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or methods to ensure privacy protection. As a result, the authors are left without a clear understanding of what steps to take to improve their draft in this area. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of analysis on the security (protection of privacy) of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the analysis should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of security analysis, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant gap in the paper, noting that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. This is a critical oversight that could impact the overall robustness and trustworthiness of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending particular analyses or methods to ensure privacy protection. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the multi-scale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer suggests that the only benefit is the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the statement, it does not provide explicit guidance on how the authors should address this misleading aspect. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the time scales involved and possibly revise the statement to be more accurate. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-scale statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, explaining that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The comment further suggests that the only benefit is the reduction of gradient path by the slow RNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the multi-scale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer supports this claim by explaining the distinction between physical and logical time scales and the potential benefit of reducing gradient path by the slow RNN. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. As it stands, the comment is mostly verifiable, as it provides a logical explanation but lacks specific references or detailed evidence to fully support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential misleading aspect in the paper regarding the multi-scale statement. It points out that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and understanding of the work. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this aspect or rephrase the statement to be more accurate. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. It also points out that the framework seems not to be limited to raw-level selection, as evidenced by the discussion in Section 4. The comment provides a clear direction for the authors to consider incorporating representation learning into the feature selection process in Section 4.2. This feedback is explicit and concrete, as it specifies the exact area that needs improvement and how to address it. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167-174, Sec. 4,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue with the proposed invariant learning module, suggesting that it could be improved by considering representation learning. Additionally, it provides a specific suggestion for improvement by mentioning the appendix, where representation learning is discussed. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed invariant learning module focuses on mask selection and raw-level features, while the framework discussed in Section 4 seems not to be limited to raw-level selection. The reviewer suggests that the feature selection in Section 4.2 could be improved by considering representation learning, which is currently discussed in the appendix. The comment provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that representation learning would improve the feature selection process. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the proposed invariant learning module, suggesting that it could be enhanced by considering representation learning. It points out that the framework discussed in Section 4 seems not to be limited to raw-level selection, as evidenced by the discussion in the appendix. This feedback is clear and actionable, providing the authors with a concrete direction for improving their work. By suggesting that the feature selection process in Section 4.2 could be improved by incorporating representation learning, the comment offers a valuable suggestion that could significantly enhance the paper. However, it could be more helpful if it provided additional details or examples on how to implement this suggestion. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the quality of paraphrases generated for training data, specifically noting that the paraphrases need to be sufficiently different from the original sentences. It suggests that this impacts the subsequent steps in the process, as the model relies heavily on the quality of these paraphrases. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to ensure the paraphrases are sufficiently different. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the process of generating paraphrases for training data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear paraphrases and how this impacts the quality of the final training data. The comment provides a clear rationale for the concern, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paraphrases generated for training data are unclear and impact the quality of the final training data. This claim is supported by logical reasoning, as it explains how the paraphrases' similarity to the original sentences affects the model's reliance on them. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of paraphrase quality in training data. As it stands, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the quality of paraphrases generated for training data, noting that the paraphrases need to be sufficiently different from the original sentences to ensure the model's reliance on them. This is a crucial point that could significantly impact the quality of the final training data and the overall success of the project. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to ensure that the paraphrases are sufficiently distinct from the original sentences. However, the comment could be more helpful if it offered specific guidance on how to measure the difference between paraphrases and original sentences or suggested ways to improve the paraphrasing process. Overall, the comment is mostly helpful as it highlights a critical issue and provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should verify the effectiveness and universality of the Flipped-QA framework beyond LLM-based models, specifically mentioning HiTeA and InternVideo as examples. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable. The authors can infer that they need to conduct additional experiments to verify the framework\\'s effectiveness and universality, but the comment lacks concrete details on how to implement this action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Flipped-QA framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to verify the effectiveness and universality of the framework beyond LLM-based models. The comment provides a clear direction for the authors to expand their experimental evaluation to include non-LLM-based models like HiTeA and InternVideo. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Flipped-QA framework is a general framework for various generative VideoQA models but is only applied to LLM-based models. The reviewer suggests that verifying its effectiveness and universality to non-LLM-based models like HiTeA and InternVideo would be beneficial. While the comment provides a logical reasoning for the need to expand the application of the framework, it lacks specific examples or references to support the claim that other models are not effectively utilizing the framework. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, specifically the narrow application of the Flipped-QA framework to LLM-based models. It suggests that verifying the effectiveness and universality of the framework to non-LLM-based models like HiTeA and InternVideo would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental evaluation and demonstrate the generalizability of their framework. By addressing this suggestion, the authors can enhance the robustness and applicability of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address these concerns to improve the paper. However, it does not provide specific guidance on how to address these concerns or what aspects of the method should be improved. The mention of existing methods and references to Clopper-Pearson intervals and Gaussian elimination suggest that the authors should provide more detailed explanations or comparisons to these methods. However, the comment lacks concrete steps or suggestions on how to enhance the theoretical novelty or address the concerns. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the methodology and its theoretical novelty, specifically mentioning the use of existing methods like Clopper-Pearson intervals and Gaussian elimination. However, it does not specify which part of the paper this critique is based on, such as the methodology or theoretical sections. The authors can infer that it relates to the methodology or theoretical aspects, but this inference is not as direct as it could be. The comment is specific in detailing the concerns about the lack of theoretical novelty, but it lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer provides references to Clopper-Pearson intervals and Gaussian elimination, suggesting that the method is not original. However, the comment does not provide detailed reasoning or examples to support why these existing methods are insufficient or how the proposed method could be improved. The references are provided as a basis for the claim, but the lack of detailed justification or explanation makes the claim somewhat verifiable. The authors would need to further explore and address the concerns raised by the reviewer to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern about the novelty of the proposed method, noting that it primarily builds upon existing methods like Clopper-Pearson intervals and Gaussian elimination. This is a critical observation that could impact the paper\\'s impact and originality. However, the comment lacks specific guidance on how the authors might address this concern or what aspects of the method could be improved to demonstrate greater originality. While it points out a potential weakness, it does not provide actionable advice or suggestions for improvement, making it somewhat helpful. The authors are left with a general understanding of the issue but without clear steps to resolve it, which limits its utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks explicit or implicit actions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the concatenation of text input by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the concatenation process, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the concatenation of text input by the four text elements of an object. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the concatenation of text input by the four text elements of an object. While it highlights a potential area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the concatenation process might be improved. Without actionable feedback or context, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide a stronger motivation for why the topic is important. However, it does not specify what kind of motivation is needed or how it should be presented. The authors are left to infer that they need to include a motivation section, but without concrete guidance on what aspects to focus on or how to structure it, the action remains vague. Therefore, this comment is somewhat actionable, as it identifies a potential area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not specify which part of the paper this issue pertains to, such as the introduction or the sections where the topic is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what kind of motivation is needed or how it should be presented. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this motivation or what aspects of the paper need to be revised. Without actionable advice or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. While the suggestion is clear, it lacks specific guidance on how to conduct these experiments or what specific aspects of the C2D method should be tested on these datasets. The authors are left to infer that they should conduct these experiments, but without detailed instructions on how to implement them, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention which part of the paper should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the method. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This is a clear and actionable suggestion that could enhance the robustness and generalizability of the method. However, the comment lacks specific guidance on which aspects of the C2D method should be tested or how these experiments should be designed. While it points to a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but requires further elaboration to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of essential visualization of intermediate processes and comparisons, which is a clear indication of an area that needs improvement. However, it does not provide specific guidance on what types of visualizations or comparisons are missing or how they could be incorporated into the paper. The authors are left to infer that they need to add visualizations and comparisons, but without concrete suggestions on what to include or how to present them, the action remains vague. Therefore, this comment is somewhat actionable, as it points out an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of essential visualization of intermediate processes and comparisons, which is a specific issue related to the presentation of the paper. However, it does not specify which parts of the paper should include these visualizations or comparisons, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the need for visualization and comparison, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it highlights a gap in the presentation of the paper that could enhance its clarity and understanding. However, the comment could be more helpful if it provided suggestions on what types of visualizations or comparisons would be beneficial or how they could be incorporated into the paper. Despite this, the comment still offers valuable insights that can guide the authors in improving their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could impact the significance of the result. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The authors are left to infer that they might need to reconsider the importance of their result in light of the external work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the iteration complexity in Theorem 3 is no longer dimension-free, which is a clear concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could impact the significance of the result. However, the comment does not provide specific examples or detailed reasoning from the external work to support the claim that the result is not surprising or significant. While the reference to [15] provides some context, the comment lacks sufficient evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the concern but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could impact the significance of the result. While the comment identifies potential weaknesses in the paper\\'s contribution, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. It explicitly states that resolving this issue would influence the reviewer\\'s rating. While the comment does not provide specific guidance on how to address this issue, it implies that the authors should investigate the robustness of their results to different hyperparameter settings. The action is implicit but concrete, as the authors can infer that they need to assess the sensitivity of their results and consider different hyperparameter choices. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"empirical results\" and the \"hyperparameter choices,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of sensitivity to hyperparameter choices and the potential impact on the method\\'s effectiveness. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. This claim is somewhat verifiable as it highlights a potential issue with the robustness of the results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer suggests that resolving this issue would influence their rating, indicating a need for more detailed analysis or evidence to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the robustness of the empirical results, specifically the sensitivity to hyperparameter choices. It highlights the potential impact of incorrect choices on the effectiveness of the method, which is a crucial consideration for the authors. The comment explicitly states that resolving this issue would influence the reviewer\\'s rating, providing a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it offered specific guidance on how to assess the sensitivity or how to make more robust choices for hyperparameters. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation of their method's novelty and contribution, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they need to provide a more detailed explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to address the issue of novelty and contribution, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work is similar to existing attack methods on a surrogate model, suggesting that the novelty and contribution of the proposed method are not adequately addressed. However, the comment does not provide specific examples or references to existing methods, making it difficult for the authors to understand the exact nature of the similarity. Without detailed comparisons or references, the claim lacks sufficient evidence to be fully verifiable. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some support but requires more detailed evidence or references to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the proposed method is similar to existing attack methods on a surrogate model. It suggests that the authors need to further claim the novelty and contribution of their method to differentiate it from existing work. While the comment highlights an important area for improvement, it lacks specific guidance on how the authors might effectively demonstrate the novelty and contribution of their method. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides two ways to strengthen the experiment: by either using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. While the comment provides some guidance on how to address the issue, it lacks specific instructions on how to implement these suggestions. The action is explicit but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, which relies on pseudo feature importance due to the unavailability of true feature importance. The comment provides specific guidance on how to strengthen the experiment by suggesting two ways: using a different method to estimate true feature importance or providing a more detailed explanation of the perturbation value. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment relies on pseudo feature importance due to the unavailability of true feature importance. It suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The reviewer provides a logical reasoning by explaining the potential issue with the experiment's reliance on pseudo feature importance and suggests ways to strengthen it. However, the comment lacks specific examples or references to Proposition 3.2 or the perturbation value, which would enhance the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests two ways to strengthen the experiment: by using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. This feedback is clear and actionable, as it offers concrete suggestions for improving the experiment\\'s reliability and validity. By addressing these points, the authors can enhance the robustness and credibility of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that non-convexity may not be an issue for the SGD to converge if the function Z has certain properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific properties of Z should be considered or how to address the issue of non-convexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ln. 182--184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies the issue of non-convexity and suggests that it may not be a problem if the function Z has certain properties. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that non-convexity may not be an issue for the SGD to converge if the function Z has certain properties. However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific line in the paper (ln. 182--184) and suggests that non-convexity may not be an issue for the SGD to converge if the function Z has certain properties. While this feedback highlights a potential issue, it lacks depth and does not provide specific guidance or examples of what properties of Z would be beneficial for convergence. The comment could be more helpful if it offered suggestions on how to explore or test these properties, or if it provided references to similar studies or literature. As it stands, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of proper experimental settings and the absence of code. While it points out the importance of result reproducibility, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to include experimental settings and provide the code, but the comment lacks concrete details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental settings\" and the absence of \"code,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of proper experimental settings and the provision of code to ensure result reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings are not mentioned properly and that the result reproducibility is critical. It also notes the absence of code, which is a significant concern. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of these issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experimental settings and result reproducibility, noting that the provided information is insufficient. It highlights the absence of code, which is a significant concern for ensuring result reproducibility. However, the comment does not provide specific guidance on how to address these issues or what additional information should be included. While it points out a significant problem, it lacks actionable suggestions or detailed feedback to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. However, it does not provide any guidance on how the authors should address this issue or what specific actions they should take to support their claim. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the slight improvement reported in these tables and the claim about the effectiveness of the proposed prompts. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the slight improvement reported in Tables 6 and 7 does not support the claim that experimental results prove the effectiveness of the proposed prompts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the slight improvement reported in Tables 6 and 7 and the claim that experimental results prove the effectiveness of the proposed prompts. This is a critical observation that could impact the validity of the authors\\' claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental design to better support their claims. Without actionable feedback or specific advice, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, as it points out a potential problem but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the analysis, specifically the alignment of features at different spatial locations to the same channel. It suggests that there could be many different designs for this analysis, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they need to explore different designs or variations, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. However, it does not specify which part of the paper this analysis is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment does provide a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes, which adds some level of specificity. However, without explicit references to sections or figures, the comment remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of Cycle FC align features at different spatial locations to the same channel is insufficient. However, it does not provide any specific examples, reasoning, or references to support this claim. The suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes, is vague and lacks detail. Without concrete evidence or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. It provides a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes. This feedback is somewhat helpful as it points out a potential area for improvement and offers a direction for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or what specific aspects of the analysis should be expanded. Overall, the comment offers some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the feature extractor used for dimensionality of each region, specifically asking about the feature extractor used in line 201. This is an explicit question that directly asks for clarification, providing a clear action for the authors to take. However, it does not offer specific guidance on how to address the issue or what information should be included in the response. The action is explicit but somewhat vague in terms of detail, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the feature extractor used for dimensionality, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the feature extractor used for dimensionality in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the feature extractor used for dimensionality in line 201. This is a clear and actionable point, as it prompts the authors to clarify an important aspect of their methodology that could impact the understanding and reproducibility of their work. By addressing this question, the authors can improve the clarity and transparency of their paper, which is valuable feedback. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information in the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not provide specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. The comment lacks concrete details or suggestions on how to enhance the explanation, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a clearer explanation of the motivation, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically the clarity of the motivation behind applying CMD in federated learning. It suggests that the motivation could benefit from a more explicit demonstration or explanation. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to enhance the clarity or what aspects of the motivation should be emphasized. This limits the comment\\'s usefulness, as it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform and suggesting that comparisons to UNets are necessary. While the comment identifies a potential issue with the model, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should make comparisons to UNets, but the comment lacks specific instructions on how to conduct these comparisons or what aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"fractional transform\" and \"UNet part,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the contribution of the UNet part in the fractional Fourier domain and suggests comparisons to UNets, which are necessary to understand the performance boost. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the contribution of the UNet part in the fractional Fourier domain and suggests that comparisons to UNets are necessary to understand the performance boost. The reviewer provides a logical reasoning by pointing out that UNets have shown strong performance on regular gridded domains, as evidenced by references to Raonic et al and Gupta et al. However, the comment lacks specific examples or detailed comparisons to UNets, which would strengthen the argument. Therefore, the claim is somewhat verifiable, as it provides a logical basis but could be further substantiated with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform. It suggests that comparisons to UNets are necessary to understand the performance boost, as UNets have shown strong performance on regular gridded domains. This feedback is somewhat helpful as it points out a potential area for improvement and provides a rationale for why comparisons to UNets are important. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. It also implies that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived marginality or how to improve the contribution. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as the methods or the stage where they are used. This lack of specificity makes it difficult for the authors to pinpoint the exact sections that need improvement or clarification. Additionally, the comment does not provide specific guidance on how to address the issue of marginality or what changes could be made to enhance the contribution. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific methods or stages where the methods are demonstrated, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contribution of the paper is marginal, as the methods used in different stages are well-designed and demonstrated. It also implies that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. While the comment identifies a potential weakness in the contribution, it lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might address the marginality or enhance the contribution, such as by providing additional context or examples. As a result, the comment is somewhat helpful, as it points out a potential issue but does not offer detailed feedback for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment implies that the authors should consider including more details about these experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should provide more information but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it does not specify which part of the paper the Appendix is attached to, making it weakly grounded. The comment also mentions the Brusselator as an example of an additional experiment, but it does not specify which part of the Appendix this experiment is discussed in. This lack of specificity makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual statement about the Appendix and its content. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment appreciates the inclusion of a comprehensive Appendix, which provides additional detail about parts of the paper. However, it acknowledges that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment highlights a potential area for improvement by suggesting that the authors should consider including more details about these experiments in the main text, it does not provide specific guidance or suggestions on how to do so. This limits the comment\\'s helpfulness, as it points out an area for improvement but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the authors\\' claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer implies that the description could be misleading if the two methods are not the same. However, the comment does not provide explicit guidance on how the authors should clarify this distinction or what specific changes should be made to the description. While the action is implied, it is not concrete, as the authors are left to infer the necessary steps to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\\' claim of using active learning and asks for clarification on whether the \"active learning pipeline\" method is the same as traditional active learning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of using active learning in step 2, specifically asking whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer provides a logical reasoning by pointing out that the description could be misleading if the two methods are not the same. However, the comment lacks specific examples or references to support the claim that the methods are different. This makes the claim somewhat verifiable, as the authors would need to further investigate and clarify the distinction themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the authors\\' claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. This is an important clarification that could impact the readers\\' understanding of the methodology and its applicability. The comment prompts the authors to clarify this distinction, which is crucial for ensuring the accuracy and clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the distinction or examples of how the two methods differ. Overall, the comment is mostly helpful as it identifies a critical area for clarification and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights an issue with the experimental methodology, specifically regarding the use of the 300W-LP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use this dataset in their training. The reviewer questions whether 300W-LP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This comment implies that the authors should clarify the use of the 300W-LP dataset in their experiments and address the potential bias. However, it does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to clarify the dataset usage, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental methodology and the use of the 300W-LP dataset. It specifies the issue by pointing out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300W-LP dataset in their training. The comment also raises a question about whether 300W-LP is used in all experiments or just some, and whether this could provide an unfair advantage to the proposed method. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the experimental methodology, specifically questioning the use of the 300W-LP dataset. The reviewer points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300W-LP dataset in their training. This observation is based on a logical inference and is not a subjective claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental methodology, specifically regarding the use of the 300W-LP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300W-LP dataset in their training. This inconsistency raises questions about the fairness of the experiments and whether the proposed method has an unfair advantage. The comment highlights a critical area for clarification and potential bias, prompting the authors to address this issue in their draft. However, the comment could be more helpful if it provided specific suggestions on how to clarify the dataset usage or how to mitigate potential bias. Overall, the comment is mostly helpful as it identifies a critical area for improvement but lacks detailed guidance on how to address it fully.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the technique should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying potential issues with the novelty of the technique, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any evidence, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. While it identifies a potential issue with the novelty of the algorithm, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the novelty of their work. The comment is somewhat helpful as it points out a potential weakness, but it does not offer actionable advice or detailed feedback for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the authors\\' understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It also points out that the authors\\' formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their assumptions about the observations and their aggregation process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the integral in Equation (1)\" and references specific works, \"Law et al., NeurIPS\\'18\" and \"4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the authors\\' formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the integral in Equation (1) corresponds to the bag observation model in [Law et al., NeurIPS\\'18] or the spatial aggregation process in [4]. The reviewer provides references to these works, which supports the claim by referencing established models and processes. However, the comment lacks detailed explanation or analysis of how these references relate to the integral in Equation (1) or the authors\\' formulation. While the references provide some context, the comment could be strengthened by further elaboration on the implications of these references for the authors\\' work. Therefore, the comment is somewhat verifiable, as it provides some support but lacks detailed justification or explanation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It points out that the authors\\' formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. The comment provides a clear and actionable suggestion for the authors to reconsider their assumptions about the observations and their aggregation process. However, it could be more helpful if it offered specific guidance on how the authors might address this issue or what alternative aggregation methods might be considered. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a direction for the authors to explore.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the comprehensiveness of the experimental analyses and the method itself, noting that the focus is primarily on the presentation of results. It suggests that the authors should provide more detailed analyses of the method and its performance, particularly in light of the baseline's underperformance. While the comment does not explicitly instruct the authors to conduct these analyses, it clearly implies that they should do so to address the issue. The action is implicit but concrete, as it specifies what additional analysis is needed. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"majority of the experiments\" and the \"analyses of the method itself and the experimental outcomes,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the analyses are not comprehensive enough and questioning the extent to which the performance improvement can be attributed to the authors\\' claim. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the majority of the experiments focus on the presentation of results and that the analyses of the method and experimental outcomes are not comprehensive enough. It questions the extent to which the performance improvement attributed to the authors\\' method can be attributed to their claim of \"moving code-switched pretraining from the word level to the sense level.\" The comment provides some logical reasoning by pointing out the underperformance of the baseline and suggesting that the authors should provide more detailed analyses to substantiate their claims. However, it lacks specific examples or references to support the claim about the baseline's underperformance, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the majority of the experiments focus on the presentation of results rather than comprehensive analyses of the method and experimental outcomes. It highlights the underperformance of the baseline and questions the extent to which the performance improvement attributed to the authors\\' method can be attributed to their claim. This feedback is valuable as it prompts the authors to reconsider the depth and comprehensiveness of their analyses, which is crucial for substantiating their claims and demonstrating the significance of their work. However, the comment could be more helpful if it provided specific suggestions on how to improve the analyses or what additional information should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical results do not have immediate practical implications, but acknowledges that this is understandable given the novelty of the work. It also expresses a desire for more practical takeaways for practitioners. The reviewer mentions a specific take-away point, which is to query a cluster proportionally to the square root of its size, but questions whether this is a novel finding in the paper. While the comment provides some guidance on what the authors might consider for practical applications, it lacks concrete suggestions on how to incorporate these ideas or what specific changes could be made to enhance the practical relevance. The action is implicit and somewhat vague, as the authors need to infer that they should consider practical applications and provide more take-away points. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and their practical implications, suggesting that the theoretical findings do not have immediate practical applications. It also mentions a specific take-away point regarding querying a cluster proportionally to the square root of its size. However, the comment does not specify which part of the paper discusses the theoretical results or the take-away points, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for more practical takeaways and the question about the novelty of the take-away point. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical results do not have immediate practical implications, which is a subjective observation. The reviewer acknowledges the novelty of the work but suggests that more practical takeaways should be provided. The comment provides a specific example of a take-away point, which is to query a cluster proportionally to the square root of its size, but questions whether this is a novel finding in the paper. However, the comment lacks detailed reasoning or references to support the claim that this finding is not novel. The suggestion for more practical takeaways is somewhat valid, but the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the theoretical results of the paper, noting that they do not have immediate practical implications. It acknowledges the novelty of the work but suggests that more practical takeaways should be provided for practitioners. The comment provides a specific example of a take-away point, which is to query a cluster proportionally to the square root of its size, but questions whether this is a novel finding in the paper. This feedback is somewhat helpful as it highlights a potential area for improvement and provides a specific example of a take-away point. However, it could be more helpful if it offered additional suggestions on how to enhance the practical relevance of the results or how to present them in a more accessible manner. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. While the comment implies that the authors should provide more information or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details or clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of separators and what additional information they provide beyond T/I/O. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This is a request for clarification and does not make a subjective claim or express an opinion. It is a factual inquiry seeking more information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This feedback is somewhat helpful as it prompts the authors to clarify the role of separators in their work, which could enhance the understanding and clarity of their methodology. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional experiments or explanations. While it points out a potential area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from using longer video sequences, such as 16 frames, to address issues with inconsistent motion, changing color, or object disappearing over time. It also mentions that running the LSTM over many time steps could be interesting. While the comment implies that the authors should consider these changes, it does not provide explicit instructions or concrete steps on how to implement them. The authors are left to infer that they should explore longer video sequences, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the synthesized results for UCF-101, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with inconsistent motion, changing color, or object disappearing over time and suggests using longer video sequences. Additionally, it provides a positive assessment of the paper, noting its interesting idea and extensive experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the synthesized results for UCF-101 exhibit inconsistent motion, changing color, or object disappearing over time. It proposes using longer video sequences (e.g., 16 frames) to address these issues. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or detailed evidence to fully substantiate the claim. The authors would need to infer the exact nature of the issues and how they might be resolved, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a positive assessment of the paper, noting its interesting idea and extensive experiments. It also identifies specific issues with the synthesized results, such as inconsistent motion, changing color, or object disappearing over time. The comment suggests that using longer video sequences (e.g., 16 frames) could address these issues. While the feedback is clear and actionable, it could be more helpful if it provided more detailed guidance on how to implement the suggested changes or what specific aspects of the results are problematic. Overall, the comment is mostly helpful as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. While it does not explicitly instruct the authors to provide this information, the question implies that the authors should include this analysis in their paper. The action is implicit but concrete, as the authors can infer that they need to include this information to address the reviewer\\'s concern. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment poses a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this information should be addressed. Additionally, the comment lacks specificity regarding what aspects of the insurance costs should be analyzed or how the method affects them. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a specific question about the impact of the method on insurance costs for men and women. This is a clear and actionable request for additional information that could help the authors better understand the practical implications of their work. By addressing this question, the authors could provide more comprehensive and relevant information about their method\\'s real-world applications. However, the comment does not offer suggestions on how to present this information or what specific aspects to focus on. While it identifies a relevant area for improvement, it lacks depth and guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October, suggesting that the authors should consider this issue in their paper. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the availability of papers on arxiv. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of splitting papers according to their publication years on the ACL anthology, noting that many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October. However, the comment does not specify which part of the paper discusses the splitting of papers, making it weakly grounded. The comment is specific in pointing out the issue of papers being available on arxiv before being published in the ACL anthology. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. The reviewer provides an example of the BERT paper being available on arxiv in October, which supports the claim. However, the comment could be strengthened by providing more examples or detailed reasoning on why this issue is significant. As it stands, the claim is somewhat verifiable, as it relies on a specific example but lacks comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s methodology, noting that it splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. This is a relevant observation that could impact the paper\\'s credibility and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as discussing the implications of this discrepancy or suggesting ways to improve the paper\\'s timeliness. While it points out a potential weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises two concerns: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to clarify the use of \u03b2 and the difference between QRS and RS, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the proposed relaxation of rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. The comment provides a clear direction for improvement by suggesting that the authors clarify the use of \u03b2 and the difference between QRS and RS. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the use of an arbitrary parameter \u03b2 in rejection sampling and questions the lack of clarity regarding the difference between QRS and RS in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should have used Importance sampling instead of rejection sampling. Additionally, the comment lacks specific examples or detailed explanations to support the claim about the difference between QRS and RS. As a result, the claim is not verifiable, as it does not provide sufficient evidence or justification for the authors to understand or address the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. However, it does not provide any explicit guidance or suggestions on how the authors should address this confusion or clarify their terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider their terminology. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \"non-sequential information such as chunks,\" suggesting that the term \"chunks\" might be considered sequential information. This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the phrase \"non-sequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. This question highlights a potential confusion in the paper that could be clarified to improve the clarity and coherence of the text. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their terminology. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). It suggests that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous papers. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to enhance the novelty of their work. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and comparing the paper to the mentioned papers, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The comment provides a specific comparison with the papers, noting that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous works. This comparison provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific sections of the papers that support the comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it lacks technical novelty and is similar to two mentioned papers (Xing and Tsang, 2022a, b). It provides a specific comparison with the papers, highlighting the similarities in the idea, co-attention mechanism, and architecture. This feedback is somewhat helpful as it points out an area where the paper could be improved by differentiating itself from existing work. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the novelty of their work. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the problem being discussed is specific to binding affinity prediction or applies to other downstream tasks. It implies that the authors should provide a justification for why the problem is specific to binding affinity prediction. However, the comment does not explicitly instruct the authors to provide this justification or specify how it should be presented. While the action is implied, it is not concrete, as the authors are left to infer what additional information is needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the problem to other downstream tasks or whether it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a justification or explanation of why the problem is specific to binding affinity prediction. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. This is a relevant point that could prompt the authors to clarify the scope and limitations of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific aspects of the computation cost or running time should be compared, nor is there any suggestion for how the authors might address this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost or running time should be compared or how the authors might address this issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the comparison in terms of computation cost or running time, but it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the comparison in terms of computation cost or running time, which could be an important aspect of the paper. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what aspects of the computation cost or running time should be compared. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes should be made to the tables. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3\" and lines 247-252, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the division of tables into three types and suggests that one type (the column header) should work. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any supporting evidence, reasoning, or references to justify why this division is problematic or how it could be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any actionable feedback or suggestions for improvement. Without additional context or guidance, the authors are left without a clear understanding of what changes, if any, should be made to address this concern. As a result, the comment is not helpful, as it lacks depth and does not offer constructive feedback for the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment implies that the authors should clarify these differences, it does not provide specific guidance on how to do so or what aspects of the task should be clarified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to clarify the differences against Argument Mining/Discussion Summarization, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the task described in the paper is closer to Argument Mining rather than Summarization. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks detailed justification or examples to explain why the task is similar to Argument Mining or how it differs from Summarization. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment identifies a potential issue with the task categorization, it lacks specific guidance on how to clarify these differences or what aspects of the task should be emphasized. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the specific definition of the sparsity of the residual term in the paper. It suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of the proposed method with existing methods. While the comment implies that the authors should provide evidence and comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the definition and suggesting that evidence is needed to support the sparsity assumption across various noisy cases. Additionally, it asks for a comparison with existing methods to highlight the advantages of the proposed method. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests that evidence is needed to support the sparsity assumption across various noisy cases. The reviewer also implies that a comparison with existing methods is necessary to highlight the advantages of the proposed method. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the sparsity assumption is unclear or that evidence is needed. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests that evidence is needed to support the sparsity assumption across various noisy cases. Additionally, it implies that a comparison with existing methods is necessary to highlight the advantages of the proposed method. While the comment provides a clear direction for improvement by suggesting the need for evidence and comparisons, it lacks specific guidance on how to present this evidence or what specific aspects to focus on. This limits the comment\\'s helpfulness, as it points out an important area for improvement but does not offer detailed guidance on how to achieve it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the models and datasets used are too toy-like and recommends using CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also asks if there are foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides specific recommendations for datasets and models, it lacks concrete guidance on how to implement these changes or what specific aspects of the language tasks should be addressed. The action is explicit but somewhat vague, as the authors know what changes to make but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for CIFAR100, ResNet 34 or 50, and ViT-tiny or small, and raises questions about language tasks. However, the comment does not provide specific guidance on how to address these issues or what aspects of the language tasks should be considered. Therefore, it is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the models and datasets used are \"toy-like\" and suggests that the authors should consider using CIFAR100, ResNet 34 or 50, and ViT-tiny or small. The reviewer also asks about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides a logical reasoning for the need for more diverse datasets and models, it lacks specific examples or references to support the claim that the current models are too toy-like. The suggestion to use CIFAR100 is a specific example, but the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks sufficient evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the models and datasets used in the paper, noting that they are too toy-like and suggesting the inclusion of more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also raises a question about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides clear and actionable feedback on improving the dataset and model selection, it could be more helpful if it offered specific guidance on how to address the language task challenges or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it directs the authors to make significant improvements in their work, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of comparison against baselines and notes that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. It suggests that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison (or codesearch). While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include comparisons against baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer specific steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison against baselines and the need for architecture-agnostic similarity comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparison against baselines and that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. The reviewer supports this claim by referencing the widely-understood nature of binary analysis applications and the existence of architecture-agnostic similarity comparison (or codesearch) in many papers. This provides a logical basis for the claim, but the comment could be strengthened by providing specific examples or references to these papers. Therefore, the comment is somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of comparison against baselines and the limited scope of the functionality similarity comparison study. It highlights that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison (or codesearch). This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific suggestions on how to address this gap, such as which baselines to consider or how to implement the suggested architecture-agnostic similarity comparison. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to expand the contribution or what specific aspects of the paper could be strengthened. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention or improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment lacks specific reasoning or evidence to support why the contribution is considered limited. It does not provide examples, comparisons, or references to similar work that might substantiate the claim. Without additional context or justification, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any specific feedback or suggestions on how the authors could enhance the contribution or what aspects of the paper could be improved. The comment lacks actionable guidance or detailed critiques, leaving the authors without clear direction on how to strengthen their work. As a result, the feedback is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The reviewer also mentions that the authors acknowledge this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the proof technique and its applicability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. The reviewer provides a specific reference to Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This reference provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential problem, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. While the comment explicitly states the action to take, it lacks concrete guidance on how to implement this change or why it is necessary. The authors are left to infer that they should make this change to enhance clarity, but without specific instructions or examples, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of \"t\" in the kernel and the suggestion to replace it with the size of T to improve clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. However, the comment does not provide any reasoning or evidence to support why \"t\" is unclear or why replacing it with the size of T would improve clarity. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement to the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of T. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the readability and understanding of the methodology. However, the comment could be more helpful if it explained why \"t\" is unclear or why the change would improve clarity. Despite this, the suggestion is valuable and offers a straightforward way for the authors to improve their draft, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it does not explicitly instruct the authors to make a specific change or provide guidance on how to address this question, it does prompt the authors to consider the implications of these assumptions and the potential differences between them. The action is implicit but concrete, as the authors can infer that they need to explore the implications of these assumptions and potentially make a change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these assumptions are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry about the difference between these distributions, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it highlights a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this question or what the implications of these assumptions might be. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, it is rated as barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. However, it does not offer any specific guidance or suggestions on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification about the section. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the intent of this section, indicating that the authors need to clarify or provide more context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the intent of Section 5.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The comment is somewhat helpful as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, which is a specific solver. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the draft. The authors are left to infer that they need to improve the approach's universality and adaptability, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but not detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the proposed approach for learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in detailing what needs to be addressed, such as the need for universality and adaptability. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. The comment provides logical reasoning by explaining the limitations of current operator learning methods compared to specialized numerical solvers, suggesting that the proposed approach needs to be more universal and adaptable. However, the comment lacks specific examples or references to support the claim about the limitations of current operator learning methods. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the proposed approach, noting that it is merely learning a surrogate model for solving linear/linearized systems arising in FEM. It highlights the need for careful choice of basis functions and meshes and points out that the approach heavily relies on FEniCS, a specific solver. The comment suggests that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal and do not need to be adapted to specific PDEs. While the comment provides a clear critique of the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve the universality and adaptability of their method. The feedback is somewhat helpful as it points out a potential weakness but does not offer actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. It acknowledges that the clarification is provided in the conclusion but does not specify how the authors should address this issue. The comment lacks explicit guidance on how to clarify the target or what specific changes are needed to improve the clarity. As a result, the authors are left without clear instructions on how to improve the draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. However, it does not specify which part of the paper this confusion arises from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does not provide specific guidance on how to address this issue, such as suggesting where the clarification should be added or what aspects of the paper are unclear. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. The reviewer acknowledges that the clarification is provided in the conclusion but does not provide any supporting evidence or reasoning to justify this confusion. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the confusion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. It acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\\'s focus or what aspects of the paper are unclear. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without guidance on how to address the confusion or enhance the clarity of their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be publicly available. While the comment implies that the authors should make the code available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the code available to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its request for the code to be publicly available, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code should be made publicly available. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the difficulty in reproducing the results and questions the availability of the code. While it identifies a potential issue with reproducibility, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the transparency of their work. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential problem but does not offer detailed guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to differentiate the method or what specific aspects could be improved to enhance the technical contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses $kNN-ECD$ or $kNN-MT$, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the similarity should be addressed or how the authors could differentiate their method. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not provide any specific guidance or suggestions on how the authors could differentiate their method or enhance its technical contribution. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors did not clarify the number of parameters used in each approach in Section B.3. This is a clear and direct request for additional information, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies the exact part of the paper that needs clarification and the exact information that is missing. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the number of parameters used in each approach. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding the number of parameters used in each approach in Section B.3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the number of parameters used in each approach in Section B.3. This feedback is clear and actionable, as it directs the authors to provide additional information that would improve the clarity and comprehensibility of their work. By addressing this point, the authors can enhance the transparency and accessibility of their methodology, which is crucial for effective communication of their findings. Therefore, the comment is rated as mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation results in Table 1 are based on only three trials for each case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. While the comment identifies a specific issue with the evaluation results, it does not provide explicit guidance on how to address this issue or improve the analysis. The authors are left to infer that they should reconsider the statistical significance of their results and potentially increase the number of trials. Therefore, the comment is somewhat actionable, as it identifies an issue but lacks concrete instructions on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation results, noting that the three trials per case are not statistically significant and that the deviations reported are not meaningful. The comment further explains why this issue affects the validity of claims like \"our performance is at least two standard deviations better than the next best baseline,\" providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation results in Table 1 are based on only three trials per case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. The comment provides a logical reasoning by explaining the statistical significance of the results and the implications for the claims made. However, it could be strengthened by providing specific references to statistical standards or examples of how this issue affects the validity of the results. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation results presented in Table 1, noting that the analysis is based on only three trials per case, which is not statistically significant. This observation is important as it highlights a potential weakness in the study\\'s methodology and the validity of the results. The comment also points out that the deviations reported are often zero, which undermines the authors\\' claims of superior performance. By addressing this issue, the authors can strengthen the credibility and robustness of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the statistical significance or how to present the results in a more meaningful way. Overall, the comment is mostly helpful as it identifies a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback implies that the authors should include these results to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. While the action is implied, it is not as clear as it could be, as the authors may not be entirely sure of the exact details or format required for these results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or analysis sections, but this inference is not direct. The comment is specific in suggesting the inclusion of detailed results, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is unreasonable to expect that increasing the model size would hurt performance, as recent work by Ni et al. demonstrates that scaling laws apply to dense retrieval models. However, the comment does not provide specific references or examples from the Ni et al. work to support this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback is somewhat helpful as it points out a potential weakness in the authors\\' argument regarding the impact of model size on performance. However, the comment lacks specific guidance on how to present these results or what aspects of the results should be emphasized. While it identifies an area for improvement, it does not provide detailed instructions or examples on how to address the issue, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they could take to investigate it further. As a result, the comment lacks actionability and does not provide any direction for the authors to improve their draft. Therefore, it is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about the current setup or the Greek language. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspect of the Greek language might be causing issues in other multilingual setups. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for information about whether other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. While it raises an interesting question, it does not provide any actionable feedback or suggestions for the authors to address this issue or improve their work. Without further context or guidance, the authors may find it challenging to understand how this information could be relevant to their paper or how to incorporate it into their analysis. Therefore, the comment is rated as barely helpful, as it identifies a potential area of interest but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, it does not provide explicit instructions or concrete steps on how to extend the analysis to multiple trucks and drones. The authors are left to infer that they should consider this extension, but without specific guidance on how to implement it, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. The authors cannot confidently determine which part of the paper needs to be addressed, making this comment weakly grounded. The suggestion is specific in terms of what the authors should consider, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. This feedback is somewhat helpful as it points out a potential area for expansion that could enhance the practicality and relevance of the work. However, the comment lacks specific guidance or suggestions on how to implement this change or what specific benefits it might bring. While it identifies a potential improvement, it does not provide detailed instructions or examples to help the authors effectively address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with Equation 8, specifically the subtraction of s from the dynamic information, which could lead to the loss of some dynamic information. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the equation. The comment lacks actionable details, such as suggesting alternative approaches or methods to mitigate the loss of dynamic information. As a result, the authors are left without a clear understanding of how to proceed with this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equation, noting that subtracting s from the dynamic information could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that subtracting s from the dynamic information in Equation 8 could lead to the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with Equation 8, specifically the subtraction of s from the dynamic information, which could lead to the loss of some dynamic information. This feedback is somewhat helpful as it points out a specific area that needs attention, but it lacks depth and does not provide detailed guidance on how the authors might address this issue or what alternative approaches could be considered. While the comment highlights a potential problem, it does not offer actionable suggestions or detailed reasoning to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses two questions about the impact of the number of MC samples and the network structure on performance. While it does not explicitly instruct the authors to conduct experiments or provide specific guidance on how to address these questions, the questions themselves are clear and actionable. The authors can infer that they need to conduct experiments to investigate the effect of these factors on performance and potentially include this analysis in their paper. Therefore, the comment is somewhat actionable, as it provides a clear direction for the authors to follow but lacks explicit instructions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the impact of the number of MC samples and the network structure on performance, but it does not specify which part of the paper these questions pertain to. The authors may infer that it relates to the experimental section, but this inference is not direct. The comment is specific in its request for empirical evidence and analysis, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for empirical evidence and analysis regarding the impact of the number of MC samples and network structure on performance. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two important questions about the impact of the number of MC samples and the network structure on performance, prompting the authors to conduct empirical investigations. By asking for empirical evidence and analysis, the comment highlights a potential area for improvement in the paper. However, it does not provide specific guidance on how to conduct these experiments or what specific aspects of the network structure should be examined. While it identifies a relevant area for exploration, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is somewhat helpful, as it points out a potential gap in the analysis but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether the notations should be standardized or clarified, or if there are specific parts of the paper where the notation is being used inconsistently. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notations of $\\\\hat{Y}$ and $Y$ being used in a mixed way. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of notations in Section 2, noting that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way. This is a clear and actionable observation that can help the authors improve the clarity and consistency of their notation usage. However, the comment could be more helpful if it provided suggestions on how to standardize the notation or clarified the context in which these notations are used. Despite this, the feedback is valuable as it directs the authors to a specific area needing attention, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"metric learning theory\" and \"generalization theory of neural networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide specific suggestions on how to address this issue or improve the results. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, the comment lacks specific references to the theoretical results or specific examples from the paper to support this claim. Without detailed evidence or references, the authors may find it challenging to verify the claim and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the metric learning theory is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. This is a clear and actionable observation that highlights a potential weakness in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a problem, it does not offer detailed advice on how to resolve it, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should change the notation, provide additional clarification, or suggest an alternative notation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, which is confusing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the confusion caused by using the same notation for different concepts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is confusing or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable observation that can help the authors clarify their notation and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending alternative notations or explaining the context in which these terms are used. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the need for making claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity, and that any potential training speed increases or cost savings must be demonstrated. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or examples to address the reviewer\\'s concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It mentions that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence or demonstrations are needed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claims and the need for evidence, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. The reviewer provides a logical reasoning by pointing out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment lacks specific examples or references to support the claim that sparsity is not beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. While the comment identifies a potential weakness in the paper\\'s claims, it does not provide specific suggestions or guidance on how the authors might address this issue or demonstrate the benefits of sparsity. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks actionable advice or detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. While the comment implies that the authors should conduct some form of analysis or provide evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional analysis or evidence to address the reviewer\\'s concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"vector space where morphological variants are just close together,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the resulting space is meaningful and suggests providing evidence or analysis to support the claim. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. The reviewer does not provide specific examples or references to support their claim, making it somewhat verifiable. The authors would need to infer the need for such evidence or analysis themselves, as the comment lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. This feedback is valuable as it prompts the authors to consider the significance of their results beyond just improved embeddings. However, the comment could be more helpful if it provided specific suggestions on how to conduct the analysis or what kind of evidence would be most relevant. While it identifies an important area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of the recurrent model, suggesting that the sequential relationship might be easier to model. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these areas to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not specify which part of the paper discusses FLOPs or inference time, making it weakly grounded. The suggestion to explore accuracy or specific properties is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks specific examples or references to support the claim that exploring accuracy or specific properties would lead to improvements. The suggestion is logical but lacks detailed evidence or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the authors to explore if there are improvements in accuracy or specific properties if they did not find improvements in FLOPs or inference time. It offers an example of the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is actionable and provides a clear direction for the authors to consider when evaluating their results. However, the comment could be more helpful if it included specific examples or references to support the claim about the sequential relationship. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not clearly explained how they arrived at the different components of the \"scoring function\" or the different threshold values/ranges. While it identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should provide more detailed explanations or examples, but it lacks concrete instructions on what specific information should be included or how to present it. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"scoring function\" and the different components and threshold values/ranges, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the methodology and rationale behind the different components and threshold values/ranges. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not clearly explained how they arrived at the different components of the \"scoring function\" or the different threshold values/ranges. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the methodology used to arrive at the different components of the \"scoring function\" and the different threshold values/ranges. By pointing out the lack of clarity in these aspects, the comment highlights an important area for improvement in the paper. However, the comment does not provide detailed guidance or suggestions on how the authors might clarify these aspects, such as recommending specific sections or details to include. While it identifies a critical issue, the feedback could be more actionable with additional direction. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant issue with the paper\\'s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. The comment provides explicit actions for the authors to take: to include more datasets with categorical features and to employ one hot encoding for the dataset with categorical features. These actions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Model Comparison\" and the \"wide range\" of datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features and that the authors do not employ one hot encoding for this dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model comparison in the paper is inadequate due to the selection of datasets, which lacks categorical features. The reviewer supports this claim by explaining that categorical features are generally more challenging for deep learning and that the omission of one hot encoding for the dataset with categorical features could negatively affect performance. This reasoning is logical and based on common knowledge, providing a clear rationale for the claim. However, the comment could be strengthened by referencing specific studies or examples that support the importance of categorical features in deep learning. Despite this, the claim is mostly verifiable, as it provides a solid foundation for the authors to address the issue.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their model comparison by including more datasets with categorical features and employing one hot encoding for the dataset with categorical features. By addressing these points, the authors can significantly enhance the robustness and credibility of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. While the comment identifies a potential issue with the choice of datasets, it does not provide explicit guidance on how to address this issue or suggest specific alternatives. The authors are left to infer that they should consider alternative datasets, but the comment lacks concrete details on which datasets would be more suitable or how to incorporate them into the study. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of two unpopular IoT datasets for benchmarking is a strange and uncommon choice, suggesting that there should have been better options. The reviewer provides some reasoning by mentioning the relative recency of one dataset and the lack of recent use of the other. However, the comment lacks specific examples or references to support the claim that these datasets are unsuitable for benchmarking. While the reasoning is somewhat logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of datasets for benchmarking, specifically the two unpopular IoT datasets mentioned. It questions why the authors chose these datasets, suggesting that there should have been better options, such as wearable health or mobile activity recognition data. The comment provides a clear rationale for the critique, highlighting the relative recency and lack of recent use of one dataset and the unfamiliarity of the other. However, the comment could be more helpful if it offered specific suggestions or examples of alternative datasets that would be more suitable for benchmarking. Despite this, the feedback is mostly helpful as it points out a potential weakness in the study and provides a direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim a regret bound for their proposed mini-batch method but do not provide it in the supplementary material. The reviewer explicitly states that they could not find the regret bound in the supplementary, which implies that the authors should include it. However, the comment does not provide specific guidance on how to present the regret bound or where it should be located in the paper. While the action is clear, the lack of detailed instructions on implementation makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed mini-batch method being cast to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the regret bound is not provided in the supplementary material and references a specific work for comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors claim a regret bound for their proposed mini-batch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support the claim. This reference provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors claim a regret bound for their proposed mini-batch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support their claim. This feedback is clear and actionable, as it directs the authors to include the missing regret bound in the supplementary material. However, the comment could be more helpful if it provided additional guidance on how to present the regret bound or why it is important for the paper. Overall, the comment is mostly helpful as it highlights a critical oversight in the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is identified as the main weakness of the method. However, the comment does not provide any guidance on how the authors should address this issue or suggest specific actions to improve the performance. The authors are left without any concrete steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed compression\" and \"PQ,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the proposed compression performs worse than PQ when a small code length is allowed, which is the main weakness of the method. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional details or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is considered the main weakness of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the performance of their method. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out a problem but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a potential improvement in the evaluation of the quality of the set of policies, specifically by using the minimum over the set of test MDPs rather than the summation. This feedback provides a clear and explicit action for the authors to consider, as it offers a specific alternative approach to evaluating the performance of the policies. The comment is concrete in its suggestion and provides a clear rationale for the change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the intuitive goal of finding a set of policies that contains an optimal policy for every test MDP in S_{test}. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for the suggested change in evaluation, explaining the potential issue with the summation approach and suggesting the use of the minimum instead. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a potential improvement in the evaluation of the set of policies by using the minimum over the set of test MDPs rather than the summation. The reviewer provides a logical reasoning for this suggestion, explaining that the summation might lead to selecting a subset of policies that are good for most MDPs but poor for the remaining ones, which could be hidden by the summation but highlighted by the minimum. This reasoning is based on a clear understanding of the evaluation process and the potential consequences of the current approach, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar approaches in the literature to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed and actionable suggestion for improving the evaluation of the set of policies. It highlights a potential issue with the current approach, which is that the summation might lead to selecting a subset of policies that are good for most MDPs but poor for the remaining ones. The reviewer suggests using the minimum over the set of test MDPs instead, which would better capture the performance of the policies in the worst-case scenario. This feedback is clear and constructive, offering a specific and meaningful improvement that could enhance the quality of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It explicitly requests a more detailed analysis of these aspects. While the comment identifies areas for improvement, it does not provide specific guidance on how to conduct the analysis or what aspects should be emphasized. The authors are left to infer that they need to provide more detailed information, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p,\" which likely refers to a specific parameter or value used in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis of these aspects, which could significantly enhance the paper\\'s clarity and rigor. While the comment identifies areas for improvement, it lacks specific guidance on how to conduct the analysis or what aspects should be emphasized. This makes the feedback somewhat helpful, as it points out potential weaknesses but does not provide detailed instructions for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to either state the content as a remark or move it to a Discussion section, or to remove it altogether. This provides a clear and direct action for the authors to take, ensuring that the content is either revised or removed as needed. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107-114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the content seems speculative or overly opinionated and suggests it should be stated as a remark or moved to a Discussion section. This provides clear guidance on how to revise the content. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"L107-114 seems speculative or overly opinionated.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (L107-114) as potentially being speculative or overly opinionated. It suggests that this content should be stated as a remark or moved to a Discussion section, or removed altogether. This feedback is clear and actionable, providing the authors with a concrete suggestion on how to address the issue of potentially overly subjective content. However, the comment could be more helpful if it explained why this section is considered speculative or overly opinionated, which would give the authors a better understanding of the rationale behind the suggestion. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, asking for clarification on the motivation behind this choice. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their choice. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, indicating a lack of clarity in the motivation behind this choice. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, suggesting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It highlights a potential lack of clarity in the paper regarding the rationale behind this choice. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify their motivation. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional guidance on how to improve the explanation or rationale. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the data used for training, validating, and testing. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should clarify the data sources, but it lacks concrete steps or examples of what should be done to improve the clarity. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the quantitative results and the need for clarity regarding the data used for training, validating, and testing. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what specific data sources or methods should be used to clarify the results. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the clarity of the quantitative results, specifically asking for more information on the data used for training, validating, and testing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the results are unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the quantitative results, specifically questioning the clarity of the data used for training, validating, and testing. This is a relevant point that could impact the reproducibility and understanding of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect of their work. While it points out a potential issue, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment requests that the authors provide a rationale for why their SE framework can help improve the system and how it does so. It suggests that the authors should not just present their achievements but also explain why and how they managed to achieve them. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not explicitly instruct the authors to use this reference or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their approach and its benefits. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a rationale and explanation of how the SE framework can help improve the system. The reference to [1] Luo, et al. provides additional context and guidance for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale and explanation behind the SE framework\\'s ability to improve the system. It suggests that the authors should provide a detailed explanation of why and how the framework can help, rather than just presenting results. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not provide specific examples or detailed reasoning from the referenced work to support the claim. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of a clear rationale and explanation for why the SE framework can help improve the system. It suggests that the authors should not just present their achievements but also provide a detailed explanation of why and how they managed to achieve them. The comment references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. This reference could be useful for the authors to consider in their response. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested ways to improve the explanation. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitation of the approach to two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps to take to improve the generalization of the approach. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitation of the approach to two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the approach need to be addressed or improved to enable generalization to more views. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the limitation of the approach to two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it could be addressed. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitation of the approach to two views and suggests that the system should be able to generalize to more views without much difficulty. While it identifies a potential weakness in the approach, it lacks specificity and actionable guidance on how to address this issue. The comment does not provide suggestions or examples of how the authors might improve the generalization of their approach, leaving them without a clear path forward. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer detailed guidance for addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It notes that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics that could be more suitable. The action is implicit and somewhat vague, as the authors can infer that they need to consider the applicability of their metrics in different settings but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the metrics used for evaluating continual learning, loss after switch, and recovery time after switch, which are key aspects of the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with these metrics, namely that they are not applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics used for evaluating continual learning are not applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This claim is somewhat verifiable as it provides a logical reasoning based on the nature of the metrics and their applicability to specific scenarios. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It points out that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This feedback is valuable as it highlights a potential weakness in the paper\\'s methodology and suggests that the authors should consider the applicability of their metrics in different contexts. However, the comment could be more helpful if it provided suggestions on how to address this limitation or offered alternative metrics that might be more suitable. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance on how to improve the experiment setup or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions on how to enhance the experiment setup, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not specify which part of the paper this pertains to, such as the experimental section or a particular figure or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the experiment setup should be improved, but without clear grounding, it is difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ablations deserve better experiment setup due to the many questions that arise. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance or examples on what aspects of the experiment setup need improvement or how to address the questions that arise. Without actionable advice or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, as it lacks the necessary depth and specificity to be useful for improving the paper.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of an error analysis on the movie dataset and highlights the need for clarity on the cases where the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis in their draft. The comment is specific and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely an error analysis on the movie dataset, and why it is important for other researchers to understand the cases where the model fails. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper\\'s contribution. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this omission. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers who may continue this work. However, the comment lacks depth and does not provide specific suggestions on how to conduct the error analysis or what aspects should be covered. While it points out a critical area for improvement, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to add a separate section or subsection to introduce the inference strategy, but the comment lacks concrete details on what should be included in this section or how to implement it. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"approach method\" and the \"inference strategy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by providing more detailed information on the inference strategy. However, the comment could be more helpful if it offered suggestions on how to structure this section or what specific aspects of the inference strategy should be covered. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like f-CLSWGAN and f-VAEGAN-D2. The reviewer implies that more explanations are needed to understand the discrepancy. However, the comment does not provide explicit guidance on what specific explanations should be given or how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanations but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like f-CLSWGAN and f-VAEGAN-D2. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for more explanations, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the low results obtained using only ML in the ablation experiments, suggesting that they are lower than those of simple early methods like f-CLSWGAN and f-VAEGAN-D2. However, the comment does not provide any supporting evidence, references, or detailed reasoning to explain why these results are unexpected or problematic. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary information to substantiate the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like f-CLSWGAN and f-VAEGAN-D2. This prompts the authors to consider providing more explanations for the discrepancy. However, the comment does not offer specific suggestions or guidance on what kind of explanations might be helpful or how the authors might address this issue. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This is a clear and direct action that the authors can take to improve their draft. The comment is specific in its request for a detailed plan, which provides a concrete direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the limitations mentioned in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more detailed plan on how the authors plan to address the limitations in their future work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address the limitations effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive approach to addressing the drawbacks. However, the comment could be more helpful if it offered specific suggestions on what elements should be included in the plan or how to prioritize these limitations. Overall, the comment is mostly helpful as it guides the authors toward a more comprehensive approach to their work, but it could be more detailed to be fully beneficial.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that similar methods have already been proposed for multi-task learning and were not discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a discussion of related work or a comparison with existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Similar methods have already been proposed for multi-task learning and has not been discussed in this paper [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on similar methods for multi-task learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar methods have already been proposed for multi-task learning and were not discussed in the paper. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by pointing out that similar methods for multi-task learning have already been proposed and were not discussed. This is a relevant observation that could prompt the authors to include a discussion on related work or to address the limitations of their approach in comparison to existing methods. However, the comment lacks specific suggestions or guidance on how to incorporate this discussion or what aspects of the existing work should be considered. While it highlights an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FedMITR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the amount of computation required for FedMITR compared to other methods, indicating a potential area for improvement or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper\\'s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment poses a question about the amount of computation required for FedMITR compared to other methods, suggesting that this might be an area for comparison. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. The comment is somewhat helpful as it points out a potential area for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it unclear whether this suggestion is being implemented. The comment provides a specific action\u2014using a generic external knowledge base\u2014but lacks concrete guidance on how to implement it or address the confusion in the writing. The authors are left with a clear action but without detailed instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests avoiding \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, it acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment references \"1) and 2)\" and Figure 3, it does not specify which parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting the use of a generic external knowledge base, but without detailed guidance on how to address the confusion in the writing, it remains under-specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using a generic external knowledge base (as shown in Figure 3) can avoid \"1) and 2)\" and that the writing is confusing. However, the comment lacks specific examples or detailed reasoning to support the claim that the external knowledge base would be beneficial or how it would address the confusion in the writing. Without additional context or evidence, the authors may find it challenging to understand and implement the suggestion. Therefore, the claim is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment provides a specific actionable suggestion, it lacks depth and does not offer detailed guidance on how to effectively implement the external knowledge base or address the confusion in the writing. This limits the comment\\'s helpfulness, as it provides a starting point but does not fully support the authors in improving their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the provided analysis seems weak in light of theoretical work on sampling and particle-based optimization methods. It specifically mentions the absence of information on the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the solution and discretization, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the provided analysis\" and \"the theoretical work on sampling and particle-based optimization methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the missing information, such as the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the provided analysis is \"somewhat weak\" due to the absence of information on the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). This claim is somewhat verifiable as it references theoretical work on sampling and particle-based optimization methods, which provides a basis for the expectation of detailed analysis. However, the comment lacks specific references to that theoretical work or examples of what kind of information is missing, making it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the provided analysis is considered weak, namely the absence of information on the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). This feedback is clear and actionable, as it points out specific gaps in the analysis that need to be addressed to strengthen the paper. By highlighting these areas, the comment provides the authors with a clear direction for improving the draft. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar issues have been addressed in related works. Overall, the comment is mostly helpful as it guides the authors toward improving the rigor and comprehensiveness of their analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the model, noting that many components have hyperparameters that are not fully provided, requiring someone to trace them in the source code. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the documentation. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed documentation for the hyperparameters. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights an issue with the model\\'s components and their hyperparameters, noting that some are not fully provided and may require tracing in the source code. However, it does not specify which components or hyperparameters are in question, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what changes or improvements are needed to address this issue. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the model has many components whose hyperparameters are not fully provided, requiring someone to trace them in the source code. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model, noting that many components have hyperparameters that are not fully provided, requiring someone to trace them in the source code. This is a relevant observation that could impact the reproducibility and usability of the model. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending additional documentation or clarifying the hyperparameters in question. While it points out a potential problem, it does not provide actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. While the comment provides a clear direction for improvement, it does not specify how to implement these changes or what specific qualitative results should be included. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. However, the comment does not specify which part of the paper these results should be included in, making it weakly grounded. The suggestion is specific, as it clearly outlines what the authors should include to improve their draft. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these additions would be beneficial. The absence of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the benefits of these additions themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also suggests showing failure cases and analyzing limitations. This feedback is valuable as it offers a concrete way for the authors to enhance the presentation of their results, which could help demonstrate the effectiveness of their method. However, the comment could be more helpful if it provided specific examples of what qualitative results or failure cases should be included. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on what specific aspects of the interpretability tax should be evaluated or how the evaluation should be conducted. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the interpretability tax should be evaluated or how it should be measured. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This is a relevant point that could enhance the paper\\'s analysis and understanding of the method\\'s impact on interpretability. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending particular metrics or analyses to include. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it implies that the authors should provide these losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses in their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses, but without clear grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it identifies a potential area for improvement, it does not provide any specific guidance or suggestions on how to address this issue. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability as being the same concept. The reviewer suggests that these are actually different perspectives on applying stronger constraints for samples with higher popularity. While the comment identifies a potential issue with the paper\\'s claims, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims and provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper overclaims the strength of the proposed BC loss by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability as the same concept. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability as the same concept. The reviewer supports this claim by explaining that these elements are actually different perspectives on applying stronger constraints for samples with higher popularity. However, the comment lacks specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning behind the claim to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claims regarding the strength of the proposed BC loss in the theoretical analysis. It points out that the paper overclaims by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability as the same concept. The reviewer explains that these elements are actually different perspectives on applying stronger constraints for samples with higher popularity. This feedback is somewhat helpful as it highlights a potential misrepresentation in the paper\\'s claims, but it could be more beneficial if it provided specific suggestions on how the authors might clarify or adjust their claims to be more accurate. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer suggests that these arena-based evaluation systems may not solve the problems of current score-based evaluation systems. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to improve the evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the relevance and effectiveness of their method in the context of score-based evaluation systems. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also mentions the framework FFAEVAL and similar frameworks like Chatbot Arena, suggesting that these systems may not be suitable for evaluating a single dialogue system. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the relevance and effectiveness of the proposed method, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer provides logical reasoning by explaining that these arena-based evaluation systems may not solve the problems of current score-based evaluation systems. However, the comment lacks specific examples or references to support the claim that these frameworks are not effective for evaluating single dialogue systems. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. This feedback is somewhat helpful as it highlights a potential weakness in the methodology and suggests that the authors should reconsider their evaluation approach. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or what alternative evaluation methods might be more appropriate. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to consider the differences between classification and regression tasks, but the comment lacks concrete details on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the use of focal loss in regression tasks and the potential inaccuracy caused by lower weight for easy samples. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of focal loss in regression tasks and suggests that it may not be appropriate due to its classification-specific properties. The reviewer provides a logical reasoning by explaining that focal loss is known for handling class imbalance in classification tasks but may not be suitable for regression tasks where the focus is on regression rather than classification. However, the comment lacks specific examples or references to support the claim that focal loss could cause inaccuracy in regression tasks. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its classification-specific properties. It points out that focal loss is known for handling class imbalance in classification tasks but may not be suitable for regression tasks where the focus is on regression rather than classification. The comment highlights a potential issue with the paper\\'s approach and encourages the authors to consider the differences between classification and regression tasks. While the comment identifies a significant area for improvement, it could be more helpful if it provided specific suggestions on how the authors might address this issue or what alternative methods might be considered. Overall, the comment is somewhat helpful as it prompts the authors to reconsider their approach, but it lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of scalability should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of scalability should be considered or how the authors might address this question. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTa-base instead of BERT. While it does not explicitly instruct the authors to use RoBERTa-base, the implication is clear that they should consider this option. The comment is somewhat actionable as it provides a concrete suggestion for improvement but lacks explicit guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"encoder\" and compares it to \"RoBERTa-base,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the observed improvement could be achieved with a better encoder, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about the potential improvement in the observed results with a better encoder, specifically mentioning RoBERTa-base as an alternative to BERT. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTa-base might be a better choice or how it could lead to improved results. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the potential improvement in the observed results with a better encoder, specifically mentioning RoBERTa-base as an alternative to BERT. This is a relevant point that could prompt the authors to consider alternative models for their encoder, which could potentially enhance the performance of their system. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement this change or what specific aspects of the current encoder might be limiting its performance. While it points out a potential area for improvement, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not specify the type of GPUs used for testing or the inference time. This is an explicit observation that the authors can directly address by including this information in their draft. The comment provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be added to improve their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the absence of information about the type of GPUs used for testing and the inference time, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be added, namely the type of GPUs and inference time, providing clear guidance on what needs to be included in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide information about the type of GPUs used for testing or the inference time. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting the lack of information about the type of GPUs used for testing and the inference time. This feedback is clear and actionable, as it directs the authors to include this information in their draft. By addressing this point, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. While the comment identifies a specific area of concern, it does not provide explicit instructions on how to address this issue or what changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to make a correction but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Perceptual Metric in Figure 2, noting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, as it points out a potential error in the experimental setup that the authors can correct to ensure the validity of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why this distinction is important or offering guidance on how to implement the correction. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete suggestions on how to address this issue. The authors are left to infer that they should explore the potential impact of using adaptive gradient methods, but the comment lacks specific guidance on how to conduct this exploration or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue might be relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the potential impact, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. The comment does not present any claims or opinions but rather seeks clarification or additional information. It is a request for further exploration rather than a statement that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. This is a valuable observation that could lead to a deeper understanding of the methodology and its effects on the results. However, the comment lacks specific guidance or suggestions on how the authors might explore this aspect or what specific experiments or analyses could be conducted to address it. While it points out an important area for consideration, the feedback could be more actionable with additional details or examples. Therefore, the comment is somewhat helpful, as it provides a direction for further exploration but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting additional teacher architectures or suggesting more recent methods to compare. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of insufficient experiments, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is lacking in the experiments, such as the limited types of teacher architectures and the age of the compared methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. While these points highlight areas for improvement, the comment lacks specific suggestions or guidance on how to address these issues. It does not provide actionable advice or examples of alternative teacher architectures or more recent methods to consider. This limits the comment\\'s usefulness in helping the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not offer detailed guidance for addressing them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While the comment implies that the authors should conduct a comparison between the two designs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison between sequential and combinational designs, but without explicit references to sections or figures, the authors may struggle to identify where this information should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the method may perform better in combinational logic. Without such information, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this comparison or what specific aspects to focus on. The comment is somewhat helpful as it points out a potential area for further exploration, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the practicality of the proposed method, which relies on known causal relationships between features. It acknowledges that prior knowledge might not always be available or accurate for specific subpopulations, which is why researchers often focus on mining causal relationships from data automatically. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern or improve their draft. It lacks guidance on how to address the practicality issue or suggestions for improving the methodology. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s proposal to use known causal relationships between features, noting that prior knowledge might not always be available or accurate for specific subpopulations. It highlights the practicality concern and suggests that researchers often focus on mining causal relationships from data automatically. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the practicality of the proposed method, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method relies on known causal relationships between features, which might not always be available or accurate for specific subpopulations. The reviewer supports this claim by noting that most researchers focus on mining causal relationships from data automatically. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable, as it requires more robust evidence to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s proposal, noting that it relies on known causal relationships between features, which might not always be available or accurate for specific subpopulations. It highlights the practicality concern and suggests that researchers often focus on mining causal relationships from data automatically. This feedback is valuable as it points out a critical aspect of the paper\\'s applicability and suggests a potential area for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or improve the practicality of their approach. Overall, the comment is mostly helpful as it directs the authors\\' attention to a relevant concern and offers a direction for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there is a lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This implies that the authors should include these comparisons in Section 4.3 to showcase the unique advantages or potential shortcomings of their proposed method in a broader context. The comment is clear and provides a specific action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is somewhat verifiable as it suggests that including these comparisons would provide a broader context for the proposed method. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of these comparisons and determine how they would enhance the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback highlights the importance of including such comparisons to showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By suggesting these comparisons, the comment provides clear and actionable guidance for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully included such comparisons. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
