{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the baseline models: the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It explicitly instructs the authors to compare their work with Campos et al. and to include comparisons with other domain adaptation methods mentioned in Section 8. The comment provides concrete guidance on what needs to be added to the paper, making it highly actionable. The authors know exactly what steps to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 277,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. While the comment identifies a potential issue with the baseline models, it lacks specific examples or references to Campos et al. or other domain adaptation methods to support the claim. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the baseline models are weak and suggesting that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. This feedback is clear and actionable, as it provides specific guidance on how to improve the paper by including comparisons that could strengthen the analysis. However, the comment could be more helpful if it explained why these comparisons are important or how they would enhance the paper\\'s contribution. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. It also asks about the KNs in source language or in English, as the mentions have been translated to English. The authors are instructed to correct Figure 3. While the comment provides explicit actions to take, it does not specify how to implement these changes or what specific details should be added to the input or figure. The action is clear but lacks concrete guidance on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be added, such as information about the input being word embeddings and the KNs in source language or in English. The comment also provides a clear request for correction, which adds to its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. It also asks about the KNs in source language or in English, as the mentions have been translated to English. The comment is somewhat verifiable as it provides a logical suggestion for clarifying the input and references a specific model for comparison. However, it lacks specific examples or references to support the claim that adding this information would be beneficial. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors add information about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. It also raises a question about the KNs in source language or in English, given that the mentions have been translated to English. This feedback is clear and offers a concrete way for the authors to improve their draft by providing additional context and clarity. However, the comment could be more helpful if it provided examples or detailed guidance on how to implement these changes. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s claims would benefit from more in-depth analysis. However, it does not provide specific examples of which claims need more analysis or what aspects of the claims should be explored further. The comment lacks concrete guidance on how to improve the analysis or what specific aspects to focus on. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that a number of claims from the paper would benefit from more in-depth analysis, but it does not specify which claims or parts of the paper are being referred to. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts of the paper need further analysis. Additionally, the comment lacks specificity regarding what aspects of the claims should be analyzed more deeply. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a number of claims from the paper would benefit from more in-depth analysis. However, it does not provide specific examples or detailed reasoning to support why these claims need further examination. Without specific claims or examples, the authors may find it challenging to understand which parts of the paper require additional analysis. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a number of claims from the paper would benefit from more in-depth analysis. However, it does not specify which claims or aspects of the paper need this additional analysis. Without specific guidance or examples, the authors are left without actionable feedback on how to improve their draft. The comment lacks depth and specificity, making it barely helpful for the authors in terms of identifying areas for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific areas where the presentation of the model needs improvement: the pooling method used for embedding features (line 397) and the clarity of Equation (7) in line 472. It provides explicit questions about the pooling method and the definition of E_i in Equation (7), asking whether it represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability. This feedback is clear and provides concrete actions for the authors to take, such as clarifying the pooling method and the definition of E_i. The explicit nature of the questions and suggestions makes this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the pooling method used for embedding features and the definition of E_i in Equation (7). The comment provides detailed guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of the pooling method used for embedding features (line 397) and the definition of E_i in Equation (7) in line 472. It suggests that the LHS of Equation (7) should be a conditional probability. The comment provides logical reasoning by pointing out that the pooling method and the definition of E_i are unclear, and it questions whether they represent the type or identity of AC i. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the context and details to fully understand and address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the presentation of the model needs improvement, providing clear and actionable feedback. It points out that the pooling method used for embedding features is not clearly defined and that Equation (7) in line 472 is not clear enough, questioning whether E_i represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability, which is a valuable suggestion for clarifying the model presentation. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and understanding of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is explicit in its request for additional evidence, providing a clear action for the authors to take. However, it does not specify what kind of evidence would be sufficient or how to present it, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it identifies a specific area for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests providing empirical evidence to support the claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of evidence would be sufficient. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its request for empirical evidence, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide any specific reasoning or examples to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by providing empirical evidence to substantiate the claim. However, the comment could be more helpful if it provided guidance on what kind of evidence would be most effective or how to present it. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment recommends conducting more analysis and providing comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\\' viewpoint regarding the benefits of increased model capacity and provides specific examples from Figure 3 to support this disagreement. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While it provides some guidance, the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. The comment provides specific examples of the performance trends and disagreements with the authors\\' viewpoint, which adds clarity to the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim that the authors\\' viewpoint is incorrect regarding the benefits of increased model capacity for both CNNs and ViTs. The reviewer supports this claim by providing specific examples from Figure 3, where the DeiT-B model does not outperform DeiT-T or DeiT-S on various datasets. This provides a clear and robust basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\\' viewpoint regarding the benefits of increased model capacity, providing specific examples from Figure 3 to support its disagreement. This feedback is clear and constructive, as it guides the authors on how to address the critique and improve their analysis. However, the comment could be more helpful if it offered suggestions on how to conduct the additional analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides valuable insights and direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the limited novelty of the proposed method and its similarity to other attentional modules in previous works. It specifically mentions that the group attention design is related to ResNeSt but not discussed in the paper. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should discuss the similarities and differences between their work and previous works, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"group attention design\" and \"ResNeSt,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the similarity to other attentional modules in previous works, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works, such as ResNeSt, and noting that the group attention design is related to these works but not discussed in the paper. However, the comment lacks detailed comparisons or specific examples from these works to fully substantiate the claim. While the references provide some context, the comment could be strengthened by offering more specific examples or detailed analysis to fully support the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules in previous works. It specifically mentions the group attention design and its relation to ResNeSt, which is not discussed in the paper. This feedback is valuable as it highlights a potential weakness in the originality of the work, prompting the authors to address this issue. However, the comment could be more helpful if it provided suggestions on how to differentiate the method or discuss its unique aspects. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or suggesting a specific approach to improve the clarity. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the Witness oracle is confusing or how it could be clarified. The comment lacks specificity regarding the issue and does not provide guidance on how to address it. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the required implicit call to the Witness oracle being confusing. This feedback is somewhat helpful as it points out a potential source of confusion for readers, which could impact the clarity and accessibility of the paper. However, the comment lacks depth and does not provide suggestions on how to clarify or improve the explanation of this concept. Without additional guidance or examples, the authors may struggle to fully address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their methodology. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" However, it does not specify which part of the paper this observation is made in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what needs to be addressed or improved in the methodology. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors are reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. However, the comment lacks specific examples or references to support the claim that this observation is unnecessary or redundant. Without such evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. While the comment identifies a potential redundancy in the authors\\' work, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semi-supervised trained. The reviewer suggests renaming the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect this distinction. Additionally, the reviewer proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. These suggestions are clear and provide specific guidance on how to improve the clarity of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semi-supervised training and the renaming of the column in Table 1. The comment also provides a detailed suggestion for improving the clarity of the table by suggesting the creation of two columns for data sources. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the distinction between weak supervision and semi-supervised training, specifically in Table 1. The reviewer provides a specific example of the proposed framework row in Table 1, suggesting that it refers to the semi-supervised version of the method and recommends renaming the column to \"Fully supervised\" from \"Supervised.\" The reviewer also proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This suggestion is based on logical reasoning and common knowledge about the distinction between weak supervision and semi-supervised training. The comment is mostly verifiable as it provides a clear rationale for the claim and offers a concrete suggestion for improvement.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides clear and actionable feedback on improving the clarity of the paper. It identifies a specific issue with the distinction between weak supervision and semi-supervised training, suggesting that the authors should clarify this distinction in Table 1. The reviewer provides a specific example of the proposed framework row in Table 1, suggesting that it refers to the semi-supervised version of the method and recommends renaming the column to \"Fully supervised.\" Additionally, the reviewer offers a more detailed suggestion by proposing the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This feedback is clear, detailed, and constructive, empowering the authors to make significant improvements to their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies the main weakness of the paper as the lack of comprehensive experimental evaluation, specifically the limited consideration of datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. While the comment provides a clear direction for improvement by recommending specific works to consider, it does not explicitly instruct the authors on how to incorporate these works into their evaluation or how to address the identified weakness. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the main weakness of the paper, which is the lack of comprehensive experimental evaluation on different datasets and model types. The comment suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main weakness of the paper is the limited scope of the experiments, specifically the use of only the CIFAR-10 dataset and the lack of consideration of other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. While the comment provides a logical reasoning for the need to consider additional datasets, it lacks specific examples or references to the works mentioned, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a clear direction for improvement but requires more detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which only consider the CIFAR-10 dataset and do not consider other datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance the comprehensiveness and relevance of their experiments. By addressing this feedback, the authors can significantly improve the quality and impact of their paper. However, the comment could be more helpful if it provided additional details on how these works could be integrated or what specific aspects of the experiments should be expanded. Overall, the comment is mostly helpful as it effectively directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a more convincing setting for training, similar to what was done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. It provides a specific reference to the paper by He et al. (EMNLP 2018) as an example of a convincing setting. This feedback is explicit and provides a clear action for the authors to take, which is to adopt a more convincing training approach. The suggestion is concrete and provides a direct path for the authors to follow, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)\" and suggests that the label distribution of unlabeled data during training is impractical in real-world applications. It also references a specific paper, \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018,\" which provides a more convincing setting for training. This level of detail allows the authors to accurately identify the part of the paper being addressed and the specific issue being raised. The comment is also specific, as it clearly specifies what needs to be addressed regarding the training setting and provides a reference for a more convincing approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in real-world applications. The reviewer suggests that the authors should use a more convincing setting, like the one described in the paper \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018,\" which directly samples unlabeled data from millions of reviews. The comment provides a specific reference to a relevant paper, which supports the claim by offering a practical example of a more convincing setting. This makes the claim mostly verifiable, as it provides a logical basis and a specific example to support the claim. However, the comment could be strengthened by further explaining why the current setting is impractical or how the proposed setting would be beneficial. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the unlabeled data from the preprocessed Amazon review dataset, noting that it is perfectly balanced, which is impractical in real-world applications. It suggests that the authors should use a more convincing setting, like the one described in the paper \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018,\" which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a specific approach to address the issue of unbalanced data. By suggesting a more convincing setting, the comment offers a concrete way for the authors to improve their draft. However, it could be more helpful if it explained why the current setting is impractical or how the proposed setting would benefit the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \\u03c4 and the use of sparse labels. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment implies that the authors should clarify this confusion by providing more detailed explanations or examples. However, it does not explicitly instruct the authors to make these changes or suggest specific ways to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should address the confusion and provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the use of sparse labels and the notation for target domain \\u03c4. The comment further questions the use of unlabeled data in source domains and references the original MFDA paper by Yue et al. (2021a) for clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \\u03c4 and the use of sparse labels. The reviewer questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper by Yue et al. (2021a). The comment is somewhat verifiable as it provides a logical basis for the confusion, referencing the original paper for clarification. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for target domain \\u03c4 is unlabeled and questions the use of sparse labels, which is not consistent with the original MFDA paper by Yue et al. (2021a). The comment also highlights the confusion regarding the use of unlabeled data in source domains during training. By pointing out these discrepancies and referencing the original paper, the comment provides clear and actionable feedback for the authors to improve the clarity and consistency of their description. This guidance is valuable for enhancing the understanding of the problem setting and the methodology, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes or which sections to address. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"details in the article\" and \"your workload is immense,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the contribution being incremental and the lack of citation of key baselines, as well as the need to introduce essential RAG algorithms like MedRetriever and KGRAG. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the absence of citation of key baselines and the need to introduce essential RAG algorithms like MedRetriever and KGRAG. The reviewer provides some reasoning by mentioning the focus on RAG for EHR and the need for essential algorithms to be introduced. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it points out some gaps, the authors would need to make a significant effort to understand and address the critique fully. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the immense workload and the incremental contribution, which are not fully explained. It points out that the paper essentially combines GraphRAG and GraphCare, and that key baselines were not cited. The reviewer also notes that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. These suggestions provide clear and actionable feedback for the authors to enhance the clarity and originality of their work. However, the comment could be more helpful if it offered specific guidance on how to integrate these algorithms or how to address the issues with the contribution. Overall, the comment is mostly helpful as it highlights areas for improvement and provides a direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of specific state-of-the-art references in the face recognition experiment, particularly mentioning \"Baidu's work\" and its reported results. It also highlights the use of the triplet loss and the similarity to the Webface dataset. The comment provides a clear and specific action for the authors to include these references in their work. By doing so, the authors can improve the comprehensiveness and accuracy of their experimental comparison. The action is explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the specific references that are missing, such as \"Baidu\\'s work\" and \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the missing references and highlights the use of the triplet loss in the mentioned work, as well as its reported results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some state-of-the-art references are missing in the face recognition experiment, specifically mentioning \"Baidu\\'s work\" and its reported results. The reviewer provides a specific reference to the work, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" which is available at http://vis-www.cs.umass.edu/lfw/results.html#baidu. This reference supports the claim by providing a direct comparison to the results in the paper, which is a significant improvement over the current state of the art. The comment is fully verifiable as it provides clear and specific evidence to support the claim, making it highly verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup in the paper, noting the absence of certain state-of-the-art references, such as \"Baidu\\'s work\" and its reported results. It provides a clear and actionable suggestion by recommending the inclusion of these references, which could enhance the comprehensiveness and accuracy of the experimental comparison. This feedback is valuable as it directs the authors to a specific area for improvement, ensuring that they address a critical aspect of their work. However, the comment could be more helpful if it explained why these references are important or how they might impact the results presented in the paper. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to cite the source of the rock-paper-scissors example, which is clearly inspired by previous work. This is a direct and concrete action, as it specifies the exact source that needs to be cited. The authors know exactly what needs to be done to address the comment, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to cite the source of the example. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by previous work and suggests that the source should be cited appropriately. However, the comment does not provide specific examples or references to the previous work that inspired the example, making it difficult for the authors to verify the claim. Without additional context or evidence, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rock-paper-scissors example is inspired by previous work and should be appropriately cited. This is a clear and actionable piece of feedback, as it directly instructs the authors to cite the source of the example. By addressing this point, the authors can ensure that their work is properly credited and that they are not plagiarizing others\\' work. Therefore, the comment is highly helpful, as it provides a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, it does not explicitly instruct the authors to average over subword representations or provide guidance on how to implement this suggestion. The action is implied and somewhat vague, as the authors need to infer that they should consider averaging over subword representations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, as done by Hewitt and Manning (2019, footnote 4). This feedback is actionable and provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, the comment does not provide specific examples or detailed reasoning to support why this is a common practice or how it would benefit the current work. While it references a specific work, the lack of detailed explanation or justification makes the claim somewhat verifiable. The authors would need to infer the importance of this suggestion and might find it challenging to understand the full implications without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in the paper, noting that it is common in similar cases to average over subword representations. It provides a reference to a specific work by Hewitt and Manning (2019, footnote 4) to support this suggestion. This feedback is somewhat helpful as it points out a potential improvement in the language used, but it lacks detailed guidance or suggestions on how to implement this change effectively. The authors are given a direction to consider, but the comment could be more helpful with additional explanation or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, additional experiments, or guidance on how to enhance the validation process. As a result, the authors are left without any clear direction on how to address the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the types of experiments conducted, but it lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that these experiments are comprehensive. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. However, it lacks specificity and actionable feedback. It does not provide guidance on how the authors could improve or expand upon these experiments, nor does it offer suggestions for further validation or analysis. As a result, the comment is somewhat helpful, as it identifies a strength but does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the bounded noise assumption in the context of stochastic optimization literature, noting its restrictiveness and suggesting that it has been extended in recent literature. It provides specific references to papers by A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou, which discuss better theory for stochastic gradient descent (SGD) in the nonconvex world. However, the comment does not explicitly instruct the authors to consider these references or incorporate the extended noise conditions into their work. While the references provide a clear direction for further exploration, the action is implicit and lacks concrete guidance on how to apply this information. Therefore, the comment is somewhat actionable, as it points to a potential area for improvement but does not provide explicit instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the bounded noise assumption, which allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by pointing out the restrictiveness of this assumption in the stochastic optimization literature and suggests that it has been extended in recent literature. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The reviewer provides specific references to external works, such as A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou, which support the claim by citing relevant literature. This provides a robust foundation for the claim, making it mostly verifiable. However, the comment could be further strengthened by explaining why the bounded noise assumption is restrictive or how these extensions have impacted the field. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the bounded noise assumption, which is common in stochastic optimization literature. It suggests that this assumption may be somewhat restrictive and points out that there have been efforts to extend these noise conditions. The comment provides specific references to recent literature, such as A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou, which could be useful for the authors to explore further. While the comment highlights an important area for improvement, it could be more helpful if it offered suggestions on how to address this issue or integrated the references into the paper. Overall, the comment is somewhat helpful as it provides a direction for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or address this issue. Without guidance on what the authors should do to improve the draft, the comment lacks actionability. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically asking whether it refers to 100 sampled strategies. This question highlights a potential area of confusion or ambiguity in the paper, which could be clarified to improve the reader\\'s understanding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors discuss the reason why the proposed algorithm, DMLCBO, does not achieve the convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ and the theoretical technique difference between DMLCBO and previous works that have achieved this rate, such as SUSTAIN and MRBO. This feedback provides a clear and concrete action for the authors to take, as it specifies the need for a detailed discussion on the convergence rate and theoretical differences. The comment is explicit and provides specific guidance on what to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm, DMLCBO, and references specific works, SUSTAIN and MRBO, which have achieved a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the reason why DMLCBO does not achieve the same convergence rate and the theoretical technique difference between DMLCBO and the mentioned works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works, specifically mentioning SUSTAIN and MRBO, which have achieved $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. The reviewer supports this claim by referencing these specific works and their convergence rates, providing a logical basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or references to the theoretical differences between DMLCBO and the mentioned works. Despite this, the claim is mostly verifiable due to the reference to specific works and the logical reasoning provided.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the convergence rate of the proposed algorithm, DMLCBO, compared to previous works that have achieved a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. It references specific works, SUSTAIN and MRBO, which have achieved this rate, and encourages the authors to discuss the reason why DMLCBO does not achieve the same rate. This feedback is clear and actionable, as it provides a concrete direction for the authors to explore and address the convergence rate issue. By addressing this point, the authors can enhance the clarity and robustness of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the modulator is heuristically designed and questions whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of scalability in the modulator design, specifically questioning whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the scalability issue and the potential need for hyperparameter tuning, but without clear grounding, the authors cannot confidently determine which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the modulator is heuristically designed and questions whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the modulator design, noting that it is heuristically designed and questioning whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. While the comment highlights a potential concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve the scalability of the modulator. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems in imaging, specifically mentioning the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with these methods. While the comment provides a clear action to take, it lacks specific guidance on how to integrate this information into the paper or what aspects of the current method should be compared. The authors are given a clear direction but may need to infer the exact steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" for inverse problems in imaging, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work on untrained NNs and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the current method is interesting because it shows strong OOD generalization, but it also mentions that untrained NNs have been used for inverse problems in imaging. The reviewer suggests that the current method should be placed in context and potentially compared with other methods in this class. While the comment provides a logical reasoning for the suggestion, it lacks specific references or examples to fully substantiate the claim about the recent work on untrained NNs. This makes the claim somewhat verifiable, as the authors would need to follow up on the suggestion to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion by pointing out that the current method is interesting due to its strong OOD generalization. However, it also highlights a potential limitation by mentioning that untrained NNs have been used for inverse problems in imaging, as demonstrated by recent work. The comment suggests that the current method should be placed in context by referencing this work and potentially comparing it with other methods in this class. This feedback is valuable as it encourages the authors to broaden the scope of their work and provide a more comprehensive understanding of the state of the art. However, the comment could be more helpful if it included specific references to the mentioned papers or detailed guidance on how to integrate this information into the paper. Overall, the comment is mostly helpful as it offers actionable suggestions for enhancing the context and comparative analysis of the work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. The reviewer explicitly asks for clarification on these points, providing a clear direction for the authors to improve the clarity of their explanations. The action is explicit and concrete, as it specifies exactly what needs to be addressed to improve the readability of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail helps the authors understand what needs to be addressed to improve the clarity of their work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first two sections of the paper are hard to read due to unclear explanations of previous approaches. It provides specific examples of unclear statements, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. These examples are detailed and provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to support the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and readability of the first two sections of the paper. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96, and asks for clarification on these points. This feedback is clear and actionable, as it directs the authors to improve the clarity of their explanations and provide more detailed descriptions of their methods. By addressing these issues, the authors can significantly enhance the readability and comprehensibility of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern regarding the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. While the comment implies that the authors should provide a comparison and justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison and justification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the goal of the paper and the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the absence of a justification for the benefits of the proposed method over these existing methods. It also suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. While the comment identifies a potential issue with the paper\\'s goals and lacks of comparison, it does not provide specific examples or references to support the claim that existing DAS earthquake detectors exist or that the proposed method is a foundation model. This makes the claim somewhat verifiable, as the authors would need to infer the need for a comparison and justification based on the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the paper\\'s goal, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the absence of a justification for the benefits of the proposed method over these existing methods. It suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. This feedback is clear and actionable, as it points out a critical gap in the paper that needs to be addressed to strengthen its claims. By suggesting a comparison and justification, the comment provides the authors with a concrete direction for improving their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works that have already explored these topics, such as RobustBench and [A, B]. The comment suggests that the authors should consider these existing works and potentially expand their analysis to include other models or datasets. However, it does not provide explicit instructions on how to incorporate these references or what specific aspects of the prior work should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific analyses and prior works, such as RobustBench and [A, B], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses have been conducted in prior works, which may not be surprising due to the limited scale of the current work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works, such as RobustBench and [A, B], which have explored these topics. The comment also mentions that the results are not particularly surprising, as they align with prior work. This provides a logical reasoning and references to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and surprise of the current work, noting that similar analyses have been conducted in prior works. It specifically references existing studies, such as RobustBench and [A, B], which have explored the robustness of CIFAR-10 models on distribution shifts. The comment suggests that the current work may not provide significant new insights or contributions due to the overlap with prior work. While it highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing studies. The feedback is somewhat helpful as it points out a potential limitation, but it lacks actionable advice or detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. The comment explicitly instructs the authors to correct the inaccuracy regarding the Walkman algorithm, specifying that it is solved by ADMM with two versions. It also points out the lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors clarify the intended reference. These actions are explicit and provide concrete guidance on what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about the Walkman algorithm, noting that it is solved by ADMM with two versions, and it points out the lack of clarity in the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed in these parts of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization.\" It provides a specific correction by pointing out that the Walkman algorithm is solved by ADMM with two versions, which contradicts the statement. This is a logical and factual observation that requires no additional evidence or references to support the claim. Therefore, the comment is fully verifiable, as it provides a clear and accurate rebuttal to the original statement.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies two specific issues in the paper: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. By pointing out these issues, the comment provides clear and actionable feedback that empowers the authors to correct their work. The suggestion to clarify the reference to \"it\" in Section 3 is particularly helpful, as it ensures that the authors provide a clear and accurate description of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the statement about the Walkman algorithm or provided examples of how to address the lack of clarity in the reference. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should include additional experiments, it does not specify which specific baselines or comparisons should be included. The action is clear but lacks concrete details on which additional experiments to conduct or how to present them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it references specific works that focus on similar questions, it does not provide detailed reasoning or evidence to support why these additional comparisons are necessary or how they would enhance the paper. The reference to specific works is a helpful starting point, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the suggestion but requires more detailed explanation to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works that focus on similar questions, providing a clear direction for the authors to expand their experimental analysis. However, the comment could be more helpful by offering specific suggestions on which additional baselines or comparisons to include, or how to present the results in a more comprehensive manner. While it provides a valuable direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors need to provide more information on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for details on the translation and filtering methodology to assess the dataset quality. This feedback is clear and concrete, as it specifies exactly what information is missing and what needs to be added. The authors know exactly what steps to take to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of details on the filtering process used to create the dataset and the need for more information on the translation and filtering methodology to assess dataset quality. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking.\" This is a factual observation about the content of the paper, as it highlights a specific area where more information is needed. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would impact the assessment of the dataset quality. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the lack of details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. The comment is clear and concrete, giving the authors specific details to include in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more comprehensive overview of existing methods and their limitations, including sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This provides clear guidance on what needs to be improved in the Related Work section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations. The reviewer provides a list of specific methods to consider, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This detailed list of examples and references provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these methods are relevant to the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the Related Work section. It identifies a lack of comprehensive details and suggests that the authors should provide a more comprehensive overview of existing methods and their limitations, including specific references to sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This detailed guidance helps the authors understand what is expected of their Related Work section and how to improve it, making the comment highly beneficial for enhancing the draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. The comment lacks explicit guidance on how to address the issues, leaving the authors without a clear understanding of what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of what needs to be clarified. Without specific references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing need improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support why the writing is unclear or how it could be improved. Without specific references or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they could be improved. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of what changes to make to enhance the clarity and readability of their paper. Therefore, the comment is barely helpful, as it identifies an area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the synthetic experiment in a non-separable case and questions how the data distribution illustrated in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or modifications to the experiment, making it difficult for the authors to know how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the data distribution in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the synthetic experiment in a non-separable case, specifically questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment lacks specific examples or references to support this claim or provide a detailed explanation of why the experiment might be problematic. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This is a valid point that could lead to a significant issue in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the experiment. It does not provide actionable feedback or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential problem but does not offer detailed guidance for resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their pairwise matching. There is no guidance on potential solutions, alternative approaches, or specific actions to take. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, specifically noting that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem with the efficiency of pairwise matching, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. This is a relevant concern that could impact the practicality and applicability of the work. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the efficiency of their pairwise matching. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to determine what constitutes a significant contribution or how to improve the transferability of the method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, method, or result. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method or transferability need improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary information to support the assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might improve the transferability of their method or what aspects of the contribution are lacking. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as it is not accurate according to the reviewer's understanding. Additionally, it advises the authors to compress the method section, particularly on essential definitions, and to double-check for grammatical errors, focusing on plurals and articles. These are clear and specific actions that the authors can take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests compressing the method section, particularly on essential definitions. Additionally, it points out grammatical errors and provides specific examples, such as \"l.\" This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the claim about the neural network memorizing critical points is inaccurate, based on the reviewer\\'s understanding of TopoNet. However, the comment does not provide any specific references or detailed reasoning to support this claim, nor does it offer alternative perspectives or evidence. The suggestion to tone down the statement is somewhat vague, as it lacks specific guidance on how to rephrase it. Additionally, the comment mentions grammatical errors and suggests compressing the method section, but it does not provide detailed examples or explanations. Overall, the claim is somewhat verifiable, as it points out a potential issue but lacks sufficient evidence or guidance for the authors to address it effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on multiple aspects of the paper. It identifies a potential inaccuracy in the statement about the neural network memorizing critical points, suggesting that the authors should tone down this claim. This is a clear and constructive suggestion that can help the authors improve the accuracy and clarity of their claims. Additionally, the comment advises the authors to compress the method section, particularly on essential definitions, and to double-check for grammatical errors, particularly with plurals and articles. This feedback is detailed and actionable, empowering the authors to make significant improvements to their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the comparison with Megatron, suggesting that it is overrated and points out that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also raises a question about the authors\\' claim of parameter efficiency, suggesting that if this claim is valid, it could apply to these other works as well. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The questions for the authors are more of an inquiry than actionable advice, as they do not directly instruct the authors on what to do. Therefore, the comment is somewhat actionable, as it points out areas for improvement but lacks concrete details on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with Megatron, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the overrating of the comparison and points out that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also raises a question about the authors\\' claim of parameter efficiency, suggesting that if this claim is valid, it could apply to these other works as well. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment provides a logical reasoning by comparing the performance of these models, which supports the claim that the comparison with Megatron is overrated. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the similarities in performance. Despite this, the claim is mostly verifiable due to the logical reasoning provided.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between COCO-LM and Megatron, suggesting that the performance of these models is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This feedback is valuable as it challenges the authors to reconsider the significance of their comparison and potentially adjust their conclusions accordingly. Additionally, the comment raises a question about the authors\\' claim of parameter efficiency, suggesting that if this claim is valid, it could apply to other related works as well. This prompts the authors to clarify their claims and potentially strengthen their argument. Overall, the comment provides clear and actionable feedback that can help the authors improve the clarity and robustness of their work. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis from lines 128 to 149 is not convincing and suggests that the GS-P-50 model has smaller class selectivity score, which means it shares more features with ResNet-50. The reviewer also hypothesizes that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the analysis. The reference to external works, while helpful, does not offer detailed instructions on how to apply this information to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of convincingness and consider the implications of the external references. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 128 to 149,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the analysis, noting that the GS-P-50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet-50. The comment further hypothesizes that additional context may allow the network to reduce its dependency. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis from lines 128 to 149 is not convincing enough, based on the histogram in Figure 3, which shows that the GS-P-50 model has a smaller class selectivity score compared to ResNet-50. The reviewer references external works [1] and [2] to support the claim that GS-P-50 shares more features with ResNet-50, which could indicate that GS-P-50 learns better representation. However, the comment does not provide detailed reasoning or examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment lacks sufficient explanation and evidence to fully verify the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from lines 128 to 149 is not convincing enough. It points out that the GS-P-50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet-50. The reviewer hypothesizes that additional context may allow the network to reduce its dependency. While the comment provides a clear direction for improvement by suggesting that the authors address the issue of convincingness, it lacks specific guidance on how to improve the analysis or what aspects of the analysis are lacking. The reference to external works is helpful but does not fully address the critique. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but could be more comprehensive with additional guidance. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of convincing evidence in the paper's conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be due to limited exploration of combination methods and points to recent works that have shown the potential of feature replay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data and the claim that it accumulates noise, which is detrimental to representation quality. It also references specific works, such as [R1], [R2], and [R3], to support the claim that feature replay methods have shown great potential in continual learning. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works that have shown the potential of feature replay methods in continual learning, such as [R1], [R2], and [R3]. These references provide a logical basis for the claim, as they demonstrate the effectiveness of feature replay methods in continual learning scenarios. However, the comment could be strengthened by providing more detailed analysis or specific examples from these works to further substantiate the claim. Overall, the claim is mostly verifiable, as it is supported by relevant references, but it could be more fully substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s conclusions, noting that some are not convincing. It provides a detailed example by referencing recent works that have shown the potential of feature replay methods in continual learning, such as [R1], [R2], and [R3]. This feedback is clear and actionable, as it suggests that the authors should explore the use of combination methods, which could strengthen their conclusions. By referencing specific works, the comment offers a concrete direction for improvement, making it highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to ensure that the observations and design decisions are not dependent on specific hardware or software. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. Without explicit references to sections, figures, or specific observations, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are dependent on hardware or software. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While it identifies a potential weakness, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific observations or design decisions might be affected. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks novelty and is a straightforward application of existing literature, specifically mentioning the DeCorr method. It highlights that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. The comment also notes that while modifications like different penalty coefficients for users and items are proposed, the paper still lacks insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific insights are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more novel insights or perspectives on the challenges of overcorrelation, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DeCorr [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The comment further details the contribution of the paper, which is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. Additionally, it notes that while modifications like different penalty coefficients for users and items are proposed, the paper still lacks insights into the unique challenges of overcorrelation in recommender systems. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically mentioning the DeCorr method. The reviewer notes that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. While the comment identifies the lack of novelty, it does not provide specific examples or detailed reasoning to support the claim that the paper is not innovative. The reference to DeCorr is specific, but the comment could be strengthened by providing more detailed reasoning or examples to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically the DeCorr method. It highlights that the contribution of the study is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. While modifications like different penalty coefficients for users and items are proposed, the comment points out that the paper still lacks insights into the unique challenges of overcorrelation in recommender systems. This feedback is somewhat helpful as it identifies a critical area for improvement, namely the need to provide more novel insights or perspectives on the challenges of overcorrelation. However, the comment could be more helpful if it offered specific suggestions on how the authors might address this issue or what additional insights could be explored. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a discrepancy between the description in Section 4.2 and the equation in the section, specifically regarding the question representation and the use of r^q. It suggests clarifying this discrepancy and provides a specific question about the meaning of \\sigma in the equation. Additionally, it raises a concern about the stability of the computation involving two sigmoid activations. The comment is explicit in its request for clarification and provides concrete guidance on what needs to be addressed. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the equation in Section 4.2, specifically pointing out the lack of a term for r^q, which is the question representation, and the unclear meaning of \\sigma in the equation. The comment suggests clarifying these points and raises a concern about the stability of the computation involving two sigmoid activations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the question representation in Section 4.2, specifically mentioning that the equation does not include a term for r^q, which is the question representation. The reviewer suggests clarifying this discrepancy and questions the meaning of \\sigma in the equation. Additionally, the comment raises a concern about the stability of the computation involving two sigmoid activations. The claim is somewhat verifiable as it provides logical reasoning by pointing out the discrepancy in the equation and suggesting clarification. However, it lacks specific examples or references to support the claim about the stability of the computation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the question representation in Section 4.2, noting that the equation does not include a term for r^q, which is the question representation. It also questions the meaning of \\sigma in the equation and raises a concern about the stability of the computation involving two sigmoid activations. The comment provides clear and actionable feedback by suggesting that the authors clarify these points to improve the clarity and understanding of their work. By addressing these issues, the authors can enhance the comprehensibility and robustness of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to provide more novelty or depth in their methodology section, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"methodology aspect\" and \"ENCODE part,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The reviewer further suggests that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific references or detailed reasoning to support the claim that the ENCODE part is already proposed. The suggestion about the decomposition part is somewhat vague, as it does not provide a clear explanation of what the authors should do to address this issue. Therefore, the claim is somewhat verifiable, as it provides some insight but lacks sufficient evidence or detailed reasoning to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment highlights a potential weakness in the paper\\'s novelty, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it alerts the authors to a potential problem, but it lacks actionable advice or detailed insights to fully support the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in cramped equations and captions too close to the figures. This is seen as a violation of the 9-page paper limit. The comment provides a clear and direct action for the authors to take, which is to address the issue by adjusting the spacing and layout of the paper to comply with the page limit. The action is concrete, as it specifies the problem and provides a clear solution, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of whitespace throughout the paper, specifically mentioning the cramped equations and captions too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9-page paper limit due to the reduced whitespace. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper violates the 9-page limit due to the reduced whitespace, specifically mentioning cramped equations and captions too close to the figures. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it affects the paper\\'s acceptability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the layout and spacing of the paper, noting that equations are cramped together and captions are too close to the figures. This is seen as a violation of the 9-page paper limit. While the comment highlights a clear problem, it does not provide actionable suggestions or guidance on how the authors might address this issue, such as recommending adjustments to the spacing or layout. Without such specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical details or formulations, nor are there suggestions for additional exploration or explanation. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not specify which part of the paper this issue pertains to, such as specific sections, figures, or formulations. Without explicit references to these elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are lacking or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide specific guidance or suggestions on how the authors might improve the technical details or formulations to enhance the paper\\'s clarity or impact. Without actionable feedback or detailed insights, the authors are left without a clear path for improvement. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can differ across datasets. It suggests that the paper lacks cross-dataset experiments, which would be a good way to test the generalization of the work. While the comment implies that the authors should conduct cross-dataset experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for cross-dataset experiments and determine how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of cross-dataset experiments, which is a critical aspect of testing the generalization of the work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential risk of methods that exploit relationships between action units, noting that these relationships can differ across datasets. It provides an example of AU6 occurring in both pain and happiness expressions, which illustrates the variability across datasets. The comment suggests that cross-dataset experiments would be a good way to test the generalization of such work. While the comment provides a logical reasoning for the need for cross-dataset experiments, it lacks specific examples or references to support the claim that the relationships differ across datasets. This makes the claim somewhat verifiable, as the authors would need to further explore the issue themselves to fully understand and address it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can differ across datasets. It provides a specific example of AU6 occurring in both pain and happiness expressions, illustrating the variability across datasets. The comment suggests that cross-dataset experiments would be a valuable way to test the generalization of the work. While the comment highlights an important area for improvement, it lacks specific suggestions on how to conduct cross-dataset experiments or what aspects to focus on. This limits the comment\\'s helpfulness, as it provides insight but does not offer detailed guidance on how to address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should reconsider their statement about over-parameterization, which is currently presented as a negative aspect. The reviewer provides a rationale by pointing out that over-parameterization can be beneficial for supervised learning of deep neural networks in practice, and references a theoretical work that supports this claim. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their stance on over-parameterization. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 47 - 48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the authors\\' claim about over-parameterization and provides a rationale by pointing out its benefits in practice and referencing theoretical work. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim about over-parameterization, suggesting that it is beneficial for supervised learning of deep neural networks in practice. The reviewer provides a rationale by referencing theoretical work that supports the benefits of over-parameterization, such as [1]. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or specific references to the theoretical work, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment challenges the authors\\' claim about over-parameterization, suggesting that it is beneficial for supervised learning of deep neural networks in practice. The reviewer provides a rationale by referencing theoretical work that supports the benefits of over-parameterization, such as [1]. This feedback is somewhat helpful as it prompts the authors to reconsider their stance on over-parameterization and potentially explore its benefits in their work. However, the comment could be more helpful if it provided specific examples or additional references to support the argument further. Overall, the comment offers a valuable perspective but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. It points out that if not, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly re-run experiments with different initialization methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental comparison with other methods and the specific issue of initialization with pre-trained models. It also references Table 1, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies the concern about the fairness of the comparison and the potential impact on the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. The reviewer supports this claim by referencing Table 1, which shows that the proposed method without SSL performs inferior to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential issue in the experimental setup. However, the comment could be strengthened by providing more detailed reasoning or examples of how this initialization might impact the results. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks full justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method with a pre-trained model. It highlights a potential bias in the results if the compared methods were not initialized with the same or similar pre-trained model. The comment references Table 1 to support its claim, which provides a clear and actionable suggestion for the authors to address this concern. By pointing out this potential flaw, the comment offers valuable guidance for the authors to improve the robustness and credibility of their experimental results. However, it could be more helpful if it provided additional suggestions on how to mitigate this issue or how to design a more fair comparison. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a clear direction for the authors to address it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a related work that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion to use better meta-data embeddings and provides a specific reference to a related work. However, it does not provide detailed guidance on how to implement this suggestion or what specific steps to take. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better meta-data embeddings for the zero-shot learning results on the CUB dataset. The comment provides a specific example of a related work that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the authors should consider this approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The reviewer provides a specific example of a related work that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" This reference provides a clear rationale for the suggestion, as it demonstrates that better meta-data embeddings can lead to improved performance. However, the comment could be strengthened by providing more detailed analysis or specific examples of how the proposed method could benefit from these embeddings. Overall, the claim is mostly verifiable, as it is supported by a specific example and logical reasoning, but it could be further substantiated with additional evidence or detailed explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by recommending the use of better meta-data embeddings for the zero-shot learning results on the CUB dataset. It references a specific example from a related work, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which demonstrates the potential for better meta-data embeddings to improve performance. This feedback is actionable and provides a clear direction for the authors to enhance their results. However, it could be more helpful if it included additional details on how to implement this suggestion or what specific steps the authors should take to explore this option. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning a specific paper (Nguyen-Tang et al AAAI\\u002721, \\u201cDistributional Reinforcement Learning via Moment Matching\\u201d). This provides a clear and direct action for the authors to take, as they are instructed to include this discussion in their paper. The comment is specific and provides concrete guidance on how to enhance the paper by incorporating relevant literature. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific paragraph (lines 22-30) and discusses the use of moment matching in distributional RL, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on using moment matching instead of quantile regression for distributional RL. This provides clear guidance on what the authors need to add to their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning a specific paper (Nguyen-Tang et al AAAI\\u002721, \\u201cDistributional Reinforcement Learning via Moment Matching\\u201d). This claim is somewhat verifiable as it provides a specific reference to a relevant work, which supports the suggestion that the paper should discuss this approach. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be beneficial in the context of distributional RL. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area where the paper lacks relevant literature, specifically on the use of moment matching instead of quantile regression for distributional RL. By pointing out this gap, the comment provides the authors with a clear and actionable suggestion to enhance their draft by discussing this approach. This feedback is valuable as it directs the authors to include a relevant and potentially impactful discussion in their paper, which could significantly improve its comprehensiveness and depth. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or suggest alternative approaches to explore. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically mentioning that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the novelty, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. This feedback highlights a potential weakness in the paper\\'s contribution, which could be addressed by providing more novel or innovative approaches to model interpretation. However, the comment does not offer specific suggestions or guidance on how the authors might enhance the novelty or address this limitation. While it points out an area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to clarify the assumptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and the significance of their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it lacks full specificity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. The reviewer provides a reference to a related work by Dombrowski et al. (2022) to support their claim about the use of PCA. However, the comment lacks detailed explanation or analysis of why the assumptions are unclear or how they impact the paper\\'s results. The reference to the external work is helpful but does not fully substantiate the claim, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. It references a related work by Dombrowski et al. (2022) to support its claim. While the comment identifies a potential weakness in the paper\\'s novelty and significance, it lacks specific guidance on how the authors might address these concerns or what aspects of the assumptions are unclear. The reference to the external work is helpful, but the comment could be more beneficial if it provided more detailed feedback or suggestions for improvement. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models, which raises concerns about its broader applicability. The reviewer suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation or expand the scope of their framework. The action is implicit and somewhat vague, as the authors need to infer that they should consider broadening the scope of their framework. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluative framework, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited scope of the framework, which is restricted to only three Question-Answering tasks and two language models. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, restricted to only three Question-Answering tasks and two language models, which raises concerns about its broader applicability. The comment suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. However, the comment lacks specific examples or references to substantiate these concerns, making it somewhat verifiable. The authors would need to infer the potential applicability issues and address them themselves, rather than having clear guidance on how to improve the framework. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. This observation raises concerns about the method\\'s broader applicability, as it may not generalize to other reasoning or generation tasks or more advanced models. The comment highlights a potential area for improvement by suggesting that the authors consider expanding the scope of their framework to address these concerns. However, the comment could be more helpful by providing specific suggestions on how to broaden the scope or examples of other tasks or models that could be included. Overall, the comment is somewhat helpful as it points out a limitation and suggests an area for improvement, but it lacks detailed guidance on how to address the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer recommends using a second y-axis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not specify which alternative visualization should be used or how to implement the change. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests using a second y-axis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why Figure 6C is awkward or why the current visualization is inaccurate. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not accurate. The reviewer suggests a solution by recommending the use of a second y-axis or another visualization that is more physically accurate. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the accuracy and clarity of their figure. However, the comment could be more helpful if it included additional context or examples of alternative visualizations that could be used. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left to infer that they should work on increasing the complexity, but without concrete steps or examples, they may struggle to know where to start or what aspects to focus on. Therefore, the comment is vague and lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of Algorithm 2 needs improvement or how it could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of Algorithm 2 should be improved or how to achieve this improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any supporting evidence, reasoning, or examples to justify why this improvement is necessary or how it could be achieved. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there is room to improve the complexity of Algorithm 2, which is a relevant observation. However, it lacks specificity and does not provide any guidance or suggestions on how to achieve this improvement. Without actionable advice or examples, the authors are left without a clear path to follow, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the statement in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. It points out that this claim is not supported by the authors\\' experience, as evidenced by the training of 1500-dimensional LSTMs on PTB by Zaremba et al. (2014). The reviewer also asks about the application of dropout to both embeddings and hidden states. While the comment identifies a specific issue with the statement, it does not provide explicit guidance on how to address it or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and potentially revise the supplemental section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that smaller architectures are necessary for LM compared to GAN models, suggesting that the baseline models are not properly regularized. The reviewer also asks about the application of dropout to both embeddings and hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim made in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer provides a counterexample by citing the training of 1500-dimensional LSTMs on PTB by Zaremba et al. (2014), which suggests that the baseline models are not properly regularized. This provides a logical reasoning that challenges the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the counterexample. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific claim in the supplemental section D.4 that is questionable, suggesting that the statement about smaller architectures being necessary for LM compared to GAN models is not supported by the authors\\' experience. The reviewer provides a counterexample by citing the training of 1500-dimensional LSTMs on PTB by Zaremba et al. (2014), which challenges the claim that baseline models are not properly regularized. Additionally, the comment asks about the application of dropout to both embeddings and hidden states, which could be a relevant area for further exploration or clarification. While the comment identifies a potential weakness in the paper, it lacks detailed guidance or suggestions on how to address it. Therefore, it is somewhat helpful, as it provides insight into a potential issue but does not fully guide the authors on how to improve their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While the action is implicit, it is clear that the authors need to revise the introduction to make it more concise and include empirical results. The comment provides a specific direction for improvement, but it lacks detailed guidance on how to achieve this concision or what specific empirical results should be included. Therefore, the action is somewhat actionable, as the authors know they need to make changes but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, it does not specify which part of the introduction is too long or where empirical results should be included. The authors can infer that the introduction and empirical results sections are being addressed, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, the comment does not provide any specific examples or reasoning to support why the current introduction is too long or how empirical results could enhance it. Without detailed guidance or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While it identifies a potential area for improvement, it lacks specific guidance on how to achieve this concision or what empirical results should be included. The comment provides a general direction for improvement but does not offer detailed suggestions or examples to help the authors effectively address the issue. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those changes. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors could clarify the technical contribution or make the analysis more novel. There is no explicit or implicit action for the authors to take, such as suggesting alternative analyses or explaining the novelty of their approach. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are unclear or where the analysis is standard. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need clarification or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide specific examples or detailed feedback on how the authors could clarify the technical contribution or make the analysis more novel. Without actionable suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the application of regularization between the LN model and GLMs. It suggests that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al., to ensure a fair comparison. While the comment implies that the authors should make an effort to replicate the previous model, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the LN model and the GLMs, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the application of regularization between the LN model and GLMs, and suggests that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors apply regularization to both LN models and GLMs, which is not consistent with the GLM presented by Pillow et al. The reviewer suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment lacks specific examples or references to the GLM by Pillow et al. to fully substantiate the claim. While the reviewer provides a logical reasoning, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the application of regularization between the LN model and GLMs, suggesting that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al. This feedback is somewhat helpful as it points out a potential issue with the comparison between models, which could impact the validity of the results. However, the comment lacks specific guidance on how to reproduce the main features of the previous model or what specific aspects of the comparison should be addressed. While it highlights an area for improvement, the lack of detailed instructions limits its utility for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include failure cases and related discussions. While it implies that the authors should consider including these elements, it does not provide specific guidance on how to implement this suggestion or what aspects of the failure cases should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should include failure cases and related discussions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including failure cases and related discussions, but it does not specify which part of the paper should include these elements. The authors cannot confidently determine which sections or parts of the paper would benefit from this addition. Additionally, the comment lacks specificity regarding what aspects of the failure cases should be discussed or how they should be integrated into the paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that including failure cases and related discussions would be beneficial. However, it does not provide any reasoning, examples, or references to support why this addition would be valuable or how it would enhance the paper. Without specific justification or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including failure cases and related discussions would be beneficial. However, it lacks specificity and does not provide guidance on what aspects of the failure cases should be discussed or how they could be integrated into the paper. Without detailed suggestions or examples, the authors may find it challenging to understand the exact improvements needed or how to implement this feedback. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not offer actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a discrepancy in the use of \\u03b4 in equations (10) and (11) and suggests introducing \\u03b4 when (11) is discussed. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"equation (11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent use of \\u03b4 in equations (10) and (11) and suggests introducing \\u03b4 when (11) is discussed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \\u03b4 is not used in equation (10) but is used in equation (11). This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of \\u03b4 in equations (10) and (11), noting that \\u03b4 is not used in equation (10) but is used in equation (11). It suggests introducing \\u03b4 when (11) is discussed to improve clarity. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by ensuring consistency in the use of mathematical symbols. However, the comment could be more helpful if it explained why this inconsistency is problematic or how it affects the understanding of the equations. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding batch normalization. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or what aspects should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and its limitations in addressing internal covariate shift. It also specifies the issue with batch normalization, which standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the paper. However, the comment could be more specific by suggesting how to discuss these limitations or what aspects should be emphasized. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some low-variance units. The reviewer supports this claim by comparing it to batch normalization, which standardizes the variance and centers the activation. However, the comment lacks specific examples or references to substantiate the claim fully. While it provides a logical reasoning, it could be strengthened with more detailed evidence or examples to fully support the assertion. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the claim about evolutional dropout addressing internal covariate shift. It suggests that the claim is limited because it can only increase the variance of some low-variance units, while batch normalization standardizes the variance and centers the activation. This feedback is clear and actionable, as it prompts the authors to explicitly discuss these limitations in their paper. However, the comment could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects should be emphasized. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and depth of their discussion on this topic.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the author to add more description about the contribution of the paper. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment provides a specific suggestion for enhancing the paper\\'s contribution section, making it highly actionable. The authors know exactly what is expected of them, and the feedback is concrete, making it easy to implement the suggested changes. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the author should add more description about the contribution of the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, results, or discussion sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to make these additions. Additionally, the comment lacks specificity regarding what kind of additional description is needed or how it should be presented. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper lacks a detailed description of its contribution. However, it does not provide any specific examples or reasoning to support why this is an issue or how it could be improved. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should add more description about the contribution of their paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what kind of additional description is needed or how it should be incorporated into the paper. Without specific suggestions or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. While the comment provides a clear and explicit action\u2014changing \"X\" to a multiset\u2014it does not offer detailed guidance on how to implement this change or what specific considerations should be taken into account. The action is concrete, but the lack of additional context or explanation makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the change from a set to a multiset in the context of representing a graph with repeated vertex or edge labels. This provides clear guidance on what needs to be corrected or improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning based on the need to include multiplicities to ensure an honest representation of the graph. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors may need to further explore the rationale behind the suggestion, which could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It points out that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and constructive, as it directly addresses a potential issue with the accuracy of the representation. However, the comment could be more helpful if it included additional context or explanation on why this change is necessary or how it would impact the analysis. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the derivation. The comment lacks actionable details, such as suggesting alternative methods or approaches to incorporate Bayesian considerations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. However, it does not specify which part of the paper this critique pertains to, such as a particular section or equation. The authors can infer that it relates to the derivation or theoretical aspects of the paper, but this inference is not direct. The comment is specific in its critique of the classical learning theory-based bounds and the need for Bayesian considerations, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. The reviewer supports this claim by mentioning Bayesian-PAC based bounds as an example of a more realistic approach. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a general idea of the issue, it does not offer enough evidence or detailed explanation to fully verify the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. It suggests that the authors should consider Bayesian-PAC based bounds as a more realistic approach. While the comment identifies a potential weakness in the derivation, it lacks specific guidance on how the authors might incorporate Bayesian considerations or what specific aspects of the derivation need to be revised. The feedback is somewhat helpful as it points out a potential issue but does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It points out a specific example from line 486 where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment provides a clear and explicit action for the authors to take, which is to conduct significance testing to support their claims. This guidance is concrete and leaves no ambiguity about what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of significance testing to support claims about the differences between methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make significant claims about the differences between methods without conducting significance testing. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment is mostly verifiable as it provides a logical reasoning and a specific example to support the claim. However, it could be strengthened by referencing external works or studies that demonstrate the importance of significance testing in similar contexts. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer points out that without proper testing, it is difficult to determine whether these differences are significant. This feedback is clear and actionable, as it directs the authors to conduct significance testing to support their claims. By addressing this issue, the authors can significantly improve the rigor and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It highlights the need for proper ablation studies to verify this claim. While the comment identifies a specific concern and suggests a potential solution (ablation studies), it does not provide explicit instructions on how to conduct these studies or what specific aspects to focus on. The action is clear but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It points out the need for proper ablation studies to verify this claim. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the claim and the need for ablation studies, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. The reviewer provides a logical reasoning by pointing out that the fine-tuning without early-stopping could lead to high variances, which would affect the validity of the claim. However, the comment lacks specific examples or references to support the argument, making it somewhat verifiable. The authors would need to conduct their own analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that the improvements in teacher performance are due to distillation. It suggests that the improvements might be due to regularization effects instead, given the lack of early-stopping and the high variances in fine-tuning. The comment highlights the need for proper ablation studies to verify the claim, providing a clear and actionable suggestion for the authors to address this concern. However, the comment could be more helpful if it offered specific guidance on how to conduct these studies or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing further exploration and validation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses a subjective opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors might address this perception or improve the contribution of their work. There is no explicit or implicit action for the authors to take, such as suggesting alternative approaches or improvements to the model. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution of the paper and the approach of the proposed model, but it does not specify which part of the paper this perception is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution or approach are considered incremental or limited. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to support the assertion, the authors may find it challenging to understand or address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific reasoning or examples to support this claim or offer suggestions for improvement. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their work need attention or enhancement. As a result, the comment lacks helpfulness, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the model. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to pretraining and possibly adjust the model\\'s architecture or training process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"prediction of homo-lumo gap\" and the \"QM9 in downstream experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the Transformer-M model performs poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as evidenced by Transformer-M\\'s poor performance on most tasks except for homo, lumo, and gap. The reviewer provides an example from QM9 in downstream experiments, which supports the claim. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have observed similar negative transfer effects. Despite this, the claim is mostly verifiable due to the provided example and logical reasoning.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. This feedback is somewhat helpful as it highlights a specific area of concern that the authors should address, but it lacks detailed guidance on how to resolve the issue or what specific changes should be made to improve the model. The authors are given a direction to explore but are not provided with actionable steps to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this aspect and compare their approach to more approaches in the continual learning literature. Additionally, it points out that the comparison to DEN is not convincing and questions whether DEN is correctly used or evaluated. While the comment provides explicit actions to take, such as including ablation and comparing to more approaches, it lacks specific guidance on how to implement these actions. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to follow. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. The comment also suggests that the comparison to DEN is not convincing and recommends using the same setup as in the DEN paper to ensure a fair comparison. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks ablation for the \"picking\" step and questions the fairness of the comparison on CIFAR. It suggests that the comparison to DEN is not convincing and recommends using the same setup as in the DEN paper to ensure a fair comparison. While the comment identifies specific issues with the experimental evaluation, it does not provide detailed reasoning or references to support these claims. The lack of specific examples or detailed justification makes it somewhat verifiable, as the authors may need to infer the basis of the critique and determine how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It points out that the comparison to DEN is not convincing and suggests that the authors should use the same setup as in the DEN paper to ensure a fair comparison. This feedback is clear and actionable, as it provides specific guidance on how to improve the experimental evaluation by including ablation and using the same setup as in the DEN paper. By addressing these issues, the authors can significantly enhance the credibility and robustness of their results. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of the trade-off and possibly explore ways to mitigate it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"ancestral graphs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. The comment further raises a question about the information encoded in the ancestral graph compared to the DAGs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the reduction in search space results in a loss of information. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a relevant consideration for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important aspect of the paper, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the definitions in Table 1, specifically questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also mentions that the literature has shown that regression methods do not significantly influence the results. The reviewer suggests that the authors clarify this issue and provides a potential solution by suggesting that direct regression to the center point is sufficient. However, the comment does not explicitly instruct the authors to clarify this issue or provide specific guidance on how to address it. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. The reviewer provides a detailed explanation of the potential confusion regarding the methods and suggests that the authors clarify this issue. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. The reviewer cites the literature to support their claim that regression methods do not significantly influence the results. However, the comment lacks specific references to the literature or detailed explanations of the differences between the methods. This makes it somewhat verifiable, as the authors would need to conduct further research to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the definitions and differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It highlights a potential confusion regarding the methods and suggests that the authors clarify this issue to strengthen the motivations in their work. While the comment identifies a critical area for clarification, it lacks specific guidance on how the authors might address this issue or what specific aspects of the definitions need clarification. This limits the comment\\'s helpfulness, as it provides a direction for improvement but does not offer detailed suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific in detailing what needs to be clarified, making it highly actionable. Authors know exactly what needs to be done to improve their draft, ensuring that the action is concrete. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the Fourier modes as numbers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests clarifying whether these modes are real or complex numbers, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their draft. By addressing this point, the authors can ensure that their explanation is accurate and complete, which is beneficial for both the readers and the review process. However, the comment could be more helpful if it provided additional context or examples to guide the clarification process. Overall, the comment is mostly helpful as it identifies a specific area for improvement, but it could be more comprehensive with additional details. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It also provides specific guidance on how to resolve the issue by mentioning the use of the \"\\\\label\" command after the \"\\\\caption\" in LaTeX. This feedback is clear and concrete, as it directly specifies the correction needed and provides a specific method for implementation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of Fig. 1 instead of Fig. 5.1 and provides guidance on how to resolve the issue by mentioning the use of \"\\\\label\" after \"\\\\caption\" in LaTeX. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction, noting that the labeling of Fig. 1 should be corrected to Fig. 5.1 on line 205. It provides a specific instruction on how to resolve the issue by mentioning the use of \"\\\\label\" after \"\\\\caption\" in LaTeX. This is a clear and straightforward correction, making the claim fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific error in the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It provides clear and actionable feedback by instructing the authors to correct the labeling and mentioning the use of \"\\\\label\" after \"\\\\caption\" in LaTeX. This guidance is precise and straightforward, enabling the authors to make a direct and easy correction to their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pre-training for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment explicitly states the need for case studies and error studies, it does not provide specific guidance on how to implement them or what aspects to focus on. The action is clear but lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Element-level Graph Pre-training\" and the \"complex structure\" mentioned in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that case studies and error studies could be beneficial in demonstrating the effectiveness of each proposed component. It provides an example of a case study from \"Graph pre-training for AMR parsing and generation\" to illustrate the potential benefits. However, the comment lacks specific examples or detailed reasoning to fully substantiate why case studies and error studies are necessary or how they would enhance the paper. While it provides a logical argument, the lack of detailed evidence or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of each proposed component. It highlights the importance of such studies by referencing an example from \"Graph pre-training for AMR parsing and generation,\" which illustrates the potential benefits of including these analyses. This feedback is valuable as it offers a concrete way for the authors to enhance the persuasiveness and credibility of their work. However, the comment could be more helpful if it provided specific guidance on how to design and conduct these studies, such as what aspects to focus on or how to present the results. Overall, the comment is mostly helpful as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation \"{\\\\cal P}\" with a subscript is used several times without being defined. This is an explicit action, as it clearly identifies the issue of missing definitions. The authors are given a direct and concrete instruction to define the notation, ensuring they know exactly what needs to be done to address the comment. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"same section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"{\\\\cal P}\" with a subscript being used without being defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"{\\\\cal P}\" with a subscript is used several times without being defined. This is a factual observation that does not require any subjective judgment or opinion. It is a request for clarification, not a claim that needs verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"{\\\\cal P}\" with a subscript being used without being defined. This is a clear and actionable point, as it directs the authors to define the notation to avoid confusion and ensure clarity in their work. By addressing this issue, the authors can improve the readability and comprehensibility of their paper. However, the comment could be more helpful if it provided suggestions on how to define the notation or examples of how it should be used. Overall, the comment is mostly helpful as it effectively points out a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It explicitly instructs them to correct \"known\" to \"know\" in line 148 and to define \"gamma_0^{***}\" in line 156. Additionally, it requests clarification on the meaning of the colors used in Figure 1, both in the caption and the text. These actions are clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (l148 and l156) and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected (correcting \"known\" to \"know\" and defining \"gamma_0^{***}\") and requests clarification on the meaning of colors in Figure 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual corrections and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out errors in the manuscript, such as correcting \"known\" to \"know\" and requesting clarification on the definition of \"gamma_0^{***}.\" Additionally, it asks for clarification on the meaning of colors used in Figure 1, both in the caption and the text. This level of detail and specificity helps the authors identify and address specific areas for improvement, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment implies that the authors should provide explanations for these choices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for these decisions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the main rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the experimental setup need clarification or explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the rationales behind certain experimental decisions. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the rationales behind certain experimental decisions, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While it identifies areas that need clarification, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these questions. The feedback is somewhat helpful as it points out areas that need further explanation, but it could be more beneficial if it offered actionable advice or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific guidance or suggestions on how to improve it. There is no explicit or implicit action for the authors to take, such as suggesting ways to clarify or organize the content. Without any actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the writing or presentation is jumbled at times, but it does not specify which parts of the paper are affected. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or presentation are jumbled, making it difficult for the authors to address the issue effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific examples or guidance on how to improve the clarity or organization of the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what aspects of their writing need attention or how to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment does not explicitly instruct the authors to perform a computational complexity analysis or provide guidance on how to address the power demand concern, it implies that the authors should consider these aspects. The action is implicit but concrete, as it points to specific areas that need attention. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where computational complexity is discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific in its inquiry about computational complexity and power demand, but without explicit references, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, the comment lacks specific examples or references to support the claim about computational complexity or power demand. Without detailed evidence or comparisons, the claim is not fully verifiable, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment identifies a relevant concern about computational complexity and power demand, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It explicitly states that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al. (2023). This provides a clear and concrete action for the authors to correct their statement, ensuring that the information is accurate. The comment is highly actionable as it directly instructs the authors on what to change in their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, noting that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al. (2023). Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect, as per Section 3 of Wang et al. (2023). The reviewer provides a specific reference to the source, which supports the claim. This makes the claim mostly verifiable, as it relies on a specific external reference to substantiate the claim. However, the comment could be strengthened by providing more detailed analysis or examples from the referenced work to further support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It points out that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al. (2023). This feedback is clear and actionable, as it directs the authors to correct their statement to ensure accuracy and credibility. By addressing this issue, the authors can improve the clarity and reliability of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on the vagueness of certain RNNs and suggests that the reinforcement learning/agent analogy is out of place. It also points to specific lines in the paper where generalization capabilities are better illustrated. While the comment identifies areas for improvement, it does not provide concrete guidance on how to address the vagueness or suggest specific changes to the analogy or examples. The authors are left with a general idea of what needs to be improved but without detailed instructions on how to implement these improvements. Therefore, the comment is somewhat actionable, as it provides a direction but lacks specificity in execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L15\" and \"L16-18,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the vagueness of certain RNNs and the reinforcement learning/agent analogy, providing clear guidance on what needs to be addressed. The comment is specific in detailing the problem with the vagueness and suggesting that the examples later in the paper better illustrate generalization capabilities. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the vagueness of certain RNNs and the reinforcement learning/agent analogy are out of place in the context of the paper. The reviewer provides a specific reference to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to support the claim that certain RNNs work well for certain natural language reasoning tasks. However, the comment lacks detailed reasoning or specific examples from the literature to fully substantiate the claim. While the reference provides some support, the comment could be strengthened by further elaboration on why the analogy is inappropriate or how it could be improved. Therefore, the comment is somewhat verifiable, as it provides a starting point but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the vagueness of certain RNNs and the reinforcement learning/agent analogy in the paper. It suggests that the examples later in the paper better illustrate generalization capabilities, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided specific suggestions on how to address the vagueness or how to better integrate the examples into the paper. While it identifies areas for improvement, the feedback lacks detailed guidance, making it somewhat helpful but not comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a statement in the paper that claims every kernel can be described by a feature space parameterized by a neural network, which is not true. The reviewer suggests that the limitation of representing infinite-dimensional RKHSs with neural networks should be made more clear. While the comment identifies a specific issue with the claim, it does not provide explicit guidance on how to address it or what specific changes should be made to clarify the limitation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitation, but it lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of feature spaces and neural networks. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of representing infinite-dimensional RKHSs with neural networks. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that every kernel can be described by a feature space parameterized by a neural network, pointing out a limitation with RBF kernels and their infinite-dimensional representation. The reviewer provides a logical reasoning by referencing the fact that RKHS is famously infinite-dimensional, making it impossible to represent with a neural network of finite width. This logical reasoning supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It points out a limitation with RBF kernels, which are famously infinite-dimensional, making it impossible to represent them with a neural network of finite width. The reviewer suggests that the limitation should be made more clear, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a critical aspect of the paper that needs clarification, guiding the authors to enhance the accuracy and completeness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It suggests that the authors should conduct a thorough literature review to identify other works that use this property. While the comment explicitly states the need for a literature review, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of originality in the proposed method and the need for a thorough literature review to identify other works that use the same property. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and score-interpolation, which have used this property. This provides a clear and robust justification for the claim, making it fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known in the literature. It provides specific examples of existing works that use this property, such as the original denoising score matching objective and score-interpolation. This feedback is valuable as it highlights a potential gap in originality and suggests a thorough literature review to address it. However, the comment could be more helpful if it offered guidance on how to conduct the literature review or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides actionable feedback on a critical aspect of the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is limited, suggesting that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could improve their technical contribution or what aspects of the typical model could be leveraged to enhance their work. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is limited and does not provide a specific part of the paper where this issue is addressed. It mentions the cross-domain recommendation setting, but without further context or detailed explanation, the authors may struggle to identify the exact section or aspect of the paper that needs attention. The comment lacks specificity in detailing what is considered typical or how the technical contribution could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is limited and does not provide a significant extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical contribution of the paper is limited, specifically noting that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any specific examples, reasoning, or suggestions for how the authors could enhance their technical contribution or what aspects of the typical model could be leveraged to improve their work. Without actionable feedback or detailed guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, it highlights that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. While the comment identifies issues with novelty and similarity, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should improve the novelty and differentiate their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"specific components of the approach,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with novelty and similarity, such as the use of MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before, and the similarity in sampling strategy to epsilon-greedy and BRP-NAS. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. The reviewer also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, the reviewer states that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. The claim is supported by references to external works, which provide a basis for the assertion that the components are not novel. However, the comment could be strengthened by providing specific examples or detailed comparisons to further substantiate the claim. Therefore, the comment is mostly verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty and originality of the approach, noting that the specific components are not novel as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also points out that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, it highlights that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. This feedback is somewhat helpful as it provides clear and actionable information about areas where the paper could be improved by differentiating its approach or presenting new insights. However, it could be more helpful if it offered suggestions on how to address these issues or improve the novelty of the approach. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the calculation of precision/recall/F1-score for a 4-class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these metrics and AUC results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of precision/recall/F1-score for a 4-class classification of breast density and the reporting of AUC results for breast cancer detection. It also specifies the need for sensitivity and specificity at different operating points for model performance comparisons. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual questions about the calculation of precision/recall/F1-score and the reporting of AUC results for breast cancer detection. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the calculation and reporting of metrics for a 4-class classification of breast density and breast cancer detection. It suggests that providing AUC results with sensitivity and specificity at different operating points could be more informative for comparisons. This feedback is clear and actionable, as it guides the authors to include specific metrics and data that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it provided examples of how these additional metrics could be presented or discussed in the context of the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is well-studied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\\' dataset can be considered extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use the Kialo dataset rather than being directly told to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters, and that it is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The suggestion to use the Kialo dataset is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. The reviewer claims that the Kialo dataset provides pairs of short claims and their counters and is cleaner than the dataset created by the authors. However, the comment lacks specific examples or references to support the claim that the Kialo dataset is cleaner or that it provides exactly what the authors need. While the suggestion to use the Kialo dataset is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community and provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner than the one created by the authors and can be considered extra data to learn from. While the comment identifies a potential source of data that could be used, it lacks specific guidance on how the authors should incorporate this dataset into their work or what specific aspects of the dataset would be beneficial. The feedback is somewhat helpful as it points out a potential resource, but it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the use of Transformer in the paper, noting that it is no longer novel in the field and that the authors' modification (cross-layer) does not bring significant insight. The reviewer also questions the significance of the self-cross attention improvement in the ablation study, suggesting that it is limited (<1%). However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific modifications should be made to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the novelty and impact of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Transformer\" and \"cross-layer,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the modification does not bring significant insight and that the self-cross attention improvement is limited. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of Transformer in the paper is not novel and that the authors\\' modification (cross-layer) does not bring significant insight. The reviewer supports this claim by referencing the widespread adoption of Transformer in NLP and vision tasks, which suggests that the modification is not innovative. Additionally, the reviewer points out that the self-cross attention improvement is limited (<1%), questioning its significance. However, the comment lacks specific examples or references to support the claim about the limited improvement. This makes the claim somewhat verifiable, as the authors would need to further explore the evidence or references to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical analysis of the paper\\'s use of Transformer, noting that it is no longer novel in the field and that the authors\\' modification (cross-layer) does not bring significant insight. The reviewer also questions the significance of the self-cross attention improvement, suggesting that it is limited (<1%). This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s novelty and contribution. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these concerns or improve the paper\\'s impact. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss a previous work on joint error for UDA, specifically mentioning \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019. It also suggests that the authors should illustrate the relationship between this work and their proposed method, as well as highlight why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the joint error for UDA and references a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the relationship between the proposed method and the previous work, and why the proposed method is better. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' claim about the joint error for UDA is incorrect, as it has already been studied in previous works like \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019. The reviewer supports this claim by referencing the specific work, providing a clear and direct reference to substantiate the claim. This makes the comment mostly verifiable, as it offers a specific example to support the claim, but it could be further strengthened by providing additional details or analysis on why the proposed method is better than the existing work. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the joint error for UDA and points out that this problem has already been studied in previous works, such as \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019. It suggests that the authors should discuss this work and its relationship to their proposed method, as well as highlight why their method is better. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the existing literature and justifying the novelty of their approach. By addressing these points, the authors can enhance the clarity and originality of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the larger-scale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors can infer that they should consider the impact of dataset size on performance and potentially adjust the comparison with SOTA methods. However, the comment lacks concrete steps or suggestions on how to conduct this adjustment or what specific aspects of the comparison should be revised. Therefore, the comment is somewhat actionable, as it points out an issue but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with state-of-the-art (SOTA) methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison with SOTA methods. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods may be unfair due to the difference in dataset size. The reviewer provides a logical reasoning by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential bias in the comparison, suggesting that the superiority of the proposed method may be due to the larger-scale datasets. However, the comment lacks specific examples or references to existing methods or datasets to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the proposed method with state-of-the-art (SOTA) methods. It points out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential bias in the comparison, suggesting that the superiority of the proposed method may be due to the larger-scale datasets. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a fairer comparison method or suggesting ways to adjust the dataset size for a more accurate comparison. While the feedback identifies a relevant concern, it lacks actionable advice, making it somewhat helpful. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It also notes the absence of a discussion on the research gap, such as why existing methods cannot be applied. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the research gap should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification for the need of a new curriculum learning method and address the research gap, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods have been discussed in Section 1, the need for designing a new curriculum learning method for text graphs is not justified. It also points out the absence of a discussion on the research gap, such as why existing methods cannot be applied. This feedback is somewhat helpful as it highlights a potential gap in the paper\\'s justification for the need of a new curriculum learning method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the research gap should be discussed. While it provides some insight, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for the authors to use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest n-gram features. This is an explicit and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done and how it can be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach to address the domain adaptation problem, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest n-gram features. This claim is somewhat verifiable as it provides a logical reasoning for the use of these models in domain adaptation. However, the comment lacks specific examples or references to support the claim, such as studies or experiments that have demonstrated the effectiveness of these models in domain adaptation. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods in their domain adaptation work. This feedback is valuable as it offers a clear and concrete way to improve the draft by leveraging existing resources and methodologies. By following this advice, the authors can enhance the robustness and generalizability of their results. However, the comment could be more helpful if it explained why these models are particularly effective in domain adaptation or provided examples of their successful application. Overall, the comment is mostly helpful as it offers a clear direction for improvement but could be further enhanced with additional context or justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. It explicitly asks if it is possible to conduct such a comparison. The comment provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. This guidance is explicit and concrete, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and suggesting a comparison with final outputs. The comment further questions whether a quantitative comparison on the final outputs is possible, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. The comment provides a logical reasoning by pointing out that the current evaluation does not fully demonstrate ModelAngelo\\'s superiority to competitors. However, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing in demonstrating ModelAngelo\\'s superiority to competitors. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct such a comparison or provided examples of how it could be done. Overall, the comment is mostly helpful as it points out a critical area for improvement and provides a clear direction for the authors to enhance their evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance. While the comment provides a clear list of specific questions that need to be addressed, it does not offer explicit guidance on how to implement these improvements. The authors are left with a clear understanding of what needs to be added but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the techniques and the reproducibility of the results. It provides detailed questions about the sparsification process, landmark generation, and number of landmarks used, as well as how to achieve shape invariance. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be clarified or improved in each area. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of detail in the paper regarding the techniques used and the reproducibility of the results. It highlights specific areas that need clarification, such as the sparsification process, landmark generation, and number of landmarks used. The reviewer also questions how to achieve shape invariance. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support the claim that these areas are crucial for reproducibility. This makes the claim somewhat verifiable, as the authors may need to infer the importance of these details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance, among other aspects. This feedback is clear and actionable, as it provides specific questions that the authors need to address to improve the clarity and reproducibility of their work. By addressing these points, the authors can significantly enhance the comprehensibility and robustness of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the utility-based approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of premature evictions. The comment lacks concrete details or suggestions on how to improve the approach or validate its effectiveness. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the utility-based approach used in FIITED, specifically the potential biases introduced by basing eviction decisions solely on utility scores. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue of temporary high utility scores leading to premature evictions, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the risk of premature evictions due to temporary high utility scores for recent chunks. While the comment highlights a potential issue, it lacks specific examples or references to substantiate the claim. The reasoning is logical but could be strengthened with additional evidence or detailed explanation. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires more detailed support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the utility-based approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. This is a valuable observation that could lead to premature evictions of other valuable chunks. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of biases. While it points out a relevant concern, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an important area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the focus on DNNs is not relevant to the paper's core focus on detecting drift types and magnitude. The comment implies that the authors should reconsider the content and relevance of this paragraph, but it does not provide specific guidance on how to revise it or what alternative content could be included. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper\\'s focus. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is somewhat verifiable as it logically suggests that the introduction should focus on the core focus of the paper, which is detecting drift types and magnitude. However, the comment lacks specific examples or references to support the claim that the DNN-related introduction is not relevant. Providing more detailed reasoning or evidence would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the paper\\'s core focus. This feedback is clear and actionable, as it suggests that the authors should reconsider the relevance and content of this paragraph to ensure it aligns with the paper\\'s central theme. By addressing this issue, the authors can improve the clarity and focus of their introduction, making the paper more effective for its intended audience. Therefore, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the paper lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include quantitative experiments and comparisons, as well as detailed explanations of the algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer specific steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the methodology and the experimental section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of quantitative experiments and comparisons with other algorithms, as well as the need for more detailed explanations of the presented ones. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the lack of quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones, makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. The comment provides a logical reasoning for the need for more detailed information, but it does not include specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. This feedback is valuable as it highlights a critical area for improvement in the paper, namely the need for more comprehensive and detailed experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps, such as which experiments to conduct or how to present the results more effectively. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to compare their captioning experiment results to the official COOC leader board on the blind test set, which is a clear and concrete action. It also suggests that the paper should compare to other approaches that have been evaluated on the blind challenge set, providing a specific example of [5,17] and mentioning that several other approaches have been proposed since then. This feedback is detailed and provides specific guidance on how to improve the paper by including comparisons to official test sets and other relevant works. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the captioning experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of results to the official COOC leader board on the blind test set and the inclusion of comparisons to other approaches that have been evaluated on the blind challenge set. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the captioning experiment should be compared to the official COOC leader board on the blind test set, which is a specific suggestion for improvement. The reviewer provides a reference to the official COOC leader board and examples of other works that have been evaluated on the blind challenge set, such as [5,17]. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would enhance the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on how the authors can improve their captioning experiment. It points out that the paper currently compares to related work only on some not official test set or dev set, which is not ideal for demonstrating the final results. The reviewer suggests that the paper should compare to the official COOC leader board on the blind test set, which is a widely recognized benchmark in the field. Additionally, the comment suggests that the paper should include comparisons to other approaches that have been evaluated on the blind challenge set, such as [5,17], and mentions that several other approaches have been proposed since then. This feedback is clear and provides a concrete direction for the authors to enhance the rigor and credibility of their results. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a specific line (L248) where the term \"wrong\" is used and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable as it offers a specific guidance on how to clarify the meaning of the terms in the paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of the term \"wrong\" and the use of concepts like \"good\" and \"bad\" explanations. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the term \"wrong\" in a specific context and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This is a request for clarification rather than a claim or opinion. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the term \"wrong\" in the paper and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and coherence of the paper. By addressing this issue, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it offered additional guidance on how to clarify these concepts or provided examples of how they might be clarified. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the current experimental comparison only compares ELF (the author\\'s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. The comment is concrete and provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental demonstration of the contribution points\" and the \"experimental comparison between ELF (the author\\'s method) and the baseline without Mid Vision Feedback (MVF),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a comparison with the image classification result of Mid Vision Feedback (MVF) to prove the superiority of the schema searched by ELF. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment highlights a gap in the experimental setup, noting that the current comparison only compares ELF (the author\\'s method) with the baseline without MVF. This critique is somewhat verifiable as it points out a specific issue with the experimental setup, but it could be strengthened by providing more detailed reasoning or examples of how the comparison with MVF could be conducted. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental demonstration of the paper\\'s contribution points. It points out that the current experimental comparison only compares ELF (the author\\'s method) with the baseline without Mid Vision Feedback (MVF), but not with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental setup by including a comparison with the image classification result of MVF. This suggestion is valuable as it could help the authors demonstrate the superiority of their method over the baseline and MVF. However, the comment could be more helpful if it offered suggestions on how to conduct this comparison or what specific metrics to use. Overall, the comment is mostly helpful as it provides a clear and actionable direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the originality of the paper, noting similarities to a previous study. It implies that the authors should address this issue by either explaining how their work differs from the previous study or demonstrating novel contributions. However, the comment does not provide explicit instructions on how to do this, such as suggesting specific ways to differentiate the work or highlighting areas where novelty is present. The action is implicit and somewhat vague, as the authors need to infer that they should address the originality concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the paper, specifically mentioning a previous study, \"How Do Nonlinear Transformers Learn and Generalize in In-Context Learning.\" This provides some grounding by referencing a specific work, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what aspects of the paper are similar to the previous study or how the authors can address the originality concerns. The lack of specificity regarding the issues or suggestions for improvement makes it weakly grounded but specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's originality is questionable due to similarities with a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The mention of a specific study, \"How Do Nonlinear Transformers Learn and Generalize in In-Context Learning,\" suggests that the authors should address the issue of originality, but without further elaboration or evidence, the claim remains somewhat verifiable. The authors would need to conduct their own analysis to fully understand and address the originality concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the paper, noting similarities to a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address the originality concerns. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice or detailed guidance on how to improve the originality of the work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. It raises a question about whether the prediction error over the entire horizon T cannot be sublinear. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to clarify or correct the discussion, but the comment lacks concrete steps on how to do so. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. The comment clearly specifies what needs to be addressed, namely, whether the prediction error over the entire horizon T cannot be sublinear. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. It points out a potential discrepancy in the discussion, asking whether the prediction error over the entire horizon T cannot be sublinear. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. It points out a potential issue in the logic of the discussion, questioning whether the prediction error over the entire horizon T cannot be sublinear. This feedback is somewhat helpful as it highlights a specific area where the authors need to clarify or correct their discussion. However, the comment could be more helpful if it provided suggestions on how to address the discrepancy or offered guidance on how to clarify the discussion. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing attention, but it lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in table 3 shows this happening, but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the importance of long-range dependencies in their paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"visualisations in table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the necessity of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that the example in table 3 shows this happening but questions whether it is fully required. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that learning long-range dependencies is not always necessary. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the necessity of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in table 3 shows this happening, but questions whether it is fully required. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the discussion should be included. This limits the comment\\'s helpfulness, as it provides insight but does not offer actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definition of $e_l$ and consider the impact of $M$ on the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of $e_l$ and pointing out the exponential dependence on the diameter $M$ of the domain of data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment lacks specific examples or references to support the claim that the exponential dependence on $M$ is a weakness. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the definition of $e_l$ in Equation (3). It also points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data, which affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. This feedback is clear and actionable, as it directs the authors to clarify the definition of $e_l$ and consider the impact of $M$ on the results. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific changes should be made to improve the draft. Overall, the comment is mostly helpful as it identifies a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the long-range modeling ability of DGNs, suggesting that it could be due to oversmoothing, another phenomenon observed in the context of very deep graph networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to improve the modeling ability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the long-range modeling ability of DGNs and suggests that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. However, it does not specify which part of the paper discusses the long-range modeling ability or oversmoothing, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of oversmoothing but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs is due to oversquashing and vanishing/exploding gradients, but also suggests that it could be due to oversmoothing. The reviewer supports this claim by referencing a paper that discusses oversmoothing in the context of very deep graph networks. However, the comment lacks specific examples or detailed explanations of how oversmoothing affects the modeling ability, making it somewhat verifiable. The authors would need to further explore the issue and potentially conduct additional experiments to fully understand and address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the long-range modeling ability of DGNs, suggesting that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. It does not provide actionable steps or examples of how to mitigate oversmoothing or improve the long-range modeling ability. As a result, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these issues are found in. The authors cannot confidently determine which sections or examples are being addressed, making it weakly grounded. The comment is specific in identifying the issue of unclear problem formulation, but without explicit references to sections or examples, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim. Without specific references or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it does not provide specific examples or guidance on how to improve the clarity. Without actionable suggestions or detailed feedback, the authors are left without a clear understanding of what needs to be addressed or how to enhance the clarity of their formulation. This lack of specificity and actionable advice makes the comment not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. While the comment implies that the authors should consider finer grouping, it does not provide explicit guidance on how to implement this change or what specific benefits it might offer. The action is implicit and somewhat vague, as the authors need to infer that they should consider finer grouping. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the choice of grouping for quantization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of per-tensor and per-channel grouping and suggests considering finer grouping instead. This provides clear guidance on what aspect of the quantization method needs reconsideration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be preferable. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. This is a valid point that could lead to a more efficient or accurate quantization process. However, the comment lacks depth and does not provide specific suggestions or examples of how finer grouping might be beneficial or how it could be implemented. While it identifies a potential area for improvement, the feedback is somewhat helpful as it prompts the authors to consider a different approach but does not fully guide them on how to implement it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"epsilon-greedy\" in the context of training, indicating what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"epsilon-greedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. This question highlights a potential area of confusion or misunderstanding in the paper, which could be clarified to enhance the readers\\' comprehension. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators. However, it also acknowledges that most existing ML accelerators use bit-parallel fixed-point numbers, which could restrict the implications of the proposed methodology. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore its implications further. The action is implicit and somewhat vague, as the authors can infer that they might need to consider the impact of this limitation on the applicability of their methodology. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the potential limitation of the proposed methodology, specifically regarding the performance gains of dynamic precision control during training on bit-serial accelerators. It also mentions the use of bit-parallel fixed-point numbers by most existing ML accelerators, which could restrict the implications of the proposed methodology. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the applicability of the methodology to existing accelerators. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators, which is a specific observation about the applicability of the proposed methodology. However, the comment lacks supporting evidence or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered borderline verifiable, as it provides a logical reasoning but lacks sufficient evidence or references to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators. This is a relevant observation that could impact the applicability and generalizability of the methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore its implications further. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusion regarding the reward in Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. It provides references to external works that might help clarify the issue, such as [1] and [2], which are articles on the topic of reinforcement learning. However, the comment does not explicitly instruct the authors to include these references or provide specific guidance on how to clarify the reward or network model. While the action is implied, it is not as direct as it could be, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of confusion regarding the reward and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. The references provided, such as [1] and [2], could be helpful in clarifying the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of Eq. 12, specifically questioning where the reward comes from and whether one of the r_i is taken from Eq. 11. The reviewer suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment identifies a potential issue with the clarity of the equations, it lacks specific examples or detailed reasoning to fully substantiate the claim. The references provided could be helpful in understanding the context, but the comment itself does not provide enough evidence or detailed reasoning to fully verify the claim. Therefore, the comment is somewhat verifiable, as it highlights an area for improvement but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Eq. 12, noting that the reward source is not clearly explained and questioning whether one of the r_i is taken from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to address the issue or suggest specific ways to clarify the equations. The references provided could be helpful, but the comment itself lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or complexity of the idea, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the idea is not enough, and that both the new metric and method are relatively straightforward. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the novelty or straightforwardness are problematic, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are relatively straightforward. However, it does not provide specific examples or detailed feedback on how the authors could enhance the novelty or complexity of their work. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. While the comment provides a clear direction for improvement, it does not specify which steps should be taken or how to implement the changes. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete guidance on how to implement the suggested improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the model description is discussed. The authors can infer that it relates to the model description section, but this inference is not direct. The comment is specific in suggesting improvements, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the understanding of the model. The suggestion is based on a general observation, but without concrete evidence or examples, it lacks verifiability. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be presented in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table, which could enhance the clarity of the description. While the comment provides actionable suggestions, it lacks depth and does not explain why these changes would be beneficial or how they would impact the overall understanding of the model. The authors are given a clear direction for improvement but could benefit from more detailed guidance on how to implement these changes effectively. Therefore, the comment is somewhat helpful, as it provides a starting point for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide a stronger motivation for why the topic is important. However, it does not specify what kind of motivation is needed or how it should be presented. The authors are left to infer that they need to include a motivation section, but without concrete guidance on what aspects to focus on or how to structure it, the action remains vague. Therefore, this comment is somewhat actionable, as it identifies a potential area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not specify which part of the paper this issue pertains to, such as the introduction or the sections where the topic is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what kind of motivation is needed or how it should be presented. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this motivation or what aspects of the paper need to be revised. Without actionable advice or examples, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance. It also points out that Table 5 shows a trade-off between head and tail categories but notes that similar trade-offs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. Additionally, the reviewer encourages the authors to continue this line of work for future submissions. While the comment provides explicit actions to take, such as investigating the trade-offs and improving the baselines, it does not specify how to implement these changes or provide detailed guidance on how to conduct the analysis. Therefore, the comment is somewhat actionable, as it clearly identifies areas for improvement but lacks concrete instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple [Kang et al.],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple [Kang et al.] and suggests exploring the trade-off between head and tail categories for the baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, and it provides a specific example of this by referencing Table 5. Additionally, it suggests that similar trade-offs have not been fully investigated for the baselines, specifically by changing hyperparameters in Decouple [Kang et al.]. This claim is somewhat verifiable as it provides a specific example of the trade-off between head and tail categories and suggests that further investigation is needed. However, the comment lacks detailed evidence or references to support the claim that changing hyperparameters could significantly improve the tail accuracy while slightly decreasing the head accuracy. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some support but could be strengthened with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights a trade-off between head and tail categories, as shown in Table 5, but points out that similar trade-offs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work. However, it could be more helpful if it offered additional guidance on how to conduct this exploration or what specific hyperparameters to consider. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear path for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of weak supervision could be improved by addressing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors' generation, suggesting that the authors' embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should improve the realism of their evaluation and generation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the generation process, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the realism of the evaluated tweets and the generation process, suggesting that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. The reviewer also points out that the authors' embeddings are initialized by averaging artificial tweets, which further undermines the realism. These claims are based on logical reasoning and observations about the nature of the prompt and the generation process. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the unrealistic nature of the evaluation or generation. As it stands, the claims are somewhat verifiable, as they provide a logical basis but lack detailed evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors' generation, suggesting that the authors' embeddings are initialized by averaging artificial tweets. This feedback is somewhat helpful as it highlights areas where the paper could be improved, but it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to consider, but the comment could be more actionable with additional details or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This explicit action provides a clear direction for the authors to take, as it specifies a specific comparison to be made. The comment is concrete, as it directly instructs the authors on what to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with existing models, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific comparison that could enhance the paper by comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is actionable and provides a clear direction for the authors to improve their draft by including a comparison that could strengthen the paper\\'s contribution. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their design. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to justify the decision. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this design choice is problematic or unjustified. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to substantiate the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. This feedback highlights a potential issue with the design and encourages the authors to reconsider their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their design. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). While it does not explicitly instruct the authors to make a change or provide additional information, it does prompt them to clarify a specific aspect of their work. The action is implicit, as the authors need to infer that they should provide an explanation or clarification, but it is concrete because it points to a specific part of the paper that requires attention. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (2),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2), which could be a significant oversight or misunderstanding in the paper. While it does not provide any suggestions or guidance on how to address this issue, it does prompt the authors to clarify a potentially important aspect of their work. However, without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as somewhat helpful, as it identifies a potential issue but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies specific lines in the SuppMat that should be moved from red to green. This provides clear and direct instructions for the authors to follow, ensuring they know exactly what changes to make. The action is concrete, as it specifies the exact lines and their corresponding SuppMat sections, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the exact lines that need to be moved from red to green, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about the SuppMat, specifically mentioning lines that should be moved from red to green. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific lines in the SuppMat that should be moved from red to green, providing clear and actionable feedback. This guidance is valuable as it helps the authors ensure that their SuppMat is accurate and up-to-date. However, the comment could be more helpful if it explained why these lines are important or how they contribute to the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to make a specific correction that can improve the clarity and accuracy of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct a comprehensive comparison with the works mentioned, GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. The reviewer provides specific references to these works, making it clear what needs to be done. Additionally, the comment mentions that the societal impact is shown on the last page of the manuscript, which is not relevant to the action being requested. Therefore, the action is explicit and concrete, as the authors know exactly what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, \"GFF[1]\" and \"EfficientFCN[2],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. The reviewer suggests a comprehensive comparison with these works. However, the comment does not provide specific details or examples of how these references would enhance the paper or what aspects of the comparison would be beneficial. While the references are mentioned, the lack of detailed justification or explanation makes the claim somewhat verifiable, as the authors would need to infer the importance of these comparisons themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, which could significantly enhance the paper\\'s contribution and relevance. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript. While the comment highlights a critical area for improvement, it could be more helpful if it provided specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a significant area for enhancement, but it could be more actionable with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the practical performance of the proposed algorithms, specifically mentioning Algorithm 1 and its reliance on Vandermonde matrices. It highlights the potential numerical instability and ill-conditioning issues, particularly for large $n$ and small $\\\\alpha$. The reviewer suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. While the comment implies that the authors should conduct experiments to address the concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for experimental results and determine how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"Vandermonde matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the numerical instability and ill-conditioning of Algorithm 1, particularly for large $n$ and small $\\\\alpha$. The comment suggests that the paper would be more convincing with experimental results, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of Vandermonde matrices and their potential numerical instability and ill-conditioning. The reviewer supports this claim by referencing the known issues with Vandermonde matrices, particularly for large $n$ and small $\\\\alpha$. This provides a logical basis for the concern, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to studies that have encountered similar issues. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific concern about the practical performance of the proposed algorithms, particularly the use of Vandermonde matrices. It highlights the potential numerical instability and ill-conditioning issues, which could lead to algorithm failure in practice, especially for moderate-sized $n$. The comment suggests that providing experimental results would enhance the paper\\'s credibility. While the comment effectively points out a potential weakness, it could be more helpful if it offered suggestions on how to address this concern or what specific experiments could be conducted to validate the algorithms\\' performance. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input, and questions whether there is a solution to address this issue. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue or improve the practical contribution of their paper. The authors are left to infer that they need to consider scalability, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed NC measure, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the method when applied to large datasets like ImageNet, and suggests that the practical contribution of the paper could be significantly reduced if this issue is not addressed. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. The reviewer questions whether there is a solution to address this issue, suggesting that the practical contribution of the paper could be significantly reduced if not addressed. However, the comment lacks specific examples or references to support the claim that the method cannot be applied to large datasets like ImageNet. Without such evidence or detailed reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It raises a valid concern about the practicality of applying this method to large datasets like ImageNet. The comment suggests that if the scalability issue is not addressed, the paper's practical contribution could be significantly reduced. However, the comment does not provide specific suggestions or examples on how to address the scalability issue or improve the method for larger datasets. While it highlights an important area for consideration, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It also suggests that a comparison of computation complexity should be included in the experiment part. While the comment identifies a specific issue with the computational complexity, it does not provide explicit guidance on how to address it or suggest ways to reduce the computational burden. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison of computation complexity in the experiment part. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"the calculation of all the flipped previous layer output into the current layer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of computation complexity in the experiment part. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. The comment suggests that a comparison of computation complexity should be included in the experiment part. While the claim is based on logical reasoning and specific observations about the algorithm, it lacks detailed evidence or references to support the assertion that the PSA method requires more computation. This makes the claim somewhat verifiable, as the authors would need to further investigate and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the computational complexity of the proposed PSA method compared to baselines, noting that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to include a specific analysis of computational complexity to address the reviewer\\'s concern. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or suggested specific metrics to use. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger, increasing the size of V_mem, Th_i, and U_i^t, and using a larger font for the \"CTRL\" label. It also points out the need for more detailed comparisons, such as epochs and number of parameters, with other state-of-the-art Transformer designs. While the comment provides explicit actions, it does not offer detailed guidance on how to implement these changes or what specific metrics to use for the comparisons. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures, such as \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, the \"CTRL\" label, and the need for more detailed comparisons with other state-of-the-art Transformer designs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims about the font size, the \"CTRL\" label, and the need for more detailed comparisons with other state-of-the-art Transformer designs. While the comment provides specific examples of font size issues and suggests improvements, it lacks detailed reasoning or references to support the claim that these changes would significantly impact the paper\\'s clarity or accuracy. The suggestion for comparisons is also somewhat vague, as it does not specify which metrics or parameters should be compared or how this would enhance the paper. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the figures, suggesting improvements such as increasing the font size of certain elements like the words in the grey box, the \"CTRL\" label, and the size of V_mem, Th_i, and U_i^t. It also points out the need for more detailed comparisons with other state-of-the-art Transformer designs, which could help emphasize the significance of the improvements. While the comment identifies areas for improvement, it could be more helpful by providing examples of how these comparisons could be structured or what specific metrics to use. Overall, the feedback is mostly helpful as it directs the authors to make concrete changes that could enhance the clarity and impact of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include ATA in the comparison under the leave one out setting in Table 2. This is a clear and direct action for the authors to take, as it provides a specific recommendation to enhance the comparison by including ATA. The comment also references the results in Table 1, which further guides the authors on where to make the change. The action is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of ATA in the comparison under the leave one out setting. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to ATA in addition to \"+LFP\" under the leave one out setting in Table 2. The claim is based on the assumption that ATA is better than FP according to the results in Table 1. However, the comment does not provide specific evidence or references to support this claim, such as detailed comparisons or specific results from Table 1. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to make a significant effort to verify the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+\"LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, as ATA is reportedly better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the comparison and improve the clarity of their results. By addressing this point, the authors can strengthen their analysis and make their findings more robust. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of mathematical definition for certain architectural details, specifically mentioning multi-head attention. It also questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer implies that a formal definition would be beneficial for readers to understand the architecture. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide a formal definition, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"multi-head attention,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multi-head attention, and questions the purpose of a split arrow in Figure 2. The comment further specifies that a formal definition would be beneficial for readers to understand the architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of mathematical definition for certain architectural details, specifically mentioning multi-head attention. It questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer assumes that these are the inputs for the attention layer, namely query, keys, and values. The comment suggests that a formal definition would be beneficial for readers to understand the architecture. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that a formal definition is necessary. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the lack of mathematical definition for certain architectural details, such as multi-head attention, and questions the purpose of a split arrow in Figure 2. It also seeks clarification on the inputs for the attention layer and whether the same vectors are used for keys and values. The comment implies that a formal definition of these concepts would be beneficial for readers to understand the architecture. While the comment highlights areas for improvement, it does not provide detailed suggestions or examples on how to address these issues. The authors are left to infer that they need to provide a formal definition, but the feedback lacks comprehensive guidance. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how to improve the presentation or what aspects are particularly challenging to understand. Without concrete advice or examples, the authors are left without a clear understanding of what changes need to be made to enhance the clarity of their draft. As a result, the comment lacks actionability, leaving the authors without direction on how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the presentation of the paper is hard to follow, but it does not specify which part of the paper is particularly challenging or where the presentation lacks clarity. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need improvement. Additionally, the comment does not provide specific guidance on how to enhance the clarity of the presentation. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of the paper is hard to follow. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or justification, the authors are left without a clear understanding of what aspects of the presentation are problematic or how they could be improved. As a result, the claim is unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment states that the presentation of the paper is hard to follow, but it does not provide any specific details or suggestions on how to improve the clarity or organization of the paper. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the presentation need attention or how to enhance the readability. This lack of specificity and direction makes the comment barely helpful, as it offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include works such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and compare them to their work conceptually. Additionally, it recommends discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). These suggestions provide clear and explicit actions for the authors to take, including identifying relevant works and discussing their differences. The comment is concrete and provides specific guidance on how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including works such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of these works and the need for a discussion on differences, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include specific works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. The comment also recommends discussing how their work differs from other chatbox research works. While the suggestion is based on logical reasoning and common knowledge about the importance of including relevant works, it lacks specific examples or detailed justification for why these works are particularly relevant or how they differ from others. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include relevant works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. It also recommends discussing how their work differs from other chatbox research works. This feedback is mostly helpful as it guides the authors on how to enhance their draft by incorporating relevant references and discussing their unique contributions. However, it could be more helpful if it provided additional context or examples of how these works differ from the current paper. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to Foester et al. (NIPS 2016) as an example. This provides a clear and concrete action for the authors to take, as they are given a specific area to address and a reference to guide their understanding. The comment is highly actionable because it directly tells the authors what to do and provides a concrete example to follow.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"meta solvers\" and the \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL, and provides a reference to Foester et al. (NIPS 2016) to guide the authors in their understanding. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta solvers are centralized controllers, and suggests that the authors should clarify the difference between them and centralized RL. The reviewer provides a reference to Foester et al. (NIPS 2016) to support this claim. However, the comment lacks detailed explanation or analysis of why the meta solvers are considered centralized controllers, making it somewhat verifiable. The reference to Foester et al. provides some support, but the authors would need to further explore the context and implications of the claim to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the classification of the meta solvers as centralized controllers. It suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al. (NIPS 2016) as an example of centralized RL, which is a clear and actionable suggestion. This feedback is valuable as it directs the authors to a specific area that needs clarification, helping them improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in their clarification efforts. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. However, it does not provide any explicit guidance or suggestions on how the authors should address this confusion or clarify their terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider their terminology. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \"non-sequential information such as chunks,\" suggesting that the term \"chunks\" might be considered sequential information. This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the phrase \"non-sequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. This question highlights a potential confusion in the paper that could be clarified to improve the clarity and coherence of the text. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their terminology. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a discrepancy between equation 9 and figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it or what specific changes should be made to the figure or the methodology. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the figure and possibly use bilinear sampling. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions, and suggesting that bilinear sampling might provide better results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The reviewer suggests that the figure is misleading and proposes an alternative method, bilinear sampling, as a potential solution. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the misleading nature of Figure 1. The suggestion to use bilinear sampling is logical but could be strengthened with more detailed explanation or references. Therefore, the claim is somewhat verifiable, as it provides a reasonable basis for the authors to consider the issue but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between equation 9 and Figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. This feedback is somewhat helpful as it points out a potential issue with the figure and provides a suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to address the discrepancy or why bilinear sampling might be a better approach. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). It suggests that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous papers. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to enhance the novelty of their work. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and comparing the paper to the mentioned papers, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The comment provides a specific comparison with the papers, noting that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous works. This comparison provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific sections of the papers that support the comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it lacks technical novelty and is similar to two mentioned papers (Xing and Tsang, 2022a, b). It provides a specific comparison with the papers, highlighting the similarities in the idea, co-attention mechanism, and architecture. This feedback is somewhat helpful as it points out an area where the paper could be improved by differentiating itself from existing work. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the novelty of their work. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of fairness in the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pre-training module. It suggests that to ensure fairness, the authors should compare CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This feedback provides a clear and explicit action for the authors to take, specifying which model to compare and why. The suggestion is concrete and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529-lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of fairness in the comparison between CPEF and PMEF. The comment suggests that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This provides clear guidance on how to improve the fairness of the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF is unfair due to the lack of a pre-training module in PMEF. The reviewer suggests that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to ensure fairness. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a potential solution. However, the comment lacks specific examples or references to support the claim that PMEF lacks a pre-training module, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It points out that PMEF lacks a pre-training module, which makes the comparison unfair. The reviewer suggests that to ensure fairness, the authors should compare CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the fairness and validity of their comparison. By addressing this issue, the authors can enhance the credibility and robustness of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. It provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment does not explicitly instruct the authors to use these methods or provide guidance on how to integrate them into their work. While the action is implied, it is not as clear as it could be, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attack methods\" and \"toy setting with classification tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not consider other classical attack methods in NLP and suggests specific examples from other papers. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of these methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment lacks detailed reasoning or evidence to support why these methods are more effective or why the current methods are inadequate. While the examples are provided, the justification for the claim is not fully developed, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the attack methods used are naive and that the paper does not consider other classical attack methods in NLP. The reviewer provides specific examples of alternative methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. This feedback is clear and actionable, as it directs the authors to consider these methods to enhance the robustness and comprehensiveness of their work. However, the comment could be more helpful if it explained why these alternative methods are more effective or how they might be integrated into the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, but temperature calibration is applied after training. The reviewer asks the authors to clarify this point, which is a clear and explicit action. Additionally, the comment suggests that reducing the entropy of the regularization term (H) may conflict with the paper's motivation to calibrate the networks, as the networks are already over-confident. This feedback is concrete and provides specific guidance on how the authors can address the confusion and improve the clarity of their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 155-160,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the relationship between temperature calibration and uncertainty calibration, particularly in the context of the regularization term H. The comment further clarifies the potential contradiction between reducing entropy and the paper's motivation to calibrate the networks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. The reviewer questions whether temperature calibration is required for uncertainty calibration, as it appears in lines 155-160. The comment also points out that reducing the entropy of the regularization term (H) may conflict with the paper's motivation to calibrate the networks, as the networks are already over-confident. While the comment identifies a potential contradiction, it lacks specific examples or references to support the claim that reducing entropy is counterproductive to calibration. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning provided.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, but temperature calibration is applied after training. This is a clear and actionable observation that the authors can address to clarify their work. Additionally, the comment highlights a potential contradiction between reducing the entropy of the regularization term (H) and the paper's motivation to calibrate the networks, as the networks are already over-confident. This feedback is valuable as it prompts the authors to reconsider their approach and potentially adjust their methodology to better align with their goals. Overall, the comment is mostly helpful as it provides clear and actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of an important reference, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. It also highlights the importance of discussing similarities and differences with Lista and placing the paper in appropriate context. While the comment identifies the missing reference and the need for contextualization, it does not provide specific guidance on how to integrate these elements into the paper. The action is clear but lacks detailed instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the missing reference, \"Lista,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the importance of discussing similarities and differences with the reference and placing the paper in appropriate context. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. The reviewer suggests that the paper should discuss similarities and differences with \"Lista\" and place itself in appropriate context. While the comment identifies the missing reference, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of discussing similarities and differences, and the contextualization of the paper. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the absence of an important reference, \"Lista,\" which is relevant to the idea of unrolling. It highlights the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This feedback is clear and actionable, as it directs the authors to include a missing reference and provide a more comprehensive discussion of their work in relation to existing literature. However, the comment could be more helpful if it offered specific suggestions on how to integrate these elements into the paper or provided examples of how similarities and differences might be discussed. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and contextualization of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and points of confusion regarding the algorithm, specifically regarding the use of \"avg\" and the meaning of \"j'\" and \"i'\". While it identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take to address these issues. The authors are left to infer that they need to clarify these points, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the use of \"avg\" and the meaning of \"j'\" and \"i'\". This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of Algorithm 2, specifically regarding the use of \"avg\" and the meaning of \"j'\" and \"i'\". It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification and does not make a claim that needs justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several areas of confusion and potential improvement in the paper, specifically regarding the clarity of Algorithm 2 and the use of \"avg.\" It points out that \"j'\" and \"i'\" are not defined, which is a critical oversight. The comment acknowledges the authors\\' response and suggests that they keep the initial scores, indicating that the authors have addressed some concerns. However, it also highlights that the algorithm remains unclear, which is a significant issue that needs to be addressed. Overall, the comment provides actionable feedback by pointing out specific areas that need clarification and improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, and that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. The reviewer suggests that these decisions should be explained in the paper to help readers understand them without needing to check the code. The comment provides clear and concrete actions for the authors to take, ensuring that they know exactly what needs to be addressed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the handling of comparisons between episodes with different lengths and the lack of a normalization factor of 1/T. The comment provides detailed guidance on how to handle these issues, such as stating how the authors handle comparisons and explaining the consequences of the lack of normalization. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides specific observations, such as checking the provided code and noting that the authors pad the shorter sequence by replicating its last state to compare both trajectories. Additionally, the comment points out that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. These observations are supported by logical reasoning and specific examples, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in the literature. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the handling of comparisons between episodes with different lengths in the equation between lines 282 and 283. It points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, which could lead to biased results. Additionally, it highlights the lack of a normalization factor of 1/T, which can cause distance increases with T and favor longer trajectories. The comment suggests that these decisions should be explained in the paper to help readers understand them without needing to check the code. This feedback is clear and constructive, guiding the authors on how to improve the clarity and accuracy of their results. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the figures, including the size of the text, the clarity of the inputs and outputs, and the self-contained nature of the captions. While it points out these problems, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to make the figures more readable and better linked to the main text, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the small text size, unclear inputs and outputs, and the lack of self-contained captions. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures in question are difficult to parse due to small text size, unclear inputs and outputs, and lack of self-contained captions. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support why these elements are problematic or how they impact the clarity of the figures. The lack of specific examples or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the claim is somewhat verifiable, as it provides some basis but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the figures in the paper, noting that they are difficult to parse due to small text size, unclear inputs and outputs, and lack of self-contained captions. It also points out that the captions are not linked to the main text effectively. This feedback is clear and actionable, as it provides the authors with a concrete understanding of what needs to be improved in terms of figure clarity and organization. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending font size adjustments or providing examples of how to improve the figure captions. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional molecule generation framework based on GDSS, which was recently proposed in [2], as a baseline. While the comment provides a clear action\u2014to include the continuous diffusion model as a baseline in Table 3\u2014it does not specify how to implement the conditional framework or provide detailed guidance on how to incorporate it into the paper. The action is explicit but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of the continuous diffusion model as a baseline in Table 3 and the use of a conditional molecule generation framework based on GDSS. This provides clear guidance on what changes need to be made to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. The reviewer provides a logical reasoning by pointing out that the continuous diffusion model should be considered as a baseline for the conditional generation task. However, the comment lacks specific examples or references to support the claim that GDSS does not explicitly present a conditional framework. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It points out that the continuous diffusion model (e.g., GDSS) outperforms the discrete diffusion model (e.g., DiGress) in Table 2 and should be compared as a baseline in Table 3. The reviewer also suggests using a conditional molecule generation framework based on GDSS, which was recently proposed in [2], as a baseline. This feedback is valuable as it directs the authors to include a more relevant baseline for comparison and provides a specific suggestion for improvement. However, the comment could be more helpful if it explained why the continuous diffusion model is particularly relevant for the conditional generation task or how the proposed framework would enhance the analysis. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include a comparison against state-of-the-art loss functions commonly used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This is a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions commonly used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this comparison should be added to, such as the results or discussion sections. The authors can infer that it relates to the experimental evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what needs to be added. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions commonly used in face/iris verification. This claim is somewhat verifiable as it provides a logical suggestion for enhancing the paper\\'s contribution by including a comparison with established methods. However, the comment lacks specific examples or references to these state-of-the-art loss functions, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include a comparison against state-of-the-art loss functions commonly used in face/iris verification. This is a clear and actionable suggestion that could enhance the paper\\'s contribution by demonstrating the effectiveness of the proposed method against established benchmarks. By including such a comparison, the authors can provide a more comprehensive evaluation of their work and potentially improve its impact. However, the comment could be more helpful if it specified which loss functions should be included or provided examples of how they might be used in the context of the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more detailed to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a confusion regarding the name \"PointNet\" in Figure 1, noting that it is not mentioned in the paper and that there is another paper with the same name. The reviewer suggests that the authors should clarify this issue by referring to the correct paper or providing a footnote. This feedback is explicit and provides concrete guidance on how to address the confusion. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"PointNet,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of \"PointNet\" as it is not mentioned in the paper and there is another paper with the same name. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that referring to [15] as \"PointNet\" is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to another paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which supports the claim by pointing out the correct name. This provides a clear and verifiable basis for the claim, making it fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the labeling of \"PointNet\" in Figure 1, noting that it is confusing as the name does not appear in the paper and there is another paper with the same name. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their draft. By addressing this issue, the authors can improve the accuracy and clarity of their figure captions, which is valuable guidance for improving the paper. However, the comment could be more helpful if it suggested a way to avoid similar confusion in future figure captions or provided additional context on the importance of accurate labeling. Overall, the comment is mostly helpful as it effectively directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to present the results comparing standard- vs. evolutional dropout on shallow models as a mean over many runs (at least 10) and ideally with error-bars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. The comment provides clear and concrete actions for the authors to take, specifying the exact changes needed to improve the presentation of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results comparing standard- vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with error-bars and providing statistics. This level of detail provides clear guidance on how to improve the presentation of the results. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error-bars, as the plotted curves are from single runs and might be subject to significant fluctuations. The reviewer also suggests that the models are small, so there is no excuse for not providing statistics. The comment is mostly verifiable as it provides logical reasoning and specific suggestions for improvement, such as presenting results as a mean over multiple runs and using error-bars. However, the comment could be strengthened by providing examples or references to similar studies that have used similar methods. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback on the presentation of results comparing standard- vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs (at least 10) with error-bars, which is a standard practice in scientific research. This suggestion is based on the observation that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the comment points out that the models are small, so there is no excuse for not providing statistics. This feedback is highly helpful as it guides the authors on how to improve the presentation and robustness of their results. By addressing these points, the authors can enhance the credibility and reproducibility of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the clarity of the experimental setup. The comment is specific and provides concrete guidance on how to implement the suggested improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the impact of different versions of the experimental environment on training and inference speed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This claim is somewhat verifiable as it logically suggests that different versions of the experimental environment could impact training and inference speed. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about the experimental environment, including the CUDA and PyTorch versions. This feedback is clear and actionable, as it directly addresses a potential issue with the clarity and reproducibility of the experimental setup. By providing this information, the authors can ensure that their work is more robust and easily replicable. However, the comment could be more helpful if it included suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve the clarity and transparency of their experimental setup.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses doubt about the paper's current strength for the ICLR conference, but it does not provide any specific guidance or suggestions on how the authors might improve their draft to meet the standards of the conference. There is no explicit or implicit action for the authors to take, nor are there any concrete details on what aspects of the paper need improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment does not specify which part of the paper is being addressed, making it not grounded. It also lacks specificity as it does not provide details on what aspects of the paper are insufficient for the ICLR conference or how the authors might improve their draft to meet those standards. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is \"doubtful\" for the ICLR conference, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the criteria or standards expected for the ICLR conference, the authors are left without a clear understanding of what needs to be improved or how to address the concern. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses doubt about the paper\\'s current strength for the ICLR conference, indicating that it may not be suitable for the event. However, it does not provide any specific feedback or suggestions on how the authors might improve their draft to meet the standards of the conference. Without actionable guidance or detailed insights into what aspects of the paper need improvement, the comment offers limited value to the authors. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should run experiments multiple times and report statistics, as a way to address the reproducibility issue in deep RL. It references a recent paper that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a clear action to take, it does not specify how many times the experiments should be run or what specific statistics should be reported. The authors are given a general direction but may need to infer the exact details of implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that experiments should be run multiple times and that statistics should be reported to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. However, the comment does not specify which part of the paper this issue pertains to, such as the experimental section or the discussion on reproducibility. While the authors might infer that it relates to the experimental section, the comment lacks full grounding. It is specific about the need for multiple experiments and statistics, but without explicit references to the paper or the paper\\'s sections, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that experiments should be run multiple times to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. This reference provides a logical basis for the claim, as it suggests that running multiple experiments is a necessary step to ensure the reliability and significance of deep RL. However, the comment could be strengthened by providing more detailed examples or specific suggestions on how to implement this suggestion. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks comprehensive evidence or detailed guidance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with deep RL, specifically the reproducibility and significance of their improvements. It suggests that experiments should be run multiple times and that statistics should be reported to address this issue. The comment references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL, providing a relevant external reference to support the suggestion. While the comment highlights a significant area for improvement, it could be more helpful by offering specific guidance on how to implement these changes, such as suggesting a minimum number of experiments or specific statistics to report. Overall, the comment provides valuable insight into a critical area for improvement, but it lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiom-specific and that the results appear to indicate that \"better NMT systems are also better at idiomatic translations.\" However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. It lacks concrete steps or detailed advice on how to make the methods more idiom-specific or how to improve the results. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed upweighing and KNN methods\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the methods appear to be similar for idiomatic and random data, suggesting that the results indicate that \"better NMT systems are also better at idiomatic translations.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed upweighing and KNN methods are not idiom-specific, as the impact on idiomatic and random data appears similar. The reviewer supports this claim by referencing Figure 3, which presumably shows the results of the methods on different language and score combinations. However, the comment lacks specific details or examples from the figure to fully substantiate the claim. While the reference to Figure 3 provides some context, the lack of detailed evidence or explanation makes the claim somewhat verifiable, as the authors would need to refer to the figure to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiom-specific and that the results appear to indicate that \"better NMT systems are also better at idiomatic translations.\" This feedback highlights a potential weakness in the methodology and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue, such as proposing alternative methods or explaining how idiom-specificity could be achieved. While the comment identifies a critical area for improvement, it lacks detailed guidance, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, particularly in the language and vision tasks used for evaluation. It notes that while there is a comparison of training loss and a comparison of the rank of possible solutions, there is no direct comparison of test accuracy. The comment implies that the authors should include direct comparisons of test accuracy to demonstrate the improvement over the baseline. However, it does not explicitly instruct the authors to add these comparisons, leaving the action implicit. The comment is somewhat actionable as it provides a clear direction for improvement but lacks concrete guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the prior approach PRANC, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of direct comparisons with PRANC in the language and vision tasks used to evaluate the proposed approach. The comment provides a clear direction for improvement by suggesting the inclusion of direct comparisons of test accuracy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no direct comparisons with the prior approach PRANC in the language or vision tasks used to evaluate the proposed approach. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. The comment suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline that it directly modifies. This claim is somewhat verifiable as it logically points out the need for direct comparisons to substantiate the claims of improvement. However, it lacks specific examples or references to similar studies that might provide a more robust basis for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of the proposed approach, noting the lack of direct comparisons with the prior approach PRANC in the language or vision tasks used to assess the proposed approach. It highlights the importance of including direct comparisons of test accuracy to demonstrate the improvement over the baseline that is directly modified by the authors. This feedback is clear and actionable, providing the authors with a specific area to address in order to strengthen their evaluation and substantiate their claims. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or provided examples of similar studies that have successfully demonstrated such comparisons. Overall, the comment is mostly helpful as it effectively guides the authors on how to enhance their evaluation section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the proposed method does not show significant improvement over existing RL methods, but it does not provide any specific guidance or suggestions on how the authors could address this issue. There is no explicit or implicit action for the authors to take, such as suggesting ways to improve the method or providing examples of existing RL methods that could be compared. Without actionable advice or detailed feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed method does not show significant improvement over existing RL methods, but it does not specify which part of the paper discusses this improvement or where the comparison is made. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of the improvement are lacking or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method does not show significant improvement over existing RL methods. However, it does not provide any specific examples, comparisons, or evidence to support this claim. Without detailed reasoning or references to existing methods, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the proposed method does not show significant improvement over existing RL methods, which is a critical observation that could impact the paper\\'s impact and contribution. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the method\\'s performance. Without actionable feedback or detailed insights into what aspects of the method need improvement, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the model design, specifically mentioning that the architecture and learning details are fragmented or missing. It provides a clear suggestion for the authors to address this issue by either providing a plot of model illustration, pseudo-code table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the lesser-known nature of Neurochaos Learning. The explicit action and concrete details on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"model design\" and \"model architecture and learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the fragmented or missing details of the model design, and provides a concrete suggestion to address this issue by providing a plot, pseudo-code table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the lesser-known nature of Neurochaos Learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model design is unclear due to fragmented or missing details, specifically mentioning the importance of demonstrating integrated details to facilitate reproducibility. The comment suggests providing a plot, pseudo-code table, or code repository to address this issue. However, the comment lacks specific examples or references to support the claim that Neurochaos Learning is not well-known, making it somewhat verifiable. The authors would need to infer the significance of this point themselves, as the comment does not provide detailed reasoning or evidence to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides a clear and actionable suggestion for the authors to address this issue by either providing a plot of model illustration, pseudo-code table, or code repository. This feedback is valuable as it guides the authors on how to improve the clarity and reproducibility of their work. Additionally, it highlights the importance of demonstrating integrated details, especially considering the lesser-known nature of Neurochaos Learning. However, the comment could be more helpful if it included specific examples or additional guidance on how to present the model details. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the authors\\' approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"pruning\" and \"distributed settings,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients. This is a logical claim based on the observation that pruning is often used with large networks and that distributed settings are common for training. However, the comment lacks specific examples or references to support the claim that finding global top Q values is necessary to avoid breaking acceleration techniques like quantization and sparsification. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. This feedback is valuable as it highlights a potential gap in the authors\\' discussion of pruning and its implications on distributed settings. However, the comment could be more helpful if it provided specific examples or references to support the claim about the impact on acceleration techniques. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important aspect of their work that requires further consideration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some subfigures in Figures 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures and potentially correct any errors, it does not provide explicit instructions on how to do so or what specific subfigures might be affected. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether some subfigures in Figures 1 and 2 have been swapped by mistake. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the possibility of subfigures in Figures 1 and 2 being swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or verify the accuracy of the figures. The comment lacks actionable feedback or detailed analysis, making it somewhat helpful as it points out a potential problem but does not assist the authors in resolving it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the paper formatting does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the paper style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as adjusting the formatting style to conform to the NeurIPS guidelines and reorganizing the content accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper formatting, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the formatting, such as the font size of the abstract and the bottom page margins, and suggests that these issues could be addressed by following the NeurIPS formatting style. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper formatting is off, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that following the NeurIPS formatting style could improve the paper. While the comment identifies specific formatting issues, it lacks detailed reasoning or references to justify why the current formatting is problematic or how following NeurIPS guidelines would improve the paper. This makes the claim somewhat verifiable, as the authors would need to make an effort to understand and address the issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out issues with the font size of the abstract and the bottom page margins, suggesting that these could be improved by following the NeurIPS guidelines. The comment also suggests that this formatting change could gain some space and allow the inclusion of the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the formatting and organization of their paper. However, it could be more helpful if it included examples of how the NeurIPS formatting style should be applied or provided additional context on why this change is beneficial. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a clear path for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND and ICM). However, it does not provide any explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or comparison of these methods, but it lacks concrete instructions on how to structure this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on these methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being referred to. Without detailed explanations or references, the claim is not fully verifiable, as it relies on general knowledge of RL literature. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that it does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND, ICM). This is a critical oversight, as these methods are widely used and relevant to the field. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as which methods to discuss or how to structure the comparison. While it points out a significant gap in the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the definition of the quantile is confusing and recommends adding extra brackets around the term or defining the bracketed term separately if space allows. This provides a clear and explicit action for the authors to take, which is to clarify the definition by adding brackets or defining the bracketed term. The comment is specific and provides concrete guidance on how to improve the clarity of the definition. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to clarify the definition by adding extra brackets or defining the bracketed term separately if space allows. This level of detail provides the authors with clear guidance on how to improve the clarity of the definition. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the definition of the quantile is confusing and proposes adding extra brackets or defining the bracketed term separately to clarify it. However, the comment does not provide any specific reasoning or examples to support why the current definition is confusing or how the proposed changes would improve clarity. Without additional context or explanation, the authors may find it challenging to understand and implement the suggested improvements. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the definition of the quantile, which is described as \"a little confusing.\" It provides a clear and actionable suggestion to improve clarity by adding extra brackets around the term or defining the bracketed term separately if space allows. This feedback is valuable as it directly addresses a potential source of confusion and offers a concrete way to enhance the clarity of the definition. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context on how the suggested changes would improve understanding. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the RQ1 mentioned in the paper is redundant and does not provide additional information. It also proposes an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 t-sne plots. The reviewer provides a specific reference to a related work that could guide the authors in conducting this analysis. While the comment implies that the authors should reconsider their RQ1 and explore the proposed analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RQ1\" and \"RQ2\" and \"RQ3 t-sne plots,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the redundancy of RQ1 and the potential analysis on the effect of explicit hate information on implicit hate speech detection performance. The comment provides a reference to a related work, which is helpful in guiding the authors on how to proceed with their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information. It suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 t-sne plots. The reviewer provides a reference to a related work, which supports the claim by suggesting a specific direction for further analysis. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed reasoning or examples from the reference to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in the RQ1 mentioned in the paper and suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance. It also proposes an exploration of how this effect impacts RQ2 and RQ3 t-sne plots. The comment provides a specific reference to a related work, which could guide the authors in conducting this analysis. While the comment offers actionable suggestions, it could be more helpful if it provided more detailed guidance on how to conduct the analysis or what specific metrics to consider. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a starting point for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify in the introduction that the proposed solution is a fix of [12], rather than a new PIC approach. It provides a specific suggestion to make this clarification by mentioning the reference in lines 29-30. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (29-30) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of whether the proposed solution is a fix of [12] or a new PIC approach. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors need to clarify in the introduction that the proposed solution is a fix of [12], rather than a new PIC approach. The reviewer supports this claim by referencing specific lines in the paper (29-30) where the proposed solution is introduced as a new PIC approach. This provides a clear and specific example of the issue, making the claim verifiable. However, the comment could be strengthened by referencing [12] directly or providing more context on why this distinction is important. Overall, the claim is mostly verifiable, as it is supported by a specific example from the paper.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the introduction, noting that the proposed solution is presented as a new PIC approach rather than a fix of [12]. It provides a clear and actionable suggestion by recommending that the authors clarify this distinction in the introduction. This feedback is valuable as it helps the authors ensure that their work is accurately presented and understood by readers. However, the comment could be more helpful if it explained why this distinction is important or how it affects the overall contribution of the paper. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC and asks if G4RL requires HRAC's regularization in the latent space. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HRAC-G4RL,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC's regularization in the latent space. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC's regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind combining G4RL with HRAC and asks if G4RL requires HRAC's regularization in the latent space. This is a relevant question that could help the authors understand the basis of their method and its potential limitations. However, the comment does not provide any suggestions or guidance on how to address this question or improve the paper. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison with a NeRF-based method, specifically mentioning the recent Zero-1-to-3 and point-e. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides explicit actions to include comparisons and question the relevance, it lacks concrete details on how to implement these suggestions. The authors are given a clear direction but may need to infer the specifics of how to conduct these comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including comparisons with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment does not specify which part of the paper these comparisons should be included in or how the relevance of the occlusion experiment should be addressed. While the authors can infer that the suggestions relate to the experimental section, the comment lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e, is missing. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment lacks specific examples or detailed reasoning to support these claims. The suggestion to include comparisons is somewhat verifiable, as it provides a direction for improvement, but the critique of the relevance is not fully substantiated. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting the inclusion of comparisons with NeRF-based methods, such as Zero-1-to-3 and point-e. This suggestion is clear and can help the authors improve the comprehensiveness and relevance of their experimental evaluation. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment identifies areas for improvement, it could be more helpful if it provided additional context or examples of how these comparisons could be conducted. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the missing discussion on arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment also highlights the importance of this discussion for readers to understand the practical implications of the work. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion on \"arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice and the sensitivity analysis of this hyperparameter. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion on arbitrary hyperparameter \u03b3 is missing, including how to set it in practice and analyzing its sensitivity. This claim is somewhat verifiable as it highlights a specific omission in the paper, which could be a significant issue for readers who need to understand the practical implications of the work. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why this discussion is crucial or how it would enhance the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the lack of discussion on the arbitrary hyperparameter \u03b3, including how to set it in practice and analyzing its sensitivity. This is a critical point as it affects the practical applicability and understanding of the work. By pointing out this gap, the comment provides clear and actionable feedback for the authors to address. However, the comment could be more helpful if it offered suggestions on how to incorporate this discussion or provided examples of how similar issues have been addressed in related works. Despite this, the feedback is mostly helpful as it directs the authors to a crucial area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the Methodology section, particularly regarding the model architecture description and notation. It points out inconsistencies in the notation, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the use of labels ($l_0$, $l_{t-1}$) that may give the impression of a sequence of tokens being generated as the label. The comment provides a clear and concrete action for the authors to take, which is to clarify and standardize the notation used in the Methodology section. This guidance is explicit and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Methodology section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the model architecture description and notation, such as the inconsistent use of notation ($v^p_{t-1}$) and the potential confusion regarding the labels ($l_0$, $l_{t-1}$). This provides clear guidance on what needs to be addressed in the Methodology section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Methodology section is difficult to follow due to confusing notation and inconsistencies. It provides specific examples, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the use of labels ($l_0$, $l_{t-1}$) that may lead to confusion about the nature of the labels. These examples are logical and provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in the literature, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the Methodology section, particularly regarding the model architecture description and notation. It points out inconsistencies in the notation, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the use of labels ($l_0$, $l_{t-1}$) that may lead to confusion about the nature of the labels. This feedback is clear and actionable, as it guides the authors to clarify and standardize the notation used in the Methodology section. By addressing these issues, the authors can improve the clarity and comprehensibility of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer implies that discussing how to design prompts effectively is crucial. However, the comment does not provide specific guidance on how to achieve this or what aspects of prompt design should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to focus on prompt design but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper discusses these prompting methods or where the authors should focus their attention. The authors can infer that it relates to sections discussing prompt design, but this inference is not direct. The comment is specific in its suggestion to discuss prompt design effectively, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer argues that different prompts may result in varying performance outcomes, emphasizing the importance of discussing how to design prompts effectively. However, the comment lacks specific examples or references to support the claim that different prompts lead to varying performance outcomes. This makes the claim somewhat verifiable, as the authors would need to infer the importance of prompt design and the potential impact on performance outcomes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer highlights the importance of discussing how to design prompts effectively, given that different prompts may result in varying performance outcomes. This feedback is clear and actionable, as it directs the authors to focus on a critical aspect of their work that could significantly impact its impact and effectiveness. However, the comment could be more helpful if it provided specific suggestions or examples of effective prompt design strategies. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should clarify the condition in Proposition 6.1, which appears to be strong, by comparing it with the condition in Section 4 (correct model case). This feedback provides a clear and concrete action for the authors to take, as it specifies the exact part of the paper that needs clarification and offers a specific comparison to be made. The comment is highly actionable because it gives the authors a direct and specific step to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Proposition 6.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the condition \\eta \\ge C_0 and its implications for the signal-to-noise ratio. The suggestion to compare this condition with that in Section 4 is also specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the condition in Proposition 6.1, suggesting that it is too strong given the typical signal-to-noise ratio. The reviewer provides a logical reasoning by pointing out that \\eta is typically a small value, which supports the claim that the condition is not typical. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the condition in Proposition 6.1, suggesting that it may be too strong given the typical signal-to-noise ratio. It provides a clear and actionable suggestion for the authors to clarify this condition and compare it with the condition in Section 4 (correct model case). This feedback is valuable as it prompts the authors to address a potential weakness in their argument, which could enhance the clarity and robustness of their work. However, the comment could be more helpful if it included specific examples or references to support the claim about the typical signal-to-noise ratio. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to make the legends for tables 1, 2, and 3 longer and clarify whether the numbers are percent errors or percent correct. This feedback provides clear and direct guidance on what needs to be done to improve the clarity of the tables. The action is explicit and concrete, as it specifies exactly what needs to be added or clarified in the legends. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the legends for these tables, and it provides guidance on what should be clarified, such as whether the numbers are percent errors or percent correct. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a factual observation and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a clear and direct suggestion that can help improve the clarity and accuracy of the tables, which are crucial for effectively communicating the results. By addressing this feedback, the authors can enhance the readability and comprehensibility of their work. Therefore, the comment is highly helpful, as it offers a concrete way to improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also mentions that the concept of peak in Figure 5 is not described. While the comment provides explicit actions to take, such as revisiting the energy concept and clarifying the peak concept, it does not specify how to implement these actions or what specific details should be included in the refreshed explanation. The authors are given clear guidance on what needs to be addressed, but the execution of these actions is somewhat vague. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing a possible interpretation of high energy on a character. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and should be refreshed in Section 5.2, where it is used several times. The reviewer provides a specific suggestion to clarify the interpretation of high energy on a character, which could be a point of confusion. Additionally, the reviewer points out that the concept of peak in Figure 5 is not described. This feedback is mostly verifiable as it provides a clear rationale for the need to clarify the energy concept and the peak concept. However, it could be strengthened by referencing specific examples or additional details that would further support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also points out the lack of description for the concept of peak in Figure 5. This feedback is clear and offers a concrete way for the authors to improve the clarity and understanding of their work. By addressing these suggestions, the authors can enhance the comprehensibility and effectiveness of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. This feedback provides a clear and explicit action for the authors to take, which is to clarify the title to avoid confusion. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the ambiguity in the title regarding whether it refers to human reading comprehension or machine comprehension of text. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. This claim is somewhat verifiable as it provides a logical reasoning for the clarification, but it lacks specific examples or references to support the claim that \"reading comprehension\" and \"readability\" typically refer to human reading comprehension. The authors might find it challenging to fully understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the title of the paper, suggesting that it may refer to human reading comprehension rather than machine comprehension of text. It provides a clear and actionable suggestion to clarify the title to avoid confusion. This feedback is valuable as it helps the authors ensure that their title accurately reflects the focus of their work, which is important for readers to understand the paper\\'s content. However, the comment could be more helpful if it offered additional guidance on how to clarify the title or suggested alternative wording. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific claim made by the authors on line 238, which is incorrect according to the Central Limit Theorem (CLT). It highlights that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment explicitly identifies the issue with the claim and provides a clear explanation of why it is incorrect. However, it does not offer any guidance on how the authors should address this issue or suggest alternative statements to correct the claim. The action is explicit but lacks concrete details on how to implement the correction, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made by the authors regarding the Central Limit Theorem (CLT) and why it is incorrect. The comment provides a detailed explanation of why the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim made by the authors regarding the Central Limit Theorem (CLT) and its applicability to a finite linear combination of random variables. The reviewer provides a detailed explanation of why the claim is incorrect, citing specific aspects of the CLT that do not guarantee Gaussianity in a non-asymptotic regime and do not hold for a finite linear combination of arbitrary random variables. This logical reasoning and reference to established theory provide a strong basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and its applicability to a finite linear combination of random variables. It points out that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it highlights a critical error in the authors\\' understanding of the CLT. By correcting this mistake, the authors can improve the accuracy and credibility of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the implications of this error. Overall, the comment is mostly helpful as it effectively guides the authors towards a correction, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should show confidence intervals and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. The comment provides explicit actions for the authors to take, such as including confidence intervals and expanding the evaluation to more datasets. However, it does not specify which datasets should be used or how to calculate the confidence intervals. While the actions are clear, the lack of detailed guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results and the limited evaluation on two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of not showing confidence intervals and the need to evaluate on more datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. The reviewer supports this claim by referencing external works that discuss the importance of confidence intervals and the need for more datasets to evaluate robustness. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of confidence intervals or by explaining why the two datasets used are insufficient. Despite this, the claim is mostly verifiable due to the references to external works, which provide a solid foundation for the critique.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should include confidence intervals to demonstrate statistical significance and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the robustness and credibility of their results. However, the comment could be more helpful if it offered suggestions on how to calculate confidence intervals or which datasets to consider. Overall, the comment is mostly helpful as it effectively directs the authors toward improving their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of scalability should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of scalability should be considered or how the authors might address this question. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRM-RL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or explore more general tasks. The authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRM-RL. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the paper\\'s applicability to more general tasks, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is limited in its application to navigation problems and suggests that combining RL and planning has already been discussed in PRM-RL. However, the comment does not provide specific references or examples from PRM-RL to substantiate this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s applicability to navigation problems and suggests that the method discussed is already discussed in PRM-RL. It points out that combining RL and planning has been discussed in the literature, which could be relevant to more general tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore more general tasks. While it highlights an area for improvement, the feedback lacks actionable advice or detailed suggestions, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider whether all feature spaces are well-suited for 1-NN and warns that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends standardizing feature dimensions to avoid this issue. While the comment provides a clear action\u2014to evaluate the suitability of feature spaces and standardize dimensions\u2014it does not offer specific guidance on how to implement this suggestion or what metrics to use for evaluation. The action is explicit but lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suitability of feature spaces for 1-NN and the potential issue with non-spherical Gaussian feature spaces. The comment provides a clear suggestion to standardize feature dimensions to avoid this issue, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the suitability of feature spaces for 1-NN and suggests that non-spherical Gaussian feature spaces may perform poorly. The comment provides a logical reasoning by explaining that standardizing feature dimensions can avoid this issue. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not as robust as it could be. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, specifically the suitability of feature spaces for 1-NN. It points out that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment suggests a potential solution by recommending standardizing feature dimensions to avoid this issue. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft. However, it could be more helpful if it included examples or additional details on how to standardize feature dimensions or what metrics to use for evaluation. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the meaning of \\u03b4 in the statement of Lemma 5. While it does not explicitly instruct the authors to clarify this term, it implies that the authors should provide a definition or explanation of \\u03b4 to improve the clarity of the paper. The action is implicit but concrete, as the authors can infer that they need to address this issue to enhance the understanding of their work. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \\u03b4 in the statement of Lemma 5. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the meaning of \\u03b4 in the statement of Lemma 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the meaning of \\u03b4 in the statement of Lemma 5. While it identifies a potential area of confusion, it does not provide any guidance or suggestions for clarification or improvement. The comment lacks actionable feedback or context that would help the authors understand how to address this issue or improve the clarity of their work. As a result, it offers limited value to the authors in terms of enhancing the draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include the bottom-up method [9] in their tables and evaluate its performance on the standard MS COCO dataset to see if there is a drop in performance in easy (non occluded) settings. While the comment explicitly states what needs to be done, it does not provide detailed guidance on how to implement these actions. The authors are given a clear direction but may need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the bottom-up method [9] and the crowdpose dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the inclusion of the bottom-up method in the tables and the evaluation of its performance on the MS COCO dataset. This provides clear guidance on what needs to be added or improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the bottom-up method [9] has reported results on the crowdpose dataset outperforming all methods, including the paper\\'s own method, with a ResNet-50. The comment also recommends evaluating the method\\'s performance on the standard MS COCO dataset to see if there is a drop in performance in easy settings. While the comment provides a specific example of the bottom-up method\\'s performance, it lacks detailed justification or references to support the claim that this method outperforms others. The suggestion to evaluate on the MS COCO dataset is logical, but the claim about the bottom-up method\\'s performance is not fully substantiated. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed reasoning or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include the bottom-up method [9] in their tables and evaluate its performance on the standard MS COCO dataset. This suggestion is based on a specific example of the method\\'s reported results on the crowdpose dataset, which could help the authors validate their claims and provide additional context for their work. By addressing these points, the authors can enhance the comprehensiveness and robustness of their evaluation. However, the comment could be more helpful if it explained why this evaluation is important or how it would impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and few-shot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. It provides an example from the TACRED slot filling guidelines to illustrate the depth of understanding required. However, the comment does not explicitly instruct the authors to revise their claim or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claim and provide more detailed information about their understanding of annotation guidelines. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim of using \"annotation guideline\" and provides a specific example of the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to identify the exact part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the overstatement of using annotation guidelines and the need to provide more detailed information about the understanding of annotation guidelines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim of using \"annotation guideline\" and provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This example is used to support the claim that the paper's prompts may not fully capture the depth of true guideline understanding. The reasoning is logical and provides a specific example to substantiate the claim, making the comment mostly verifiable. However, the comment could be strengthened by referencing additional examples or sources to further support the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential overstatement in the paper\\'s claim of using \"annotation guideline\" and provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This example highlights the depth of understanding required for annotation guidelines, which the paper may not have fully captured. The comment is clear and actionable, as it prompts the authors to reconsider their claim and provide more detailed information about their understanding of annotation guidelines. This feedback is valuable as it guides the authors to improve the accuracy and depth of their claims, making it highly helpful. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about what happens if the original CAD model is already associated with spatially-varying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what potential implications it might have for their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the potential consequences of this association, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment poses a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. While it highlights an area of interest, it does not provide any guidance or suggestions for the authors to address this question or explore its potential implications. Without actionable feedback or direction, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This is a clear and concrete action that the authors can take to address the issue of lacking direct evidence for the motivation. The comment provides a specific suggestion for how to present the evidence, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of direct evidence for the motivation and suggests plotting a figure to support the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evidence for the motivation is not direct, as the problem is stated as \"a predictor suffers from accuracy decline due to long-term and continuous usage.\" The reviewer suggests that the authors should plot a figure showing the decline in accuracy over time (search steps) in different settings to support their claim. This claim is somewhat verifiable as it provides a logical suggestion for addressing the issue, but it lacks specific examples or references to similar studies that have successfully used such figures to demonstrate the decline in accuracy. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of direct evidence for the motivation of the study. It suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This feedback is clear and actionable, providing the authors with a concrete step to address the identified weakness. However, the comment could be more helpful if it explained why this figure is necessary or how it would strengthen the paper. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement that can enhance the clarity and credibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the definition and calculation of excessive risk in the paper, particularly in relation to the optimal solution and data from different groups. It suggests that the authors should explain more about the concept of excessive risk and how it is calculated in practice, including the expectation. Additionally, it questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment provides a clear direction for the authors to clarify their explanation of excessive risk, it does not offer specific guidance on how to address these questions or improve the draft. The action is explicit but somewhat vague, as the authors need to determine the exact details of how to implement the suggested improvements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of excessive risk and how it is calculated in practice, particularly in relation to the optimal solution and data from different groups. The comment further raises questions about the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the definition and calculation of excessive risk, particularly in relation to the optimal solution and data from different groups. It suggests that the values of excessive risk in Figure 3 and Figure 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The reviewer questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment identifies a potential issue with the definition and calculation of excessive risk, it lacks specific examples or references to support the claim that the values are positive. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or clarification to fully address the reviewer\\'s concerns.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of confusion regarding the definition and calculation of excessive risk in the paper. It questions the relevance of the concept of excessive risk as a fairness metric and points out that the values in Figures 3 and 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The comment also raises questions about the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. This feedback is clear and actionable, as it prompts the authors to clarify their explanation of excessive risk and its practical application. By addressing these points, the authors can significantly improve the clarity and coherence of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide more information about the motivation and potential applications of their work, but the comment lacks specific suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the motivation and potential applications of the work, but without explicit references to sections or parts of the paper, the authors may struggle to identify where these issues are addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the motivation is unclear or that the task is difficult to predict. The comment is somewhat verifiable as it highlights potential gaps in the paper, but it does not provide detailed reasoning or evidence to fully substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance the clarity of their motivation. The feedback is somewhat helpful as it points out areas for improvement, but it lacks actionable advice or detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take by asking for examples. The comment is concrete because it specifies the exact part of the paper where the examples should be provided, making it easy for the authors to understand and implement the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors\" mentioned in those lines. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area in the paper where examples of \"unreliable neighbors\" are mentioned. By asking for examples, the reviewer prompts the authors to provide more detailed explanations or examples to support their claims. However, the comment could be more helpful if it offered suggestions on how to present these examples or what specific aspects to focus on. While it provides a clear direction for improvement, it lacks depth and could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the practicality of the proposed work, specifically regarding the use of known causal relationships between features. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the practicality of their work or what specific steps they could take to ensure the validity of their causal relationships. As a result, the comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s proposal to use known causal relationships between features, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment also highlights a concern about the practicality of using prior knowledge, which is relevant to the paper\\'s focus on causal relationships. However, it does not specify what aspects of the paper\\'s approach or results are problematic or how they could be improved. This lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed work relies on known causal relationships between features, which may not always be available or accurate. The reviewer supports this claim by mentioning that most researchers focus on mining causal relationships from data automatically. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable, as it requires more detailed support to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s approach, noting that it relies on known causal relationships between features, which may not always be available or accurate. The reviewer highlights a practical concern by mentioning that most researchers focus on mining causal relationships from data automatically. This feedback is somewhat helpful as it points out a potential limitation in the paper\\'s applicability, prompting the authors to consider the practicality of their approach. However, the comment could be more helpful if it provided suggestions on how to address this limitation or examples of alternative methods that could be considered. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the contrastive learning framework used in the paper is the same as SimCLR, which is a direct observation. However, it does not provide any guidance or suggestions on how the authors should address this observation or what changes they should make to their framework. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the contrastive learning framework used in the paper is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the comparison to SimCLR. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which could be a potential issue or a point of comparison. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this observation or differentiate their work from SimCLR. Without actionable feedback or constructive advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that Table 4 and 5 should be split into two tables each, with one table per measure. This provides a clear and concrete action for the authors to take, as it specifies the exact change needed to improve the readability of the tables. The suggestion is specific and actionable, leaving no ambiguity about what the authors should do to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of the tables by splitting them into two tables each, with one table per measure. This guidance is detailed and actionable, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that splitting tables 4 and 5 into two tables each would improve their readability. This claim is based on a logical reasoning that splitting the tables would make them more organized and easier to follow. However, the comment does not provide specific examples or references to support this claim, such as how other papers or studies have successfully implemented this structure. While the suggestion is logical, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, with one table per measure. This is a clear and concrete piece of feedback that can help the authors enhance the presentation and organization of their data. By following this suggestion, the authors can make their tables more organized and easier to navigate, which can improve the overall clarity and accessibility of their work. However, the comment could be more helpful if it explained why this change would improve readability or provided examples of how other studies have successfully implemented this structure. Despite this, the feedback is mostly helpful as it offers a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by making the comparisons with the most closely related work more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. The comment is explicit in its suggestion and offers a specific improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and the \"present paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely making comparisons more systematic with respect to the tuning of each method. This provides clear guidance on how to enhance the originality and comparative analysis of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s originality is improved by comparing it to the most closely related work of Zemel et al. (2013) and explaining how it differs. The comment suggests that the comparisons could be made more systematic by comparing the best performance of each method. This claim is somewhat verifiable as it provides a logical reasoning for improvement, but it lacks specific examples or references to the original work or the current paper\\'s comparisons. The authors would need to infer the specifics of the comparisons and the need for systematic analysis, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need to make comparisons with the most closely related work more systematic. It suggests that the authors should compare the best performance of each method, which is a clear and actionable suggestion. This feedback is valuable as it provides a concrete direction for enhancing the originality and comparative analysis of the paper. However, the comment could be more helpful if it explained why this systematic comparison is important or how it would benefit the paper. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explicitly estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion for how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need to estimate the time complexity of the learning algorithm to prove its scalability properties, which provides full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the estimation of time complexity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a clear and actionable suggestion that can help the authors strengthen their claims about the algorithm\\'s performance. By addressing this point, the authors can provide more robust evidence to support their conclusions. However, the comment could be more helpful if it included examples or guidance on how to estimate the time complexity effectively. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit suggestions for how the authors should improve the discussion or clarify the explanation. Without guidance on what specific aspects need attention or how to address the issue, the authors are left without actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the discussion around equation (10) is terse and not clearly explained. This provides full grounding and specificity, as the authors can accurately identify the part of the paper being addressed and what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks depth and does not provide suggestions on how to improve the discussion or clarify the explanation. While it highlights an area for improvement, the comment could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
