{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It implies that these options might be better than the ones chosen. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they should consider these alternatives but are not given clear instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"261\" and \"272,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of operators and suggesting that the \"and\" operator or elementwise max might be better options. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. The reviewer suggests that these options might be better than the ones chosen, implying that the current choices are not welljustified. However, the comment lacks specific reasoning or examples to support why the \"and\" operator or elementwise max would be better options. Without detailed justification or references, the claim remains 3, as the authors may find it challenging to understand the basis of the suggestion without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these options might be better than the ones chosen, as they correspond to the ideas of union and intersection from the \"or\" operator and elementwise min. This feedback is 3 as it prompts the authors to reconsider their choice of operators and potentially improve the clarity and effectiveness of their work. However, the comment could be more helpful if it provided specific reasons or examples why the \"and\" operator or elementwise max might be preferable. Overall, the comment offers a valuable suggestion for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the description of the data sources, specifically mentioning that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be revised to make the description more accurate and precise. The action is concrete and leaves no ambiguity, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the description of the data sources, suggesting that the authors should revise the description to mention Li et al. (2019a) earlier to clarify and improve the precision of the information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a discrepancy in the description of the data sources, specifically mentioning that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This claim is 3 as it provides a logical reasoning for the suggested revision, but it lacks specific examples or references to support the claim fully. The authors would need to make a logical deduction to understand the issue and the suggested revision. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the data sources, noting a discrepancy between lines 226238 and 242244 regarding the selection of sentences from raw data. It suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to revise their description to avoid confusion and ensure accuracy. By addressing this issue, the authors can improve the clarity and precision of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing antecedent in the text and suggests checking the references for format issues, such as capitalization and bibliographic details. While the comment explicitly identifies the missing antecedent and provides specific guidance on what to check, it does not offer detailed instructions on how to implement these checks or what specific issues to focus on. The action is clear but somewhat vague in terms of execution, as the authors need to determine the exact details of how to address the formatting issues. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number \"781,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the references, suggesting that they should be checked for format, such as capitalization and bibliographic details. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of references, noting that the antecedent is missing and suggesting that the references should be checked for capitalization and bibliographic details. While the comment provides clear guidance on what needs to be addressed, it lacks depth and does not offer suggestions on how to improve the formatting or why it is important. The feedback is 3 as it points out a specific issue but could be more beneficial with additional context or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the baseline models: the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It explicitly instructs the authors to compare their work with Campos et al. and to include comparisons with other domain adaptation methods mentioned in Section 8. The comment provides concrete guidance on what needs to be added to the paper, making it 5. The authors know exactly what steps to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the baseline models, noting the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. While the comment identifies a potential issue with the baseline models, it lacks specific examples or references to Campos et al. or other domain adaptation methods to fully substantiate the claim. The reasoning is 3, as it points out a potential gap in the comparison, but it could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the baseline models used in the paper, noting that they are weak and lack comparison with relevant works. It specifically points out the absence of a comparison with Campos et al. (2020), which also uses feedback in QA tasks, and the lack of comparison with other domain adaptation methods mentioned in Section 8. The comment provides clear and actionable feedback by suggesting that the authors should include these comparisons to strengthen their work. This guidance is valuable for the authors as it helps them improve the robustness and comprehensiveness of their baseline models. However, the comment could be more helpful if it provided specific examples or references to the relevant works, which would further enhance its utility. Overall, the comment is 4 as it effectively directs the authors to address a critical area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also asks about the KNs in source language or English in Figure 3, noting that the mentions have been translated to English. The authors are instructed to correct the figure. While the comment provides explicit actions, it does not specify how to implement these changes or what specific details should be added to the input or figure. The action is clear but lacks concrete guidance on execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as adding information about the input being word embeddings and clarifying the KNs in source language or English in Figure 3. The comment provides clear guidance on what needs to be corrected, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also questions the KNs in source language or English in Figure 3, noting that the mentions have been translated to English. The comment is 3 as it provides a logical suggestion for clarifying the input and figure, but it lacks specific examples or references to support the claim. The authors are prompted to make a correction, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also raises a question about the KNs in source language or English in Figure 3, noting that the mentions have been translated to English. This feedback is clear and directs the authors to make a specific correction that could improve the clarity and accuracy of their work. By addressing these points, the authors can enhance the transparency and comprehensibility of their methodology. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two specific areas where the presentation of the model needs improvement: the pooling method used for embedding features (line 397) and the clarity of Equation (7) in line 472. It provides explicit questions about the pooling method and the definition of E_i in Equation (7), asking whether it represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability. This feedback is clear and provides concrete actions for the authors to take, such as clarifying the pooling method and the definition of E_i. The explicit nature of the questions and suggestions makes this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the pooling method used for embedding features and the definition of E_i in Equation (7). The comment provides detailed guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of the pooling method used for embedding features (line 397) and the definition of E_i in Equation (7) in line 472. It suggests that the LHS of Equation (7) should be a conditional probability. The comment is 3 as it provides logical reasoning by questioning the clarity of the equations and suggesting improvements. However, it lacks specific examples or references to support the claim, which would make it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the presentation of the model needs improvement, providing clear and actionable feedback. It points out that the pooling method used for embedding features is not clearly explained and questions the definition of E_i in Equation (7). The reviewer also suggests that the LHS of Equation (7) should be a conditional probability, which is a valuable suggestion for clarifying the model\"s theoretical basis. This feedback is detailed and constructive, empowering the authors to make significant improvements to their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and specific hypotheses tested. However, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and specific hypotheses tested. However, the comment does not specify which parts of the paper are particularly challenging to understand or where the authors should focus their efforts to improve clarity. Without explicit references to sections or specific analyses, the authors may struggle to identify the areas needing attention. Therefore, the comment is weakly grounded because it does not specify which parts of the paper are being addressed, and it is not specific in detailing what needs to be clarified. This aligns with a score of 2.", "verifiability_rationale": "The review point expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and specific hypotheses tested. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant challenge in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and specific hypotheses tested, as well as how the different pieces of the puzzle fit together. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors\" attention to a key area for clarity, but it could be more beneficial with actionable advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The comment is specific in detailing what additional comparisons are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental comparisons and suggests testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional comparisons are needed and why they are important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional comparisons are necessary or how they would impact the results. Without such justification, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental comparisons, specifically noting that the proposed InvP method is not tested with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback is valuable as it suggests a potential area for improvement in the experimental design, which could enhance the robustness and generalizability of the results. However, the comment could be more helpful if it provided specific guidance on how to implement these additional comparisons or why they are important. Overall, the comment is 4 as it points out a relevant area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection is not wellestablished and recommends either formalizing it more or adjusting the language to clarify the connection. While the comment provides a clear direction for improvement, it does not specify which parts of the paper need formalization or clarification. The authors are left to infer the exact actions to take, such as identifying specific sections or phrases that need attention. The feedback is 3 as it provides a general direction but lacks concrete guidance on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment suggests that the probabilistic connection is not wellestablished and recommends either formalizing it more or adjusting the language to clarify the connection. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in suggesting that the connection should be formalized or clarified, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not wellestablished and suggests that it should be formalized more or clarified. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific sections of the paper where the connection is unclear or inadequately formalized. As a result, the claim is 3, as it points to a potential issue but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the probabilistic connection, suggesting that it is not wellestablished and lacks formalization. It provides a clear and actionable suggestion to either formalize the connection more or adjust the language to clarify it. This feedback is valuable as it points out a specific area where the paper could be improved, offering the authors a concrete direction for enhancing the clarity and rigor of their work. However, the comment could be more helpful if it provided examples of how the connection could be formalized or clarified. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the callout to Table 5 should be changed to Table 3 and provides the correct page and section number. Additionally, it points out that the figure 6 callout is not directing properly. This feedback is clear and provides specific actions for the authors to take, ensuring that they know exactly what needs to be corrected. The explicit nature of the instructions and the concrete details on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the callout to Table 5 and the figure 6 callout, providing detailed guidance on how to correct these issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the callout to Table 5 should be changed to Table 3 and that the figure 6 callout is not directing properly. However, the comment does not provide any supporting evidence, reasoning, or examples to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a mistake in the callout to Table 5, which should be changed to Table 3, and noting that the figure 6 callout is not directing properly. This feedback is clear and directs the authors to correct specific errors in their paper, ensuring that the references are accurate and easy to follow. By addressing these issues, the authors can improve the clarity and accuracy of their work. Therefore, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a significant concern with the paper\"s experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be beneficial in a generative setting. While the comment implies that the authors should include comparisons with SketchRNN, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of comparisons with other models and the absence of an explanation for the selfcomparison. The comment suggests that comparisons with SketchRNN could be beneficial in a generative setting. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a significant concern due to the lack of comparisons with other models and the absence of an explanation for the selfcomparison. The reviewer suggests that comparisons with SketchRNN could be beneficial in a generative setting. While the comment identifies a potential issue with the paper\"s experimental design, it lacks specific examples or references to support the claim that comparisons with SketchRNN would be beneficial. This makes the claim 3, as the authors would need to make a logical inference to understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be beneficial in a generative setting. While the comment highlights a critical area for improvement, it does not provide detailed guidance on how to address this issue or what specific comparisons with SketchRNN could entail. The feedback is 3 as it points out a significant weakness but lacks actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment recommends conducting more analysis and providing comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\" viewpoint regarding the benefits of increased model capacity and provides specific examples from Figure 3 to support this disagreement. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While it provides some guidance, the action is implicit and lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trending of increasing the number of parameters for ViT (DeiT) and disagrees with the authors\" viewpoint regarding the benefits of increased model capacity. The comment provides specific examples from Figure 3 to support its claims, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim that the authors\" viewpoint is incorrect regarding the benefits of increased model capacity for ViT (DeiT) compared to CNNs. The reviewer supports this claim by providing specific examples from Figure 3, where DeiTB does not outperform DeiTT on APTOS2019 and DeiTS on APTOS2019, ISIC2019, and CheXpert. This provides a clear and robust basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint regarding the benefits of increased model capacity, providing specific examples from Figure 3 to support its disagreement. This feedback is clear and constructive, as it guides the authors on how to address the critique and improve their analysis. However, the comment could be more helpful if it offered suggestions on how to conduct the additional analysis or what specific aspects to focus on. Overall, the comment is 4 as it provides valuable insights and actionable guidance for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges that the paper is not difficult to follow but points out specific areas that may cause confusion. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve clarity or what specific changes should be made to avoid confusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not specify which sections or parts of the paper these areas are located in, making it difficult for the authors to pinpoint the exact issues. The comment is specific in identifying potential areas of confusion but lacks grounding as it does not specify where these issues are located in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the identified areas of confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any detailed guidance or suggestions on how to address these areas of confusion. Without actionable feedback or specific examples, the authors are left without a clear path to improve the clarity of their draft. Therefore, the comment is 2, as it points out an issue but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or how to improve the technical competency required to understand them. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not specify which part of the paper this issue pertains to, such as the results section or a particular technique. Without explicit references to sections or techniques, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the results or techniques are not obvious or require technical competency. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. This feedback highlights a potential weakness in the paper\"s presentation, as it may not be accessible to a broader audience. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to address this issue. Without detailed feedback or examples, the authors may struggle to understand and implement the necessary improvements. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify how the implemented billinear layer differs from other approaches that perform billinear pooling. It raises questions about the major difference, such as the dimensionality of embeddings, and how the billinear layer is swapped out with other approaches like hadarmard product and MCB. Additionally, it asks if the compression of the representations using Equation (3) is still done in this case. While the comment provides specific questions that need clarification, it does not explicitly instruct the authors on how to address these points. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the differences between the billinear layer and other approaches that perform billinear pooling. The comment raises questions about the dimensionality of embeddings, how the billinear layer is swapped out with other approaches, and whether the compression of representations using Equation (3) is still done. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the differences between the billinear layer and other approaches that perform billinear pooling. It suggests that the major difference might be the dimensionality of embeddings, and it asks how the billinear layer is swapped out with other approaches like hadarmard product and MCB. The comment also inquires about the compression of the representations using Equation (3) in this case. While the comment identifies areas for clarification, it lacks specific examples or references to support the claim that the billinear layer is different from other approaches. This makes the claim 3, as the authors would need to provide more detailed explanations or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable set of questions that the authors need to address to clarify the differences between the billinear layer and other approaches that perform billinear pooling. It raises specific questions about the dimensionality of embeddings, how the billinear layer is swapped out with other approaches, and whether the compression of the representations using Equation (3) is still done. By addressing these points, the authors can significantly improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered additional context to guide the authors in their responses. Overall, the comment is 4 as it identifies important areas for clarification and improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. This feedback provides a clear and explicit action for the authors to take, which is to include the illustration of the results in the paper. The comment is specific and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e.\" and \"Eqn 13,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the illustration of the results of the latter loss term of Eqn 13. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results of the latter loss term of Eqn 13 should be illustrated directly, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this illustration is necessary or how it would enhance the understanding of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, specifically suggesting that the authors should illustrate the results of the latter loss term of Eqn 13 directly. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and comprehensiveness of the paper. By addressing this point, the authors can enhance the understanding and interpretation of their results, which is valuable for improving the draft. However, the comment could be more helpful if it explained why this illustration is important or how it would benefit the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or suggesting a specific approach to improve the clarity. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the Witness oracle is confusing or how it could be clarified, making the comment weakly grounded but specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the confusion caused by the implicit call to the Witness oracle. This feedback is clear and actionable, as it points out a specific area that needs clarification or explanation. However, the comment could be more helpful if it provided suggestions on how to clarify or improve the explanation of this concept. Despite this, the feedback is 3 as it directs the authors to a critical area that requires attention. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. The reviewer suggests renaming the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect this distinction. Additionally, the reviewer proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. These suggestions are clear and provide specific guidance on how to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semisupervised training and the renaming of the column in Table 1. The comment also provides a detailed suggestion for improving the clarity of the table by suggesting the creation of two columns for data sources. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between weak supervision and semisupervised training, specifically in Table 1. The reviewer provides a specific example of renaming the column from \"Supervised\" to \"Fully supervised\" to reflect this distinction. Additionally, the reviewer proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This suggestion is based on logical reasoning and common knowledge about data labeling, making the claim 4. However, the comment could be strengthened by providing references to similar practices or studies that support the proposed changes. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on improving the clarity of the paper. It identifies a specific issue with the distinction between weak supervision and semisupervised training, particularly in Table 1, and suggests renaming the column to \"Fully supervised\" to reflect this distinction. Additionally, the reviewer proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This feedback is 5 as it offers concrete steps for the authors to improve the clarity and comprehensibility of their work. By addressing these suggestions, the authors can significantly enhance the clarity and accessibility of their paper, making it more valuable to both reviewers and readers. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet 6 and Sparse NCNet 21) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment implies that the authors should consider how to differentiate their work from previous methods, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of differentiation but may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper makes small contributions over previous methods (NCNet 6 and Sparse NCNet 21) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. However, the comment does not specify which part of the paper discusses these contributions or differentiates from previous methods, making it weakly grounded. The comment is specific in its critique of the paper\"s contributions and differentiation from previous work, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper makes small contributions over previous methods (NCNet 6 and Sparse NCNet 21) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. However, the comment lacks specific examples or references to support these claims, making it challenging for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique from the limited information provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet 6 and Sparse NCNet 21) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment identifies a potential issue with the paper\"s differentiation from previous work, it lacks specific suggestions or guidance on how the authors might address this concern. The feedback is 3 as it points out a potential weakness, but it does not provide actionable advice or detailed insights for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. It also questions the ecological validity of such a study and suggests that previous work has considered multiple vulnerabilities simultaneously. The reviewer asks whether the authors argue that identifying one vulnerability at a time is an intended use case. While the comment highlights areas of concern, it does not provide explicit guidance on how the authors should address these issues or improve their methodology. The action is implicit and somewhat vague, as the authors need to infer that they should consider multiple vulnerabilities and justify their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vulnerability discovery methodology\" and the \"single vulnerability\" approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the ecological validity of the study and suggesting that previous work has considered multiple vulnerabilities. The comment further highlights the difficulty in interpreting the results and whether the authors are arguing for a singlevulnerability approach. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. The reviewer questions the ecological validity of such a study and suggests that previous work has considered multiple vulnerabilities simultaneously. The comment also points out that the results are difficult to interpret, or at best, marginal improvements. While the comment provides a logical basis for questioning the methodology, it lacks specific references to external works or detailed reasoning to fully substantiate the claim. This makes the comment 3, as it provides a reasonable basis for the critique but requires more detailed evidence or examples to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the vulnerability discovery methodology, questioning the authors\" approach of considering only a single vulnerability at a time. It highlights the potential problem of ecological validity and suggests that previous work has considered multiple vulnerabilities simultaneously. The reviewer also points out that the results are difficult to interpret, or at best, marginal improvements. This feedback is valuable as it challenges the authors to reconsider their methodology and potentially improve the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or improve the methodology. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or suggest alternative approaches. As a result, the authors are left without any clear direction on how to enhance the originality of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of originality, specifically mentioning that the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered unoriginal, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the originality of the paper, specifically noting that the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide specific guidance on what aspect of the claim is questionable or how it could be improved. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. The reviewer points out that a model that can only handle a single time series data is almost useless. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this concern or what aspects of the claim are misleading. As a result, the comment is not helpful, as it does not provide the authors with a clear path forward to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. Additionally, it recommends including more analysis and discussion for GPT2, specifically asking for the results of Figure 2 for GPT2. While the comment provides explicit actions and concrete details on what to investigate and include, it could be more helpful if it explicitly instructed the authors on how to conduct these analyses or provided examples of what such analyses might entail. Overall, the comment is 4 as it clearly outlines specific areas for improvement and provides concrete guidance on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the generalizability of results to other models and the need for more analysis and discussion of GPT2. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. The comment provides a logical reasoning by pointing out the limitations of the current experiments and the need for more analysis and discussion, particularly for GPT2. However, it lacks specific examples or references to support the claim that the results cannot be generalized, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, and recommends including more analysis and discussion for GPT2. The comment provides clear and actionable feedback by specifying what aspects of the experiments need to be expanded and clarified. By suggesting additional analyses and discussions, the comment offers the authors a concrete path to improve their draft. However, it could be more helpful if it provided specific guidance on how to conduct these analyses or examples of what such analyses might entail. Overall, the comment is 4 as it directs the authors to important areas for improvement and enhances the quality of the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback provides clear and concrete actions for the authors to take, such as adding a description of the evaluation process and addressing language issues. The comment is specific and direct, giving the authors a clear understanding of what needs to be added or improved. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues on page, providing specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving their draft by adding a description of the evaluation process and addressing language issues. However, the comment could be more helpful if it offered suggestions on how to structure the evaluation section or provided examples of what such a description might look like. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment implies that the authors should clarify this confusion by providing more detailed explanations or examples. However, it does not explicitly instruct the authors to make these changes or suggest specific ways to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the notation and provide more context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the notation for target domain \u03c4 and the use of sparse labels. The comment further questions the use of unlabeled data in source domains and references the original MFDA paper by Yue et al. (2021a) for clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. The reviewer questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper by Yue et al. (2021a). The comment is 3 as it provides a logical basis for the confusion, referencing the original paper for clarification. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for target domain \u03c4 is unlabeled and questions the use of sparse labels, which is not consistent with the original MFDA paper by Yue et al. (2021a). The comment also highlights the confusion regarding the unlabeled data in source domains and suggests that the authors should clarify this issue. This feedback is clear and actionable, as it directs the authors to address the confusion in their description and potentially provide more detailed explanations or examples. However, the comment could be more helpful if it offered specific suggestions on how to improve the clarity or provided examples of how the original paper handled these issues. Overall, the comment is 4 as it effectively identifies a critical area for improvement and offers a clear direction for the authors to enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a specific issue with the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. The reviewer implies that the authors should provide more detailed explanations or examples to clarify this distinction. While the comment does not explicitly instruct the authors to make changes, it implies a clear action for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the specific issue of distinguishing between the three classes of extreme speech. It also references the sample data file and line 438441, allowing the authors to pinpoint the exact part of the paper being addressed. The comment is specific because it details the difficulty in differentiating derogatory and exclusionary extreme speech and questions the annotation of a specific instance. It also seeks clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the distinction between the three classes of extreme speech, specifically questioning the annotation of a specific instance as exclusionary extreme speech. The reviewer provides a specific example from the sample data file and questions the annotation, asking for clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. This request for clarification is a logical step in the evaluation process, as it seeks to understand the basis of the annotation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the annotation of a specific instance as exclusionary extreme speech. The reviewer also seeks clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. This feedback is clear and actionable, as it prompts the authors to clarify their definitions and annotations to improve the clarity and coherence of their work. By addressing these points, the authors can enhance the comprehensibility and robustness of their analysis. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should consider different timesteps for training and evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the relevance of different timesteps and how they might impact the effectiveness of the proposed methods. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of the proposed methods, noting that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep. This observation raises questions about the novelty and practical relevance of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or explore different timesteps. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the disentanglement aspect of the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed. The reviewer suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Disentanglement\" and \"Broader Impacts and Limitations,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding how disentanglement is achieved and guaranteed without certain bias types. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that disentanglement is not clearly explained and questions how it is achieved and guaranteed without certain bias types. While the comment references the \"Broader Impacts and Limitations\" section, it does not provide specific examples or detailed reasoning to support the claim that disentanglement is unclear. The reference to the \"Broader Impacts and Limitations\" section suggests that the authors should address this issue, but without further elaboration, the claim remains 3. The authors would need to make a significant effort to understand and address the issue, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the disentanglement aspect in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed without certain bias types. The comment suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is clear and actionable, as it directs the authors to a specific area that needs further explanation and justification. However, it could be more helpful if it provided examples or additional guidance on how to address this issue. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of specific stateoftheart references in the face recognition experiment, particularly mentioning \"Baidu\"s work\" and its reported results. It also highlights the use of the triplet loss and the similarity to the Webface dataset. The comment provides a clear and specific action for the authors to include these references in their work. Additionally, it suggests that the VRF achieved a better result than reported in Table 3, which could be a valuable comparison for the authors to make. The action is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the specific references that are missing, such as \"Baidu\"s work\" and the reported results on the dataset containing 9K identities and 450K images. It also provides specific details about the triplet loss and the reported results, which allows the authors to identify the exact parts of the paper being addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the face recognition experiment, specifically mentioning \"Baidu\"s work\" and its reported results. The reviewer provides a specific reference to the work, which is a clear and verifiable claim. Additionally, the comment provides a detailed comparison with the Webface dataset, which further strengthens the claim. The inclusion of specific references and data points makes the claim 5, as it provides a clear and robust basis for the critique. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup in the paper, noting the absence of certain stateoftheart references, such as \"Baidu\"s work\" on face recognition. It provides a detailed comparison with the Webface dataset, highlighting the reported results and suggesting that the VRF achieved a better result. This feedback is clear and actionable, as it directs the authors to include these references and potentially compare their results with the stateoftheart. By addressing this feedback, the authors can enhance the rigor and comprehensiveness of their experimental evaluation. Therefore, the comment is 4, as it provides a concrete direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the ICLHAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. It suggests that this issue should be discussed or at least acknowledged in the main text in more detail. This feedback provides a clear and direct action for the authors to take, which is to address this issue in their draft. The comment is specific and provides concrete guidance on how to improve the paper by discussing or acknowledging the impact of the ICLHAR on accuracy scores. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLHAR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ICLHAR, noting that it has impeded accuracy scores and dropping them from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the paper, namely the discussion or acknowledgment of this issue in more detail. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This claim is supported by the provided data, which shows a significant decline in accuracy scores. However, the comment could be strengthened by providing more detailed analysis or explanation of why this decline occurred or how it affects the overall contribution of the paper. While the data itself is a strong indicator, additional context or reasoning would enhance the verifiability of the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the ICLHAR, noting that it has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This is a clear and actionable observation that the authors should address in their draft. The comment suggests that the issue should be discussed or acknowledged in more detail in the main text, providing a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or what aspects of the ICLHAR might be contributing to the accuracy drop. Overall, the comment is 4 as it highlights a significant issue that the authors should address to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or improve their draft. There is no guidance on whether this drop is a concern, what factors might be contributing to it, or how the authors might mitigate it. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper needs attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the correlation drop need to be addressed or how it might be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation about the correlation drop after a short period of training, which increases with more training iterations. This is a clear and actionable point that could guide the authors in understanding and addressing a potential issue in their work. However, the comment lacks depth and does not provide suggestions on how to investigate or mitigate this drop in correlation. While it points out a problem, it does not offer detailed guidance on how to resolve it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. This provides a clear and direct action for the authors to take, ensuring that they either include the temperature or acknowledge its absence in the paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing temperature parameter, \u03c4, and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on how to improve the derivation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. The reviewer suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the temperature should be included or why its absence is problematic. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation from Equation 3 to Equation 4, noting that the temperature parameter, \u03c4, is missing. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this issue, the authors can enhance the rigor and clarity of their derivation, which is valuable for the overall quality of the paper. However, the comment could be more helpful if it included additional context or explanation on why the temperature is important or how its inclusion might impact the paper\"s conclusions. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting described in the paper is only partially strategic or game theoretic, as the opponent does not behave strategically. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the strategic nature of the setting or what specific changes should be made to make it more game theoretic. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the setting described in the paper, suggesting that it is only partially strategic or game theoretic because the opponent does not behave strategically. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the setting but lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the setting described in the paper is only partially strategic or game theoretic because the opponent does not behave strategically. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s setting, noting that it is only partially strategic or game theoretic because the opponent does not behave strategically. This is a relevant observation that could impact the paper\"s contribution and relevance. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the strategic nature of the setting. Without actionable advice or detailed feedback, the authors are left with a general critique but no clear path forward. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail for the authors to effectively improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to run the corresponding experiments and add the results to the figures and Table 1, clarifying specific aspects of the data used in the experiments. The comment also asks for clarification on the nature of the random data used in Figures 3c and 3, specifically whether the network was trained on random data or unaltered data, and whether the data was normalized. Additionally, it suggests including examples of random data in the appendix. These actions are clear and specific, providing the authors with a clear path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3c\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as running the corresponding experiments and adding the results to the figures and Table 1. The comment also asks for clarification on the nature of the random data used in Figures 3c and 3, and suggests including examples in the appendix. This level of detail provides clear guidance for the authors to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification and additional experiments, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the paper could be improved. It points out that the figures do not show results for untrained networks and suggests running the corresponding experiments and adding them to the figures and Table 1. Additionally, it clarifies some aspects of the random data used in the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also suggests including examples of random data in the appendix. While the comment provides clear and actionable feedback, it could be more helpful if it offered suggestions on how to interpret and analyze the results of the additional experiments. Overall, the comment is valuable in guiding the authors to improve their draft, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify these aspects in their draft, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the task setup is not described clearly, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the task setup, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are unclear or how they impact the paper\"s clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the task setup, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This feedback is clear and actionable, as it points out areas where the authors need to provide more detailed information to ensure the task setup is understandable. However, the comment could be more helpful if it suggested ways to clarify these aspects or provided examples of how similar tasks have been addressed in the literature. Despite this, the feedback is 4 as it directs the authors to a critical area needing improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems in imaging, specifically mentioning the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with these methods. While the comment provides a clear action\u2014mentioning the relevant work and potentially comparing the current method\u2014it does not specify how to integrate this information into the paper or what specific aspects of the work should be compared. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" for inverse problems in imaging, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work by Ulyanov et al. (CVPR 2018) and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the OOD experiments are interesting because the trained network can provide strong OOD generalization. However, it also mentions that untrained NNs, like those used in the Ulyanov et al. (CVPR 2018) paper, can be used for inverse problems across a wide range of images. The reviewer suggests that the current method should be placed in context and potentially compared with these methods. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to the Ulyanov et al. paper to fully substantiate the claim. This makes the claim 3, as the authors would need to follow up on the suggestion to fully understand and address the critique.", "helpfulness_rationale": "The review comment provides a constructive suggestion by pointing out that the OOD experiments are interesting due to the strong OOD generalization demonstrated by the trained network. However, it also highlights a potential limitation by mentioning that untrained NNs, like those used in the Ulyanov et al. (CVPR 2018) paper, can be used for inverse problems across a wide range of images. The comment suggests that the current method should be placed in context and potentially compared with these methods. This feedback is 4 as it encourages the authors to consider the broader context of their work and potentially enhance its impact by including a comparison with other methods. However, the comment could be more helpful if it provided specific guidance on how to integrate this information into the paper or what aspects of the Ulyanov et al. paper should be considered. Overall, the comment is 4 as it offers actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments are limited to toy data and recommends expanding the analysis to include real data. While the comment implies that the authors should consider using real data, it does not provide specific guidance on how to implement this suggestion or what aspects of real data should be considered. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to toy data and recommends expanding the analysis to include real data. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should consider using real data and exploring the performance of the method in those settings. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and recommends expanding the analysis to include real data. However, the comment does not provide specific examples or references to support the claim that real data would be beneficial or how it would impact the results. The suggestion is based on a logical inference but lacks detailed justification or evidence, making it 3. The authors would need to make a significant effort to understand and address the suggestion, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are currently limited to toy data. It suggests expanding the analysis to include real data, which could provide valuable insights into the performance of the method in more practical settings. This feedback is clear and actionable, as it directs the authors to consider a broader range of data types to enhance the robustness and generalizability of their results. However, the comment could be more helpful if it provided specific examples or guidance on how to implement this suggestion. Overall, the feedback is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. The reviewer explicitly asks for clarification on these points, providing a clear direction for the authors to improve the clarity of their explanations. The action is explicit and concrete, as it specifies exactly what needs to be addressed to improve the readability of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail helps the authors understand what needs to be addressed to improve the clarity of their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are hard to read due to unclear explanations of previous approaches. It provides specific examples of unclear statements, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. These examples are detailed and provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to support the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity and readability of the first two sections of the paper. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96, and asks for clarification on these points. This feedback is clear and actionable, as it directs the authors to improve the clarity of their explanations and provide more detailed descriptions of their methods. By addressing these issues, the authors can significantly enhance the readability and comprehensibility of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the captions should be more descriptive and provides a specific example of the issue of having to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment provides a clear action to make the captions more descriptive and an explicit request for an explanation of the scramble network, it does not provide detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specifics of how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests making the captions more descriptive and provides an example of the issue of having to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the figures or captions in the paper. The comment is specific in its request for more descriptive captions and an explanation of the scramble network, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions are not descriptive enough and provides an example of having to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment identifies a specific issue with the captions, it lacks detailed reasoning or examples to fully substantiate the claim that the captions are not descriptive. The suggestion to make them more descriptive is logical, but the lack of specific examples or detailed reasoning makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the captions should be more descriptive, which would improve the clarity and accessibility of the figures in the paper. It also highlights the issue of having to search through the text for interpretations of figures, which are usually on a different page. This feedback is valuable as it directly addresses a common challenge in scientific writing and offers a clear solution to improve the draft. Additionally, the comment requests an explanation of the scramble network, which could further enhance the clarity and understanding of the paper. Overall, the comment is 5 as it provides clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some abbreviations, such as \"NE\" on L73, are not defined and that the superscript notation in Equation 6 is not defined until later in the paper, which hinders understanding in an initial read. It also references specific works that may be relevant to the paper. While the comment identifies specific issues that need attention, it does not provide explicit instructions on how to address them. The authors are left to infer that they should define these abbreviations and clarify the notation, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L73 and L166) and equations (Eq 6), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of undefined abbreviations and notation, such as \"NE\" and superscript notation, which hindered understanding in an initial read. Additionally, it references specific works that may be relevant to the paper, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue with the paper, namely that some abbreviations and notation are not defined, which hinders understanding in an initial read. The reviewer provides examples of these issues, such as \"NE\" on L73 and the superscript notation in Eq 6, which are not defined until later in the paper. The reviewer also references specific works that may be relevant to the paper, which adds credibility to the claim. However, the comment lacks detailed reasoning or references to explain why these issues are significant or how they impact the overall understanding of the paper. Therefore, the claim is 3, as it provides some evidence but could be strengthened with more detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that some abbreviations and notation are not defined, which hinders understanding in an initial read. It provides examples of these issues, such as \"NE\" on L73 and the superscript notation in Eq 6, which are not defined until later in the paper. Additionally, the comment references specific works that may be relevant to the paper, which could be helpful for the authors to consider. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing definitions or explanations for the abbreviations or suggesting ways to improve the clarity of the notation. Overall, the comment is 3 as it identifies a clear area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the evaluation or suggest alternative baselines that are better suited for fair classification. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"evaluation\" and \"baselines used in the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation being weak and the baselines not being designed for fair classification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, noting that the baselines used in the paper are not designed for fair classification. This is a critical observation that highlights a potential weakness in the paper\"s methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the evaluation. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. The comment explicitly instructs the authors to correct the inaccuracy regarding the Walkman algorithm, specifying that it is solved by ADMM with two versions. It also points out the lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors clarify the intended reference. These actions are explicit and provide concrete guidance on what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about the Walkman algorithm, noting that it is solved by ADMM with two versions, and it points out the lack of clarity in the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed in these parts of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization.\" It does so by pointing out that the Walkman algorithm is solved by ADMM with two versions, which suggests that the claim is inaccurate. The reviewer provides a specific example of the Walkman algorithm, which is a clear and logical point. However, the comment could be strengthened by referencing the specific ADMM versions or providing more detailed information about the Walkman algorithm. Despite this, the claim is 4 due to the clear reasoning and specific example provided.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. By pointing out these issues, the comment provides clear and actionable feedback that empowers the authors to correct their draft. The suggestion to clarify the reference to \"it\" in Section 3 is particularly helpful, as it ensures that the authors provide a clear and accurate description of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the statement about the Walkman algorithm or provided additional context on the significance of the ADMM versions. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. The comment is clear and concrete, giving the authors specific details to include in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more comprehensive overview of existing methods and their limitations, including sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This provides clear guidance on what needs to be improved in the Related Work section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations. The reviewer provides a list of specific methods to consider, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This detailed list of examples and references provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these methods are relevant to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the Related Work section, noting that it lacks details and suggesting that the authors should provide a more comprehensive overview of existing methods and their limitations. The comment lists several specific approaches, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, which should be discussed in the context of the paper. This detailed guidance helps the authors understand what aspects of the related work are important to include and how to present them effectively. Therefore, the comment is 5, as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to enhance the paper. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this acknowledgment pertains to, making it weakly grounded. The comment does provide a specific suggestion for improvement, which is to consider the relaxation proposed by Guzman et al. This provides some level of specificity, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a minor suggestion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. It identifies a minor suggestion, but without further elaboration or guidance, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the presentation of results, such as labeling the yaxis in Figures 2 and 3 and using a scatter plot with runtime/performance axes. It also recommends highlighting the best results in tables. These actions are explicit and concrete, providing clear guidance on how to enhance the clarity and interpretability of the results. The authors know exactly what changes to make to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as labeling the yaxis and using a scatter plot with runtime/performance axes. The comment also suggests highlighting the best results in tables, providing clear guidance on how to enhance the presentation of results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results presentation in Figures 2 and 3 could be improved by labeling the yaxis more clearly and using a scatter plot with runtime/performance axes. It also recommends highlighting the best results in tables. While the comment provides a logical suggestion for improving the clarity of the results, it lacks specific examples or references to support the claim that these changes would indeed improve the presentation. The suggestion is 3, as it provides a reasonable direction for improvement but could be strengthened with more detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It identifies ambiguities in the yaxis labeling in Figures 2 and 3 and suggests using a scatter plot with runtime/performance axes to enhance clarity. Additionally, it recommends highlighting the best results in tables, which is a helpful suggestion for readers. The comment is clear and provides detailed guidance, making it 4 for the authors to improve the clarity and interpretability of their results. However, it could be more helpful if it included examples of how the suggested changes would enhance the results presentation. Overall, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific technical considerations should be explored or how to address them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what technical considerations are being questioned or how they might impact the analysis. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not present any claims, opinions, or suggestions that require verification. It is a request for clarification, which is not a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, which is a relevant point for the authors to address. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might explore or justify their choice of using advantage over q value. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment identifies these errors, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to revise these sections to correct the errors and add a title. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be corrected, namely, the writing errors and the lack of a title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it points out specific areas that need correction to improve the clarity and professionalism of the paper. However, the comment could be more helpful if it provided suggestions on how to correct these errors or offered guidance on how to improve the overall writing quality. Despite this, the feedback is 4 as it directs the authors to specific areas for improvement, which can enhance the clarity and professionalism of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the motivation or clarify the architecture. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not specify which part of the paper discusses the hGRU architecture, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered adhoc or poorly motivated, leaving the authors without clear guidance on how to address these concerns. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any specific reasoning or evidence to support this claim. There is no detailed explanation or examples given to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated, which could be a significant concern for the authors. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to address this issue. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and suggests that the authors should provide average return results with more env steps. While the comment implies that the authors should make a change to Line 8 and potentially include additional results, it does not explicitly instruct them to do so. The action is concrete, as it specifies the change needed and the additional information to be provided, but it is somewhat vague because it does not provide detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 8 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of s_t instead of s_n and suggests providing average return results with more env steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and a request for additional results. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the use of s_t instead of s_n on Line 8 of Algorithm 1, which is a clear and actionable point for the authors to address. It also suggests providing average return results with more env steps, which could be beneficial for understanding the asymptotic performance of the proposed method. However, the comment could be more helpful if it provided additional context or examples to guide the authors in implementing these changes. Overall, the comment is 4 as it identifies a specific area for improvement and offers actionable suggestions, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as it is not accurate according to the reviewer\"s understanding. Additionally, it advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, focusing on plurals and articles. These are clear and specific actions that the authors can take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests compressing the method section, particularly on essential definitions. Additionally, it points out grammatical errors and provides specific examples, such as \"l.\" This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the claim about the neural network memorizing critical points is inaccurate, based on the reviewer\"s understanding of TopoNet. However, the comment does not provide any specific references or detailed reasoning to support this claim, nor does it offer alternative perspectives or evidence. The suggestion to tone down the statement is somewhat vague, as it lacks specific guidance on how to rephrase it. Additionally, the comment mentions grammatical errors and suggests compressing the method section, but it does not provide detailed examples or explanations. Overall, the claim is 3, as it points out a potential issue but lacks sufficient evidence or guidance for the authors to address it effectively.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on multiple aspects of the paper. It identifies a potential inaccuracy in the statement about the neural network memorizing critical points, suggesting that the authors should tone down this claim. This is a clear and constructive suggestion that can help the authors improve the accuracy and clarity of their claims. Additionally, the comment advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, particularly with plurals and articles. This feedback is detailed and actionable, empowering the authors to make significant improvements to their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the comparison with Megatron, suggesting that it is overrated and points out that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer also raises a question about the authors\" claim of parameter efficiency, suggesting that if this claim is valid, it could apply to these other works as well. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the comparison with Megatron and clarify their claims about parameter efficiency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with Megatron, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the overrating of the comparison and suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also raises a question about the authors\" claim of parameter efficiency, which is relevant but not directly addressed in the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the comparison with Megatron, suggesting that it is overrated and that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment provides a logical reasoning by comparing the performance of these models, which supports the claim that the comparison with Megatron is overstated. However, the comment could be strengthened by providing specific examples or references to the performance comparisons, which would make the claim more verifiable. As it stands, the comment is 3, as it provides a logical argument but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between COCOLM and Megatron, suggesting that the performance of these models is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This feedback is valuable as it highlights a potential overstatement in the comparison, which could lead the authors to reconsider their claims about the superiority of COCOLM. Additionally, the comment raises a question about the authors\" claim of parameter efficiency, prompting them to clarify their reasoning and potentially address a gap in their analysis. While the comment could be more helpful by providing specific examples or references to support the comparison, it still offers actionable feedback that can guide the authors in improving their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis from lines 128 to 149 is not convincing and suggests that the GSP50 model has smaller class selectivity score, which means it shares more features with ResNet50. The reviewer also hypothesizes that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the analysis. The reference to external works, while helpful, does not offer detailed instructions on how to apply this information to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of convincingness and consider the implications of the external references. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 128 to 149,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the analysis, noting that the GSP50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet50. The comment further hypothesizes that additional context may allow the network to reduce its dependency. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis from lines 128 to 149 is not convincing enough, based on the histogram in Figure 3, which shows that the GSP50 model has a smaller class selectivity score compared to ResNet50. The reviewer references external works 1 and 2 to support the claim that GSP50 shares more features with ResNet50, suggesting that additional context may allow the network to reduce its dependency. However, the comment does not provide detailed reasoning or examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment could be strengthened by explaining how the external works support the claim or by providing specific examples from the references. Therefore, the claim is 3, as it requires further elaboration to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from lines 128 to 149 is not convincing enough. It points out that the GSP50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet50. The reviewer hypothesizes that additional context may allow the network to reduce its dependency. While the comment provides a clear direction for improvement by suggesting that the authors address the issue of convincingness, it lacks specific guidance on how to improve the analysis or what aspects of the analysis are lacking. The reference to external works is helpful but does not fully address the critique. Overall, the comment is 3 as it identifies a critical area for improvement but could be more comprehensive with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to ensure that the observations and design decisions are not dependent on specific hardware or software. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine which sections or elements of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are dependent on hardware or software. Without clear guidance on what needs to be addressed or improved, the authors cannot effectively address the comment. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While it identifies a potential weakness, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the paper might be affected. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern about the practical impact or suggestions for improving the paper to better demonstrate its relevance. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the theoretical interest and the potential practical impact, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. This feedback highlights a potential limitation in the paper\"s relevance and applicability, which could impact its impact on the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or demonstrate the practical relevance of their work. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific direction for the experiments, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides full grounding as it clearly identifies the part of the paper that needs revision. The comment is also specific because it specifies the exact comparison that needs to be made, which is the number of learnable parameters and GFLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. By doing so, the authors can demonstrate the effectiveness of their method in comparison to other approaches, which could enhance the paper\"s contribution and credibility. However, the comment could be more helpful if it included suggestions on how to design and conduct these experiments, or if it highlighted potential challenges or considerations in doing so. Overall, the comment is 4 as it provides a clear and actionable direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it does not provide explicit instructions or concrete actions for the authors to take. The comment mentions that Figure 5a seems strange and asks for more explanations, but it does not specify what aspects of the figure are problematic or how to address them. Similarly, it mentions the handling of DVS input when the input is in AER format but does not offer guidance on how to improve this aspect. The comment also suggests analyzing energy consumption like reference 15 did, but it does not provide details on how to implement this analysis or what specific aspects to focus on. Overall, the comment lacks explicit instructions or concrete steps for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a\" and \"11,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with \"Fig. 5a\" and suggests providing more explanations, as well as addressing the handling of DVS input when the input is in AER format. Additionally, it recommends analyzing energy consumption like reference 15 did, which provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several questions and suggestions for improvement, rather than making subjective claims or opinions. It does not contain any claims or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several pieces of feedback that can help the authors improve their draft. It points out that Figure 5a seems strange and suggests that more explanations are needed. Additionally, it questions how the authors handled DVS input when the input is in AER format, which could be a critical aspect to address. The comment also recommends analyzing energy consumption like reference 15 did, which could strengthen the paper\"s foundation. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how to address these issues. Therefore, it is 3, as it provides some direction but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete request, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB\" and \"fig. 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification about the dashed lines in figures 2AB and 4B. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it directly addresses a specific issue by requesting clarification on the definition of the dashed lines in figures 2AB and 4B. This feedback is clear and actionable, as it guides the authors to provide a necessary explanation for their figures, which could enhance the clarity and understanding of their work. By addressing this point, the authors can improve the readability and comprehensibility of their draft, making the comment 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and concrete action that the authors can take to improve their draft. The comment provides a specific direction for visualizing the results, which is a direct and actionable point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing a plot of how different weights of the model move, specifically after unlearning, to see which layers are affected the most. However, it does not specify which part of the paper this plot should be included in, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular visualization, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a request for additional visualization to support the understanding of the method. However, the comment does not provide any specific reasoning or evidence to justify why this plot is necessary or how it would enhance the paper. Without additional context or explanation, the claim is 3, as it requires the authors to make a leap of faith to understand the importance of the suggested plot. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and constructive piece of feedback that can help the authors better understand and communicate the impact of their method. By addressing this point, the authors can enhance the clarity and comprehensiveness of their results, making the paper more informative and valuable to the reader. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in cramped equations and captions too close to the figures. This is considered a grounding comment as it clearly identifies the issue with the spacing. However, the comment does not provide any guidance on how to address this issue, such as suggesting specific adjustments or improvements to the spacing. The action is implicit and vague, leaving the authors without clear direction on how to improve the spacing in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of whitespace throughout the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9page paper limit due to the reduced whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper violates the 9page limit due to the reduced whitespace, specifically mentioning cramped equations and captions too close to the figures. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s acceptability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s formatting, noting that the reduced whitespace throughout the document results in cramped equations and captions too close to the figures. This is a clear and actionable observation that could impact the paper\"s readability and adherence to the 9page limit. However, the comment does not provide suggestions on how to address this issue or improve the spacing, such as recommending adjustments to the spacing between elements or providing examples of better spacing practices. While it highlights a significant problem, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can differ across datasets. It suggests that the paper lacks crossdataset experiments, which would be a good way to test the generalization of the work. While the comment implies that the authors should conduct crossdataset experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for crossdataset experiments and determine how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of crossdataset experiments, which is a critical aspect of testing the generalization of the work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods that exploit relationships between action units can suffer from differences in cooccurrences across datasets, as seen in Figure 1. The reviewer suggests that crossdataset experiments are necessary to test the generalization of such work. While the comment provides a logical reasoning for the need to test generalization, it lacks specific examples or references to datasets or studies that demonstrate these differences. This makes the claim 3, as the authors would need to infer the significance of the issue and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a specific example of this issue by pointing out the cooccurrence of AU1 and AU12 in Figure 1, which illustrates the difference in correlation across datasets. The comment suggests that crossdataset experiments are necessary to test the generalization of the work. While it provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to conduct crossdataset experiments or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from incremental engineering papers. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is problematic or where the motivation is unclear. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation or the paper are unclear or how they could be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or originality of their work. Without actionable feedback or detailed insights into what aspects of the paper are unclear or lacking, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning, and it explicitly asks for an explanation of the correspondence between the learning curves and MPHATE in Figure 3. The reviewer also questions the rationale behind the learning curves and the accuracy numbers, providing specific questions that the authors should address. These actions are clear and detailed, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the need for an explanation of the experimental setting for continual learning, the correspondence between the learning curves and MPHATE, and the accuracy numbers. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add a few more sentences to explain the experimental setting for continual learning. It also asks for an explanation of the correspondence between the learning curves and MPHATE in Figure 3, questioning the rationale behind the learning curves and the accuracy numbers. This feedback is clear and constructive, as it guides the authors to clarify their experimental setup and provide more detailed explanations. By addressing these points, the authors can improve the clarity and comprehensibility of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This explicit action provides a clear and concrete step for the authors to take, as it specifies the exact visualization needed to demonstrate the practical benefits of SGC. The comment is 5 because it directly instructs the authors on how to enhance their draft with a specific visualization, ensuring that the authors know exactly what to do to improve their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the limited applicability of SGC and the need for a plot to compare its flexibility with LoRA. It specifies the issue by suggesting a visualization with sparsity on the xaxis and performance on the yaxis. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the SGC method offers a more flexible, finegrained tradeoff but is limited in practicality due to the need for extra tuning. The reviewer suggests that a plot comparing SGC with LoRA would be beneficial to demonstrate the flexibility of SGC. This claim is 3 as it provides a logical reasoning for the need for a visualization but lacks specific examples or references to support the claim. The suggestion for a plot is a clear and actionable step, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s claim about the flexibility and performance of SGC. It suggests that a plot comparing SGC with LoRA would be beneficial to demonstrate the practical benefits of SGC\"s finegrained control at different sparsity levels. This feedback is clear and actionable, as it provides a specific suggestion for how the authors can enhance their draft by including a visualization that could help substantiate their claims. By addressing this point, the authors can improve the clarity and persuasiveness of their argument, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests that the authors explicitly state the model used in the paper, suggesting that this information could be added to the appendix. While the comment provides some guidance on what the authors should include, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide examples and model details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"support data\" and \"predicted training count data\" in Figure 1, as well as requests that the model used be explicitly stated in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific terms and data used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests that the authors explicitly state the model used in the paper, suggesting that this information could be added to the appendix. While the comment identifies areas for clarification and potential enhancement, it does not provide specific guidance or suggestions on how to address these issues. The authors are left with a clear understanding of what needs to be clarified but may not have a full understanding of how to implement the suggested improvements. Therefore, the comment is 3, as it points out areas for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not contribute novelly to the understanding of the winnertakeall property, as it uses extremely simplified settings and reports findings that have been previously reported in other works. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or how to present the findings in a more novel or innovative way. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"winnertakeall property\" and \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not contribute novelly to the understanding of this behavior due to the use of extremely simplified settings and the repetition of findings from previous works. This provides clear guidance on what needs to be addressed to improve the originality of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. However, the comment lacks specific references to these previous works or detailed examples of how the findings have been reported. Without such references or evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. This is a critical observation that could impact the paper\"s originality and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from previous studies. While it points out a potential weakness, it does not provide actionable feedback to help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors elucidate the EEG token quantization process in greater detail, specifically addressing the ambiguity in interpretation. It suggests that the authors should clarify whether the spatial arrangement of the EEG sensors played a role in this process. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity in the interpretation of the EEG topography plots and the need to clarify the role of the spatial arrangement of the EEG sensors in the EEG token quantization process. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents ambiguity in interpretation due to the EEG topography plots for both the input and output during the EEG token quantization process. The reviewer suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role. While the comment identifies a potential issue with interpretation, it lacks specific examples or references to support the claim that the spatial arrangement of the sensors is relevant. This makes the claim 3, as it provides a direction for improvement but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and understanding of their results. By addressing this point, the authors can enhance the interpretability and reproducibility of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning the paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This provides a clear and direct action for the authors to take, as they are instructed to include this discussion in their paper. The comment is specific and provides concrete guidance on how to enhance the literature review section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph (lines 2230) and discusses the use of moment matching in distributional RL. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on moment matching and its relevance to distributional RL. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL. The reviewer supports this claim by referencing a specific paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This reference provides a clear and specific example of relevant literature that could be included in the paper. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be beneficial in the context of distributional RL. Despite this, the reference to the specific paper is sufficient to make the claim 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL. It provides a clear and actionable suggestion by referencing a specific paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This feedback is valuable as it directs the authors to include a discussion on moment matching, which could enhance the literature review and broaden the scope of the paper. However, the comment could be more helpful if it explained why moment matching is important or how it could benefit the paper. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. This feedback provides a clear and explicit action for the authors to take, which is to include an analysis of the quality of the local minima. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Algorithm 1 and the local minima, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of these local minima, such as the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors analyze the quality of the local minima, particularly the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and improve the paper. By addressing this suggestion, the authors can strengthen their work by providing more detailed insights into the performance of their algorithm. However, the comment could be more helpful if it included specific examples or references to similar analyses in the literature, which would guide the authors in implementing this suggestion effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for each domain. It also questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on morphologic segmentation across domains. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"morphologic segmentation\" and \"domain\" aspects, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of morphologic segmentation across domains and how it should differ for each domain. The comment also raises important questions about the assumption of morphologic segmentation invariance across domains, which is relevant to the task of domain adaptation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks information on how to use morphologic segmentation across domains and how it should differ for each domain. It questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim that morphologic segmentation should differ across domains. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of addressing these questions themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the use of morphologic segmentation across domains and how it should differ for each domain. It questions the assumption of morphologic segmentation invariance across domains, given the task of domain adaptation. This feedback is valuable as it highlights an important area for improvement in the paper, particularly regarding the applicability and adaptation of the proposed method. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or how to conduct morphologic segmentation differently across domains. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results, including identifying the reasons behind the poor performance. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, leaving some ambiguity about the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for a more detailed analysis themselves, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the results. By pointing out the lack of analysis, the comment empowers the authors to enhance their draft by including a more detailed explanation of the underlying reasons for the observed performance. However, the comment could be more helpful if it suggested specific areas to explore or provided examples of how to conduct a more thorough analysis. Overall, the comment is 4 as it directs the authors to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. While the comment implies that the authors should clarify these labels, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the labels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the labels for each dataset, including \"caspealr1\" and \"mugshot.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the labels for each dataset in 4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. This is a relevant inquiry that could help the authors clarify their methodology and provide more transparency about the datasets used. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address this issue. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to the \u03bb parameters, and questions how \u03bb is calculated. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but does not fully understand the implications. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to improve the explanation or calculations. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the process of calculating \u03bb and improve the explanation of the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines on pages 8 and 9, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters, questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific examples or detailed reasoning to support the claim that performance and sample efficiency are sensitive to \u03bb parameters. The references are provided as a means of context, but they do not fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the sensitivity of performance and sample efficiency to \u03bb parameters, which is a critical aspect of the paper. It raises questions about how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment, which are important areas for clarification. The reviewer also provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the explanation. While it points out areas for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it highlights important areas for clarification but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or suggest alternative approaches to explore. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspects of the paper are lacking in novelty or how the authors could address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. This feedback highlights a potential weakness in the paper\"s contribution, which could impact its impact and originality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not provide specific guidance on how to expand the experiments or what additional aspects to consider. While it highlights an area for improvement, it lacks concrete steps or suggestions on how to achieve this expansion. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in identifying the need for more comprehensive and general experiments, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It highlights the limitation of the model size and the restrictive baselines, which constrain the scope of the experiments. However, the comment does not provide specific examples or references to support why these limitations are problematic or how they impact the results. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which constrains the experiments\" generalizability and comprehensiveness. This feedback is valuable as it highlights an area where the authors could expand their experiments to enhance the robustness and relevance of their results. However, the comment does not provide specific suggestions on how to address this limitation or what additional experiments could be conducted. While it offers a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This feedback provides a clear and direct action for the authors to take, which is to include an ablation study to address this issue. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of an ablation study, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of an ablation study to explain why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This provides clear guidance on what the authors need to add to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this ablation study is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the lack of an ablation study explaining why the prompt was chosen in a particular way, such as using fewshot examples for CoT. This feedback is clear and actionable, as it points out a gap in the paper that could be addressed by including an ablation study. By addressing this issue, the authors could enhance the transparency and robustness of their work. However, the comment could be more helpful if it provided additional guidance on how to design and conduct the ablation study. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what alternative demonstrations could be used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific statement \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim that \"better than random\" is a strong demonstration of capability, providing a clear point of critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is questionable. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. This feedback is 3 as it points out a potential weakness in the paper\"s argument, prompting the authors to reconsider the strength of their evidence. However, the comment lacks specific suggestions or guidance on how to strengthen the demonstration or what alternative methods could be used to substantiate the claim. While it identifies an area for improvement, it does not provide detailed guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. However, it does not provide any guidance on how the authors should address this limitation or suggest ways to expand the results to include other network architectures. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results only apply to shallow fullyconnected ReLU networks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand their results to include other network architectures. While it points out an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments or citing relevant literature to support their claims. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplified selfattention model\" considered in the theoretical analysis, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The mention of Kaplan et al. 2020 provides additional context and guidance on what kind of empirical results should be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The reviewer references Kaplan et al. 2020 as a potential source for empirical results. However, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient or how additional experiments would address the issue. The reference to Kaplan et al. 2020 provides some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental setup, noting that the experiments are insufficient to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that more empirical experiments or toy experiments are needed to address this gap. Additionally, it references the result in Kaplan et al. 2020 as a potential source for empirical evidence. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their experimental setup and substantiate their claims. By addressing these points, the authors can significantly improve the robustness and credibility of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary use of the absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This is a factual observation about the mathematical definition of the Frobenius norm, which does not require an opinion or subjective judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the Frobenius norm in line 77, noting that the absolute value operation is unnecessary because tensor entries are real numbers. This is a clear and actionable point that can help the authors improve the clarity and accuracy of their draft. By pointing out this oversight, the comment provides the authors with a concrete step to take in revising their manuscript. However, the comment could be more helpful if it offered suggestions on how to better explain or justify the use of the absolute value operation in the context of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions that this would allow for inspection of the longrange inference capacity of the model. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. The action is explicit and concrete, as it clearly specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions the need to inspect the longrange inference capacity of the model. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for the experiment. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the longrange inference capacity of the model. The reviewer provides a logical reasoning for why this experiment would be beneficial, noting that it would simulate realworld scenarios where keypoint detection may fail. However, the comment lacks specific examples or references to similar experiments in the literature, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be further supported with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending an experiment where the image is occluded to simulate irregularity in neural/behavioral data. This suggestion is relevant as it addresses a potential limitation in the current study and offers a way to test the model\"s longrange inference capacity. The reviewer also explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. This feedback is 5 as it guides the authors on how to enhance their study with a specific and meaningful addition. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer recommends using a second yaxis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not specify how to implement this suggestion or what alternative visualization should be used. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests using a second yaxis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. However, the comment lacks specific reasoning or examples to support why Figure 6C is awkward or how it implies negative rates. Without detailed justification or references, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when it should represent positive rates. The reviewer suggests a solution by recommending the use of a second yaxis or another visualization that is more physically accurate. This feedback is clear and actionable, providing the authors with a concrete step to improve the accuracy and clarity of their figure. However, the comment could be more helpful if it included additional context or examples of alternative visualizations that could be used. Overall, the comment is 4 as it effectively guides the authors on how to address the issue, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. It highlights the need to address how the method can effectively use \"fewshot\" and ensure generalizability to new tasks with 0/few training steps. While the comment implies that the authors should provide more detailed justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot situation for graph link prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not consider how to effectively use \"fewshot\" and how to ensure generalizability to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work is not adequately justified, specifically regarding the fewshot learning context. It suggests that the paper defines a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or ensure generalizability to new tasks with 0/few training steps. While the comment provides a logical reasoning for the need to justify the motivation, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to further develop the argument to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the motivation of the work, particularly in the context of fewshot learning. It points out that the paper defines a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or ensure generalizability to new tasks with 0/few training steps. This feedback is clear and actionable, as it prompts the authors to provide a more detailed justification for their approach and its applicability in the fewshot learning context. By addressing this issue, the authors can enhance the clarity and robustness of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the methodology need to be adjusted. The action is implied and somewhat vague, as the authors need to infer that they should consider using robotic manipulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to use robotic manipulation, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current methodology is insufficient or why robotic manipulation would be more appropriate. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the proposed methodology may not be specific to bimanual manipulation. It recommends using robotic manipulation instead, which could be more appropriate. This feedback is 3 as it points out a potential limitation in the methodology and provides a suggestion for improvement. However, the comment lacks depth and does not explain why robotic manipulation is more appropriate or how it would address the issue. To be more helpful, the comment could provide additional context or examples to support the suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting. The comment also praises the clarity and welldesigned experiments, providing a clear direction for improvement. However, it does not specify how the authors should address the issue or provide guidance on what aspects of the theory should be clarified. While the action is implicit, it is somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"tables\" and \"1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the advantage of UNIFORM over other procedures, noting that the tables show that UNIFORM does not always offer a clear advantage. Additionally, it asks for clarification on why the method is not as effective in the 1shot setting. The comment is detailed and provides specific guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the method is not as effective in the 1shot setting and questions whether the authors have a theory to explain this. The comment provides a logical reasoning by pointing out the inconsistency in the results and the need for an explanation. However, it lacks specific examples or references to the tables or experiments that support the claim, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be improved with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting, which is a valuable point for the authors to consider. Additionally, the comment praises the clarity and welldesigned experiments, providing constructive feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to address the issue with the 1shot setting or how to improve the clarity of the results. Overall, the comment is 4 as it highlights a potential weakness and provides actionable feedback on clarity and experimental design."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the clarity of the empirical analysis in Figure 3 and requests additional clarification on the adjustments made to the input series and forecasting target based on the Frequency Stability score. It also asks for an explanation of why these adjustments enhance the model\"s performance. While the comment provides specific questions that the authors need to address, it does not offer concrete guidance on how to present this information or what specific details should be included. The action is explicit but somewhat vague, as the authors know they need to provide clarification but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the adjustments made to the input series and forecasting target based on the Frequency Stability score and the explanation of why these adjustments enhance the model\"s performance. The comment also points out the spacing issue in Equations (9) and (10) and references external work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the empirical analysis in Figure 3, specifically questioning the adjustments made to the input series and forecasting target based on the Frequency Stability score. The reviewer requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also mentions the spacing issue in Equations (9) and (10) and references external work. While the comment identifies a potential issue with the clarity of the analysis, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to external work provides some support, but the comment could be strengthened with more detailed explanations or examples. Therefore, the comment is 3, as it provides a starting point for the authors to address the issue but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific area of confusion in the empirical analysis presented in Figure 3. It requests additional clarification on the adjustments made to the input series and forecasting target based on the Frequency Stability score and the reasons behind their effectiveness. This feedback is valuable as it guides the authors to enhance the clarity and understanding of their results. Additionally, the comment points out the spacing issue in Equations (9) and (10) and references external work, which could be helpful for the authors to consider. However, the comment could be more helpful if it provided specific suggestions on how to present the additional clarification or examples of how the adjustments affect the model prediction accuracy. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and provides a reference for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. While the comment provides a clear direction for improvement, it does not specify how to enhance the figure or what specific elements should be added or changed. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is 3, as it provides a clear direction but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, including suggestions for enhancing the figure to show the processing pipeline more clearly. The comment details the elements that should be included, such as prompt generation, manual check, demonstration selection, ground truth scores, and model training optimization. This level of detail provides a clear direction for improvement, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these elements are necessary or how they would enhance the figure. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is categorized as 3, as it provides a direction for improvement but lacks the necessary detail to be 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the clarity and comprehensiveness of Fig. 1. It suggests adding elements such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring along with model training optimization. This detailed guidance helps the authors understand what specific aspects of the figure need improvement and how to enhance it to better convey the processing pipeline. However, the comment could be more helpful if it included examples or references to similar figures or studies that effectively illustrate these elements. Overall, the comment is 4 as it provides clear and actionable suggestions for improving the draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove abbreviations like \"MoCo\" from section headers, as they might not be familiar to readers. This is a clear and direct action that the authors can take to improve the clarity of their draft. The comment provides concrete guidance on what to remove, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of abbreviations like \"MoCo\" in section headers. This provides clear guidance on what the authors need to change to improve the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the reader\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper. By pointing out that abbreviations like \"MoCo\" should not appear in section headers, the reviewer highlights a potential source of confusion for readers who might not be familiar with the term. This feedback is clear and direct, offering a straightforward way for the authors to enhance the accessibility of their work. However, the comment could be more helpful if it provided additional context or examples of how this change would improve the clarity of the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors could clarify the technical contribution or make the analysis more novel. There is no explicit or implicit action for the authors to take, such as suggesting new analyses or methods to differentiate their work. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are unclear or where the analysis is standard. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need clarification or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide specific examples or detailed feedback on how the authors could clarify the technical contribution or make the analysis more novel. Without actionable suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This implies that the model may not be incentivized to use fewer factors, leading to increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the model. The authors are left to infer that they need to consider adding a sparsity constraint, but without concrete instructions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"factorized model with an IBP prior,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which leads to increased computation with more tasks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which leads to increased computation with more tasks. The comment provides a logical reasoning by explaining the potential consequences of this lack of constraint, but it does not provide specific examples or references to substantiate the claim. The authors might find it challenging to understand the exact impact of this constraint without additional context or evidence. Therefore, the claim is 3, as it provides a logical argument but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation highlights a potential limitation of the model, which could lead to increased computation with more tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the impact of the lack of sparsity constraint. While it points out a relevant concern, the feedback could be more helpful by offering actionable advice or examples of how to incorporate a sparsity constraint. Therefore, the comment is 3, as it provides insight but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the application of regularization between the LN model and GLMs. It suggests that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al., to ensure a fair comparison. While the comment implies that the authors should make an effort to replicate the previous model, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the LN model and the GLMs, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the application of regularization between the LN model and GLMs, and suggests that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors apply regularization to both LN models and GLMs, which is not consistent with the GLM presented by Pillow et al. The reviewer suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment lacks specific examples or references to the GLM by Pillow et al. to fully substantiate the claim. While the reviewer provides a logical reasoning, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the application of regularization between the LN model and GLMs, suggesting that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al. This feedback is 3 as it points out a potential issue in the comparison between models and provides a direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to reproduce the main features of the previous model or what aspects of the comparison should be emphasized. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a discrepancy in the use of \u03b4 in equations (10) and (11) and suggests introducing \u03b4 when (11) is discussed. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"equation (11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent use of \u03b4 in equations (10) and (11) and suggests introducing \u03b4 when (11) is discussed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \u03b4 is not used in equation (10) but is used in equation (11). This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue in the paper regarding the inconsistent use of \u03b4 in equations (10) and (11). It suggests that introducing \u03b4 when (11) is discussed might improve clarity. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by ensuring consistency in the notation used. However, the comment could be more helpful if it explained why this inconsistency is problematic or how it affects the reader\"s understanding. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the proof in Theorem A.3, specifically regarding the input x having two indices when it is a vector. It also points out a potential error in the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors can infer that they need to clarify the input x and correct the equation, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential error in the proof regarding the input x having two indices when it is a vector, and it questions the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual observations and questions about the proof in Theorem A.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue in the proof of Theorem A.3, pointing out that the input x is a vector, not a matrix, and questioning the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This feedback is clear and actionable, as it directs the authors to correct the input and equation to ensure accuracy and clarity in their work. However, the comment could be more helpful if it provided additional context or explanation on why this correction is necessary or how it affects the overall proof. Despite this, the feedback is 4 as it guides the authors toward a significant improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in section 4.3 and 4.4, questioning the effectiveness of beam search in ensuring the correctness of the results. It suggests that the reviewer is concerned about the reliability of the results, particularly when relationships and entities are replaced. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve the reliability of their results. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies an area of concern but does not offer clear steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. The comment further raises concerns about the reliability of the results and suggests a potential method for addressing this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. It questions the reliability of the results and suggests a potential method for addressing this issue. However, the comment lacks specific examples or references to support the claim that only 77% of the result lists contain the ground truth logical forms. Without such evidence or detailed reasoning, the claim is 3, as it provides a logical basis for the concern but lacks concrete evidence or references to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. It questions the reliability of the results and suggests a potential method for addressing this issue by discussing the percentage of correct entities/relationships being plugged in. This feedback is 3 as it highlights a potential weakness in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this concern or what metrics to use to evaluate the reliability of the results. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of supervised baselines in the paper and suggests that it is reasonable to assume that full annotation is available for datasets of scale ~100k images. It also notes that even if this is not the case, having an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. While the comment implies that the authors should include supervised baselines, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of supervised baselines in the paper, specifically mentioning that most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. It suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. However, the comment does not specify which part of the paper should include this baseline, such as the experimental section or the discussion. While the authors can infer that it relates to the experimental section, the comment lacks full grounding. It is specific about the need for a supervised baseline but does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a significant issue, as most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. The reviewer suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This claim is 3 as it provides a logical reasoning for the inclusion of supervised baselines, but it lacks specific examples or references to support the assertion that full annotation is typically available for datasets of this scale. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which are crucial for understanding the performance of selfsupervised methods. It logically argues that since most experiments are conducted on datasets of scale ~100k images, it is reasonable to assume that full annotation is available. The comment suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental design and analysis. However, it could be more helpful if it offered examples of suitable supervised baselines or provided guidance on how to incorporate them into the paper. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. While the comment provides a clear and explicit action\u2014changing \"X\" to a multiset\u2014it does not offer detailed guidance on how to implement this change or what specific considerations should be taken into account. The action is concrete, but the lack of additional context or explanation makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the change from a set to a multiset in the context of representing graphs with repeated vertex or edge labels. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning based on the need to include multiplicities to ensure an honest representation of the graph. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the rationale and potential implications to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft by recommending that the authors change the representation of \"X\" from a set to a multiset in Section 4. This feedback is clear and directly addresses a potential issue with the accuracy of the representation, which is crucial for the validity of the results. By making this change, the authors can ensure that their histogram accurately represents a graph with repeated vertex or edge labels. However, the comment could be more helpful if it provided additional context or examples to further explain the rationale behind the suggestion. Overall, the comment is 4 as it offers a concrete and actionable improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment provides specific feedback on the paper\"s organization, writing, and content clarity. It suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. These points are explicit and provide concrete actions for the authors to take, such as creating a table and revisiting the selection criteria. The feedback is clear and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"writing\" and \"content clarity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the writing, including suggestions for improvement (drawing a table to compare different CoT prompting methods) and questions about the selection criteria in section 4.2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is wellorganized and provides a clear writing style. However, it also identifies specific areas for improvement, such as drawing a table to compare different CoT prompting methods across different dimensions and questioning the selection criteria in section 4.2. The comment suggests that the writing could be improved by providing more detailed explanations and examples, which is a logical suggestion for improvement. While the comment does not provide specific references or detailed reasoning, it offers a clear direction for the authors to enhance their work. Therefore, the comment is 4, as it provides a solid foundation for the authors to address the feedback.", "helpfulness_rationale": "The review comment provides a mix of positive and constructive feedback. It acknowledges the wellorganized structure and clear writing style of the paper, which is a positive aspect. However, it also identifies areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods across different dimensions and questioning the selection criteria in section 4.2. The comment is 3 as it provides specific suggestions for enhancing the paper, but it could be more helpful if it offered more detailed guidance on how to address the identified weaknesses. Overall, the comment provides some actionable feedback, but it could be more comprehensive to fully support the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It points out a specific example from line 486 where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment provides a clear and explicit action for the authors to take, which is to conduct significance testing to support their claims. This guidance is concrete and leaves no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of significance testing to support claims about method differences. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about method differences without conducting significance testing. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment is 4 as it provides a clear example of the issue and references specific lines in the paper, allowing the authors to understand the basis of the claim. However, it could be strengthened by including more detailed reasoning or references to statistical methods for significance testing. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about method differences. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that without proper testing, it is difficult to determine whether these differences are significant. This feedback is 5 as it directs the authors to a specific area where their claims are not supported by evidence, providing them with a clear and actionable step to improve their draft. By addressing this issue, the authors can strengthen the credibility and robustness of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on how to enhance the robustness and reliability of their results, making it 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results over multiple runs, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it would improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their results. By suggesting a specific method for analyzing the data, the comment provides a concrete step for the authors to take in order to enhance the credibility of their findings. However, the comment could be more helpful if it explained why averaging over multiple runs is necessary or provided examples of how this approach has been used in similar studies. Overall, the comment is 4 as it directs the authors to a specific improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses a subjective opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors might address this perception or improve the contribution of their work. There is no explicit or implicit action for the authors to take, such as suggesting alternative approaches or improvements to the model. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution of the paper and the approach of the proposed model, but it does not specify which part of the paper this perception is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution or approach are considered incremental or limited. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed explanations, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses a subjective opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific reasoning or examples to support this claim or offer suggestions for improvement. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their work need attention or how to enhance its impact. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a discrepancy in the experimental part of the paper, specifically noting that the different metrics used for different OPE methods are not consistent across the two sets of benchmarks presented in Figures 4 and 5. The reviewer explicitly requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The comment is concrete, as it specifies the issue and provides a clear direction for addressing it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy in the metrics used for different OPE methods across the two sets of benchmarks presented in the figures. This provides clear guidance on what needs to be addressed, namely the differences between the two sets of evaluation methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part of the paper verifies different metrics for different OPE methods but notes a discrepancy in the metrics used across the two sets of benchmarks presented in Figures 4 and 5. The reviewer suggests that the authors should provide comments on the differences between the two sets of evaluation methods. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental part of the paper, noting that the metrics used for different OPE methods are inconsistent across the two sets of benchmarks presented in Figures 4 and 5. It explicitly requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and actionable, as it directs the authors to clarify and address the discrepancy in their experimental results. By providing a specific area for improvement, the comment offers valuable guidance for enhancing the clarity and accuracy of the paper. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the possibility of using other statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment implies that the authors should explore alternative methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative statistics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the regularization term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support or explore alternative statistics, such as the median, to replace the mean and standard deviation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the possibility of using other statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment provides a logical reasoning for the need for more theoretical support, it lacks specific examples or references to substantiate the claim fully. The suggestion to explore alternative statistics is a valid point, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support or explore alternative statistics, such as the median, to replace the mean and standard deviation. This feedback is clear and actionable, as it points out a specific area for improvement and offers a constructive suggestion. However, the comment could be more helpful if it provided examples or detailed reasoning for why the median might be a better choice. Overall, the comment is 4 as it guides the authors toward a more robust and theoretically grounded approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to report average results over multiple runs, which is a clear and actionable step. It also suggests discussing the decision boundaries in the toy dataset, which is another actionable point. Additionally, it asks for clarification on what information is in Fig. 9, which is a specific request for more detail. Each of these points is clearly stated and provides concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section\" and specific sections within it, such as \"Sec. 3.1\" and \"Sec. 3.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what needs to be addressed, such as reporting average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes several claims regarding the experimental section, including the need to report average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these suggestions. Therefore, the claims are considered 1.", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the experimental section of the paper. It highlights the need to report average results over multiple runs, which is a common practice in experimental studies. This feedback is clear and can help the authors improve the reproducibility and robustness of their results. Additionally, it suggests discussing the decision boundaries in the toy dataset, which could provide insight into the method\"s behavior and limitations. Finally, it asks for clarification on the information in Fig. 9, which could help the authors better present their findings. Overall, the comment is 4 as it offers concrete guidance on how to enhance the experimental section, making it more actionable and valuable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper. While the comment provides explicit actions to take, such as including ablation and using the same setup as in the DEN paper, it does not specify how to implement these actions. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental evaluation, such as the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. Additionally, it points out the need for a more comprehensive comparison with the DEN paper, including using the same setup. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks ablation for the \"picking\" step and that the comparison on CIFAR is not convincing. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper. The comment provides some reasoning by pointing out the extensive experiments in the continual learning literature and the need for a fair comparison. However, it lacks specific examples or references to support the claim that the comparison is not convincing. This makes the claim 3, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper to ensure fairness and correctness. This feedback is clear and actionable, as it provides specific guidance on how to improve the experimental evaluation section. By addressing these points, the authors can significantly enhance the credibility and robustness of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the texts in legends and axis labels larger, similar to the text size. It also clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. These actions are direct and concrete, providing clear guidance on how to improve the draft. The authors know exactly what changes to make, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the legends and axis labels, and the beginning of page 6, where Proposition (1) is mentioned. It also specifies the issue with the confusion between Proposition (1) and Equation 1. Additionally, it provides specific guidance on font size and clarifies the issue with captions and legends in Figures 2 and 3. This level of detail provides clear direction for the authors to address the issues raised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the font size of legends and axis labels, suggesting that they should be larger to improve readability. The comment provides a specific example of the confusion between Proposition (1) and Equation 1, which supports the claim. Additionally, it suggests increasing the font size of captions and legends in Figures 2 and 3, providing a clear and actionable suggestion for improvement. This level of detail and specificity makes the claim 4, as it provides a logical basis and examples for the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the readability of the paper. It identifies issues with the font size of legends and axis labels, noting that they should be larger to enhance clarity. Additionally, it points out the confusion between Proposition (1) and Equation 1, suggesting that the former should be labeled as Proposition 1. The comment also suggests increasing the font size of captions and legends in Figures 2 and 3, which is a clear and constructive suggestion for improving the presentation of the figures. Overall, the comment is 5 as it offers detailed guidance on how to improve the readability and clarity of the paper, providing the authors with specific and actionable steps to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments. It specifies that this comparison should be made at a particular step of the sampling trajectory, referring to Figure 2 in Journey TRAK. This provides a clear and concrete action for the authors to take, as they are given specific steps to follow in order to enhance their experimental analysis. The comment is 5 because it provides a direct and specific request for improvement, ensuring that the authors know exactly what needs to be done to address the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the counterfactual experiments and suggests a comparison against Journey TRAK, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, namely a comparison against Journey TRAK at a particular step of the sampling trajectory, as shown in Figure 2. This provides clear guidance on what the authors should include in their experiments to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison against Journey TRAK should be included in the counterfactual experiments. The reviewer provides a specific reference to Figure 2 in Journey TRAK, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This provides a logical basis for the claim, as it suggests that including this comparison could enhance the understanding of the results. However, the comment could be strengthened by providing more detailed reasoning or examples from Journey TRAK to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments in the paper. It suggests including a comparison against Journey TRAK, which is a relevant work in the field, at a particular step of the sampling trajectory. This feedback is valuable as it offers a clear direction for the authors to enhance their experimental analysis by incorporating a comparison that could provide insights into the effectiveness of their method. The comment is also 3 as it references Figure 2 in Journey TRAK, which could help the authors understand the context and significance of the comparison. However, the comment could be more helpful if it explained why this comparison is important or how it could contribute to the overall understanding of the results. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. While the comment implies that the authors should include such results, it does not provide explicit instructions or concrete steps on how to achieve this. The authors are left to infer that they should include these results, but the comment lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not specify which part of the theoretical discussions needs improvement or which specific results should be included. The authors can infer that it relates to the theoretical sections, but the comment lacks full grounding as it does not explicitly mention the sections or elements being addressed. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on how to implement these changes. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. The reviewer provides a specific expectation, such as \"given confidence levels, what is the sufficient amount of training data points that would not return NSF.\" This suggestion is based on a logical expectation of what should be included in the theoretical discussions, but it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could benefit from additional results related to sample complexity. The reviewer provides a specific example of what they expected, which is a discussion on the necessary amount of training data points to avoid returning NSF based on confidence levels. This feedback is clear and actionable, as it points out a gap in the theoretical discussions and offers a concrete suggestion for improvement. However, the comment could be more helpful if it provided additional guidance on how to implement these changes or examples of similar studies that have addressed this issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear direction for enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It also mentions that the literature has shown that regression methods do not significantly influence the results. The reviewer suggests that the authors clarify this issue and provides a potential solution by suggesting that direct regression to the center point is sufficient. However, the comment does not explicitly instruct the authors to clarify this issue or provide specific guidance on how to address it. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer provides a detailed explanation of the potential confusion regarding the methods and suggests that the authors clarify this issue. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer cites the literature to support their claim that regression methods do not significantly influence the results. However, the comment lacks specific references to the literature or detailed explanations of the differences between the methods. This makes it 3, as the authors would need to conduct further research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the definitions and differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It highlights a potential confusion regarding the methods and suggests that the authors clarify this issue to strengthen the motivations in their work. While the comment identifies a critical area for clarification, it could be more helpful if it provided specific examples or references to the literature that support the claim about regression methods not significantly influencing results. Overall, the comment is 3 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific in detailing what needs to be clarified, making it 5. Authors know exactly what needs to be done to improve their draft, ensuring that the action is concrete. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the Fourier modes as numbers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests clarifying whether these modes are real or complex numbers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of the clarification. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is a specific and actionable suggestion that can help improve the clarity and precision of the paper. By addressing this point, the authors can ensure that their explanation is accurate and complete, which is beneficial for both the readers and the authors themselves. However, the comment could be more helpful if it provided additional context or examples to guide the clarification process. Overall, the comment is 4 as it identifies a specific area for improvement, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to supplement the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the draft. The comment provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be supplemented, which is the result comparison. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is important or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the overall understanding of the results. Despite this, the feedback is 4 as it points out a specific area for improvement, which the authors can address to strengthen their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to correct the caption. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption for Figure 7, and provides the correct label (\"Edge Dynamics\"). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the caption for Figure 7 is incorrect and should be corrected. However, it does not provide any supporting evidence, reasoning, or references to justify why the current caption is incorrect or how it should be corrected. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the caption for Figure 7, noting that it should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This is a clear and actionable piece of feedback that the authors can easily implement to improve the accuracy and clarity of their paper. By addressing this issue, the authors can enhance the quality and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment explicitly states the need for case studies and error studies, it does not provide specific guidance on how to implement them or what aspects to focus on. The action is clear but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Elementlevel Graph Pretraining\" and the \"complex structure\" mentioned in the paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that case studies and error studies could be beneficial in demonstrating the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits. However, the comment does not provide specific examples or detailed reasoning to support why case studies and error studies are necessary or how they would enhance the paper. While it offers a logical suggestion, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of each proposed component. It highlights the importance of such studies by referencing an example from \"Graph pretraining for AMR parsing and generation,\" which illustrates the potential benefits of including these analyses. This feedback is valuable as it guides the authors on how to enhance the persuasiveness and credibility of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to design and conduct these studies. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies what needs to be clarified: the standard deviation after multiple experiments and the improvement brought by SoRA compared to the baseline. The comment provides guidance on how to address this issue by suggesting the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement brought by the SoRA method is limited due to random fluctuations, suggesting that the standard deviation after multiple experiments is not provided. The comment provides a logical reasoning by pointing out that the limited improvement could be due to random fluctuations, but it lacks specific examples or references to support this claim. The authors are left to infer the significance of the standard deviation and its impact on the results, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, noting the lack of standard deviation after multiple experiments. It also points out that the improvement brought by the SoRA method is limited, which may be due to random fluctuations. The comment provides clear and actionable feedback by suggesting that the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This guidance is valuable as it helps the authors understand the significance of their results and how to present them more effectively. However, the comment could be more helpful if it offered suggestions on how to address the issue of limited improvement or how to better present the results. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their proposed method separately from baseline detection or parsing techniques to better support their claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. The suggestion is concrete, as it specifies the need for separate evaluations and provides a rationale for why this is important. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generative shape model\" and the \"word parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that it is unclear which component contributes to the performance gain and recommends evaluating the method separately from baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain, and suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. The comment provides a logical reasoning by suggesting that the proposed approach follows a detectionparsing paradigm, which implies that evaluating separately would be beneficial. However, the comment lacks specific examples or references to support the claim, such as mentioning which baseline techniques should be used or providing data to substantiate the claim. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, noting that it is unclear which component contributes to the performance gain. It suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. This feedback is actionable as it provides a clear direction for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. By doing so, the authors can better understand the impact of their method and provide stronger evidence to support their claims. However, the comment could be more helpful if it included specific suggestions on which baseline techniques to use or how to structure the evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether they should provide additional analysis, discuss the implications, or suggest modifications to the method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Lipschitz Hessian assumption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the method\"s behavior without the Lipschitz Hessian assumption. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the method\"s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the robustness and generalizability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific aspects of the method might be affected. While it points out a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment implies that the authors should provide explanations for these choices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for these decisions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the main rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the experimental setup need clarification or explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the experimental setup, specifically regarding the rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While it identifies areas that need clarification, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these questions. The feedback is 3 as it points out potential areas for improvement, but it could be more beneficial if it offered more detailed advice or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include the results for all four datasets in Table 4, which provides a clear and direct action for the authors to take. The comment is specific in identifying the missing information and offers a concrete step to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely the results for all four datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and should include results for all four datasets. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and concrete step to improve their draft. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their results, which is valuable guidance for improving the paper. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a weakness in the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to substantiate this claim. This feedback is clear and concrete, as it specifies exactly what needs to be done to address the issue. The authors know exactly how to apply this suggestion to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the assumption that PCC is more relaxed than KL divergence due to its invariance to scale and shift. The comment provides a logical reasoning for why this assumption is not convincing and suggests a comparison between the gradients of KL and PCC to substantiate the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by comparing the gradient distribution of KL and PCC, suggesting that this comparison is necessary to substantiate the claim. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the gradient comparison themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key assumption in the paper regarding the relative relaxation of the Pearson correlation coefficient (PCC) compared to KL divergence. It challenges this assumption by pointing out that the constraint strength of a loss function is defined by its gradient distribution, and provides a logical reasoning for why this comparison is necessary. The comment suggests that the authors should provide a gradient comparison between KL and PCC to substantiate their claim. This feedback is clear and actionable, as it guides the authors on how to address a critical aspect of their argument. However, it could be more helpful if it included specific examples or references to similar comparisons in the literature. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from neighborhood agents compared to faraway nodes. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or explain their choice. The comment lacks concrete steps or detailed advice on what aspects of the explanation should be improved or expanded. As a result, the authors are left without clear direction on how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from neighborhood agents compared to faraway nodes. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the transformer\"s lack of locality bias, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from neighborhood agents compared to faraway nodes. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples or references to studies that demonstrate the impact of locality bias on transformer performance or the consequences of using a transformer without it. As a result, the claim is not 5, as it relies on a logical argument without sufficient evidence or references to support it. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from neighborhood agents compared to faraway nodes. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this concern or explain their choice. It does not offer guidance on what aspects of the explanation should be improved or expanded, leaving the authors without clear direction on how to respond to the critique. Therefore, the comment is 2, as it identifies a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper discusses ODA as a method for solving the MOIP problem but does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not provide specific guidance on how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not clearly explain how the presented method improves performance and computation speed over ODA. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not clearly explain how the presented method improves performance and computation speed over ODA, which is a subjective claim. The reviewer provides a logical reasoning by pointing out that ODA is a method for solving the MOIP problem and that the paper does not clearly suggest how the presented method enhances performance and speed. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it does not clearly explain how the presented method improves performance and computation speed over ODA, which is one of the methods for solving the MOIP problem. This feedback is valuable as it highlights a gap in the paper\"s explanation, prompting the authors to clarify their contributions. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how the authors might improve their explanation. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with some figures, particularly Figure 4, where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This feedback implies that the authors should provide additional explanations or labels to make the figure more selfexplanatory. However, the comment does not explicitly instruct the authors to add these explanations or labels, leaving the action somewhat implicit. While the authors can infer that they need to make these changes, the comment lacks concrete guidance on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, specifically the lines \"No adapt or Finetune\" being covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 where lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This claim is 3 as it provides a specific example of an issue with the figure, which could be addressed by adding labels or explanations. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with some figures, particularly Figure 4, where lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it points out a specific area where the figures could be improved by providing additional labels or explanations. By addressing this issue, the authors can enhance the clarity and selfexplanatory nature of their figures, which is crucial for effectively communicating their research findings. However, the comment could be more helpful if it offered suggestions on how to improve the figures or provided examples of how similar issues have been addressed in other works. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. The comment is clear and concrete, as it specifies exactly what needs to be added and how it should be presented. This provides the authors with a direct and specific action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of jointly discovering, hallucinating, and adapting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of discussion on the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. This feedback is clear and actionable, as it points out a critical area that needs attention and suggests a specific improvement to enhance the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects to consider. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, it does not provide specific guidance on how the authors should address this issue or what theoretical evidence should be presented. The comment implies that the authors should provide more detailed analysis or theoretical justification, but it does not offer concrete steps or examples of what this might entail. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of the correlation between dataset size and the Frobenius norm and singular values, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of theoretical evidence for the correlation and the need for more detailed analysis across different model architectures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is underwhelming and lacks theoretical evidence. It highlights the need for more detailed analysis and theoretical justification to support this correlation. While the comment points out a critical area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or what additional evidence might be needed. This limits the comment\"s helpfulness, as it offers insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the approximation error should be mathematically characterized, which provides a clear and direct action for the authors to take. This feedback is specific and concrete, as it specifies the exact improvement needed to clarify the approximation error. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the approximation error, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a mathematical characterization of the approximation error. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current definition is unclear or how a mathematical characterization would improve clarity. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approximation error definition, noting that it is ambiguous without additional context. It suggests that a mathematical characterization would be beneficial to clarify the concept. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can enhance the clarity and understanding of the paper. However, the comment could be more helpful if it included examples or additional details on how to implement the mathematical characterization. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. While the comment identifies a specific issue with the model dynamics, it does not provide explicit guidance on how to address this problem or suggest alternative approaches. The action is implicit and somewhat vague, as the authors can infer that they need to consider ways to improve the dynamics and complexity of the model. However, without concrete suggestions or examples, the comment lacks clarity and is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"evolution model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the model dynamics, noting that the model produces only one node changing cluster per time step and that the evolution model is simplistic, with no other edges changing except those associated with the 1 node changing cluster. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. The comment provides logical reasoning by explaining the consequences of the reassignment probability and the simplicity of the evolution model. However, it lacks specific examples or references to support the claim, such as data or comparisons with other models. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. This results in slow dynamics, as the model can only change one node at a time. Additionally, the comment points out that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. This feedback is 3 as it highlights a potential limitation in the model\"s dynamics and complexity, which the authors can consider when refining their approach. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of alternative models that might be more effective. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is limited, suggesting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could improve their technical contribution or what aspects of the typical model could be leveraged to enhance their work. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is limited and does not provide a specific part of the paper where this issue is addressed. It mentions the crossdomain recommendation setting, but without further context or detailed explanation, the authors may struggle to identify the exact section or aspect of the paper that needs attention. The comment lacks specificity in detailing what is considered typical or how the technical contribution could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited and does not provide a significant extension based on a typical model for the crossdomain recommendation setting. However, it lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is limited, specifically noting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific examples, detailed reasoning, or suggestions for improvement. Without actionable feedback or guidance on how to enhance the technical contribution, the authors are left without a clear path forward. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the previous work should be discussed or how the authors should incorporate this discussion into their paper. The comment lacks explicit guidance or concrete suggestions on how to address this issue, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the discussion should be included. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. The comment is specific in identifying the need for a comprehensive discussion of previous work, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which previous works are missing or how they should be discussed. Without specific references or examples, the claim lacks verifiability as it does not provide a clear basis for the critique. The authors would need to infer the specific works that should be discussed and how to integrate them into their paper, making the comment 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical observation that could significantly impact the paper\"s credibility and depth. However, the comment lacks specific guidance on which previous works should be discussed or how the authors should integrate this discussion into their paper. Without actionable suggestions or examples, the authors are left with a general direction but no clear path to follow. Therefore, the comment is 3, as it points out an important area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises questions about the OT sample selection process, specifically whether it runs once or iteratively, and suggests that more details and a flow chart would be helpful. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment implies that the authors should provide more details and a flow chart, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and a flow chart. However, the comment does provide specific questions about the process, which can guide the authors in understanding what information is missing and how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. The comment also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment identifies areas for clarification and potential improvements, it does not provide specific reasoning or evidence to support the need for these changes. The authors are left to infer the importance of these details, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the clarity of the paper regarding the OT sample selection process, specifically questioning whether it runs iteratively or only once. It suggests that more details and a flow chart would be beneficial for readers to understand the process. Additionally, it asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This feedback is clear and actionable, as it provides specific suggestions for improving the clarity and comprehensibility of the paper. By addressing these points, the authors can enhance the reader\"s understanding of the methodology and its execution. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider conducting a human evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a human evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper discusses the evaluation metrics or the caption generation process, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include human evaluation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is 3 as it identifies a potential weakness in the paper\"s evaluation methodology and suggests an alternative approach that could provide a more robust assessment. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the caption generation process should be evaluated by humans. While it points out a potential issue, it does not offer detailed instructions or examples on how to address it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It highlights that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting specific ways to motivate the problem or providing examples of streaming applications that could benefit from such algorithms. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger rationale for the problem\"s relevance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the objective of the paper, which is to design fast label aggregation algorithms for a streaming setting. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the lack of motivation for the problem and the use of static datasets in the empirical analysis. It suggests that the paper should provide a stronger rationale for the problem\"s relevance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It notes that all the datasets used in the empirical analysis are static, which undermines the paper\"s usefulness. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the lack of motivation is problematic. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It points out that all the datasets used in the empirical analysis are static, which undermines the paper\"s usefulness. This feedback is valuable as it highlights a critical area for improvement, namely the need to provide a stronger rationale for the problem\"s relevance. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as by discussing potential applications or providing examples of streaming scenarios where such algorithms could be beneficial. Overall, the comment is 3 as it directs the authors\" attention to a crucial aspect of their paper that requires further development."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether the GAT is trained with the whole model and suggests that the text needs to be reviewed by an English native speaker to improve clarity. While the comment implies that the authors should review the text for clarity, it does not provide specific guidance on how to achieve this or what aspects of the text need to be revised. The action is implicit and somewhat vague, as the authors can infer that they need to review the text but may not be entirely sure of the exact changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the training of the GAT with the whole model and suggests that the text needs to be reviewed for clarity. However, it does not specify which part of the paper this pertains to, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting that the text needs to be reviewed and rewritten for clarity, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training of the GAT with the whole model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the training of the GAT with the whole model, suggesting that it needs to be reviewed for clarity. While this point highlights an area that may need further clarification, it does not provide specific guidance or suggestions on how to improve the clarity or what aspects of the text need to be revised. The comment lacks actionable feedback, such as identifying specific sentences or sections that need clarification or offering suggestions for rephrasing. As a result, the comment is 3, as it points out a potential issue but does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to perform these analyses or discussions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should include these discussions, making it weakly grounded. The suggestion to analyze the domain gap and discuss the gap between datasets is specific, as it provides clear guidance on what aspects to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a logical basis for the suggestion, it lacks specific examples or references to support the claim about the domain gap or the value of finetuning on synthetic data. This makes the claim 3, as it requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to analyze the domain gap and discuss the gap between datasets. It also highlights the potential value of the approach if it can finetune a pretrained model on synthetic data. This feedback is specific and offers a direction for the authors to enhance their draft by addressing the domain gap and its implications. By providing a concrete suggestion for improvement, the comment is 4 in guiding the authors toward a more comprehensive and valuable analysis of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the scalability of the model, specifically noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment implies that the authors should consider this issue, it does not provide explicit instructions or concrete steps on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider scalability and performance tradeoffs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and the issue of scalability, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the performance degradation as the maximum number of identities grows, and suggests that the capacity should be set to a small number, like 10. This provides clear guidance on what needs to be addressed regarding scalability and performance. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of the model degrades as the maximum number of identities grows, suggesting that the capacity should be set to a small number, like 10. The reviewer provides a specific example from Table 3 (a) to support this claim. However, the comment lacks detailed reasoning or references to explain why this specific capacity threshold is necessary or how it affects performance in realworld scenarios. While the claim is based on a specific observation, it could be strengthened with additional context or examples to fully substantiate the argument. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the model, noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, to address this issue. The comment also raises a valid concern about scalability in realworld scenarios, where the number of objects to handle can be unpredictable. However, the comment could be more helpful by providing suggestions on how the authors might address this scalability issue or by offering examples of how similar models have been scaled effectively. While it highlights an important area for improvement, the feedback lacks detailed guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. It explicitly asks if it is possible to conduct such a comparison. The comment provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. This guidance is explicit and concrete, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and suggesting a comparison with final outputs. The comment further questions whether a quantitative comparison on the final outputs is possible, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. The comment provides a logical reasoning by pointing out that the current evaluation does not fully demonstrate ModelAngelo\"s superiority to competitors. However, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing in demonstrating ModelAngelo\"s superiority to competitors. This feedback is clear and actionable, as it provides a direct suggestion for improvement. By addressing this issue, the authors can enhance the credibility and persuasiveness of their evaluation. However, the comment could be more helpful if it offered additional guidance on how to conduct such a comparison or provided examples of how it might be done. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance. While the comment provides a clear list of specific questions that need to be addressed, it does not offer explicit guidance on how to implement these improvements. The authors are left with a clear understanding of what needs to be added but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the techniques and the reproducibility of the results. It provides detailed questions about the sparsification process, landmark generation, and number of landmarks used, as well as how to achieve shape invariance. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be clarified or improved in each area. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of detail in the paper regarding techniques and the reproducibility of results. It highlights specific areas that are unclear, such as the sparsification process, landmark generation, and number of landmarks used. The reviewer also questions how to achieve shape invariance. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support the claims. This makes the comment 3, as it points out areas that need clarification but lacks the depth and evidence needed for full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks detail and clarity, particularly regarding the techniques used and the reproducibility of the results. It highlights specific questions that need to be addressed, such as the sparsification process, landmark generation, and number of landmarks used. The comment also questions how to achieve shape invariance and provides a clear list of issues that need clarification. This feedback is actionable and offers a detailed roadmap for the authors to improve the clarity and comprehensiveness of their paper. However, it could be more helpful if it provided suggestions on how to address these issues or examples of how similar techniques have been implemented in other works. Overall, the comment is 4 as it guides the authors toward improving the clarity and reproducibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars or more random trials to potentially reduce random fluctuations in the results. While the comment implies that the authors should consider adding these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars or more trials to improve the figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger with the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why error bars or more trials would be beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in Figure 1, suggesting that the inclusion of error bars or more random trials could strengthen the figure by potentially reducing random fluctuations in the results. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the figure\"s robustness and clarity. However, the comment could be more helpful if it explained why error bars or additional trials are beneficial or how they might impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. It also references external works that discuss contextaware robust finetuning, finetuning impact on foundation models, and robust finetuning of zeroshot models. While the comment provides explicit actions, it does not specify how to implement these suggestions or what specific details should be included in the introduction or Figure 1. The authors are given clear guidance on what to add but lack detailed instructions on how to execute these actions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a brief introduction to energy models in the related work section and the lack of clarity regarding the correspondence between different learning rates and steps in Figure 1. The comment also provides references to external works that could be relevant to the contextaware robust finetuning, finetuning impact on foundation models, and robust finetuning of zeroshot models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. The reviewer references external works to support their claim, such as \"Contextaware robust finetuning,\" \"Finetuning can cripple your foundation model; preserving features may be the solution,\" and \"Robust finetuning of zeroshot models.\" These references provide a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how these references relate to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section. It also points out a lack of clarity in Figure 1, specifically regarding the correspondence between different learning rates and steps. The reviewer references external works that could be relevant to the contextaware robust finetuning, finetuning impact on foundation models, and robust finetuning of zeroshot models. This feedback is valuable as it guides the authors to enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided specific suggestions on how to integrate these external references or what aspects of the energy models should be covered in the introduction. Overall, the comment is 4 as it directs the authors to improve their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of biases. The comment implies that the authors should consider the potential for biases and the impact of temporary high utility scores, but it lacks concrete steps or suggestions for improvement. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the heart of FIITED,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential bias introduced by basing eviction decisions purely on utility scores, particularly the risk of premature evictions due to temporary high utility for recent chunks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically the risk of premature evictions due to temporary high utility for recent chunks. The comment provides a logical reasoning by pointing out the potential for biases in the utilitybased approach. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. This is a valuable observation that could lead to premature evictions of other valuable chunks. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of biases. While it points out a critical area for consideration, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the paper lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include quantitative experiments and comparisons, as well as detailed explanations of the algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not offer specific steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the methodology and the experimental section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of quantitative experiments and comparisons with other algorithms, as well as the need for more detailed explanations of the presented ones. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the lack of quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones, makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. The comment provides a logical reasoning for the need for more detailed information, but it does not include specific examples or references to support the claim. This makes the claim 3, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. This feedback is valuable as it highlights a critical area for improvement in the paper, namely the need for more comprehensive and detailed experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps, such as which experiments to conduct or how to present the results more effectively. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use styles or add color to make it easier to distinguish between the different curves in Figure 2. While the suggestion is clear and provides a specific action to take, it does not offer detailed guidance on how to implement these changes or which styles or colors to use. The authors are left with a general idea of what needs to be done but without concrete steps or examples. Therefore, the comment is 3, as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the difficulty in distinguishing between the different curves. The comment provides a clear suggestion to use styles or add color to improve the figure, offering a concrete action for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the curves in Figure 2 are difficult to distinguish, and it provides a specific suggestion to use styles or add color to improve the figure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current figure is difficult to distinguish or how the suggested changes would improve it. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand and implement the suggested changes without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that the different curves are difficult to distinguish. It provides a clear and actionable suggestion to improve the figure by using styles or adding color. This feedback is valuable as it directly addresses a visual aspect of the paper that could impact the reader\"s understanding and interpretation of the data. However, the comment could be more helpful if it included examples of styles or colors that might be effective. Overall, the comment is 4 as it guides the authors toward a specific improvement that could enhance the clarity and usability of their figure."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors tone down the introduction and not refer to the task as \"language learning.\" It suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is 5 as it gives a direct and specific direction for improvement, ensuring that the authors know exactly how to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"claims made in the introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the overstatement of the task as \"language learning\" and the suggestion to tone down the introduction. The comment provides a clear and detailed critique of the introduction, which is helpful for the authors to understand and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are far from what has been achieved by the tasks and models, and suggests that the authors should tone down the introduction. The reviewer provides a logical reasoning by pointing out that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment lacks specific examples or references to support the claim that the task is significantly different from language learning. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are far from what has been achieved by the tasks and models. It suggests that the authors should tone down the introduction and not refer to the task as \"language learning,\" as it is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the introduction. By addressing this issue, the authors can enhance the clarity and accuracy of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the kernels are implemented with OpenAI\"s Triton, not CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. This provides clear and direct guidance on what the authors should change in their draft. The comment is specific about the issue and suggests a clear action to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OpenAI\"s Triton\" and \"CUDA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the implementation of kernels with OpenAI\"s Triton instead of CUDA. This provides clear guidance on what the authors need to correct or clarify in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the kernels are implemented with OpenAI\"s Triton, not CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this is the case. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific observation about the implementation of kernels with OpenAI\"s Triton, rather than CUDA, which is a wellknown engineering improvement. It suggests that a fullpage explanation is unnecessary due to this fact. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it does not provide actionable feedback or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability. The reviewer also points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the transferability and complexity of the tasks but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the zeroshot nature of the work and the transferability of the policy, suggesting that the difficulty of the source and target tasks might limit the transferability. It also provides specific examples of the manipulation scenario, such as the 3prong task with clockwise and counterclockwise rotations, and the 4prong task, which could be used to clarify the target task. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the transferability and the complexity of the tasks, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims. While it provides some evidence and examples, it could be strengthened by including more detailed explanations or references to support the argument. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to illustrate this point. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or clarify the transferability in the paper. While it identifies potential weaknesses and areas for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights important areas for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the current experimental comparison only compares ELF (the author\"s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. This feedback provides a clear and concrete action for the authors to take, which is to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. The comment is 5 as it directly instructs the authors on how to enhance their experimental setup to address the critique.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental demonstration of the contribution points\" and the \"experimental comparison between ELF (the author\"s method) and the baseline without Mid Vision Feedback (MVF),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the lack of a comparison with the image classification result of Mid Vision Feedback (MVF)\u2014and why this is important for proving the superiority of the schema searched by ELF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment provides a logical reasoning by pointing out that the current experimental comparison only compares ELF (the author\"s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. However, the comment does not provide specific examples or references to support the claim that a comparison with the image classification result of MVF is necessary. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It points out that the current experimental comparison only compares ELF (the author\"s method) with the baseline without Mid Vision Feedback (MVF), but not with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it directs the authors to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. By addressing this critique, the authors can significantly enhance the experimental section of their paper, providing stronger evidence for their claims. Therefore, the comment is 5, as it offers a concrete and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should add more content on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors can infer that it relates to the dataset analysis or discussion, but the comment lacks full grounding. It is specific in suggesting what needs to be addressed, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they could be addressed. Without specific examples or detailed explanations, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it points out a gap in the paper that could enhance its depth and relevance. However, the comment could be more helpful if it provided examples of specific activities or detailed suggestions on how to address this issue. Overall, the comment is 4 as it directs the authors to a meaningful area for expansion and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should use different notation to avoid confusion between the dimensionality of points and the dilation factor. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the clarity of their paper. The comment is concrete, as it specifies the need for different notation, and it is also somewhat vague as it does not provide detailed guidance on what specific notation should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"D\" to represent both dimensionality and dilation factor, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of different notation to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using \"D\" to represent both dimensionality and dilation factor can cause confusion. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the suggestion or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, suggesting that using \"D\" to represent both dimensionality and dilation factor can cause confusion. This is a clear and actionable suggestion that can help improve the clarity and readability of the paper. However, the comment could be more helpful if it provided examples of alternative notations or explained why the current notation is problematic. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can enhance the overall quality of the paper. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer concrete steps or examples of what these details should include. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not specify which part of the paper discusses the FRM, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for more details on the innovative aspects of the FRM, but it is 1 as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation. It suggests that the innovative aspects should be detailed, but it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. While the comment highlights a potential weakness, it lacks actionable advice or examples that would help the authors improve their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider the potential social impacts of their work, such as increased automation and the risks from dual use. While the comment does not explicitly instruct the authors to include these aspects in their paper, it provides a clear direction for improvement by highlighting areas that could be explored. The action is implicit but concrete, as it specifies the potential social impacts that should be addressed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential social impacts of the work, such as increased automation and dual use risks. This provides clear guidance on what the authors should consider in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not consider the potential negative social impacts of their work, specifically mentioning increased automation and dual use risks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the social impact of the work, specifically the risks associated with increased automation and dual use. While the reviewer acknowledges that they are not sure how to review this aspect, they provide a clear direction for improvement by suggesting that the authors should consider these potential impacts. This feedback is actionable and constructive, as it prompts the authors to address a critical aspect of their work that could enhance its societal relevance. However, the comment could be more helpful if it offered specific examples or guidance on how to integrate these considerations into the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the applicability or what specific steps to take to mitigate the assumptions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the assumptions made and their impact on applicability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods, specifically noting that strong assumptions are made about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. This feedback highlights a potential weakness in the paper that could impact its relevance and practicality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. While it points out a relevant concern, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the effect of rounding core tensors on the full tensor error and seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should provide more information on the theoretical aspects of the approximation error, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the rounding of core tensors to smaller ranks with a given accuracy by clustering values or imposing some error decision epsilon. This allows the authors to accurately identify the relevant section. The comment is also specific because it asks for clarification on the effect of rounding on the full tensor error and seeks information on any error bound in terms of epsilon. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical aspects of rounding core tensors and the effect on the full tensor error. It seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors need to provide more information or clarification. It points out that the paper mentions the rounding of core tensors to smaller ranks with a given accuracy, but it is unclear what the effect on the full tensor error is and whether there is an error bound in terms of epsilon. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could impact its theoretical foundation. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it guides the authors toward improving the clarity and completeness of their theoretical analysis."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what kind of evidence or examples would be sufficient or how they should be presented. The comment lacks explicit guidance on how to implement this suggestion, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and lacks concrete details, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or example that needs improvement. The comment is 1, as it does not specify where in the paper this issue is addressed. Additionally, it lacks specificity as it does not provide details on what kind of evidence or examples would be sufficient to convince the reader. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without concrete evidence or reasoning, the claim is not verifiable, as it does not provide a clear path for improvement. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. While it identifies a potential weakness in the paper, it lacks specificity and does not provide guidance on what kind of evidence or examples would be sufficient to address this concern. The comment is 3 as it points out an area for improvement, but it does not offer actionable steps or detailed suggestions for the authors to enhance their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that it would be helpful to describe the form of p, which is assumed to be a Gaussian distribution, near line 135. It also references the reviewer\"s previous comment, providing a clear expectation for the authors to include this information. The action is concrete, as it specifies the exact location in the paper where the information should be added, and it is also explicit, as it directly instructs the authors to include the description. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the form of p, which is assumed to be a Gaussian distribution. The comment provides a clear direction for the authors to improve the clarity of their paper by including this information. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the form of p, which is assumed to be a Gaussian distribution, should be explicitly stated in the paper. The reviewer references their previous comment, which implies that this information is already known or assumed. However, the comment does not provide specific reasoning or evidence to support why this information is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 3, as it lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper, noting that the form of p, which is assumed to be a Gaussian distribution, is not explicitly stated. It references the reviewer\"s previous comment, providing context and expectation for the authors. This feedback is clear and actionable, as it directs the authors to include a description of the form of p near line 135. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how it could be integrated into the paper. Overall, the comment is 4 as it effectively points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It also proposes a minor point about optimizing the inference part of the model by keeping the generative model fixed and parameterizing it as either SIGVAE or VGAE to compare representations. While the comment provides a clear action to take regarding the VGAE implementation, it lacks specific guidance on how to implement the suggested comparison with SIGVAE or VGAE. The minor point about optimizing the inference part is also mentioned but not further elaborated on. Therefore, the comment is 3, as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VGAE with a vamp prior\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential benefits of the generative model and the inference part of the model. The comment provides a clear suggestion to run VGAE with a vamp prior to better match the doubly stochastic construction and offers a minor point about optimizing the inference part of the model. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This claim is 3 as it provides a logical reasoning for the potential benefits of the generative model and inference part of the model. However, the comment lacks specific examples or references to support the claim, such as explaining how the vamp prior would improve the model or providing data or studies that demonstrate its effectiveness. This makes the claim 3, as it requires further elaboration to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help inform whether the benefits are coming from a better generative model or better inference due to doublysemi implicit variational inference. This is a clear and actionable suggestion that could significantly impact the authors\" understanding and interpretation of their results. Second, it proposes a minor point about optimizing the inference part of the model by keeping the generative model fixed and parameterizing it as either SIGVAE or VGAE to compare the representations. This suggestion is also actionable but lacks depth, as it does not provide detailed guidance on how to implement this comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers valuable insights and suggestions for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors can infer that they need to include a discussion on the importance of longrange dependencies but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"visualisations in table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the requirement of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that the truth lies somewhere in between and points out the need for a discussion on this topic. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The comment suggests that the truth lies somewhere in between and points out the need for a discussion on this topic. However, the comment lacks specific examples or references to support the claim that learning longrange dependencies is not always necessary. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The comment suggests that the truth lies somewhere in between and points out the need for a discussion on this topic. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the discussion should be included. This limits the comment\"s usefulness, as it provides some insight but does not offer actionable advice. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer suggests that this may indicate a weakness in the proposed approaches or at least the theoretical results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The feedback is 3 as it highlights a potential problem but lacks concrete instructions on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3 and Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the exponential dependence on the diameter $M$ of the domain of data and how this affects the constant factor of the required feature size. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It suggests that this dependence affects the constant factor of the required feature size, which may indicate a weakness in the proposed approaches or theoretical results. The comment provides logical reasoning by explaining the implications of the exponential dependence on $M$ and how it affects the constant factor. However, it lacks specific examples or references to support the claim that this dependence indicates a weakness. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of definition for $e_l$ in Equation (3) and the exponential dependence of the results on the diameter $M$ of the domain of data. It points out that this dependence affects the constant factor of the required feature size, which could indicate a weakness in the proposed approaches or theoretical results. The comment provides a logical explanation of the implications of this dependence and suggests that it may be a critical issue for the authors to address. However, it lacks specific suggestions or guidance on how the authors might address this issue or what specific changes could be made to improve the paper. While it highlights an important area for improvement, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, another phenomenon observed in the context of very deep graph networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to improve the modeling ability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs and suggests that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. However, it does not specify which part of the paper discusses the longrange modeling ability or where the issue of oversmoothing might be discussed. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in detailing the potential issue of oversmoothing, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modeling ability of DGNs is due to oversmoothing, a phenomenon observed in the context of very deep graph networks. The reviewer supports this claim by referencing a specific work, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI'18,\" which discusses oversmoothing. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how oversmoothing affects the modeling ability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. While the comment provides a reference to a specific work that discusses oversmoothing, it does not offer detailed guidance or suggestions on how the authors might address this issue or improve their modeling ability. The feedback is 3 as it points out a potential problem but lacks actionable advice or detailed analysis, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use generalized Voronoi graphs, semantic maps, or pose graphs for exploration. While the comment implies that the authors should provide a comparison or discussion of their method with these existing methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of their method in relation to these existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"generalized Voronoi graph or semantic maps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the proposed method in relation to existing methods that use similar concepts for exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer supports this claim by referencing existing methods, such as graphbased SLAM, where loop closure is applied. This provides a clear and specific rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to these existing methods, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas presented are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer suggests that the paper should discuss the proposed method in relation to these existing methods, which could provide a more comprehensive understanding of its novelty and contributions. While the comment highlights an important area for improvement, it does not offer specific guidance on how to address this issue or what aspects of the existing methods should be compared. This limits the comment\"s helpfulness, as it provides insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide explicit guidance on what specific part of the framework is vital or how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the importance of the framework in the context of weakly supervised learning. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of the framework are vital or how the discussion could be improved. Without clear guidance, the authors may struggle to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not provide any supporting evidence, reasoning, or references to justify why this part is crucial or how it distinguishes the paper from other related work. Without such information, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the discussion. While it identifies a potential area for improvement, the lack of actionable feedback limits its usefulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a clear direction for the authors to consider broadening their definition of content and style, it does not offer specific guidance on how to implement this suggestion. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" neural application and provides a specific example from Gabbay & Hosehn (2018) to illustrate the broader definition of content and style. It also raises a question about the authors\" understanding of the term \"style\" in their model, which adds specificity to the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, providing an example from Gabbay & Hosehn (2018) where style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a logical reasoning for broadening the definition of content and style, it lacks specific examples or references to support the claim that the authors\" understanding is incorrect. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider broadening their definition of content and style, particularly in the context of their neural application. It offers an example from Gabbay & Hosehn (2018) to illustrate how style can be defined more broadly and how content can be understood as information that can be transferred among groups. Additionally, the comment raises a specific question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. This feedback is valuable as it prompts the authors to reconsider their terminology and potentially improve the clarity of their work. However, the comment could be more helpful if it provided additional guidance on how to address the question or suggested specific ways to broaden the definition. Overall, the comment is 4 as it offers clear and actionable feedback, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. It provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. While the comment identifies areas that need further explanation, it does not explicitly instruct the authors on how to improve the analysis or provide specific guidance on how to address the issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 45\" and \"Fig1(b) v.s. Fig5(b) for Block.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the analysis of vit quantification, particularly the information distortion and the quantization of MHSA, which introduces a large loss of precision. The comment provides specific examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. The reviewer provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This provides a logical and detailed explanation of the issue, making the claim 4. However, the comment could be strengthened by referencing specific studies or literature that support the claims about information distortion and quantization. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the information distortion and the quantization of MHSA. It highlights the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This feedback is 5 as it identifies specific areas where the authors need to provide more depth and clarity in their analysis. By pointing out the limitations of the proposed approach and referencing existing works, the comment offers actionable guidance for the authors to improve their draft. However, it could be further enhanced by suggesting specific ways to address the issues or providing additional references to support the claims. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a confusion regarding the reward in Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. It provides references to external works that may help clarify the issue, such as 1 and 2, which are articles on the topic of reinforcement learning. However, the comment does not explicitly instruct the authors to include these references or provide specific guidance on how to clarify the reward or network model. While the action is implied, it is not as direct as it could be, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of confusion regarding the reward and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. The references provided, such as 1 and 2, could be helpful in clarifying the issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Eq. 12, specifically questioning where the reward comes from and whether one of the r_i is taken from Eq. 11. The reviewer suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment identifies a potential issue with the clarity of the equations, it lacks specific examples or detailed reasoning to fully substantiate the claim. The references provided could be helpful in understanding the context, but the comment itself does not provide enough evidence or detailed reasoning to fully verify the claim. Therefore, the comment is 3, as it highlights an area for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Eq. 12, noting that the reward source is not clearly explained and questioning whether one of the r_i is taken from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to address the issue or suggest specific ways to clarify the equations. The references provided could be helpful, but the comment itself lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a single spelling mistake, \"Empiically\" on line 32 of page 1, and suggests it should be corrected to \"Empirically.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies the exact spelling correction needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the spelling, suggesting that \"Empiically\" should be corrected to \"Empirically.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about a spelling mistake in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor but specific issue with the spelling in the paper, noting that \"Empiically\" should be corrected to \"Empirically.\" This is a clear and actionable suggestion that can help improve the accuracy and professionalism of the paper. However, while it is helpful in pointing out a specific error, it does not provide any context or explanation about the impact of this spelling mistake or how it might affect the overall quality of the paper. Therefore, the comment is 3, as it provides a clear and actionable suggestion but lacks depth and context."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or complexity of the idea, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the novelty or straightforwardness are problematic, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions for how the authors might enhance the novelty or complexity of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of what improvements could be made to address the critique. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggests that another color or a larger font might help in highlighting the humanidentified rationales better. While the comment provides a clear and concrete suggestion for improvement, it does not explicitly instruct the authors on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider changing the font or color of the text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that identifying rationales for more complicated NLP tasks like machine translation is not a simple problem, and that the paper is wellorganized and easy to follow. The comment suggests that Figure 2 is cluttered and that the \"bold\" text is hard to see, proposing a solution of using another color or a larger font to improve clarity. While the comment provides a logical reasoning for the issue with Figure 2, it lacks specific examples or references to support the claim about the difficulty of identifying rationales for more complex NLP tasks. The suggestion to improve the figure is 3, as it provides a clear direction for improvement but could benefit from more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This feedback is actionable and provides a clear direction for improvement, which can help the authors enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it offered additional suggestions or examples of alternative colors or font sizes that might work better. Overall, the comment is 4 as it provides a clear and actionable suggestion for improving the figure, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance. It also points out that Table 5 shows a tradeoff between head and tail categories but notes that similar tradeoffs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. Additionally, the reviewer encourages the authors to continue this line of work for future submissions. While the comment provides explicit actions to take, such as investigating the tradeoffs and improving the baselines, it lacks specific guidance on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple Kang et al.,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple Kang et al. and suggests exploring the tradeoff between head and tail categories for the baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance, and it provides a specific example of this by referencing Table 5. Additionally, it suggests that similar tradeoffs have not been fully investigated for the baselines, specifically by changing hyperparameters in Decouple Kang et al.. This claim is 3 as it provides a specific example of the tradeoff between head and tail categories and suggests that further investigation is needed. However, the comment lacks detailed evidence or references to support the claim that the proposed approach is worse than Decouple Kang et al. or that similar tradeoffs have not been fully explored. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several pieces of constructive feedback that can help the authors improve their draft. First, it points out that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance, which is a significant concern. It also highlights the tradeoff between head and tail categories shown in Table 5 and suggests that similar tradeoffs have not been fully explored for the baselines. The reviewer encourages the authors to continue this line of work for future submissions, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to investigate these tradeoffs or improve the baselines. Overall, the comment is 4 as it identifies areas for improvement and offers a clear direction for the authors to take."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. However, it does not provide any guidance on how the authors should address this issue or what specific changes need to be made to ensure compliance with the stated condition. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Definition 1\" and \"expected counterfactual,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This is a clear and actionable point that the authors can address to improve the accuracy and validity of their work. However, the comment lacks depth and does not provide suggestions on how to resolve the issue or what specific changes need to be made. While it highlights a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This explicit action provides a clear direction for the authors to take, as it specifies a specific comparison to be made. The comment is concrete, as it directly instructs the authors on what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with existing models, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific comparison that could enhance the paper by comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is actionable and provides a clear direction for the authors to improve their draft by including a comparison that could strengthen the paper\"s contribution. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance (perf) to explore the impact of layer count on NER tasks. While the suggestion is explicit, it lacks concrete guidance on how to implement this study or what specific aspects to focus on. The authors are given a clear direction but are left to determine the details of execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study of the number of layers versus performance (perf) to explore the impact of layer count on NER tasks. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting a potential area for exploration, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study of the number of layers versus performance (perf) to explore the impact of layer count on NER tasks. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this study would be beneficial or how it would contribute to the understanding of NER tasks. Without such justification, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance (perf) to explore the impact of layer count on NER tasks. This is a clear and actionable suggestion that could provide valuable insights into the effectiveness of different layer configurations in NER tasks. However, the comment could be more helpful if it offered specific guidance on which aspects of the performance to focus on or how to design the ablation study. Despite this, the feedback is 4 as it directs the authors to a meaningful area for exploration and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed discussion on computational aspects and address the practical limitations of their methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It specifically mentions the appendix and the algorithm\"s requirement to solve several LPs in high dimensions, which is not easily calculable. The comment also points out that the experiments are performed on small datasets. However, it does not explicitly mention which part of the paper discusses computational aspects or where the appendix is located, making it weakly grounded. The comment is specific in detailing the issues with the computational aspects and the experiments, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods for high dimensions. The reviewer supports this claim by pointing out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific calculations or examples to illustrate the practical limitations. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects and the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This feedback is valuable as it highlights a critical area for improvement in the paper, particularly regarding the scalability and practicality of the proposed methods. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues or improve the discussion of computational aspects. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their design choice. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to justify the decision. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or how it might impact the paper\"s results or analysis. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. This feedback highlights a potential issue with the methodology, prompting the authors to reconsider their approach. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the design choice. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies specific lines in the SuppMat that should be moved from red to green. This provides clear and direct instructions for the authors to follow, ensuring they know exactly what changes to make. The action is concrete, as it specifies the exact lines and their corresponding SuppMat sections, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the exact lines that need to be moved from red to green, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the SuppMat, specifically mentioning lines that should be moved from red to green. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific lines in the SuppMat that should be moved from red to green, providing clear and actionable feedback. This guidance is valuable as it helps the authors ensure that their SuppMat is accurate and uptodate. However, the comment could be more helpful if it explained why these lines are important or how they contribute to the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to make a specific correction that can improve the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of a proper comparison against online learning approaches and reinforcement learning (RL). It suggests that the authors should clarify why online learning cannot be used, particularly in relation to retraining cost. The reviewer also questions how to compare retraining cost with incremental updates in online learning and why it is discarded. While the comment provides a clear direction for the authors to address these issues, it does not offer specific guidance on how to conduct the comparison or what aspects to focus on. The action is explicit but somewhat vague in terms of execution, as the authors need to determine the exact methodology for comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors mention that online learning formulation overlooks key practical considerations. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of a proper comparison against online learning approaches and reinforcement learning, and questions about the retraining cost and its impact on the evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of a proper comparison against online learning approaches and reinforcement learning, suggesting that the abstract and other parts of the paper overlook key practical considerations. The reviewer questions why online learning cannot be used and how to compare retraining cost with incremental updates in online learning. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that online learning formulations overlook key practical considerations. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a proper comparison against online learning approaches and reinforcement learning. It questions why online learning cannot be used and highlights the importance of considering retraining cost in evaluations. The comment provides a clear direction for the authors to address this issue by suggesting that they clarify why online learning cannot be used and how to compare retraining cost with incremental updates in online learning. This feedback is actionable and offers a specific area for improvement, making it 4. However, it could be more comprehensive by providing examples or references to support the claim about the practical considerations of online learning. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. While the comment implies that the authors should include a summary of the supplementary experiments, it does not provide explicit instructions on how to do so or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the main text should be revised or where the summary should be placed. The authors can infer that it relates to the sections discussing the experiments or results, but this inference is not direct. The comment is specific in suggesting the need for a summary of supplementary experiments, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. This feedback is 3 as it identifies a potential area for improvement in the clarity and organization of the paper. However, the comment lacks specific guidance on how to achieve this clarity or what aspects of the supplementary experiments should be highlighted. While it points out a potential issue, it does not provide detailed suggestions or examples on how to address it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a comprehensive comparison with the works mentioned, GFF1 and EfficientFCN2, which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer provides specific references to these works, making it clear what needs to be done. Additionally, the comment mentions that the societal impact is shown on the last page of the manuscript, which is not relevant to the action being requested. Therefore, the action is explicit and concrete, as the authors know exactly what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, \"GFF1\" and \"EfficientFCN2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF1 and EfficientFCN2, which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer suggests a comprehensive comparison with these works. However, the comment does not provide specific examples or detailed reasoning to support why these references are important or how they could enhance the paper. While it identifies a potential gap, the lack of detailed justification makes the claim 3, as the authors would need to infer the significance of these references themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning GFF1 and EfficientFCN2, which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, which could significantly enhance the paper\"s contribution and relevance. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript. While the comment highlights a critical area for improvement, it could be more helpful if it provided specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a significant area for enhancement, but it could be more actionable with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input, and questions whether there is a solution to address this issue. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue or improve the practical contribution of their paper. The authors are left to infer that they need to consider scalability, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed NC measure, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the method when applied to large datasets like ImageNet, and suggests that the practical contribution of the paper could be significantly reduced if a solution is not found. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. The reviewer questions whether there is a solution to address this issue, suggesting that the practical contribution of the paper could be significantly reduced if not. However, the comment lacks specific examples or references to support the claim that the method cannot be applied to large datasets like ImageNet. Without such evidence or detailed reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It raises a valid concern about the practicality of applying this method to large datasets like ImageNet. The comment suggests that if no solution is found to address the scalability issue, the paper\"s practical contribution could be significantly reduced. This feedback is 3 as it highlights an important area for improvement, but it lacks specific suggestions or guidance on how to address the scalability issue. The authors are left with a clear direction but without detailed steps on how to implement the suggested solution. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the \"filter manifold network\" (FMN) and its scalability with the number of filter parameters. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these questions, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it implies actions but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the scalability of the FMN with larger input and output channels, and it suggests experimenting with other architectures. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. The reviewer also questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it lacks specific examples or references to support the claims about scalability or the need for further analysis. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It raises important questions about the scalability of the FMN with larger input and output channels, suggesting that the authors should experiment with other architectures and explore the impact of adaptive convolutions on the number of filter parameters. The comment also questions whether the FMN can scale well in practice, which is a crucial consideration for the applicability of the technique. While the comment provides valuable insights and prompts the authors to consider these aspects, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It also suggests that a comparison of computation complexity should be included in the experiment part. While the comment identifies a specific issue with the computational complexity, it does not provide explicit guidance on how to address it or suggest ways to reduce the computational burden. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison of computation complexity in the experiment part. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"the calculation of all the flipped previous layer output into the current layer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison of computation complexity in the experiment part. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. The comment suggests that a comparison of computation complexity should be included in the experiment part. While the claim is based on logical reasoning and specific observations about the algorithm, it lacks detailed evidence or references to support the assertion that the PSA method requires more computation. This makes the claim 3, as the authors would need to further investigate and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the computational complexity of the proposed PSA method compared to baselines, noting that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to include a specific analysis of computational complexity to address the concern. However, the comment could be more helpful if it provided suggestions on how to optimize the computational complexity or offered examples of similar comparisons in related work. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger, increasing the size of V_mem, Th_i, and U_i^t, and using a larger font for the \"CTRL\" long form explanation. Additionally, it points out the lack of details comparison with other stateoftheart Transformer designs, suggesting a \"table\" manner to emphasize the data for readers. While the comment provides explicit actions and concrete details on how to implement these improvements, it could be more helpful if it offered suggestions on how to present the data comparison in a \"table\" format. Overall, the comment is 4 as it provides clear guidance on what needs to be addressed, but it could be more detailed in its suggestions for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures, such as \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other stateoftheart Transformer designs. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes several claims about the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other stateoftheart Transformer designs. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claims are 1, as they lack the necessary support to be convincing or actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the figures, suggesting that the fonts could be larger, particularly for the words in the grey box, and that the size of V_mem, Th_i, and U_i^t should be increased. It also points out the need for a more detailed comparison with other stateoftheart Transformer designs, suggesting a \"table\" manner to emphasize the data for readers. While the comment identifies specific areas for improvement, it could be more helpful if it provided examples of how to present the data comparison in a \"table\" format or offered suggestions on how to effectively use this format. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests that the authors rewrite the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This is a clear and direct action for the authors to take, as it provides a specific line and page number for them to address. The comment also indicates that the current sentence is unclear, which further guides the authors on what changes are needed to improve the clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and pages (\"P. 5, p. 3, l.\") where the issue is located, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarity of the sentence regarding the use of \"j\" to simulate errors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and a specific suggestion to rewrite a sentence. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a sentence, requesting that the authors rewrite it to improve understanding. This is a clear and actionable piece of feedback that can help the authors enhance the readability and comprehensibility of their draft. By addressing this issue, the authors can improve the overall quality of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to rewrite the sentence to improve clarity. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and application, specifically questioning the need for domain adaptation and the usefulness of the proposed method. It suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. While the comment implies that the authors should provide examples of how the method could be applied in practice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of domain adaptation tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results of mapping one RGB image to another RGB image with a different style, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the motivation and usefulness of the paper, suggesting that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the motivation and usefulness of the paper, suggesting that the proposed method does not have a clear application or demonstrate its value in domain adaptation tasks. The reviewer provides a logical reasoning by pointing out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily require domain adaptation. The comment suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. However, the comment lacks specific examples or references to support the claim that domain adaptation is necessary or beneficial. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the motivation and usefulness of the proposed method. It points out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily require domain adaptation. The reviewer suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by addressing the need for domain adaptation and its potential applications. However, the comment could be more helpful if it offered examples of such tasks or provided guidance on how to integrate domain adaptation into the paper. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include ATA in the comparison under the leave one out setting in Table 2. This is a clear and direct action for the authors to take, as it provides a specific recommendation to enhance the comparison by including ATA. The comment also references the results in Table 1, which further guides the authors on where to make the change. The action is concrete and specific, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of ATA in the comparison under the leave one out setting. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to ATA in addition to \"+LFP\" under the leave one out setting in Table 2. The claim is based on the assumption that ATA is better than FP according to the results in Table 1. However, the comment does not provide specific evidence or references to support this claim, such as detailed comparisons or specific results from Table 1. This lack of detailed justification makes the claim 3, as the authors would need to make a significant effort to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+\"LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, as ATA is reportedly better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the comparison and improve the clarity of their results. However, the comment could be more helpful if it explained why ATA is considered better or how it should be compared to the other methods. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. It suggests that a better comparison should be considered. While the comment implies that the authors should reconsider their comparison, it does not provide specific guidance on how to conduct a fairer comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with baselines, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison is unfair due to the lack of prior knowledge of users or language embedding computation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of baselines, noting that the lack of prior knowledge of users or language embedding computation may unfairly skew the results. This is a valuable observation that could lead to a more robust and fair evaluation of the baselines. However, the comment does not provide specific suggestions on how to address this issue or what alternative comparisons could be considered. While it highlights an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. While the comment identifies areas that need clarification or expansion, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they need to address these issues, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses several issues, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and the absence of limitations and potential negative societal impact discussions. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of Figure 4 and the presentation of Pixelshuffle details. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and observations, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and the absence of limitations and potential negative societal impact discussions. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to address these points effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and the absence of limitations and potential negative societal impact discussions. While the comment highlights important areas for clarification and expansion, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how the authors could improve the presentation to make it more understandable. There is no explicit or implicit action for the authors to take, such as recommending changes to the structure, organization, or content of the paper. Without actionable advice, the authors are left without a clear path to follow to enhance the clarity of their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is hard to follow, but it does not specify which part of the paper is particularly challenging to understand. Without explicit references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need improvement. Additionally, the comment lacks specificity regarding what aspects of the presentation are confusing or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment states that the presentation of the paper is hard to follow, but it does not provide any specific details or suggestions on how the authors could improve the clarity or organization of the paper. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the presentation need attention or how to address them. This lack of specificity and depth makes the comment 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly requests more detailed information about the compared models, specifically mentioning the KVAE, DMM, and DVBF. It highlights that the KVAE is simpler due to linear state space transitions but requires the computation of timedependent LGSSM parameters \u03b3. The reviewer asks for clarification on the computation requirements of the three methods compared in Table 1. This feedback provides clear and concrete actions for the authors to take, such as elaborating on the models and their computation requirements. The explicit nature of the request and the specific questions make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, namely the differences between KVAE, DMM, and DVBF, and the computation requirements of these models. The comment provides a clear request for more detailed information about the models, which is specific and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the detailed presentation of the compared models, specifically mentioning the KVAE, DMM, and DVBF. The reviewer acknowledges their understanding of the differences with KVAE but requests more detailed information about the compared models. The comment provides a logical reasoning for the need for more detailed information, noting that the KVAE is simpler due to linear state space transitions but requires the computation of timedependent LGSSM parameters \u03b3. However, the comment lacks specific examples or references to support the claim about the computation requirements of the models. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by requesting more detailed information about the compared models, particularly the KVAE, DMM, and DVBF. It highlights the differences between these models and the KVAE, noting that the latter is simpler due to linear state space transitions but requires the computation of timedependent LGSSM parameters \u03b3. The comment also asks for clarification on the computation requirements of the models compared in Table 1. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the presentation of their models and their differences. By addressing these points, the authors can improve the clarity and comprehensiveness of their paper, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include works such as  Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and compare them to their work conceptually. Additionally, it recommends discussing how their work differs from other chatbox research works, such as  He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). These suggestions provide clear and explicit actions for the authors to take, including identifying relevant works and discussing their differences. The comment is concrete and provides specific guidance on how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests including works such as  Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discussing how their work differs from other chatbox research works, such as  He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of these works and the need for a discussion on differences, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include works such as  Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discuss how their work differs from other chatbox research works, such as  He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). The comment provides a logical reasoning for including these works, as they are relevant to the taskoriented recommendation perspective of the paper. However, it lacks specific references or detailed justification for why these works are particularly important or how they differ from others. This makes the claim 3, as the authors would need to make a concerted effort to understand and incorporate the suggested references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors should include relevant works such as  Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discuss how their work differs from other chatbox research works, such as  He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). This feedback is valuable as it directs the authors to include relevant references that could enhance the comprehensiveness and depth of their work. Additionally, it encourages the authors to discuss their work\"s differences from other research in the field, which could help clarify their contributions and set them apart. Overall, the comment is 4 as it provides clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests that a simpler approach could be to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. The comment implies that it is not necessary for each initialization to reach the global minimum, as long as at least one does. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific changes should be made to improve the experimental setup. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their experimental approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests a simpler approach, which is to run vanilla Adam on the final network with 40 random initial points. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the experimental setup and suggesting a simpler alternative. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the experimental strengths of the approach, specifically the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests that a simpler approach could be to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. The claim is 3 as it provides a logical reasoning for why the current approach might not be optimal, but it lacks specific examples or references to support the claim. The authors would need to further explore the implications and potential consequences of the suggested alternative approach to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests a simpler alternative, which is to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. This feedback is 3 as it points out a potential issue with the experimental setup and provides a suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to implement the suggested alternative or why it might be more effective. Overall, the comment provides some insight but lacks depth and actionable details, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a typographical error in the phrase \"for \"inbetween\" uncertainty\" by noting that the first quotation mark should be a forward mark rather than a backward mark. This is a clear and concrete action for the authors to take, as they are provided with specific guidance on how to correct the error. The comment is 5 as it directly instructs the authors on what to change to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the typographical error, noting that the first quotation mark should be a forward mark rather than a backward mark. This provides clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a typographical error in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific typographical error in the paper, noting that the first quotation mark in the phrase \"for \"inbetween\" uncertainty\" should be a forward mark rather than a backward mark. This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and readability of their draft. However, the comment does not provide any additional context or explanation about why this error is important or how it might impact the overall understanding of the paper. While it is helpful in pointing out a specific issue, it could be more beneficial if it included suggestions for how to ensure consistency in typography throughout the paper. Therefore, the comment is 3, as it provides a clear and actionable suggestion but lacks depth and context."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it does not provide specific guidance on how to do so or what aspects of the dataset should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their exploration of the dataset but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper should have more exploration or what aspects of the dataset should be highlighted. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this exploration is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it lacks specificity and does not provide guidance on how to effectively integrate this exploration into the paper or what aspects of the dataset should be highlighted. Without detailed suggestions or examples, the authors are left with a general direction but without actionable steps to improve their draft. Therefore, the comment is 3, as it identifies an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. While the comment provides a specific suggestion to use more objective terms, it does not offer concrete guidance on what terms to use or how to present the improvement in a more objective manner. The action is implicit and somewhat vague, as the authors need to infer the specific terms to use and the exact way to present the improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"axes\" and \"squished,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement and points out that the axes are squished, making it difficult to characterize the improvement as remarkable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"remarkable\" is subjective and that the axes are squished, making it difficult to characterize the accuracy improvement as remarkable. However, the comment does not provide any supporting evidence, reasoning, or references to justify why \"remarkable\" is inappropriate or how the squished axes affect the interpretation of the improvement. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. This feedback is actionable and constructive, as it offers a clear direction for the authors to improve the clarity and precision of their language. By addressing these points, the authors can enhance the credibility and objectivity of their claims. However, the comment could be more helpful if it provided examples of alternative, objective terms to use or explained why \"remarkable\" is not appropriate. Overall, the comment is 4 as it offers clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the observed performance enhancements are modest and implies that there is room for further refinement in the future. However, it does not provide specific guidance on how to achieve this refinement or what aspects of the work need improvement. The action is implicit and vague, as the authors are left to infer that they need to make improvements but without clear direction on what those improvements should be. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, such as specific experiments or results. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the work need refinement or how to achieve it. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation and how it relates to their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work need improvement. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230234 and 234235, and to clarify what \"MLP\" refers to in Figure 2. These are clear and direct actions that the authors can take to improve their draft. Additionally, the comment highlights a missing reference, which is also actionable. The feedback is specific and provides concrete guidance on what needs to be added or clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in Section 3.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for references for two passages and clarifies what \"MLP\" refers to in Figure 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of requests for references and clarifications, which are factual in nature and do not contain subjective claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying specific lines in Section 3.2 that lack references and asking for clarification on what \"MLP\" refers to in Figure 2. This detailed guidance helps the authors address specific gaps in their work, ensuring that their references are accurate and their figures are clearly explained. Additionally, the comment highlights a missing reference, which is an important detail for the authors to consider. Overall, the comment is 5 as it directs the authors to specific areas for improvement and provides clear instructions on how to address them."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the cause of this similarity. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the experimental results or what specific aspects of the method need to be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, specifically mentioning the similarity in performance to IRM. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the experimental results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method. However, it does not provide any specific evidence, reasoning, or examples to support this claim. The mention of \"IRM\" is not sufficient to substantiate the claim, as it does not explain why the performance is similar to IRM or how this relates to the issues mentioned above. Without detailed justification or references, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their experimental results. Without detailed guidance or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is no empirical validation and suggests including experiments to validate the bounds. This provides a clear and direct action for the authors to take, which is to conduct experiments to validate the bounds. The comment is specific in its request for empirical validation and offers a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of empirical validation, which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of experiments to validate the bounds. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is no empirical validation and suggests including experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical validation for the bounds. It suggests that including experiments to validate the bounds would be beneficial. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of empirical validation. However, the comment could be more helpful if it offered examples of what types of experiments might be appropriate or how to design them. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a discrepancy between equation 9 and figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it or what specific changes should be made to the figure or the methodology. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the figure and possibly use bilinear sampling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions, and suggesting that bilinear sampling might provide better results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The reviewer suggests that the figure is misleading and proposes an alternative method, bilinear sampling, as a potential solution. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the misleading nature of Figure 1. The suggestion to use bilinear sampling is based on logical reasoning but could be strengthened with more detailed justification or references. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a discrepancy between equation 9 and Figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. This feedback is 3 as it points out a potential issue with the figure and provides a suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to address the discrepancy or why bilinear sampling might be a better approach. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. It suggests that this observation has not been revisited in the Discussion section, which is fine, and suggests that the authors should delete \"Discussion.\" While the comment provides a clear action to take, it does not offer specific guidance on how to revise the Discussion section or what aspects should be revised. The action is explicit but lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. This provides clear guidance on what needs to be addressed in the Discussion section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. It suggests that this observation has not been revisited in the Discussion section, which is fine, and recommends deleting \"Discussion.\" This feedback is clear and actionable, as it directs the authors to address a specific point in the paper that could be improved. However, it could be more helpful if it provided additional guidance on how to revise the Discussion section or what aspects should be emphasized. Overall, the comment is 4 as it points out a potential area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and concrete, as it instructs the authors to adjust the font size to make it more readable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a factual observation about the font size in Figure 6 being too small. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the font size in Figure 6, noting that it is too small. While this feedback is clear and actionable, it does not provide any context or explanation as to why the font size is important or how it affects the overall presentation of the figure. Additionally, it does not offer suggestions on how to address this issue, such as recommending a specific font size or discussing the impact of font size on readability. Despite these limitations, the comment is 3 as it directs the authors to a specific area for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a specific suggestion for improvement, it lacks concrete guidance on how to implement this change or what specific aspects of the paper need to be revised to address this issue. The authors are left with a general idea of what to do but without detailed instructions on how to execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, suggesting that the examples chosen do not convincingly demonstrate the need for interprocess communication and recommending a focus on problems where the loss function does not decompose as the sum of sample losses. The comment provides a clear direction for improvement by suggesting a focus on Hogwild and other ERMbased distributed algorithms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples chosen in the paper do not convincingly demonstrate the need for interprocess communication, particularly in the second paragraph where samplingbased Bayesian methods are mentioned. The reviewer suggests that the paper\"s results are irrelevant in this context and recommends focusing on problems where the loss function does not decompose as the sum of sample losses. The comment provides a logical reasoning for the claim by pointing out that the paper\"s results are not relevant to the context of interprocess communication. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the context and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This feedback is specific and offers a concrete direction for the authors to enhance their paper by addressing a potential weakness in the introduction. By suggesting a specific area of focus, the comment empowers the authors to make a meaningful change to their draft. However, it could be more helpful if it provided additional context or examples of how the authors might apply this suggestion to their work. Overall, the comment is 4 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of fairness in the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pretraining module. It suggests that to ensure fairness, the authors should compare CPEF with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design of CPEF. This feedback provides a clear and explicit action for the authors to take, specifying which model to compare and why. The suggestion is concrete, as it directly instructs the authors on how to improve the fairness and clarity of their comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of fairness in the comparison between CPEF and PMEF. The comment provides a clear suggestion to compare CPEF with another pretrained model, such as ExpertBert, to ensure fairness and highlight the advantages of the innovative pretraining module design of CPEF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF is unfair due to the lack of a pretraining module in PMEF. The reviewer suggests that to ensure fairness, the authors should compare CPEF with another pretrained model, such as ExpertBert. This claim is 3 as it logically argues that a fair comparison should include models with similar pretraining capabilities. However, the comment lacks specific examples or references to support the claim that ExpertBert is a suitable alternative for comparison. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It points out that PMEF lacks a pretraining module, which makes the comparison unfair. The reviewer provides a clear and actionable suggestion to ensure fairness by recommending a comparison with another pretrained model, such as ExpertBert. This feedback is valuable as it guides the authors to make a necessary adjustment to their experimental design to ensure a fair comparison. By addressing this issue, the authors can enhance the validity and credibility of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance on how to address these concerns or what specific steps the authors should take to mitigate these risks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper this concern is related to, such as a specific section or experiment where this issue might arise. Without explicit references to sections or experiments, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specific guidance on how to address these concerns or what steps to take to mitigate the risks. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. While the comment identifies a critical issue, it lacks specific guidance or suggestions on how the authors might address this concern or mitigate the risks. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing element in the paper, specifically the FLOT cost matrix in Algorithm 1, which is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"FLOT cost matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the FLOT cost matrix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission or how it affects the paper. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of a definition for the FLOT cost matrix in Algorithm 1. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their draft. By providing this feedback, the reviewer helps the authors ensure that their work is presented in a more comprehensive and accurate manner. However, the comment could be more helpful if it offered suggestions on how to define the FLOT cost matrix or provided additional context on its importance. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the terminology. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the term \"connectivity,\" explaining that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"connectivity,\" noting that it is misleading as it does not refer to the structural connections between the brain and body. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and precision of the terminology. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what specific changes could be made to improve the clarity of the terminology. While it points out a relevant issue, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance on what the authors should do to improve their draft. It suggests that the authors should study the essentialness of using an orthogonal matrix weight for the local window MLP, which is not currently presented. This feedback is clear and concrete, as it specifies the need for further exploration and validation of the orthogonal matrix weight. The authors know exactly what needs to be done to address this point, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the importance of studying the essentialness of using an orthogonal matrix weight for the local window MLP. The comment provides a clear direction for the authors to improve their draft by suggesting that they should explore the validity of using an orthogonal matrix weight. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Step 2 and Step 3 are important for validating the essentialness of using an orthogonal matrix weight for the local window MLP. The reviewer suggests that Step 2 can be done regardless of the weight matrix, and Step 3 is crucial for using an orthogonal matrix weight. However, the comment lacks specific examples or references to support these claims, making it 3. The authors may find it challenging to fully understand and address the claims without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that needs improvement, namely the lack of exploration into the essentialness of using an orthogonal matrix weight for the local window MLP. It suggests that Step 2, which involves the transpose of the matrix, can be done regardless of the weight matrix, and that Step 3 is crucial for validating the use of an orthogonal matrix weight. The comment provides a clear and actionable suggestion for the authors to further explore and validate the use of an orthogonal matrix weight, which is a significant contribution to the paper. However, the comment could be more helpful if it offered specific examples or references to support the claim about the importance of Step 3. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, and that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. The reviewer suggests that these decisions should be explained in the paper to avoid readers needing to check the code. The comment provides clear and concrete actions for the authors to take, ensuring that they know exactly what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the handling of comparisons between episodes with different lengths and the use of padding to compare trajectories. The comment provides a detailed explanation of the issue, including the use of a normalization factor of 1/T and how this affects the distance calculation. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides specific observations, such as the use of padding to compare trajectories and the lack of a normalization factor of 1/T, which affects the distance calculation. These observations are supported by logical reasoning and specific examples from the provided code, making the claim 4. However, the comment could be strengthened by referencing specific sections of the code or providing additional examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the paper regarding the handling of comparisons between episodes with different lengths in the equation between lines 282 and 283. It points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, which can lead to biased results. Additionally, the comment highlights the lack of a normalization factor of 1/T, which can cause distance increases with the length of the trajectory, favoring longer trajectories. The reviewer suggests that these decisions should be explained in the paper to avoid readers needing to check the code, which is a clear and actionable suggestion. This feedback is valuable as it helps the authors improve the clarity and accuracy of their results, ensuring that their work is more accessible to readers. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential oversight in the experiment, noting that the Vision Transformer was not considered and questioning its applicability to larger image datasets like ImageNet. It also raises a question about the pruning strategy in selfattention layers. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should consider including the Vision Transformer and address the pruning strategy question, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of the Vision Transformer model and raises questions about its applicability to larger datasets like ImageNet. The comment also questions the pruning strategy in selfattention layers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment did not consider the Vision Transformer, which is an important SOTA model in image classification. It also questions whether such a technique would still work for larger datasets like ImageNet. The comment suggests that the pruning strategy in selfattention layers might differ. While the comment identifies a potential oversight, it lacks specific examples or references to support the claim that the Vision Transformer is an important model. The suggestion to consider it is logical, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential oversight in the experiment by noting the absence of the Vision Transformer, an important SOTA model in image classification. It raises a question about the applicability of the technique to larger datasets like ImageNet and questions the pruning strategy in selfattention layers. While the comment highlights important areas for consideration, it lacks specific guidance or suggestions on how to address these issues. The authors are given a direction to explore but are not provided with detailed steps or examples on how to incorporate the Vision Transformer or how to conduct the pruning strategy analysis. Therefore, the comment is 3, as it points out areas for improvement but does not fully guide the authors on how to implement these improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the figures, including the size of the text, the clarity of the inputs and outputs, and the selfcontained nature of the captions. While it points out these problems, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to make the figures more readable and better linked to the main text, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the small text size, unclear inputs and outputs, and the lack of selfcontained captions. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures in the paper are difficult to parse due to small text size, unclear inputs and outputs, and lack of selfcontained captions. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support why these elements are problematic or how they impact the clarity of the figures. The lack of specific examples or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the claim is 3, as it provides some basis but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that the texts are too small, the inputs and outputs are not clearly explained, and the captions are not selfcontained. It also points out the difficulty in linking the figures to the main text. This feedback is clear and actionable, as it provides the authors with a concrete understanding of what needs to be improved in terms of figure clarity and organization. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending font size or providing examples of how to improve the figure captions. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional molecule generation framework based on GDSS, which was recently proposed in 2, as a baseline. The comment provides explicit actions for the authors to take, such as including the continuous diffusion model as a baseline and considering the conditional framework based on GDSS. The suggestions are concrete and provide clear guidance on how to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison of the continuous diffusion model (e.g., GDSS) as a baseline in Table 3 and the suggestion to use a conditional molecule generation framework based on GDSS. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. The reviewer provides a logical reasoning by pointing out that the continuous diffusion model should be considered as a baseline for the conditional generation task. Additionally, the comment suggests using a conditional molecule generation framework based on GDSS, which was recently proposed in 2. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by referencing 2 directly or providing more detailed reasoning about why GDSS is a suitable baseline. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional molecule generation framework based on GDSS, which was recently proposed in 2, as a baseline. This feedback is valuable as it guides the authors on how to improve the comparison and evaluation of their results, providing a clear direction for enhancing the paper. However, the comment could be more helpful if it explained why GDSS is a suitable baseline or how the proposed conditional framework would benefit the analysis. Overall, the comment is 4 as it offers actionable suggestions for improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This is a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be added to, such as the results or discussion sections. The authors can infer that it relates to the experimental evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what needs to be added. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s contribution by including a comparison with established methods. However, the comment lacks specific examples or references to these stateoftheart loss functions, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification. This is a clear and actionable suggestion that could significantly enhance the paper\"s contribution by demonstrating the effectiveness of the proposed method against established benchmarks. By including this comparison, the authors can provide a more robust evaluation of their work and potentially improve its impact. However, the comment could be more helpful if it specified which loss functions should be included or provided examples of how they might be used in the comparison. Overall, the comment is 4 as it offers a concrete direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as giving the EF and D2 transcription norms, correcting specific phrases in the text, and addressing issues with repeated words in a table. Additionally, it points out a discrepancy in the DOI number and the link behind the title. These actions are clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and tables in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the phrasing in lines 029 and 188, the repeated words in Table 3, and the discrepancy in the DOI number. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of technical corrections and observations, such as correcting phrasing, addressing repeated words, and pointing out discrepancies in the DOI number. These are factual statements that do not involve subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of technical corrections and observations, which can be beneficial for the authors in improving the clarity and accuracy of their work. It points out specific errors in phrasing and references, such as correcting \"lightweight\" to \"in a lightweight\" and \"PLN\" to \"NLP.\" Additionally, it highlights a discrepancy in the DOI number and the link behind the title. These corrections and observations are actionable and can help the authors improve the clarity and consistency of their work. However, the comment could be more helpful if it provided additional context or suggestions for how to address these issues. Overall, the comment is 3 as it offers specific guidance but lacks depth in its feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the notation used in the paper, including the lack of definitions for M and N and the small font size in Figure 1. It provides a specific suggestion to spell out F.L.T.R in Figure 4 and recommends crossreferencing notation and figures to avoid confusion. While the comment does not explicitly instruct the authors to make these changes, the suggestions are clear and actionable, providing concrete steps for the authors to improve the clarity and readability of their paper. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as spelling out F.L.T.R in Figure 4 and making the text larger. The comment also suggests crossreferencing notation and figures to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation is confusing and suggests spelling out F.L.T.R in Figure 4. It also mentions that the font size in Figure 1 is too small to see and recommends crossreferencing notation and figures. While the comment identifies specific issues with the notation and figure presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to crossreference notation and figures is a logical step, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including confusing notation and font size in figures. It provides specific suggestions for improvement, such as spelling out F.L.T.R in Figure 4 and making the text larger in Figure 1. Additionally, it recommends crossreferencing notation and figures to avoid confusion. These suggestions are clear and actionable, offering the authors a concrete path to enhance the clarity and readability of their draft. However, the comment could be more helpful if it provided additional guidance on how to address the confusion in the notation or why it is confusing. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks for clarification on the comparison results between YOSO and linformer in terms of iterationwise convergence and accuracy in downstream tasks. It also suggests that the authors should provide a comparison of these results to explain the difference in performance. The feedback is clear and concrete, giving the authors specific actions to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments: YOSO takes linformer as baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the lack of steps vs PPL of linformer with YOSO in Figure 4 and the comparison of YOSO and linformer on iterationwise convergence. Additionally, it suggests a comparison to an explanation of the difference in performance between YOSO and linformer. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of comparison results between YOSO and linformer in terms of iterationwise convergence and accuracy in downstream tasks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the pretraining experiment part does not provide steps vs PPL of linformer with YOSO in Figure 4. It also questions the comparison result of YOSO with linformer on iterationwise convergence and suggests a comparison to an explanation of the difference in performance. This feedback is clear and actionable, as it directs the authors to provide missing information and comparisons that could enhance the clarity and comprehensiveness of their experimental results. By addressing these points, the authors can improve the transparency and rigor of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion regarding the name \"PointNet\" in Figure 1, noting that it is not mentioned in the paper and that there is another paper with the same name. The reviewer suggests that the authors should clarify this issue by referring to the correct paper or providing a footnote. This feedback is explicit and provides concrete guidance on how to address the confusion. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"PointNet,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of \"PointNet\" as it is not mentioned in the paper and there is another paper with the same name. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to 15 as \"PointNet\" is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to another paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which supports the claim by pointing out the correct name. This provides a clear and verifiable basis for the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the labeling of \"PointNet\" in Figure 1, noting that it is confusing as the name does not appear in the paper and there is another paper with the same name. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their draft. By addressing this issue, the authors can improve the clarity and accuracy of their figure captions, which is valuable guidance for improving the paper. However, the comment could be more helpful if it suggested a way to avoid similar confusion in future figure captions or provided additional context on the importance of accurate labeling. Overall, the comment is 4, as it effectively points out a specific issue and offers a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity. This feedback provides clear and concrete actions for the authors to take, such as creating a new section or expanding the existing one to address the clarity issues. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further clarification of the assumed threat model, including the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. This level of detail provides clear guidance on what needs to be improved, making the comment 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This claim is 3 as it logically suggests that such clarification would enhance the clarity of the paper, particularly around the assumed whitebox access to the victim model. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the threat model. It suggests that the authors should define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and understanding of their work. By addressing these points, the authors can improve the comprehensibility and robustness of their threat model, which is crucial for the overall effectiveness of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies specific parts of the text that could be written more clearly, such as line 97 regarding proper rotation matrices and line 105106 regarding the matrix being non positive semidefinite. It provides clear and concrete actions for the authors to take, such as explicitly explaining the concepts in these sections. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the text, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the definition of a proper rotation matrix and the problem of the matrix being non positive semidefinite. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification regarding specific terms and concepts in the text. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific parts of the text that could be written more clearly, such as line 97 regarding proper rotation matrices and line 105106 regarding the matrix being non positive semidefinite. By pointing out these areas for clarification, the comment provides actionable feedback that can help the authors improve the readability and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to clarify these concepts or provided examples of how they might be explained more effectively. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is explicit and provides a concrete suggestion for how the authors might improve their draft by changing the terminology. The action is clear and specific, leaving no ambiguity about what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The comment also references the activationpooling operator introduced by Cohen and Shashua, which helps clarify the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The reviewer provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This reference provides a logical basis for the suggestion, making the claim 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It offers a clear and actionable piece of feedback by providing a concrete example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is valuable as it helps the authors improve the clarity and consistency of their terminology, potentially enhancing the readability and comprehensibility of their paper. However, the comment could be more helpful if it explained why this change might be beneficial or how it would impact the paper\"s overall message. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for their methods or related work. This is a clear and direct action that the authors can take to improve the presentation of their figures. The comment provides a specific suggestion for how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1\" and \"Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they should be shrunk to leave more space for the authors\" methods or related work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, and it provides a specific suggestion to shrink the captions to leave more space for the authors\" methods or related work. This claim is 3 as it logically suggests a way to improve the presentation of the figures, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to experiment with different caption sizes to determine the optimal size for their purposes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to shrink the captions to leave more space for the authors\" methods or related work. This feedback is valuable as it directs the authors to a specific area that could be improved, offering a concrete way to enhance the clarity and presentation of their figures. However, the comment could be more helpful if it included examples of how the captions could be revised or if it explained why this change would be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al, 2021, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add this work as a benchmark. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide specific reasoning or evidence to support why Vidgen et al, 2021, should be included as a benchmark. The absence of detailed justification or references makes the claim 3, as the authors would need to infer the importance of including Vidgen et al, 2021, based on the suggestion alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This feedback is 3 as it points out a potential oversight in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to incorporate Vidgen et al, 2021, or provided examples of how this dataset could be used in the evaluation process. Overall, the comment is 3 as it highlights an area for improvement but lacks depth and actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the clarity of the experimental setup. The comment is specific and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the impact of different versions of the experimental environment on training and inference speed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This claim is 3 as it logically suggests that different versions of the experimental environment could impact training and inference speed. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of providing this information themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about the experimental environment, including the CUDA and PyTorch versions. This feedback is clear and actionable, as it directly addresses a potential issue with the clarity and reproducibility of the experimental setup. By providing this additional information, the authors can ensure that their work is more robust and easily replicable. However, the comment could be more helpful if it included suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it effectively guides the authors on how to enhance the transparency and reliability of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and the difficulty in controlling multiple aspects of variation with precision due to the use of fully realistic datasets. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address the issue of controlling variation or how to improve the societal impact assessment. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of controlling multiple aspects of variation with precision in the context of using fully realistic datasets. It also agrees with the authors\" judgement about the lack of immediate societal impact. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the difficulty in controlling variation and the lack of immediate societal impact, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using fully realistic datasets makes it difficult to control multiple aspects of variation with precision. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" judgement about the lack of immediate societal impact and the difficulty in controlling multiple aspects of variation with precision due to the use of fully realistic datasets. However, it does not provide any specific suggestions or guidance on how the authors might address these issues or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the standard deviation of the noise in the simulation study is stated as 3 but appears to be too low based on observations. While the comment implies that the authors should conduct additional simulations with higher noise levels, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional simulations to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the noise standard deviation being too low and suggests studying the behavior of the model under higher noise levels. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise in the simulation study is too low, based on observations compared to the true trajectories. However, the comment does not provide specific evidence or examples to support this claim, such as data or observations that would substantiate the assertion. Without such details, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the standard deviation of the noise in the simulation study, suggesting that it may be too low based on observations compared to the true trajectories. It recommends studying the behavior of the model under higher noise levels, which could provide valuable insights into its robustness. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct the additional simulations or what specific aspects to focus on. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed steps for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and suggests that this could limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to ensure the applicability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds of the approach, specifically mentioning the o(1) terms and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential limitation of the approach due to the o(1) terms, but it does not provide details on how this limitation affects the applicability of the approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds of the approach have o(1) terms and that this could limit the applicability of the approach. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the approach, specifically the use of o(1) terms in the bounds. It raises a concern about the applicability of the approach due to the size of inputs required for improvement over previously known results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the approach could be improved to overcome this limitation. While it points out a potential problem, it does not provide actionable advice or detailed feedback for the authors to improve their draft. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the connection or depth of the analysis. The comment implies that the authors should make improvements, but it lacks concrete details on how to implement them. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not specify which part of Section 2 is lacking a connection or how the theoretical analysis could be improved. The authors can infer that the comment relates to the theoretical analysis and its connection to the methodology section, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be improved. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without detailed justification or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between Section 2 and the methodology section, as well as the simplicity of the theoretical analysis. It suggests that the analysis is closely related to a specific reference, which could be problematic. However, the comment lacks specific guidance on how to address these issues or what changes could be made to improve the connection or depth of the analysis. While it points out areas for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights potential weaknesses but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses doubt about the paper\"s current strength for the ICLR conference, but it does not provide any specific guidance or suggestions on how the authors might improve their draft to meet the standards of the conference. There is no explicit or implicit action for the authors to take, nor are there any concrete details on what aspects of the paper need improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is being addressed, making it 1. It also lacks specificity as it does not provide details on what aspects of the paper are insufficient for the ICLR conference or how the authors might improve their draft to meet those standards. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"doubtful\" for the ICLR conference, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the criteria or standards expected for the ICLR conference, the authors are left without a clear understanding of what needs to be improved or how to address the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment expresses doubt about the paper\"s current strength for the ICLR conference, indicating that it may not be suitable for the event. However, it does not provide any specific feedback or suggestions on how the authors might improve their draft to meet the standards of the conference. Without actionable guidance or detailed insights into what aspects of the paper need improvement, the comment offers limited value to the authors. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should run experiments multiple times and report statistics, as a way to address the reproducibility issue in deep RL. It references a recent paper that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a clear action to take, it does not specify how many times the experiments should be run or what specific statistics should be reported. The authors are given a general direction but may need to infer the exact details of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that experiments should be run multiple times and that statistics should be reported, as a way to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. However, the comment does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on reproducibility. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for multiple experiments and reporting statistics, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that experiments should be run multiple times and that statistics should be reported to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. This reference provides a logical basis for the claim, as it supports the need for increased reproducibility in the field. However, the comment could be strengthened by providing more detailed examples or specific suggestions on how to implement these changes. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive evidence or detailed guidance.", "helpfulness_rationale": "The review comment identifies a critical issue with deep RL, specifically the reproducibility of their results and the significance of their improvements. It suggests that experiments should be run multiple times and that statistics should be reported to address this issue. The comment references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL, providing a relevant external reference to support the suggestion. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement these changes or what specific statistics should be reported. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for minor issues with the ending punctuation of equations. It also explicitly states that they should ensure consistency in the punctuation, providing clear and concrete guidance on what needs to be done. This level of detail and specificity makes the action 5, as the authors know exactly what to check and how to ensure consistency in their work. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ending punctuation of equations, instructing the authors to ensure consistency in the punctuation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the ending punctuation of equations in Figure 2, Line 433, and Line 468. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the punctuation of equations in Figure 2, Line 433, and Line 468. It provides clear and actionable feedback by instructing the authors to ensure consistency in the ending punctuation of equations, which is a minor but important detail that can enhance the clarity and professionalism of their work. This feedback is 3 as it guides the authors to a specific area for improvement, but it could be more helpful if it also suggested how to address the issue or provided examples of correct punctuation. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks depth and detailed guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This feedback implies that the authors should clarify the nature of the figures and potentially conduct additional experiments to validate their findings. While the action is implicit, it is clear and concrete, as it specifies what the authors need to do to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially, and suggests conducting realworld experiments to support the phenomenon shown in the figures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This claim is 3 as it logically suggests that realworld experiments could provide additional validation for the results presented in the figures. However, the comment lacks specific examples or references to support the need for such experiments, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This feedback is valuable as it prompts the authors to consider the validity and robustness of their results, which is an important aspect of scientific research. However, the comment could be more helpful if it provided specific guidance on how to conduct these realworld experiments or what aspects of the figures need further validation. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance the robustness of their findings."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This provides a clear and direct action for the authors to take, which is to include these elements in their draft to enhance understanding. The suggestion is concrete, as it specifies exactly what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment suggests adding an example and a figure to help explain the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the definition is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an example and a figure, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why this addition would be beneficial or how it would enhance the understanding of the concept. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to determine the necessity or impact of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This feedback is 3 as it identifies a specific area where the paper could be improved by providing visual aids to enhance understanding. However, the comment lacks depth and does not explain why examples or figures would be beneficial or how they could be integrated into the paper. While it points out a potential improvement, it does not offer detailed guidance or suggestions on how to implement this change. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the assumption among classes not being practical, but it does not provide any explicit or implicit actions for the authors to take. It mentions that the formulation or definition is trivial but suggests that the optimization and theoretical property analysis could provide insights. However, it does not specify what aspects of the optimization or theoretical property analysis should be addressed or how the authors should incorporate these findings into their work. Without clear guidance or actionable steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption among classes and suggests that the formulation or definition is trivial but highlights the importance of optimization and theoretical property analysis. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and the potential value of optimization and theoretical property analysis, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the formulation or definition is trivial, but it lacks specific examples or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption among classes, suggesting that it may not be practical. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment mentions the importance of optimization and theoretical property analysis, but it lacks actionable advice or detailed feedback on how to incorporate these aspects into the paper. Without specific suggestions or examples, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on what specific aspects of the explanation are unclear or how they could be clarified. The comment implies that the authors should clarify these points, but it lacks concrete instructions or examples of what needs to be improved. As a result, the authors are left with a vague suggestion to clarify the explanations, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the last paragraph of Section 3 (lines 207210), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the explanations are vague and provides a specific example of the issue, which is the last paragraph of Section 3. This level of detail helps the authors understand what needs to be clarified or improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the vagueness and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the explanations in the paper, particularly in the last paragraph of Section 3 (lines 207210) regarding the single image case. It points out that the explanations are vague, which is a valuable observation that can help the authors improve the clarity and comprehensibility of their work. However, the comment lacks specific suggestions or guidance on how to address the vagueness, such as recommending specific phrases or concepts to clarify. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but not detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, particularly in the language and vision tasks used for evaluation. It notes that while there is a comparison of training loss and a comparison of the rank of possible solutions, there is no direct comparison of test accuracy. The comment implies that the authors should include direct comparisons of test accuracy to demonstrate the improvement over the baseline. However, it does not explicitly instruct the authors to make these comparisons, leaving the action implicit. The comment is 3 as it provides a clear direction for improvement but lacks concrete guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prior approach PRANC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of direct comparisons with PRANC in the language and vision tasks used to evaluate the proposed approach. The comment provides a clear direction for improvement by suggesting the inclusion of direct comparisons of test accuracy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in the language or vision tasks used to evaluate the proposed approach. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. The comment suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline that it directly modifies. This claim is 3 as it logically points out the need for direct comparisons to substantiate the claims of improvement. However, it lacks specific examples or references to similar studies that might provide a more robust basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, noting the lack of direct comparisons with the prior approach PRANC in the language or vision tasks used to assess the proposed approach. It highlights the importance of including direct comparisons of test accuracy to demonstrate the improvement over the baseline that is directly modified by the authors. This feedback is clear and actionable, providing the authors with a specific area to address in order to strengthen their evaluation and substantiate their claims. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or provided examples of similar studies that have successfully demonstrated such comparisons. Overall, the comment is 4 as it effectively guides the authors on how to enhance their evaluation section."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. While the comment implies that these tasks should be included, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that these tasks should be added to the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the language modeling capability is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not conduct experiments on generation tasks that require a wellperforming language model, such as language modeling, machine translation, or text summarization. The reviewer suggests that these tasks should be included to strengthen the evaluation of the language modeling capability. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the evaluation. The reasoning is based on general assumptions and lacks detailed justification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the lack of experiments on generation tasks that are more likely to require a wellperforming language model. It suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft. However, the comment could be more helpful if it included specific examples or references to similar studies that have used these tasks to evaluate language modeling capabilities. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the proposed method does not show significant improvement over existing RL methods, but it does not provide any specific guidance or suggestions on how the authors could address this issue. There is no explicit or implicit action for the authors to take, such as suggesting ways to improve the method or providing examples of existing RL methods that could be compared. Without actionable advice or detailed feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed method does not show significant improvement over existing RL methods, but it does not specify which part of the paper discusses this improvement or where the comparison is made. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method does not show significant improvement over existing RL methods. However, it does not provide any specific examples, comparisons, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the proposed method does not show significant improvement over existing RL methods, which is a critical observation that could impact the paper\"s contribution. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the method\"s performance. Without actionable feedback or detailed insights into what aspects of the method need improvement, the authors are left without a clear path forward. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to differentiate their design or what aspects could be improved to enhance novelty. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of novelty in the paper, specifically mentioning that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what aspect of novelty is lacking, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the novelty of the paper, specifically noting that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the model design, specifically mentioning that the architecture and learning details are fragmented or missing. It provides a clear suggestion for the authors to address this issue by either providing a plot of model illustration, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the novelty of the Neurochaos Learning method. The explicit action and concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model design\" and \"model architecture and learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the fragmented or missing details of the model design, and provides suggestions for improvement, such as providing a plot, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the novelty of the Neurochaos Learning method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details, specifically mentioning the importance of demonstrating integrated details to facilitate reproducibility. The comment suggests providing a plot, pseudocode table, or code repository to address this issue. However, the comment lacks specific examples or references to support the claim that the model design is unclear or that Neurochaos Learning is not wellknown. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides a clear and actionable suggestion for the authors to address this issue by either providing a plot of model illustration, pseudocode table, or code repository. This feedback is valuable as it directly guides the authors on how to improve the clarity and reproducibility of their work. Additionally, it highlights the importance of demonstrating integrated details, especially considering the novelty of the Neurochaos Learning method. However, the comment could be more helpful if it included specific examples or detailed guidance on how to present the model illustration or pseudocode table. Overall, the comment is 4 as it provides clear and actionable feedback, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include rejection rates or consider misclassifications as rejections in their experiments. This is a clear and direct action, as it specifies exactly what needs to be added or changed in the paper. The comment provides concrete guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rejection rate\" and \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of rejection rates or the consideration of misclassifications as rejections in the results. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests that one could view a misclassification as a rejection. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it affects the paper\"s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that one could view a misclassification as a rejection, and recommends including rejection rates or considering misclassifications as rejections in the results. This feedback is clear and actionable, as it provides a direct suggestion for how the authors can improve their experimental analysis and presentation. By addressing this point, the authors can enhance the transparency and clarity of their results, making the comment 4. However, it could be more helpful if it included additional context or examples on how to implement this suggestion effectively. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly instructs the authors to optimize Figure 1 to use less whitespace, providing a clear and direct action for the authors to take. This guidance is specific and concrete, as it specifies the exact area that needs improvement and offers a specific improvement suggestion. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the optimization of Figure 1 to use less whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests optimizing Figure 1 to use less whitespace. However, it does not provide any reasoning, evidence, or examples to support why this optimization is necessary or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment provides a specific and actionable suggestion to optimize Figure 1 by using less whitespace. This feedback is clear and direct, offering the authors a concrete way to improve the visual presentation of their data. However, the comment could be more helpful if it provided additional context or examples of how to achieve this optimization. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the paper formatting does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the paper style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as adjusting the formatting style to conform to the NeurIPS guidelines and reorganizing the content accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper formatting, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the formatting, such as the font size of the abstract and the bottom page margins, and suggests that these issues could be addressed by following the NeurIPS formatting style. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that following the NeurIPS formatting style could improve the paper. While the comment provides specific examples of formatting issues, it lacks detailed reasoning or references to justify why the current formatting is problematic or how following NeurIPS guidelines would improve the paper. This makes the claim 3, as the authors would need to make an effort to understand and address the issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It provides clear and actionable feedback by suggesting that the authors fix the paper style to conform to the NeurIPS guidelines, which could potentially gain some space and allow for the inclusion of the NLP experiments in the main body of the paper. This feedback is valuable as it directs the authors to a concrete area for improvement, making the comment 4. However, it could be more helpful if it included specific examples or guidance on how to apply the NeurIPS formatting style to the paper. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 4, noting that one of the labels on the color bar should likely say \"worse\" instead of \"better.\" This is an explicit observation that the authors can directly address by changing the label. The action is clear and concrete, as the authors know exactly what needs to be corrected. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, noting that one of the labels should say \"worse\" instead of \"better.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a specific figure, Figure 4, noting that one of the labels on the color bar is incorrect. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that one of the labels on the color bar is incorrect. This is a clear and actionable observation that the authors can easily address to improve the accuracy and clarity of their visual presentation. However, the comment does not provide additional context or suggestions on how to improve the figure or what other labels might be mislabeled. While it points out a specific issue, it could be more helpful if it included additional guidance or context for the authors to fully address the problem. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely, changing \"training/validation/test\" to \"training/validation/test sets.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, noting a specific error in the text regarding the use of \"training/validation/test\" instead of \"training/validation/test sets.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and actionable suggestion that can help the authors improve the accuracy and clarity of their manuscript. By addressing this error, the authors can ensure that their paper is more precise and professional in its presentation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and recommends adding extra brackets around the term or defining the bracketed term separately if space allows. This provides a clear and explicit action for the authors to take, which is to clarify the definition by adding brackets or defining the bracketed term. The comment is specific and provides concrete guidance on how to improve the clarity of the definition. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to clarify the definition by adding extra brackets or defining the bracketed term separately if space allows. This level of detail provides the authors with a clear understanding of what needs to be addressed to improve the clarity of the definition. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and proposes adding extra brackets or defining the bracketed term separately to clarify it. However, the comment does not provide any specific reasoning or examples to support why the current definition is confusing or how the proposed changes would improve clarity. Without additional context or explanation, the authors may find it challenging to understand and implement the suggested changes. Therefore, the claim is considered 2, as it lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the definition of the quantile, which is described as \"a little confusing.\" It provides a clear and actionable suggestion to improve clarity by adding extra brackets around the term or defining the bracketed term separately if space allows. This feedback is valuable as it directly addresses a potential source of confusion and offers a concrete way to enhance the clarity of the definition. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context on how the suggested changes would improve understanding. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any specific guidance on which tasks should be discussed or how to incorporate this information into the paper. The action is implicit and vague, as the authors are left to infer what additional tasks might be relevant and how to address this suggestion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion where this topic could be addressed. The authors can infer that it relates to the broader context of the paper, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a topic for expansion, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this expectation is valid or how it relates to the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on which tasks or aspects of PE should be discussed. The comment is vague and does not offer actionable advice or examples, leaving the authors without clear direction on how to enhance their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the inclusion of zeroshot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not provide explicit guidance on whether the authors should remove these results or explain their inclusion. The comment lacks concrete instructions on how to address this issue, leaving the authors uncertain about how to proceed. Therefore, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the inclusion of zeroshot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not specify which part of the paper this discussion should be included in, such as the results or discussion sections. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in its critique of the inclusion of zeroshot generation results but lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results in the paper, suggesting that it might be somewhat unusual and questioning its relevance. While it acknowledges the interest of the experiments, it points out that the inclusion of zeroshot generation results might not be as relevant as other experiments. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or justify the inclusion of these results. The feedback is 3 as it highlights a potential weakness but lacks actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific problem, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to update the caption or add references to the body text, but the comment lacks concrete details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that \"OAA\" is never referenced in the body text and suggesting that there might be more content in the appendix that is missing or that the caption is out of date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"OAA\" is never referenced in the body text of Figure 3, suggesting that there might be more content in the appendix that is missing or that the caption is out of date. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment highlights a specific problem, it lacks depth and does not provide actionable guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential problem, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to clarify in the introduction that the proposed solution is a fix of 12, rather than a new PIC approach. It provides a specific suggestion to make this clarification by mentioning the reference in lines 2930. The comment is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (2930) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of whether the proposed solution is a fix of 12 or a new PIC approach. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors need to clarify in the introduction that the proposed solution is a fix of 12, rather than a new PIC approach. The reviewer supports this claim by referencing specific lines in the paper (2930) where the proposed solution is introduced as a new PIC approach. This provides a clear and specific example of the issue, making the claim verifiable. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the introduction section of the paper. It points out that the authors need to clarify that the proposed solution is a fix of 12, rather than a new PIC approach, as it is currently presented. This feedback is clear and actionable, as it provides a direct suggestion for improvement by suggesting the authors mention the reference in lines 2930. By addressing this issue, the authors can enhance the clarity and accuracy of their introduction, which is crucial for the overall understanding and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison with a NeRFbased method, specifically mentioning the recent Zero1to3 and pointe. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides explicit actions to include comparisons and question the relevance, it lacks concrete details on how to implement these suggestions. The authors are given a clear direction but may need to infer the specifics of how to conduct these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment does not specify which part of the paper these comparisons should be included in or how the relevance of the occlusion experiment should be addressed. While the authors can infer that the suggestions relate to the experimental section, the comment lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point suggests that a comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe, is missing. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment lacks specific examples or detailed reasoning to support these claims. The suggestion to include comparisons is 3, as it provides a direction for improvement, but the critique of the relevance is not fully substantiated. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of comparisons with NeRFbased methods, such as Zero1to3 and pointe. This suggestion is clear and can help the authors improve the comprehensiveness of their evaluation. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment identifies areas for improvement, it could be more helpful if it provided additional context or examples of how these comparisons could be conducted. Overall, the comment is 4 as it offers clear and actionable suggestions for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the use of subscripts s and t in Figure 1. While the comment implies that the authors should provide an explanation for \"multiaspect\" and clarify the subscripts in Figure 1, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and clarify the subscripts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (14 and 47) and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a brief explanation of \"multiaspect\" and the use of subscripts s and t in Figure 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the use of subscripts s and t in Figure 1. However, it does not provide any reasoning or evidence to support why these elements are unclear or problematic. The comment lacks specific examples or references to justify the need for an explanation or clarification. As a result, the claim is not verifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement by suggesting that a brief explanation of \"multiaspect\" would be helpful and questions the use of subscripts s and t in Figure 1. While the comment highlights these issues, it does not provide detailed guidance or suggestions on how to address them. The feedback is 3 as it points out potential areas for clarification, but it lacks depth and actionable advice that could help the authors improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider freezing some layers of the model while only training a few layers or using parameterefficient methods like LoRA. These suggestions are explicit and provide clear actions for the authors to take, such as considering these methods for experimental comparison. The comment also specifies the potential benefits of these approaches, making it clear what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests considering freezing some layers of the model while only training a few layers or using parameterefficient methods like LoRA. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the model training or parameter efficiency sections, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors consider alternative methods, such as freezing some layers of the model or using LoRA, for parameterefficient model training. While the comment provides a logical reasoning for considering these methods, it lacks specific examples or references to support the claim that these methods are \"natural to think about\" or \"valuable for experimental comparison.\" This makes the claim 3, as the authors would need to infer the benefits and applicability of these methods themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors consider alternative methods for parameterefficient model training, such as freezing some layers or using LoRA. This feedback is actionable and provides a clear direction for the authors to explore additional approaches that could enhance their experimental comparison. By suggesting these methods, the reviewer highlights a potential area for improvement that could enhance the rigor and comprehensiveness of the study. However, the comment could be more helpful if it provided specific examples or references to these methods, which would guide the authors more directly in implementing these suggestions. Overall, the comment is 4 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing citation for the public skipgram data set in L425. This is a clear and direct action for the authors to take, as it specifies the exact part of the paper where the citation is missing. The comment provides concrete guidance on what needs to be added, making it 5. Authors know exactly what to do to address this issue, ensuring that the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing citation for the public skipgram data set. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing citation for the public skipgram data set in L425. This is a factual statement that does not require any verification or justification. It is a request for clarification or correction, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the missing citation for the public skipgram data set in L425. This is a clear and actionable piece of feedback that the authors can easily address by adding the missing citation. By pointing out this oversight, the comment helps the authors improve the accuracy and completeness of their work. However, it could be more helpful if it provided additional context or explanation about the significance of the citation or how it relates to the paper\"s content. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not provide specific guidance on how the authors should address these issues or what steps to take to improve the model. The comment lacks concrete actions or detailed suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of model performance and suggesting that assumptions might not be satisfied or that there could be learning difficulties. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that assumptions are not satisfied or that learning difficulties exist. Without such evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. It prompts the authors to consider whether the model is encountering difficulties in learning or if assumptions are not being met. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve the model. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing discussion on arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on \"arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice and the sensitivity analysis of this hyperparameter. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on arbitrary hyperparameter \u03b3 is missing, including how to set it in practice and analyzing its sensitivity. This claim is 3 as it highlights a specific omission in the paper, but it lacks detailed justification or examples to fully substantiate the importance of including this discussion. The authors may need to infer the significance of this omission themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the lack of discussion on the arbitrary hyperparameter \u03b3, including how to set it in practice and analyzing its sensitivity. This feedback is clear and actionable, as it points out a critical area that needs to be addressed in the paper to ensure that the research is accessible and understandable. By providing this guidance, the comment helps the authors improve the clarity and completeness of their draft. However, the comment could be more helpful if it offered suggestions on how to incorporate this discussion or provided examples of how similar analyses have been conducted in related work. Overall, the comment is 4 as it effectively directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends simplifying the description and explaining the architecture and computations better. It also suggests reducing Figure 7, Section 8, and specific lines (3964) to gain more space. These explicit actions provide clear guidance on what the authors need to do to improve the draft. The comment is concrete, as it specifies which parts of the paper need simplification and reduction, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the paper being too dense and difficult to follow, suggesting that it needs simplification and better explanation of the architecture and computations. It provides specific examples of sections and lines that could be reduced to gain more space. However, it does not explicitly mention which sections or lines should be reduced, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as simplifying the description and explaining the architecture and computations better. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to understand the concepts and contributions. It suggests simplifying the description and explaining the architecture and computations better. The comment provides specific examples of sections and lines that could be reduced to gain more space. This claim is 3 as it provides some reasoning and examples, but it lacks detailed justification or references to support the claim that simplification is necessary. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is too dense and difficult to follow. It suggests simplifying the description and explaining the architecture and computations better, which is a crucial recommendation for improving the clarity and accessibility of the paper. The comment provides specific examples of sections and lines that could be reduced to gain more space, offering actionable guidance for the authors. However, the comment could be more helpful if it provided additional suggestions on how to simplify the description or explained why simplification is necessary. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment results could be discussed more, specifically questioning whether the MaxGapTop2UCB algorithm is better than others based on the Streetview experiment. It also points out that the realworld applications of the problem setting are not clear, and it raises a concern about the computational complexity of the proposed algorithms when applied to ranking problems. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects of the discussion should be expanded upon. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and address the computational complexity concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Streetview experiment\" and the \"realworld applications of this new problem setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the conclusion from the Streetview experiment and asking about the computational complexity of the proposed algorithms when applied to ranking problems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the conclusions drawn from the Streetview experiment and the computational complexity of the proposed algorithms when applied to ranking problems. While it identifies potential issues, it lacks specific evidence or references to support the claim that MaxGapTop2UCB is better than other algorithms or that the computational complexity is problematic. The comment is 3, as it provides a logical basis for the questions but does not fully substantiate the claims with detailed reasoning or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement: the discussion of experiment results and the clarity of realworld applications. It questions whether the MaxGapTop2UCB algorithm is better than others based on the Streetview experiment and points out the computational complexity of the proposed algorithms when applied to ranking problems. While the comment highlights important aspects that need further exploration, it lacks specific suggestions or guidance on how to address these issues. The authors are given direction but may need to infer the exact steps to take. Therefore, the comment is 3, as it provides insight but could be more actionable with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper and suggests that if the authors computed these results themselves, they should mention it. This provides a clear and direct action for the authors to take, ensuring that they either report the results from the original paper or acknowledge their selfcomputation. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"model (3) (Chung et al. 2016) for CsEn,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the results were taken from the original paper or computed by the authors themselves. This provides clear guidance on what needs to be corrected or clarified in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper, suggesting that the authors should mention if they computed these results themselves. The comment is 3 as it provides a specific reference to the original paper, which could help the authors verify the claim. However, the comment lacks detailed reasoning or explanation about why the results should be reported or how they might impact the paper. Therefore, the claim is rated as 3, as it provides a starting point for verification but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper. It suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, as it directs the authors to either report the results from the original paper or acknowledge their selfcomputation. By addressing this issue, the authors can improve the accuracy and transparency of their work. However, the comment could be more helpful if it provided additional context or guidance on how to present these results or why they are important. Overall, the comment is 4 as it effectively points out a potential oversight and offers a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer implies that discussing how to design prompts effectively is crucial. However, the comment does not provide specific guidance on how to achieve this or what aspects of prompt design should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to focus on prompt design but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper discusses these prompting methods or where the authors should focus their attention. The authors can infer that it relates to sections discussing prompt design, but this inference is not direct. The comment is specific in its suggestion to discuss prompt design effectively, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer argues that different prompts may result in varying performance outcomes, emphasizing the importance of discussing how to design prompts effectively. However, the comment lacks specific examples or references to support the claim that different prompts lead to varying performance outcomes. This makes the claim 3, as the authors would need to infer the importance of prompt design and the potential impact on performance outcomes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer highlights the importance of discussing how to design prompts effectively, given that different prompts may result in varying performance outcomes. This feedback is clear and actionable, as it directs the authors to focus on a critical aspect of their work that could significantly impact its impact and effectiveness. However, the comment could be more helpful if it provided specific suggestions or examples of effective prompt design strategies. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of the choice, and whether other influential losses have been considered. While the questions are explicit, they do not provide concrete guidance on how to address them. The authors are left to infer that they should provide more information about their methodology and consider alternative approaches, but the comment lacks specific suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of this choice, and whether other influential losses have been considered. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the questions are specific, the lack of grounding in the comment makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also asks whether other influential losses have been considered, such as replacing the min with a mean or NDCG. These questions are relevant and could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific guidance or suggestions on how the authors might address these questions or improve their work. While it identifies areas for further exploration, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out potential areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the legends for tables 1, 2, and 3 longer and to clarify whether the numbers are percent errors or percent correct. This feedback provides clear and concrete guidance on what needs to be done to improve the clarity of the tables. The authors know exactly what changes to make and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the legends for these tables, and it provides guidance on what needs to be clarified, such as whether the numbers are percent errors or percent correct. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a factual observation that does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a clear and direct suggestion that can help the authors improve the clarity and accuracy of their tables, which is an important aspect of the paper\"s presentation. By addressing this feedback, the authors can enhance the readability and comprehensibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to describe the size and elements of G, which is the graph used in the DGCN model. It also suggests adding the dimensions of G, X, and W to provide a better understanding of the model. These actions are clear and concrete, as they specify exactly what needs to be added or clarified in the paper. The authors know exactly what steps to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of G, the size and elements of G, and the dimensions of G, X, and W. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of G in Section 3.3 and suggests that it would be better to describe the size and elements of G. It also recommends adding the dimensions of G, X, and W to enhance understanding. While the comment identifies a potential gap in the explanation, it does not provide specific examples or references to support the claim that these details are necessary. The suggestion is logical but lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where additional clarity is needed, specifically regarding the construction of G in Section 3.3. It suggests that the authors should describe the size and elements of G and provide the dimensions of G, X, and W to enhance understanding. This feedback is clear and actionable, as it directs the authors to add specific details that could improve the clarity and comprehensibility of their work. By addressing these points, the authors can significantly enhance the reader\"s ability to understand the DGCN model and its components. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also mentions that the concept of peak in Figure 5 is not described. While the comment provides explicit actions to take, such as revisiting the energy concept and clarifying the peak concept, it does not specify how to implement these actions or what specific details should be included in the refreshed explanation. The authors are given clear guidance on what needs to be addressed, but the execution of these actions is somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing a possible interpretation of high energy on a character. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and that it should be refreshed in Section 5.2, where it is used several times. The reviewer provides a specific suggestion to clarify the interpretation of high energy on a character, which is a clear and actionable point. Additionally, the reviewer points out that the concept of peak in Figure 5 is not described, which is another area for improvement. The comment is 4 as it provides logical reasoning and specific examples to support the claim, making it 4. However, it could be strengthened by providing more detailed examples or references to similar concepts in the literature. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also points out that the concept of peak in Figure 5 is not described, which is a clear area for improvement. This feedback is valuable as it directs the authors to clarify and enhance the explanation of the energy concept, ensuring that the paper is more comprehensible to readers. By addressing these points, the authors can significantly improve the clarity and coherence of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific gaps in the paper regarding the details of the models, particularly the grammar over kernels and the probabilities associated with it. It explicitly asks for clarification on how the approach is applied in practice, including inference. The comment provides a clear and concrete action for the authors to take, which is to provide more detailed explanations of these aspects. This guidance is explicit and specific, leaving no ambiguity about what needs to be addressed to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the grammar over kernels\" and \"probabilities associated with the grammar,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail in explaining the grammar over kernels and the probabilities associated with it, as well as how inference is performed. This provides clear guidance on what needs to be clarified or expanded in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of detail in the explanation of the grammar over kernels and the probabilities associated with it, which makes it difficult to understand how the approach is applied in practice. The reviewer suggests that there might be probabilities associated with the grammar that define a hypothesis space of kernels, and questions how inference is performed. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issue, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors have not provided sufficient detail, namely the explanation of the grammar over kernels and the probabilities associated with it. It points out that this lack of detail makes it difficult to understand how the approach is applied in practice. The comment also raises questions about inference and the hypothesis space of kernels, providing clear guidance on what needs to be clarified or expanded in the paper. This feedback is actionable and offers a concrete direction for the authors to improve the clarity and comprehensibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This implies that the authors should include references to these works to provide a more comprehensive comparison. The comment is explicit in its request for inclusion of these references, making it clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the end of Section 4.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of references to previous works on Lasso screening, such as Ren et al. (2017), which should be included for a more comprehensive comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This claim is 3 as it highlights a potential omission in the paper\"s literature review, but it lacks specific references to the works that should be included. The reviewer provides a specific example of a relevant work, which would strengthen the claim. However, the comment does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This feedback is clear and actionable, as it points out a gap in the literature review that the authors should address to provide a more comprehensive analysis. By including these references, the authors can enhance the credibility and depth of their work. However, the comment could be more helpful if it suggested how to integrate these references into the paper or provided additional guidance on how to conduct a more thorough comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title is ambiguous and recommends clarifying that it pertains to machine comprehension of text, not human reading comprehension. This feedback provides a clear and explicit action for the authors to take, which is to clarify the title to avoid confusion. The comment is specific in its suggestion and offers concrete guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"title\" and provides a specific suggestion to clarify that it pertains to machine comprehension of text, not human reading comprehension. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified in the title to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying that it pertains to machine comprehension of text, not human reading comprehension. This claim is 3 as it provides a logical reasoning for the clarification, but it lacks specific examples or references to support the claim that \"reading comprehension\" and \"readability\" typically refer to human reading comprehension. The authors might find it challenging to fully understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title of the paper, suggesting that it may be misleading as it pertains to machine comprehension of text, not human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for clarification that could help the authors avoid confusion and ensure their title accurately reflects the content of their paper. By addressing this point, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided additional context or examples to further explain the issue with the title. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should show confidence intervals and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. The comment provides explicit actions for the authors to take, such as including confidence intervals and expanding the evaluation to more datasets. However, it does not specify which datasets should be used or how to calculate the confidence intervals. While the actions are clear, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results and the limited evaluation on two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of not showing confidence intervals and the need to evaluate on more datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. The reviewer supports this claim by referencing external works that discuss the importance of confidence intervals and the need for more datasets to evaluate robustness. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of confidence intervals or by explaining why the two datasets used are insufficient. Despite this, the claim is 4 due to the references to external works, which provide a solid foundation for the critique.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should include confidence intervals to demonstrate statistical significance and evaluate on more datasets to enhance robustness. The comment references external works that discuss the importance of confidence intervals and the need for more datasets, providing a clear rationale for the suggestions. However, the comment could be more helpful by offering specific guidance on how to calculate confidence intervals or which datasets to consider. Overall, the comment is 4 as it provides actionable feedback that can significantly improve the paper, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to verify whether the improvements of the proposed model over the RL without feedback model are statistically significant. This is a clear and direct action for the authors to take, as it provides a specific task to ensure the robustness of their findings. The comment is concrete in its request for statistical verification, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the proposed model\"s improvements over the RL without feedback model. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed model\"s improvements over the RL without feedback model are not statistically significant, specifically mentioning the comparison between rows 3 and 4 in Table 6. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed model\"s improvements over the RL without feedback model, noting that the improvements are not statistically significant as evidenced by the comparison between rows 3 and 4 in Table 6. The comment suggests that the authors verify if these improvements are statistically significant, providing a clear and actionable piece of feedback. This guidance is valuable as it directs the authors to a specific area that needs further investigation, ensuring that their findings are robust and reliable. However, the comment could be more helpful if it included additional context or examples of how to conduct the statistical verification. Overall, the comment is 4 as it effectively points out a potential weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" While the action is implicit, it is clear that the authors need to provide a method for achieving fair policy learning without negatively impacting the predictive model\"s performance. However, the comment does not specify how to achieve this or what specific steps to take, leaving some ambiguity. Therefore, the comment is 3, as it provides a direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request to demonstrate fair policy learning without negatively impacting performance, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" This feedback is 3 as it identifies a potential weakness in the paper, specifically the impact of the proposed method on the predictive model\"s performance. However, the comment lacks specific guidance or examples on how to achieve this goal or what aspects of the method might be causing performance issues. While it points out an area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback implies that the authors should clarify the use of P in these instances to avoid confusion. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a change in notation or clarifying the context in which P is used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the clarity of their manuscript. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the manuscript, including \"P mostly represents a probability but sometimes for a cumulative distribution function (e.g., Eqs. (3) and (4) and L44, all in Appendix), which leads to confusion.\" This allows the authors to accurately identify the parts of the manuscript being addressed. The comment is also specific because it clearly specifies the issue of using P for both probability and cumulative distribution functions, which leads to confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of P in the manuscript is confusing because it is used to represent both a probability and a cumulative distribution function. This claim is 3 as it provides a specific example (P used in Eqs. (3) and (4) and L44) to illustrate the confusion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why this confusion is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 3, as it provides some support but could be strengthened with additional justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that P is used to represent both a probability and a cumulative distribution function, which leads to confusion. This feedback is clear and actionable, as it points out a specific area where the manuscript could be improved by clarifying the use of P. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a change in notation or explaining the context in which P is used. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but notes that the setting is less convincing and lacks clarity. However, the comment does not provide specific guidance on how to define the contrastive gap or what aspects of the definition should be clarified. While the authors can infer that they need to provide a formal definition, the comment lacks concrete steps or examples to guide them in doing so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is central to the work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear and formal definition for the contrastive gap. The comment provides detailed feedback on the example given and the setting, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" is not clearly defined, despite being central to the work. It acknowledges that an example was provided but finds it less convincing due to the setting. The comment suggests that a clear, formal definition is needed. While the comment provides some reasoning by pointing out the lack of clarity in the example, it lacks specific examples or references to support the claim that the contrastive gap is not clearly defined. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but notes that the setting is less convincing and lacks clarity. The comment highlights the importance of a formal definition and provides a detailed critique of the example, which is helpful in guiding the authors to address this issue. However, the comment could be more helpful if it offered specific suggestions on how to improve the definition or examples to provide a clearer understanding. Overall, the comment is 4 as it points out a significant gap in the paper and provides actionable feedback for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the meaning of \u03b4 in the statement of Lemma 5. While it does not explicitly instruct the authors to clarify this term, it implies that the authors should provide a definition or explanation for \u03b4. The action is implicit but concrete, as the authors can infer that they need to address this question to improve the clarity of their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \u03b4 in the statement of Lemma 5. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the meaning of \u03b4 in the statement of Lemma 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the meaning of \u03b4 in the statement of Lemma 5. While it identifies a potential area of confusion or ambiguity in the paper, it does not provide any guidance or suggestions for clarification or improvement. The comment lacks actionable feedback or context that would help the authors address the issue. As a result, it is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the uniform setting of \u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. The reviewer suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should consider dynamically weighting the modalities but without detailed instructions on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform setting of \u03b1_m and suggests that dynamically weighting the modalities is important in multimodal fusion. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that setting \u03b1_m uniformly to 1/M implies that the contributions from all modalities are the same, which is not accurate. The reviewer supports this claim by referencing works in multimodal fusion that demonstrate the importance of dynamically weighting modalities. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to these works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the uniform setting of \u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. This is a relevant observation that could impact the validity and applicability of the work. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative weighting methods or discussing the implications of this uniform setting. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in Figure 1. While this is a minor issue, it is still important for the authors to correct this inconsistency to maintain consistency in their work. The comment is explicit in identifying the problem and provides concrete guidance on how to address it, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the task loss being labeled differently in the text and the figure, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in Figure 1. This is a factual observation that does not require any subjective interpretation or opinion. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor inconsistency in the labeling of the task loss between the text and Figure 1, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. While this is a minor issue, it could be confusing for readers and may affect the clarity of the paper. The comment provides a clear and actionable suggestion for the authors to correct this inconsistency, ensuring that the paper is consistent and easier to understand. Therefore, the comment is 4 as it points out a specific area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. While the comment identifies specific issues, it does not provide explicit instructions on how to address them. The authors can infer that they need to correct the table and the paragraph, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"Page 3, Line 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the monotonic increase in performance of RSD4PG with respect to \u03bb values and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point makes a claim about the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and questions what happens when \u03bb is even smaller. The reviewer also points out missing symbols and references in the text. However, the comment lacks specific examples or references to support the claim about the monotonic increase or the missing symbols, which makes it 3. The authors would need to make a significant effort to verify the claim themselves, as the comment does not provide enough detail for them to fully understand or address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues in the paper, such as the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. These are important points that could impact the clarity and accuracy of the paper. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as suggesting ways to present the data or explaining the significance of these missing symbols. While the feedback is clear and actionable, it lacks detailed guidance, making it 3. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several instances where citations are missing or needed, specifically in lines 7879, 129130, 156158, and 217218. While it identifies these areas, it does not provide explicit instructions on how to include the missing citations or what specific references should be used. The actions are implicit and somewhat vague, as the authors need to infer that they should include citations but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for citations in lines 7879, 129130, 156158, and 217218. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of claims that require specific citations to support the assertions. For example, the claim about diffusion models outperforming generative adversarial networks is not substantiated with a reference. Similarly, the claim about previous work having limited success is also unsupported. The reviewer requests citations for these claims, which would provide the necessary evidence to support the claims. Therefore, the comment is considered 1 due to the lack of supporting evidence or references.", "helpfulness_rationale": "The review comment identifies specific areas where citations are missing or needed, which is a clear and actionable piece of feedback. It highlights specific lines in the paper where references should be included, providing the authors with a concrete list of places to improve their draft. However, the comment could be more helpful if it offered suggestions on which specific works or references might be relevant for each of these citations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include the bottomup method 9 in their tables and evaluate its performance on the standard MS COCO dataset to see if there is a drop in performance in easy (non occluded) settings. While the comment explicitly states what needs to be done, it does not provide detailed guidance on how to implement these changes or what specific aspects of the method should be included in the tables. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bottomup method 9 and its results on the crowdpose dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is to include the bottomup method in the tables and evaluate its performance on the MS COCO dataset. This provides clear guidance on what changes need to be made to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method 9 has reported results on the crowdpose dataset outperforming all methods, including the paper\"s own method, and recommends including it in the tables. The comment also suggests evaluating the method\"s performance on the standard MS COCO dataset to determine if there is a drop in performance in easy settings. While the comment provides a logical suggestion for improvement, it lacks specific references or detailed evidence to support the claim that the bottomup method outperforms all others on the crowdpose dataset. This makes the claim 3, as the authors would need to conduct their own analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include the bottomup method 9 in their tables and evaluate its performance on the standard MS COCO dataset. This suggestion is based on the reported results of the bottomup method on the crowdpose dataset, which outperforms all methods, including the paper\"s own method. By including this information, the authors can enhance the comprehensiveness and comparability of their work. Additionally, the comment suggests evaluating the method\"s performance on the MS COCO dataset to determine if there is a drop in performance in easy settings. This additional evaluation could provide valuable insights into the method\"s robustness and generalizability. Overall, the comment is 5 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison to coordinateaware methods in their experimental section. The comment is specific in identifying the missing comparison and offers a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This provides clear guidance on what the authors should add to their experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This claim is 3 as it logically suggests that including such comparisons would provide a more comprehensive understanding of the methods being evaluated. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, suggesting that a comparison to coordinateaware methods, such as TFN or SchNet, would be beneficial. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental analysis by including a comparison to methods that are aware of the point coordinates. By addressing this point, the authors can enhance the comprehensiveness and depth of their experimental evaluation. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s overall contribution. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the binder design needs further optimization and validation, specifically mentioning that ProtPainter only provides empirical conformation estimation. However, it does not provide any explicit guidance on how to optimize or validate the binder design or what specific aspects need attention. The action is implied but not clearly stated, leaving the authors to infer the necessary steps to take. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ProtPainter\" and \"binder design,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further optimization and validation of the binder design. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ProtPainter only provides empirical conformation estimation for binder design, suggesting that further optimization and validation are required. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the binder design, noting that ProtPainter only provides empirical conformation estimation and that further optimization and validation are required. This feedback is clear and actionable, as it points out a gap in the current work and suggests specific areas for enhancement. However, the comment could be more helpful if it provided examples or guidance on how to optimize or validate the binder design. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the model in Figure 7 was trained, specifically inquiring about the stimulus used and the duration of the cycle. It also raises a question about whether the time scale of adaptation would shorten if the duration of the cycle changes, referencing a specific work by Smirnakis et al. in Nature 1997. The comment provides clear and direct actions for the authors to take, such as clarifying the training process and addressing the potential impact of cycle duration changes on adaptation. The explicit nature of the request and the concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the training process and the potential impact of cycle duration changes on the time scale of adaptation. The comment provides a clear direction for the authors to address the issue by asking for clarification on the training process and its potential implications. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training process of the model in Figure 7, specifically inquiring about the stimulus used and the duration of the cycle. It also references a specific work by Smirnakis et al. in Nature 1997 to support the claim that the time scale of adaptation might change with cycle duration. While the comment does not make a subjective claim or opinion, it does require clarification and evidence to be fully understood. Therefore, it is classified as \"3\" as it provides some basis for the question but lacks detailed justification or references.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of the paper that requires clarification regarding the training process of the model in Figure 7. It asks for clarification on the stimulus used and the duration of the cycle, which are crucial details for understanding the methodology. Additionally, it raises a relevant question about the potential impact of cycle duration changes on the time scale of adaptation, referencing a specific work by Smirnakis et al. in Nature 1997. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and completeness of their methodology section. However, the comment could be more helpful if it offered suggestions on how to address the potential impact or provided additional references to support the claim. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This is a clear and concrete action that the authors can take to address the issue of lacking direct evidence for the motivation. The comment provides a specific suggestion for how to present the evidence, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of direct evidence for the motivation and suggests plotting a figure to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct, as the problem is stated as \"a predictor suffers from accuracy decline due to longterm and continuous usage.\" The reviewer suggests that the authors should plot a figure showing the decline in accuracy over time (search steps) in different settings to support their claim. This claim is 3 as it provides a logical suggestion for how the authors might address the issue of lacking direct evidence. However, the comment lacks specific examples or references to similar studies that have successfully addressed this issue, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of direct evidence for the motivation of the study. It suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This feedback is clear and actionable, providing a concrete suggestion for how the authors can strengthen their argument. However, the comment could be more helpful if it explained why this figure is necessary or how it would address the issue of lacking direct evidence. Overall, the comment is 4 as it guides the authors toward a specific improvement that could enhance the clarity and robustness of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises several questions about the definition and calculation of excessive risk in the paper, particularly in relation to the optimal solution and data from different groups. It suggests that the authors should explain more about the concept of excessive risk and how it is calculated in practice, including the expectation. Additionally, it questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment provides a clear direction for the authors to clarify their explanation of excessive risk, it does not offer specific guidance on how to address these questions or improve the draft. The action is explicit but somewhat vague, as the authors need to determine the exact details of how to implement the suggested improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"line 103\" and \"Figure 3 and Figure 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the definition of excessive risk, how it is calculated in practice, and the comparability of values among different groups. The comment also seeks clarification on the relevance of excessive risk as a fairness metric. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the definition and calculation of excessive risk, particularly in relation to the optimal solution and data from different groups. It suggests that the values of excessive risk in Figure 3 and Figure 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The reviewer questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment identifies a potential issue with the definition and calculation of excessive risk, it lacks specific examples or references to support the claim that the values are positive. This makes the claim 3, as the authors would need to provide additional evidence or clarification to fully address the reviewer\"s concerns.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion regarding the definition and calculation of excessive risk in the paper. It questions the relevance of the concept of excessive risk as a fairness metric and points out that the values in Figures 3 and 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The comment also raises questions about the comparability of excessive risk values among different groups and suggests that the authors should provide more explanation about how to calculate excessive risk in practice. This feedback is clear and actionable, as it prompts the authors to clarify and strengthen their explanation of excessive risk, which is crucial for the paper\"s fairness analysis. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is explicit and provides a clear action for the authors to take, which is to include experiments with GPT3.5. The comment is concrete because it specifies the exact change needed to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of the proposed approach. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not direct. The comment is specific in suggesting the inclusion of GPT3.5 experiments but lacks grounding as it does not explicitly mention which part of the paper should include this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. However, the comment does not provide any supporting evidence or reasoning to justify why GPT3.5 is a better option or why it would provide a more comprehensive evaluation. Without additional context or comparisons, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly advises the authors to include a more costeffective option in their experiments. However, the comment could be more helpful if it explained why GPT3.5 is a better choice or how it might impact the evaluation. Despite this, the suggestion is valuable as it encourages the authors to consider a broader range of options for their experiments. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what to add, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of bold numbers for the baselines of previous work, particularly for WMT17WIKT where the best result in terms of BLEU is in the baselines. This provides clear guidance on what needs to be added to the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 4 should include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with Table 4, suggesting that bold numbers should be included for the baselines of previous work, particularly for WMT17WIKT where the best result in terms of BLEU is in the baselines. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of the data. However, the comment could be more helpful if it explained why this change would be beneficial or how it would enhance the clarity of the table. Overall, the comment is valuable in guiding the authors to make a specific improvement to their draft, but it could be more comprehensive with additional context or explanation. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take by asking for examples. The comment is concrete because it specifies the exact part of the paper where the examples should be provided, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors\" mentioned in those lines. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for verifiability.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area in the paper where examples of \"unreliable neighbors\" are mentioned. By asking for examples, the reviewer prompts the authors to provide more detailed explanations or examples to support their claims. However, the comment could be more helpful if it offered suggestions on how to present these examples or what specific aspects to focus on. While it provides a clear direction for improvement, it lacks depth and could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to enhance the generalizability of the findings or suggestions for further exploration. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. However, it does not specify which part of the paper this observation is based on, such as specific sections, tables, or figures. The authors can infer that it relates to the results or findings section, but this inference is not direct. The comment is specific in detailing the expected outcome of taskspecific finetuning, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited due to the expected outcome of taskspecific finetuning, which generally increases confidence for a specific task while potentially reducing generalizability. This claim is 3 as it provides a logical reasoning based on the general understanding of taskspecific finetuning. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. It suggests that this expected outcome reduces the novelty of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their findings. While it identifies a potential issue, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights a weakness but does not offer a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that Table 4 and 5 should be split into two tables each, with one table per measure. This provides a clear and concrete action for the authors to take, as it specifies the exact change needed to improve the readability of the tables. The suggestion is specific and actionable, leaving no ambiguity about what the authors should do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of the tables by splitting them into two tables each, with one table per measure. This gives the authors a clear idea of what needs to be addressed to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that splitting tables 4 and 5 into two tables each would improve their readability. This claim is based on a logical reasoning that splitting the tables would make it easier to follow the presentation of the data. However, the comment does not provide specific examples or references to support this claim, such as how other papers or studies have successfully implemented this structure. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, with one table per measure. This is a clear and constructive piece of feedback that can help the authors enhance the presentation and organization of their data. By following this suggestion, the authors can improve the clarity and ease of understanding their results, which is valuable guidance for improving the draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. This is a clear and direct action for the authors to take, as it provides a specific request for clarification that can be easily implemented. The comment is explicit and concrete, as it specifies exactly what needs to be added to the figure to improve its clarity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of \"valid\" and \"orig\" in the context of Fig. 5. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the understanding of the figure. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Fig. 5, noting that the terms \"valid\" and \"orig\" are used without explanation. This feedback is clear and actionable, as it suggests that the authors should specify what these terms mean in the context of the figure. By providing this guidance, the comment helps the authors improve the clarity and accessibility of their visual presentation. However, the comment could be more helpful if it offered suggestions on how to present this information effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons with the most closely related work more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. The comment is explicit in its suggestion and offers a specific improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely making comparisons more systematic with respect to the tuning of each method. This provides clear guidance on how to enhance the originality and comparative analysis of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with the most closely related work more systematic, specifically by comparing the best performance of each method. The comment provides a logical reasoning by suggesting that such comparisons would enhance the originality and depth of the paper. However, it lacks specific examples or references to the Zemel et al. (2013) work, which would strengthen the claim. Therefore, the comment is 3, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need to make comparisons with the most closely related work more systematic. It suggests that the authors should compare the best performance of each method, which could enhance the originality and depth of the paper. This feedback is clear and actionable, providing the authors with a concrete step to improve their draft. However, the comment could be more helpful if it included specific examples or guidance on how to implement these comparisons. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their work."}
