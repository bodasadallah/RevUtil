{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more analysis around the quality of the collected dataset and the potential noise it might contain. While the comment implies that the authors should conduct additional analysis, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis but are not given detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the artificially created dataset and its potential noise, specifically mentioning the \"pristine\" set of tweets and outofcontext images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that more analysis is needed around the quality of the dataset and the amount of noise it might have. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the dataset might have noise due to the artificial creation process, and it provides a specific example of the \"pristine\" set of tweets that might contain misinformation or outofcontext images. However, the comment lacks specific examples or references to support the claim that the dataset is indeed noisy. Without detailed evidence or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, suggesting that it might contain noise due to its artificial creation process. It provides a specific example of the \"pristine\" set of tweets that might not be pristine enough and could contain misinformation or outofcontext images. This feedback is valuable as it highlights a potential weakness in the dataset that the authors should address. However, the comment could be more helpful if it offered suggestions on how to analyze the dataset or how to mitigate the potential noise. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific theoretical aspects to explore or methods to demonstrate convergence. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these aspects should be addressed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the theory profs or convergence properties should be explored or demonstrated. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. This feedback is clear and actionable, as it points out a critical area where the paper could be strengthened by providing more theoretical analysis and experimental evidence. However, the comment could be more helpful if it offered specific suggestions on how to address this gap, such as which theoretical aspects to explore or how to demonstrate convergence. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the authors\" choice of operators and suggests considering the \"and\" operator or elementwise max. While it implies that the authors should reconsider their choices, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"261\" and \"272,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\" choice of operators and suggesting that the \"and\" operator or elementwise max might be better options. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" choice of operators and suggests considering the \"and\" operator or elementwise max. However, it does not provide any reasoning or evidence to support why these alternatives might be better options or how they relate to the current choices. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" choice of operators and suggests considering the \"and\" operator or elementwise max. This feedback is 3 as it prompts the authors to reconsider their choices, which could potentially lead to a more effective and efficient approach. However, the comment lacks depth and does not provide specific guidance or examples on how the authors might incorporate these alternatives into their work. While it points out a potential area for improvement, it could be more helpful with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that it might introduce noise due to the averaging of multiple contextual representations. However, it does not provide explicit guidance on how to clarify the description or address the issue of noise. The authors are left to infer that they need to clarify the description and possibly reconsider the averaging approach. While the comment identifies a potential problem, it lacks concrete instructions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, pointing out that the averaging of multiple contextual representations might introduce noise and suggesting that only one instantiation is likely correct. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging multiple contextual representations might introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is likely correct and that averaging multiple representations could lead to noise. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and potential consequences to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the averaging of multiple contextual representations might introduce noise. It provides a logical reasoning that only one instantiation is likely correct, which could lead to noise. This feedback is clear and actionable, as it points out a potential weakness in the description and suggests a possible improvement. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or address the issue of noise. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the selection of 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the potential impact of this selection on the underestimation of performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the selection of only 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. This is a relevant question that could prompt the authors to reconsider their methodology or provide additional context to explain their choice. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the description of the data sources, specifically mentioning that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be revised to make the description more accurate and precise. The action is concrete, as it details the specific change needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the description of the data sources, suggesting that the authors should mention Li et al. (2019a) earlier to clarify and improve the precision of the information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the description of the data sources, specifically mentioning a discrepancy between lines 226238 and 242244. The reviewer suggests that the description can be revised to clarify the source of the data, which is a reasonable observation. However, the comment lacks specific examples or references to support the claim that the data is a subset of Li et al. (2019a)\u2019s dataset, which would strengthen the verifiability. As it stands, the claim is 3, as it points out a potential issue but requires more detailed evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the description of the data sources, specifically noting that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback is clear and actionable, as it provides a specific suggestion for how the authors can revise their description to avoid confusion and ensure clarity. By addressing this issue, the authors can improve the accuracy and comprehensibility of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for a supporting explanation. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should clarify the purpose of the reported duration and potentially include information about the time spent by the user waiting for the model to generate a response. While the action is implied, it is clear and concrete, as it guides the authors to provide a more detailed explanation or clarification in their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and requests a supporting explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests a supporting explanation. It does not make a subjective claim or express an opinion, but rather seeks clarification on the methodology. Therefore, it is a factual request for information and does not require verification. It is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the purpose of the average duration reported in Table 1, noting the lack of a supporting explanation. It highlights a potential gap in the paper\"s methodology section, which could be clarified to provide a better understanding of the results. While the comment identifies an area for improvement, it does not offer specific suggestions or guidance on how to address this issue. The authors are left with a clear direction to provide a more detailed explanation, but the comment lacks actionable advice. Therefore, it is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests clarification on the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action for the authors to take, as it clearly identifies the specific area that needs clarification. The comment also expresses gratitude for the authors\" response, which implies that the authors have already addressed this issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve the clarity of their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification on the splits used for obtaining the ATIS numbers in Table 4. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of clarity needed in the paper, specifically regarding the splits used for obtaining the ATIS numbers in Table 4. By asking for clarification, the reviewer provides actionable feedback that can help the authors improve the transparency and understandability of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 3 as it directs the authors to a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, and it recommends correcting the wording. While the comment explicitly identifies the issue with the wording, it does not provide specific guidance on how to correct it or what alternative phrasing might be more appropriate. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.791,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting that the authors should correct the phrase \"on par or better\" to avoid a cognitive bias among NLP researchers. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers to phrase results in a certain way, specifically by using \"on par\" for instances where they perform worse and \"better\" for the rest. The reviewer suggests that the wording in the paper should be corrected to avoid this bias. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to fully understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It points out a potential cognitive bias among NLP researchers to phrase results in a certain way, which could lead to misinterpretation. The comment suggests correcting the wording to avoid this bias, providing a clear and actionable suggestion for improvement. However, it could be more helpful if it offered additional guidance on how to rephrase the sentence or provided examples of alternative wordings. Overall, the comment is 4 as it highlights a specific area for improvement and offers a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to clarify or explain these points, but without concrete guidance, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the interpretation of results, particularly regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions about the interpretation of results in Table 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. While the comment identifies areas of confusion, it does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not guide the authors on how to address these issues or improve the clarity of the results. As a result, the comment is 2, as it points out potential areas for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the inconsistent spacing between accuracy and standard deviation. This is an explicit observation that the authors can directly address by ensuring consistent spacing in their tables. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects the presentation\"s aesthetics. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are inconsistencies in the spacing between accuracy and standard deviation in Tables 2 and 3, which affects the presentation\"s aesthetics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting inconsistent spacing between accuracy and standard deviation. This is a clear and actionable observation that the authors can address to improve the presentation of their data. By pointing out this inconsistency, the comment provides valuable feedback that can help the authors enhance the aesthetics and readability of their tables. However, the comment could be more helpful if it offered suggestions on how to standardize the spacing or provided examples of how other tables in the field typically present this information. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing antecedent in the text and suggests checking the references for format issues, such as capitalization and bibliographic details. While the comment identifies a specific issue with the references, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to check the references for formatting errors, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number \"781,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the references, suggesting that they should be checked for format, such as capitalization and bibliographic details. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of references, noting that the antecedent is missing and suggesting that the references should be checked for capitalization and bibliographic details. While the comment highlights a clear and actionable issue, it does not provide detailed guidance on how to address the formatting errors or suggest specific tools or methods to use for verification. The authors are left with a clear direction but may need to infer more detailed instructions to fully resolve the issue. Therefore, the comment is 3, as it points out a specific problem but lacks comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or what specific aspects of the paper could be revised to enhance its originality. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered a lack of novelty, namely the application of similar ideas to videotext models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, specifically mentioning that adversarial attacks on text have been done on many NLP and imagetext models. The reviewer supports this claim by referencing related work in the paper, which summarizes the existing literature. However, the comment does not provide specific examples or references to the existing work, making it 3. The authors would need to infer the specific works mentioned and potentially conduct additional research to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models. It highlights that the paper summarizes existing work in this area and suggests that the only new effort is to apply similar ideas to videotext models. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it highlights a potential area for improvement, but it lacks actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It provides a clear and concrete suggestion to improve the organization of the section by recommending separate paragraphs for lexical features and sentencelevel features. This explicit guidance offers a direct action for the authors to take, making the comment 5. Authors know exactly what changes to make to improve the clarity and coherence of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the intertwined explanations for features and the suggestion to organize the section with separate paragraphs for lexical features and sentencelevel features. This provides clear guidance on how to improve the clarity and coherence of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It suggests that the section would be more coherent with separate paragraphs for lexical features and sentencelevel features. While the comment provides a logical reasoning for the suggested improvement, it lacks specific examples or references to support the claim that the current organization is confusing. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and clarity of the explanations for features in Section 3.2. It suggests that the section would be more coherent and easier to understand with separate paragraphs dedicated to lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the organization and readability of their draft. By following this advice, the authors can enhance the clarity and comprehensibility of their explanations, which is valuable for improving the overall quality of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a more concise presentation or offering suggestions for prioritizing content. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not specify which section or part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the assumptions or experimental results are problematic or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that dedicating a whole section and experimental results for the assumptions is a significant amount of space. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it could be improved. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any specific guidance or suggestions on how the authors might address this issue, such as by streamlining the content or focusing on the most important aspects. The comment lacks actionable feedback, leaving the authors without a clear path forward to improve their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include an ablation study to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct an ablation study but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of integrated gradients to measure attribution and the proposed postprocessing steps to filter out \"falsepositive\" neurons. It also suggests an ablation study, providing clear guidance on what needs to be addressed. However, the comment does not specify which part of the paper should include the ablation study, making it fully grounded but underspecific. Therefore, this comment aligns with category 4.", "verifiability_rationale": "The review point claims that using integrated gradients to measure attribution has been studied in existing papers and suggests that an ablation study may be needed to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. However, the comment lacks specific references to these existing studies or detailed reasoning to support the claim that an ablation study is necessary. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by suggesting an ablation study to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance their work. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would benefit the paper. Despite this, the suggestion is valuable and provides a clear direction for the authors to improve their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it suggests a method of matching the head of noun phrases. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the method. The comment lacks concrete instructions or examples, leaving the authors uncertain about how to implement the suggested approach. Therefore, the comment is 3, as it identifies a potential issue but does not offer detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses a specific issue related to identifying antecedents in the context of a prediction involving a pronoun. It suggests a method of matching the head of noun phrases, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with identifying antecedents in the context of a pronoun, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about identifying antecedents in the context of a prediction involving a pronoun. It suggests a method of matching the head of noun phrases, but it does not provide any supporting evidence, reasoning, or references to justify why this method might be insufficient or inadequate. The claim lacks detailed explanation or examples, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the methodology proposed by the authors, specifically regarding the identification of antecedents in the context of a prediction involving a pronoun. It raises a valid point about the potential limitations of the proposed method when the head word is not a pronoun. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it highlights a potential weakness, it lacks actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it points out a specific area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It implies that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to incorporate these baselines or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"MST baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison between the proposed models and models that only consider different senses but not sememes. The comment suggests that the paper would be stronger with the inclusion of more baselines based on related work. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. The comment provides a logical reasoning by pointing out the potential comparison between the proposed models and existing models that only consider different senses. However, it lacks specific examples or references to support the claim that the MST baseline is an example of such a model. Additionally, it does not provide detailed guidance on how to incorporate more baselines or what specific aspects of the comparison should be addressed. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the comparison between the proposed models and models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their comparison and strengthen their paper. By suggesting additional baselines and emphasizing the importance of sememes, the comment offers a constructive way for the authors to improve their draft. However, it could be more helpful if it provided specific examples of related work or detailed guidance on how to incorporate these baselines. Overall, the comment is 4 as it effectively guides the authors in enhancing their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract could be improved by providing an example of the inconsistency between evaluating with gold answers and human evaluation. While the comment implies that the authors should include this example, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an example to make the abstract more effective. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: adding an example of the inconsistency between evaluating with gold answers and human evaluation. This specificity helps the authors understand what needs to be addressed to improve the abstract. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract is wellwritten and invokes intrigue, but it also provides a suggestion for improvement. The reviewer suggests that including an example of the inconsistency between evaluating with gold answers and human evaluation could enhance the abstract further. However, the comment lacks specific examples or detailed reasoning to support why this addition would be beneficial or how it would improve the abstract. While the suggestion is logical, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the abstract is wellwritten and invokes intrigue, which is a positive observation. It also suggests that the abstract could be improved by providing an example of the inconsistency between evaluating with gold answers and human evaluation. This feedback is actionable and constructive, as it suggests a specific way to enhance the abstract by including an example that could help clarify the inconsistency. However, the comment could be more helpful if it provided guidance on how to select or frame the example, which would make it more comprehensive. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect of their work. The comment lacks actionable details, such as recommending specific ways to present the selection process or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the selection of frame similarity factors and attributes similarity factors. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity as it does not provide details on what is unclear about the selection process or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential area of confusion regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide specific guidance or suggestions on how the authors might clarify this aspect of their work. Without actionable feedback or detailed explanations, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This provides a clear and direct action for the authors to take, which is to include these discussions in their draft. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"joint learning process\" and the specific models \"RNN\" and \"CopyRNN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the convergence of the joint learning process and how stable points in the probabilistic metric space are obtained. This provides clear guidance on what the authors need to include in their discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This claim is 3 as it logically suggests that understanding the convergence process is crucial for reproducing results. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully grasp the importance of this discussion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that discussions on the convergence of the proposed joint learning process are required. This feedback is clear and actionable, as it directs the authors to provide more detailed information on how the stable points in the probabilistic metric space are obtained. By addressing this point, the authors can enhance the clarity and reproducibility of their results. However, the comment could be more helpful if it provided examples or references to similar discussions in related literature, which would further guide the authors in developing their analysis. Overall, the comment is 4 as it effectively points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides explicit actions to take, it does not offer concrete guidance on how to implement these suggestions or what specific terminology should be used. The authors are left with a clear understanding of what needs to be done but without detailed instructions on how to execute these tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"681\" and \"778,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it points out that the terminology used in Tables 1 and 2 should be consistent. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also mentions that it would be better to use consistent terminology in Tables 1 and 2. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the current terminology is inconsistent or inadequate. This makes the claim 3, as the authors would need to make a concerted effort to address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors discuss the results for the task of inferring knowledge on objects and include results for model (B). It also points out that it would be better to use consistent terminology in Tables 1 and 2. This feedback is clear and directs the authors to specific areas for improvement, making it 5 in guiding the authors to enhance their draft. However, the comment could be more helpful if it provided additional context or examples of how the terminology should be consistent. Overall, the comment is 5 as it offers concrete suggestions for improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific sentence in line 212 that is not correct and suggests a correction. It provides a clear and explicit action for the authors to make the sentence more accurate by suggesting that they should say they do a bidirectional encoder instead of a GRU. The comment also references Figure 2, which provides a concrete example of what the correct sentence should look like. This level of detail and specificity makes the action explicit and concrete, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the sentence, suggesting a correction by proposing a more accurate description of the process. The comment provides a clear and detailed suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not correct and suggests a correction. The reviewer provides a specific example from Figure 2, which supports the claim by showing the correct way of encoding a source sentence into a set of vectors. This provides a clear and concrete example, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar work, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the sentence in line 212, noting that it is not strictly correct. It suggests a correction by proposing that the authors should say they do a bidirectional encoder instead of a GRU. Additionally, the comment references Figure 2 to provide a concrete example of what the correct sentence should look like. This feedback is clear and actionable, as it guides the authors on how to improve the accuracy of their description. However, the comment could be more helpful if it explained why the current sentence is incorrect or provided additional context on the significance of the correction. Overall, the comment is 4 as it offers a clear and specific suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment implies that the authors should consider including these baselines, it does not provide explicit instructions or detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include additional baselines but are not given specific steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, it does not specify which part of the paper this extension or the baselines should be added to, making it weakly grounded. The comment is specific in suggesting the inclusion of character embeddings as a baseline, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension is necessary or how character embeddings would enhance the work. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement these additional baselines or why they are necessary. The suggestion is 3 as it points out a potential area for enhancement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the baseline models: the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It explicitly instructs the authors to compare their work with Campos et al. and to include comparisons with other domain adaptation methods mentioned in Section 8. The comment provides concrete guidance on what needs to be added to the paper, making it 5. The authors know exactly what steps to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 277,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. While the comment identifies a potential issue with the baseline models, it lacks specific examples or references to Campos et al. or other domain adaptation methods to fully substantiate the claim. The suggestion to compare with these works is logical, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the weakness of the baseline models used. It points out that the authors have not compared their work with Campos et al. (2020), which also uses feedback in QA tasks, and have not included comparisons with other domain adaptation methods mentioned in Section 8. This feedback is clear and actionable, as it provides specific guidance on what the authors need to address to strengthen their work. By addressing these comparisons, the authors can significantly enhance the rigor and relevance of their study. However, the comment could be more helpful if it included suggestions on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is 5 as it clearly instructs the authors on how to make a specific change to their figure, ensuring that they know exactly what needs to be done to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the yaxis label, and suggests that it should use \"Exact Match ratio\" directly. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment provides a specific and actionable suggestion for improving the clarity of Figure 5 by recommending that the yaxis label use \"Exact Match ratio\" directly. This feedback is clear and easy to implement, as it directly addresses a potential source of confusion for readers. By making this change, the authors can enhance the clarity and accessibility of their figure, which is a valuable improvement for the overall quality of their work. Therefore, the comment is 5, as it provides a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to ensure that the knowledge bases are free from societal biases. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains but does not provide any context or explanation for this preference. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains, but this is not directly related to the issue of societal biases. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. While this is an important consideration, the comment lacks specificity and does not provide any actionable guidance or suggestions on how the authors might address this issue. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains, but this is not directly related to the main concern about societal biases. Overall, the comment identifies a potential area for improvement but does not offer detailed or constructive feedback, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while it is easier to show that something (e.g., attention in seq2seq MTL) is not working, the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the reasons for failure or how to modify the attention mechanism. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate and address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the discussion of attention mechanisms, but this inference is not direct. The comment is specific in its suggestion to investigate and modify the attention mechanism, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment highlights a common issue in research, where it is easier to show that something is not working but more challenging to identify the underlying reasons and make improvements. It suggests that the true value lies in finding out why a particular aspect (e.g., attention in seq2seq MTL) is not working and changing the attention mechanism to make it work. While the comment identifies a general problem, it does not provide specific guidance or suggestions on how to address this issue or what aspects of the attention mechanism need improvement. The feedback is 3 as it points out a common problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Table 3 should include many strong baselines that are not currently compared in the paper. It explicitly asks the authors to justify the reason for not including these baselines. This feedback provides a clear and direct action for the authors to take, which is to include additional baselines and explain the rationale behind their exclusion. The comment is specific and provides concrete guidance on what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MCNC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that Table 3 should include many strong baselines that are not currently compared in the paper, and it asks for a justification of the reason for their exclusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 3 should include many strong baselines that are not currently compared in the paper. However, it does not provide any specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to justify why these baselines should be included or how they would enhance the analysis. Without specific examples or references, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the inclusion of strong baselines in Table 3. It suggests that the MCNC should have many strong baselines that are not currently compared, such as those mentioned in reference 1. This feedback is clear and actionable, as it prompts the authors to consider including additional baselines and justifying their exclusion. By addressing this point, the authors can enhance the comprehensiveness and robustness of their analysis. However, the comment could be more helpful if it provided specific examples or references to the baselines that should be considered. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It specifically mentions the reference to Supplementary Figure 6 in S3.1 and the model comparison and other details of the span vs. sentence investigation as examples of this reliance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the paper\"s independence. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their reliance on supplementary materials but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as S3.1 and the model comparison, allowing the authors to accurately identify the parts being addressed. It also specifies the issue of reliance on supplemental space, which is a clear concern for the paper\"s independence. However, the comment could be more specific in detailing what aspects of the paper\"s reliance on supplemental space are problematic or how it affects the paper\"s credibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, which makes it not truly independent. The reviewer supports this claim by referencing specific sections, such as S3.1 and the model comparison, where the paper references supplementary materials. Additionally, the reviewer mentions the investigation of spans vs. sentences as another example of reliance on supplementary materials. This provides a clear and specific rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s independence, noting that it relies heavily on supplemental space to contain the main content. This is a critical observation, as it suggests that the paper may not stand on its own without additional materials. The comment specifically references specific sections, such as S3.1 and the model comparison, where the paper relies on supplementary information. This feedback is valuable as it highlights a potential weakness in the paper\"s structure and content, prompting the authors to reconsider their approach to independence. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to integrate the supplementary materials more seamlessly into the main text. Overall, the comment is 4 as it identifies a critical area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also asks about the KNs in source language or in English, as the mentions have been translated to English. The authors are instructed to correct Figure 3. While the comment provides explicit actions to take, it does not specify how to implement these changes or what specific details should be added to the input or figure. The authors are given clear guidance on what to do, but the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as adding information about the input being word embeddings and clarifying the KNs in source language or English. The comment also provides a clear request for correction, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also asks about the KNs in source language or in English, as the mentions have been translated to English. The comment is 3 as it provides a logical suggestion for clarifying the input and references a specific model for comparison. However, it lacks specific examples or references to support the claim that adding this information would be beneficial. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also raises a question about the KNs in source language or in English, given that the mentions have been translated to English. This feedback is clear and offers a concrete way for the authors to improve their draft by clarifying the input and potentially enhancing the clarity of their work. However, the comment could be more helpful if it provided additional context or examples of how this information would benefit the paper. Overall, the comment is 4 as it directs the authors to make specific improvements, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the experiments. The feedback is vague and lacks concrete steps for the authors to take, leaving them without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the potential of the proposed augmentation method, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are the main weakness of the paper, as they are limited to an extremely lowresource regime and sentence classification, which are not the only cases for data augmentation in realworld applications. The reviewer also suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. While the comment identifies specific limitations and potential areas for improvement, it lacks detailed reasoning or references to support the claim that the experiments are weak. The suggestion for expanding the scope of the experiments is logical but could be strengthened with more specific examples or references. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. This feedback is valuable as it highlights areas where the paper could be strengthened, particularly by expanding the scope of the experiments to include more diverse tasks and scenarios. However, the comment could be more helpful if it provided specific suggestions on how to address these weaknesses or examples of other tasks that could be explored. Overall, the comment is 4 as it directs the authors to areas needing improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task, considering that generic summarization systems often build knowledge graphs and generate summaries accordingly. The reviewer suggests that with the increase in node numbers, concept maps become harder to distinguish, making general summaries more readable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they should consider the necessity of treating concept map extraction as a separate task. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether concept map extraction should be treated as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion that general summaries should be more readable, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. The comment suggests that general summaries should be more readable due to these challenges. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that concept map extraction should be treated as a separate task. Without such evidence or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the necessity of treating concept map extraction as a separate task, given that generic summarization systems often build knowledge graphs and generate summaries accordingly. The reviewer suggests that with the increase in node numbers, concept maps become harder to distinguish, making general summaries more readable. This feedback is 3 as it prompts the authors to consider the tradeoffs between treating concept map extraction as a separate task versus incorporating it into general summarization systems. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the draft. To be more helpful, the comment could provide examples of how other studies have addressed similar challenges or offer specific recommendations for integrating concept map extraction into general summarization systems. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It also asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions provide clear guidance on what the authors need to address to improve their draft. The action is explicit and concrete, as it specifies exactly what needs to be added or clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. The comment also raises questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This level of detail provides clear guidance on what the authors need to address to improve their draft, making the comment 5.", "verifiability_rationale": "The review point raises questions about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions imply a need for clarification or evidence to support the claim. However, the comment does not provide any supporting evidence or references to substantiate these claims. Therefore, the comment is considered 2, as it raises important questions but lacks the necessary evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by asking the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It also raises specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions prompt the authors to provide more detailed information about the annotation process, which could enhance the clarity and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or what specific aspects to focus on. Overall, the comment is 4 as it provides clear guidance on areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that lines 102106 are misleading, as they refer to a \"such distribution\" that cannot be related to the discussion in the previous section. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific changes or clarifications to be made to the text. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the misleading statement regarding \"such distribution\" and its relation to the discussion in the previous section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading, as they refer to a \"such distribution\" that cannot be related to the discussion in the previous section. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text, noting that lines 102106 are misleading due to the use of the term \"such distribution.\" It points out that this reference cannot be related to the discussion in the previous section. While the comment highlights a potential problem, it does not provide any suggestions or guidance on how the authors might clarify or correct this issue. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. While the action is implied, it is clear and provides a concrete direction for the authors to take. The comment explicitly states what the authors should do, which is to include examples of the system on actual texts. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where examples could be included. Without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. This feedback is 3 as it points out a potential area for improvement in the paper, which could enhance the reader\"s understanding of the system\"s capabilities. However, the comment lacks specific guidance on how to implement this suggestion or what specific examples would be most effective. While it identifies a potential improvement, it does not provide detailed instructions or examples to fully support the authors in making these changes. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s claims would benefit from more indepth analysis. However, it does not provide specific examples of which claims need more analysis or what aspects of the claims should be explored further. The comment lacks concrete guidance on how to improve the analysis or what specific aspects to focus on. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a number of claims from the paper would benefit from more indepth analysis, but it does not specify which claims or parts of the paper are being referred to. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts of the paper need further analysis. Additionally, the comment lacks specificity regarding what aspects of the claims should be analyzed more deeply. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not provide specific examples or detailed reasoning to support why these claims need further examination. Without specific claims or examples, the authors may find it challenging to understand which parts of the paper need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not specify which claims or aspects of the paper need this additional analysis. Without specific guidance or examples, the authors are left without actionable feedback on how to improve their draft. The comment lacks depth and specificity, making it 2 for the authors in terms of identifying areas for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two specific areas where the presentation of the model needs improvement: the pooling method used for embedding features (line 397) and the clarity of Equation (7) in line 472. It provides explicit questions about the pooling method and the definition of E_i in Equation (7), asking whether it represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability. This feedback is clear and provides concrete actions for the authors to take, such as clarifying the pooling method and the definition of E_i. The explicit nature of the questions and suggestions makes this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the pooling method used for embedding features and the definition of E_i in Equation (7). The comment provides detailed guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of the pooling method used for embedding features (line 397) and the definition of E_i in Equation (7) in line 472. It suggests that the LHS of Equation (7) should be a conditional probability. The comment provides logical reasoning by pointing out that the pooling method and the definition of E_i are unclear, and it questions whether they represent the type or identity of AC i. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the context and details to fully understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the presentation of the model needs improvement, providing clear and actionable feedback. It points out that the pooling method used for embedding features is not clearly defined and that Equation (7) in line 472 is not clear enough, questioning whether E_i represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability, which is a valuable suggestion for clarifying the model presentation. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and understanding of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a discrepancy between the paper\"s claims and its actual content. It points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. While the comment provides a clear direction for improvement, it lacks specific guidance on how to test the hypotheses or what aspects of the topics should be explored. The action is explicit but somewhat vague, as the authors know they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The comment suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. However, the comment lacks specific examples or references to support the claim that the hypotheses are not tested or discussed. Without detailed evidence or examples, the claim is 3, as it provides a logical basis but requires more substantiation to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. This is a critical observation that could lead to confusion and misleading expectations for readers. The comment suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics, at least to some extent. While the feedback is clear and actionable, it could be more helpful if it provided specific guidance on how to test the hypotheses or what aspects of the topics should be explored. Overall, the comment is 4 as it highlights a significant gap in the paper and offers a direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential use of feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set used by Uto et al. (2020) to achieve a QWK of 0.801. While the comment implies that the authors should explore this possibility, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the same feature set. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the potential use of feature engineering to improve the performance of the paper, suggesting that the authors could consider using the same feature set used by Uto et al. (2020) to achieve a QWK of 0.801. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where feature engineering could be applied. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the use of a particular feature set, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using feature engineering could improve the performance of the paper, referencing Uto et al. (2020) as an example. However, the comment does not provide specific details or evidence from Uto et al. (2020) to support this claim. It lacks specific examples or references to the features used in Uto et al. (2020) that led to the reported performance. This makes the claim 3, as it provides a general suggestion but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential use of feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set used by Uto et al. (2020) to achieve a QWK of 0.801. While the comment identifies a potential area for improvement, it lacks specific guidance on how to implement this suggestion or what aspects of the feature engineering process might be relevant to the current work. The feedback is 3 as it points out a potential area for enhancement but could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and seeks clarification on its role in the evaluation process. It implies that the authors should provide more information about how the CS is used, whether it is used for augmenting the training material, and the data split used. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the CS. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Challenge Set\" (CS), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the CS is used, whether it is used for augmenting the training material, and the data split used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically inquiring about its role in evaluation and whether it is used for augmenting the training material. It also asks for clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words. It also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to clarify the terminology. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the use of \"knowledge\" and the generalization of the model, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim of generalization to different knowledge and questions the use of constituent parse as knowledge. It also mentions the term \"knowledge\" and its potential misuse in the context of the paper. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the use of \"knowledge\" and the generalization of the model, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words. The reviewer questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. The comment provides a logical reasoning for the concern, noting that \"knowledge\" is typically used to refer to external knowledge sources, not syntax or semantics. However, the comment lacks specific examples or references to support the claim that the use of \"knowledge\" is misleading. This makes the claim 3, as the authors would need to further explore and address the issue to fully understand and resolve the concern.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words. It also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. This feedback is 3 as it highlights a potential misalignment in terminology and provides a direction for clarification. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how the terminology could be clarified. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should investigate the gap between the oracle GAP for PPDBClus and the performance of the clustering approach, but it lacks specific instructions on how to conduct this investigation or what specific aspects to focus on. Additionally, it does not offer suggestions on how to improve the uniformity of the performance across all parts of speech. As a result, the comment is 3, as it identifies areas for concern but lacks concrete guidance on how to address them.", "grounding_specificity_rationale": "The comment addresses the performance of the TWSI model on nouns and the contradiction with the claim of generalizability to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is not uniform, which directly contradicts the claim. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about the performance and the contradiction with the claim, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is not uniform, which directly contradicts the claim that the clustering approach is generalizable. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it provides a direction for further exploration but does not fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a concern about the performance of the TWSI model on nouns, which is a significant issue. It also questions the generalizability of the clustering approach to all parts of speech, given the performance gap between the oracle GAP for PPDBClus and the clustering approach. This feedback is valuable as it highlights a potential weakness in the paper\"s claims and encourages the authors to investigate and address these issues. However, the comment could be more helpful if it provided specific suggestions on how to investigate and resolve the performance gap or how to improve the generalizability of the clustering approach. Overall, the comment is 3 as it points out important areas for improvement but lacks detailed guidance on how to address them."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It explicitly requests examples of spurious structures to help clarify the discussion. This feedback is clear and provides a specific action for the authors to take, which is to provide examples of spurious structures to support their claims. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is that it is too abstract and does not provide insights into why the new model is better than MH. The comment also requests examples of spurious structures to help clarify the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. However, the comment lacks specific examples or references to support the claim that the discussion is abstract or unclear. Without these details, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstractness of the discussion in Section 5.2, noting that it does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. While the comment highlights a clear area for improvement, it lacks depth and does not provide specific guidance on how to address the issue or what kind of examples would be helpful. This limits the comment\"s usefulness, as it points out a problem but does not offer detailed suggestions for improvement. Therefore, the comment is 3, as it provides some direction but could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is an explicit action that the authors can directly implement by adding this information to their draft. The comment is clear and provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a statement about the maximum number of tasks done by any annotator. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors can infer that it relates to the experimental setup or results, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting what needs to be added, but without clear grounding, it is difficult for the authors to pinpoint the exact location in the paper where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors should state the maximum number of tasks done by any annotator. This is a specific and actionable piece of feedback that can help improve the transparency and reproducibility of the study. By including this information, the authors can provide a clearer understanding of the experimental setup and the variability in the number of tasks performed by different annotators. However, the comment could be more helpful if it explained why this information is important or how it might impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested. However, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not specify which parts of the paper are particularly challenging to understand or where the authors should focus their efforts to improve clarity. Without explicit references to sections or specific analyses, the authors may struggle to identify the areas needing attention. Therefore, the comment is weakly grounded because it does not specify which parts of the paper are being addressed, and it is not specific in detailing what needs to be clarified. This aligns with a score of 2.", "verifiability_rationale": "The review point expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant challenge in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different pieces of the puzzle fit together. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors\" attention to a key area for clarity, but it could be more beneficial with actionable advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and direct action for the authors to take, as it provides a specific and concrete step to enhance the presentation of their results. The comment is 5 because it clearly specifies what needs to be added to the table, making it easy for the authors to implement the suggestion.", "grounding_specificity_rationale": "The comment suggests adding the hard prompt baseline to Table 1 to show the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. However, it does not provide any reasoning or evidence to support why this inclusion is necessary or how it would benefit the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and actionable suggestion that could enhance the presentation of the results. By including the hard prompt baseline, the authors can provide a more comprehensive comparison of their methods, allowing readers to better understand the performance improvements. However, the comment could be more helpful if it explained why the inclusion of the hard prompt baseline is important or how it would benefit the paper. Overall, the comment is 4 as it provides a specific and constructive suggestion for improving the presentation of the results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. While it implies that the authors should include numerical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the application to popular algorithms should be discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for numerical results and application to popular algorithms, but it is 1 as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of numerical results in the paper. It expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. This feedback is 3 as it highlights a gap in the paper that could be addressed to enhance its comprehensiveness and rigor. However, the comment lacks specific guidance on how to implement these improvements or what specific numerical results should be included. To be more helpful, the comment could provide examples of what kind of numerical results would be relevant or suggest how to integrate these findings into the existing work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The comment is specific in detailing what additional comparisons are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental comparisons and suggests testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional comparisons are needed and why they are important. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional comparisons are necessary or how they would impact the results. Without such justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental comparisons, specifically noting that the proposed InvP method is not tested with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback is valuable as it suggests a potential area for improvement in the experimental setup, which could enhance the robustness and generalizability of the results. However, the comment could be more helpful if it provided specific guidance on how to implement these additional comparisons or why they are important. Overall, the comment is 4 as it points out a relevant area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection is not welldrawn and recommends either formalizing it more or adjusting the language to clarify the connection. This provides a clear and explicit action for the authors to take, either by strengthening the formal basis of the connection or by rephrasing the language to enhance clarity. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that the probabilistic connection is not welldrawn and recommends either formalizing it more or adjusting the language to clarify the connection. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors can infer that it relates to the discussion of the probabilistic connection, but this inference is not direct. The comment is specific in suggesting how to address the issue, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not welldrawn and suggests that it should be formalized more or clarified in the language. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific sections of the paper where the connection is unclear or inadequately formalized. As a result, the claim is 3, as it points out a potential issue but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of formalization or clarity in the probabilistic connection. It suggests that the authors either formalize this connection more or adjust the language to clarify it. This feedback is clear and actionable, as it provides a direct path for the authors to improve the draft by either strengthening the formal basis of the connection or rephrasing the language to enhance clarity. However, the comment could be more helpful if it offered specific examples or guidance on how to formalize the connection or clarify the language. Overall, the comment is 4 as it effectively points out a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is explicit in its request for additional evidence, providing a clear action for the authors to take. However, it does not specify what kind of evidence would be sufficient or how to present it, leaving some room for interpretation. Therefore, the comment is 4, as it identifies a specific area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests providing empirical evidence to support the claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of evidence would be sufficient. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this claim is made, the comment lacks full grounding. It is specific in its request for empirical evidence but lacks detailed guidance on how to present it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by providing empirical evidence to substantiate the claim. However, the comment could be more helpful if it provided guidance on what kind of evidence would be sufficient or how to present it effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for modifications to improve the scalability of the robust training scheme. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the robust training scheme, specifically questioning its scalability to practical datasets, particularly those with highdimensional domains. However, it does not specify which part of the paper this concern is based on, such as a specific section or figure where the robust training scheme is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issue with the scalability of the robust training scheme, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those with highdimensional domains. The comment provides a logical reasoning by suggesting that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning and potential implications to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. It points out that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. While the comment highlights a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the scalability of their robust training scheme. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or detailed recommendations for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without understanding the type of style shifts that occur during this period, it is difficult to appreciate what the model is capturing. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or specific actions for the authors to take, such as recommending additional datasets or discussing the type of style shifts that occur during the fouryear period. As a result, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without understanding the type of style shifts that occur during this period, it is difficult to appreciate what the model is capturing. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might infer that it relates to the datasets or experimental design sections, the comment lacks explicit grounding. It is specific in its concern about the duration and type of style shifts, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point questions the choice of datasets and the duration of four years for studying style shifts, suggesting that it may not be sufficient to capture the type of style shifts that occur during this period. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is not 5, as it relies on a general assumption rather than concrete examples or data. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the duration of four years for studying style shifts. It questions whether four years is sufficient to capture the type of style shifts that occur during this period. This feedback is 3 as it prompts the authors to consider the adequacy of their dataset choice and the potential limitations in understanding the model\"s capturing of style shifts. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative datasets or discussing the type of style shifts that occur during the fouryear period. While it points out a relevant area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the callout to Table 5 should be changed to Table 3 and provides the correct page and section number. Additionally, it points out that the figure 6 callout is not directing properly. This feedback is clear and provides specific actions for the authors to take, ensuring that they know exactly what needs to be corrected. The explicit nature of the instructions and the concrete details on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the callout to Table 5 and the figure 6 callout, providing detailed guidance on how to correct these issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the callout to Table 5 should be changed to Table 3 and that the figure 6 callout is not directing properly. However, the comment does not provide any supporting evidence, reasoning, or examples to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a mistake in the callout to Table 5, which should be changed to Table 3, and noting that the figure 6 callout is not directing properly. This feedback is clear and directs the authors to correct specific errors in their paper, ensuring that the references are accurate and easy to follow. By addressing these issues, the authors can improve the clarity and accuracy of their work. Therefore, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a significant concern with the paper\"s experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be beneficial in a generative setting. While the comment implies that the authors should include comparisons with SketchRNN, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of comparisons with other models and the absence of an explanation for the selfcomparison. The comment suggests that comparisons with SketchRNN could be beneficial in a generative setting. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a significant concern due to the lack of comparisons with other models and the absence of an explanation for the selfcomparison. The reviewer suggests that comparisons with SketchRNN could be beneficial in a generative setting. While the comment identifies a potential issue with the paper\"s experimental design, it lacks specific examples or references to support the claim that comparisons with SketchRNN would be beneficial. This makes the claim 3, as the authors would need to make a logical inference to understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be beneficial in a generative setting. While the comment highlights a critical area for improvement, it does not provide detailed guidance on how to address this issue or what specific comparisons with SketchRNN could entail. The feedback is 3 as it points out a significant weakness but lacks actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment recommends conducting more analysis and providing comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint regarding the benefits of increased model capacity for both CNNs and ViTs. The comment provides specific observations about the performance of DeiTB models compared to DeiTT and DeiTS, noting that DeiTB does not outperform DeiTS in certain datasets. However, it does not provide explicit guidance on how to conduct the analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. The comment provides specific observations about the performance of DeiTB models compared to DeiTT and DeiTS, noting that DeiTB does not outperform DeiTS in certain datasets. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim that the authors\" viewpoint is incorrect regarding the benefits of increased model capacity for both CNNs and ViTs. The reviewer provides specific observations from Figure 3, noting that DeiTB models do not outperform DeiTT or DeiTS in APTOS2019, ISIC2019, and CheXpert. This claim is supported by the data and observations presented, making it 4. However, the comment could be strengthened by providing more detailed analysis or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint regarding the benefits of increased model capacity for both CNNs and ViTs, based on the observations from Figure 3. The comment highlights that DeiTB models do not outperform DeiTT or DeiTS in APTOS2019, ISIC2019, and CheXpert, which is a significant finding. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct the analysis or what aspects to focus on. Overall, the comment is 3 as it identifies a specific area for improvement and challenges the authors\" viewpoint, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment acknowledges that the paper is not difficult to follow but points out specific areas that may cause confusion. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve clarity or what specific changes should be made to avoid confusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not specify which sections or parts of the paper these areas are located in, making it difficult for the authors to pinpoint the exact issues. The comment is specific in identifying potential areas of confusion, but it lacks grounding as it does not specify where these issues are located in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the identified areas of confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any detailed guidance or suggestions on how to address these areas of confusion. Without actionable feedback or specific examples, the authors are left without a clear path to improve the clarity of their draft. Therefore, the comment is rated as 2, as it points out an issue but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the claim of \"no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This feedback is clear and directs the authors to review the references mentioned to understand the tools available in the reinforcement learning setting. The action is explicit and concrete, as the authors know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the absence of corresponding tools for the reinforcement learning setting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides references to support the claim, which helps the authors understand the context and substantiate the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. However, the comment does not specify which references are being referred to or how they support the claim. This lack of detailed explanation or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some support but lacks the necessary detail to be 5.", "helpfulness_rationale": "The review comment challenges a claim made in the paper regarding the absence of corresponding tools for the reinforcement learning setting. It provides references to support the claim, which is a valuable piece of information for the authors. However, the comment could be more helpful if it explained why these references are relevant or how they address the issue raised. While the feedback is 3, it lacks depth and could be more actionable with additional context or explanation. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or how to improve the technical competency required to understand them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not specify which part of the paper this issue pertains to, such as the results section or a particular technique. The authors cannot confidently determine which part of the paper needs attention, making this comment weakly grounded. The comment is specific in its critique of the technical competency required to understand the results, but without explicit references to sections or techniques, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential issue with the results, suggesting that they are not immediately obvious and require a certain level of technical competency. This is a valuable observation that could prompt the authors to reconsider the accessibility and clarity of their results. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending ways to simplify the techniques or improve the presentation of results. While it identifies a potential weakness, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. While the comment implies that the authors should make this distinction, it does not provide explicit instructions or concrete steps on how to implement this distinction. The authors are left to infer that they should make this distinction, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this distinction is necessary or how it would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. While it identifies a potential area for clarification and differentiation, the comment lacks specific guidance or examples on how to implement this distinction. It does not provide actionable steps or detailed suggestions on how to enhance the clarity or relevance of this distinction. As a result, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the amount of data used to train the text disambiguation model and compares it to the data used for the endtoend system. It questions the conclusion that the direct model is clearly better, but still acknowledges that both systems are demonstrably superior to the baseline. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the discrepancy in data usage and the conclusion about the direct model. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the amount of data used to train the text disambiguation model is significantly lower than the data used for the endtoend system, which raises questions about the conclusion that the direct model is clearly better. However, the comment does not provide specific data or references to support this claim, making it difficult for the authors to verify the validity of the assertion. The lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system, which raises questions about the conclusion that the direct model is clearly better. It highlights a potential issue with the validity of the conclusion, but it does not provide specific suggestions or guidance on how the authors might address this concern or improve their analysis. While the comment points out an important area for consideration, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment highlights specific areas that need improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to provide more detailed explanations and evidence for GaRare\"s advantages over GaLore, as well as clarify the process of updating parameters. However, the comment lacks specific guidance on how to achieve these improvements, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GaRare\" and \"GaLore\" algorithms, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and provides a specific example of the lack of evidence or justification for its advantages over GaLore based on theoretical analysis. The comment also suggests that a more detailed algorithmic presentation is needed, particularly regarding the process of recovering updated parameters from projected gradients. While the comment identifies specific areas for improvement, it does not provide detailed reasoning or examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issues raised, making the comment 3. Therefore, the score is 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to address these issues, such as providing examples or references to similar works that have effectively motivated their algorithms or presented detailed algorithmic explanations. Despite this, the feedback is 4 as it directs the authors to critical areas that need attention and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides explicit actions, it does not offer detailed guidance on how to conduct the ablation study or the specific experiment with ATT(+H). The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left\" and \"visDial dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely conducting an ablation study on the visDial dataset and conducting an experiment on the performance of ATT(+H) in figure 4 left. The comment provides detailed guidance on what needs to be done, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides a logical request for additional experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact experiments and analyses required to address the suggestion. Therefore, the comment is 3, as it provides a clear direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. This feedback is clear and offers a concrete direction for the authors to improve their draft by conducting additional experiments and analyses. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers valuable suggestions for enhancing the paper, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of a reference to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"Continuous Conditional Random Fields Ristovski 2013\" and \"Continuous Conditional Neural Fields Baltrusaitis 2014,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of references to similar work that shares a similar structure and inference capabilities. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the relevance or significance of these references. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. This feedback is 3 as it points out a potential gap in the literature review that could enhance the authors\" understanding and comparison of their work. However, the comment could be more helpful if it provided specific examples or references to these similar works, which would guide the authors in incorporating them into their analysis. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. It also questions whether any input serves as white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the authors spend a lot of time showing WPA improves the test performance of the original model but do not provide insights into how WPA works. This feedback highlights a gap in the paper that needs to be addressed, suggesting that the authors should provide more detailed explanations or analysis to support their claims. The comment is explicit in its request for clarification and actionable, as it clearly identifies areas where the authors can improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"np.ones input,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of why WPA works and the implications of the results shown in Figure 2. The comment provides a clear direction for the authors to improve their draft by explaining the model\"s predictions and the limitations of Gaussian noise input. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the effectiveness of WPA and suggests that the authors should provide more insights into how it works. It references Figure 2, which appears to suggest that Gaussian noise input does not work as well as WPA. The reviewer also points out that the paper spends a lot of time showing WPA improves test performance but lacks insights into its mechanism. This claim is 3 as it provides a logical basis for the suggestion to explain WPA, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting several areas where the authors could improve their work. It suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. The comment also questions whether any input serves as a white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the paper spends a lot of time showing WPA improves the test performance of the original model but fails to provide useful insights into how WPA works. This feedback is highly valuable as it identifies specific areas where the authors can enhance their draft, particularly by providing more detailed explanations or analysis to support their claims. By addressing these points, the authors can significantly improve the clarity and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method part of the paper is similar to a related work mentioned, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification on this similarity. While the comment implies that the authors should provide more information or explanation regarding the similarities, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method part of the paper is similar to a related work mentioned, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification on this similarity. However, it does not specify which part of the paper this similarity is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the similarities, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method part of the paper is similar to a related work mentioned, \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not provide specific details or examples from the related work to support this claim. The comment lacks verifiable evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the method part seems similar to a related work mentioned in the paper, \"Generating Adversarial Disturbances for Controller Verification.\" It suggests that the authors should provide more clarification on this similarity. While the comment highlights an area for improvement, it does not offer specific guidance or suggestions on how the authors might address this issue or differentiate their work from the related work. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison with other methods and consider promoting existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed method, such as the use of a proposal generator pretrained on MSCOCO and its potential impact on comparisons with other methods. It also questions whether the proposed technique can promote existing class incremental semantic segmentation methods. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its questions about fairness and potential impact, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about fairness or the potential impact on existing methods. This makes the claim 3, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas for consideration, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the experimental section (Sec. 3) does not mention or discuss how the two important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is with respect to these parameters. This provides a clear and direct action for the authors to take, which is to include this information in the experimental section. The comment is specific and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"End of Sec.2\" and the \"experimental section (Sec. 3),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of discussion on how the two important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is with respect to these parameters. This provides clear guidance on what needs to be added or clarified in the experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental section (Sec. 3) does not mention or discuss how the two important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is with respect to these parameters. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper, specifically the absence of discussion on how the two important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is with respect to these parameters. This is a crucial oversight that could impact the reproducibility and understanding of the experimental results. The comment provides clear and actionable feedback by suggesting that the authors include this information in the experimental section. By addressing this issue, the authors can enhance the transparency and robustness of their work. Therefore, the comment is 5 as it directs the authors to a specific area for improvement, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 could benefit from a slower development to improve readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need more development. The comment lacks concrete details on how to implement this suggestion, such as recommending additional content or a different structure. As a result, the authors are left without clear instructions on how to enhance the readability of the section. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the section is \"very tersely written\" and could benefit from a slower development for easier readability. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 4 is \"very tersely written\" and could benefit from a slower development to improve readability. However, the comment does not provide any specific reasoning or examples to support this claim. It lacks detailed justification or references to similar works that might have addressed this issue, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the writing style of Section 4, noting that it is \"very tersely written\" and could benefit from a slower development to improve readability. While it highlights a potential problem, it lacks specific suggestions or guidance on how to achieve this improvement. The feedback is 3 as it points out an area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific changes could be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the use of reinforcement learning, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to studies that have demonstrated the inefficiency or difficulty of using reinforcement learning for static VQA tasks. Without such support, the claim remains 1, as it is based on a personal opinion without sufficient evidence or justification. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, making it 5. The comment is specific about what needs to be added and explained, giving the authors a clear path to improve their draft. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the distribution of videos of different lengths within the benchmark and the explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide relevant explanations regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This claim is 3 as it logically points out a gap in the paper\"s explanation and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or references to support the importance of this explanation or the impact of the distribution on the assessment of reasoning ability and robustness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of explanation regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and actionable, providing the authors with a specific and concrete step to improve their draft. By addressing this issue, the authors can enhance the transparency and clarity of their work, which is valuable for improving the paper\"s comprehensibility and credibility. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify how the implemented billinear layer differs from other approaches that perform billinear pooling. It raises questions about the dimensionality of embeddings and how the billinear layer is swapped out with other approaches. Additionally, it asks about the compression of representations using Equation (3) in this case. While the comment provides specific questions that need to be addressed, it does not offer explicit guidance on how to implement these clarifications or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the differences between the billinear layer and other approaches that perform billinear pooling. The comment raises questions about the dimensionality of embeddings, how the billinear layer is swapped out with other approaches, and whether the compression of representations using Equation (3) is still done in this case. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the differences between the billinear layer and other approaches that perform billinear pooling. It suggests that the major difference might be the dimensionality of embeddings, but it does not provide any evidence or reasoning to support this claim. The comment also asks about the compression of representations using Equation (3) and how the billinear layer is swapped out with other approaches. While it identifies areas for clarification, the lack of supporting evidence or detailed explanation makes the claim 3. The authors would need to provide additional context or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable set of questions that the authors need to address to clarify the differences between the billinear layer and other approaches that perform billinear pooling. It raises important points about the dimensionality of embeddings and how the billinear layer is swapped out with other approaches, such as the hadarmard product and MCB approaches. Additionally, it questions whether the compression of representations using Equation (3) is still done in this case. These questions are specific and guide the authors to clarify their methodology, which is crucial for ensuring the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to address these questions or what specific details should be included in the clarification. Overall, the comment is 4 as it identifies important areas for improvement and provides actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue, such as suggesting ways to make the dataset more accessible or how to mitigate the potential impact of this delay. As a result, the authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the dataset\"s availability, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not yet been made publicly available, suggesting that a cautious approach should be taken regarding the contribution until the dataset is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment highlights a significant concern about the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. This is a relevant and important point, as the availability of the dataset is crucial for the validity and impact of the contribution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as proposing alternative methods for accessing the dataset or explaining the importance of its availability. While it identifies a potential problem, the feedback could be more helpful with additional details or suggestions for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the limited novelty of the proposed method and its similarity to other attentional modules in previous works. It specifically mentions that the group attention design is related to ResNeSt but not discussed in the paper. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should discuss the similarities and differences between their method and previous works, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"group attention design\" and \"ResNeSt,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the similarity to other attentional modules in previous works, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works, such as ResNeSt, and noting that the group attention design is related to these works but not discussed in the paper. However, the comment lacks detailed comparisons or specific examples from these works to fully substantiate the claim. While the references provide some context, the comment could be strengthened by offering more specific examples or comparisons to fully support the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules in previous works. It specifically mentions the group attention design and its relation to ResNeSt, which is not discussed in the paper. This feedback is valuable as it highlights a potential weakness in the originality of the work, prompting the authors to address this issue. However, the comment could be more helpful if it provided suggestions on how to differentiate the method or discuss its unique aspects. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. This feedback provides a clear and explicit action for the authors to take, which is to include the illustration of the results in the paper. The comment is specific and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e.\" and \"Eqn 13,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the illustration of the results of the latter loss term of Eqn 13. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results of the latter loss term of Eqn 13 should be illustrated directly, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this illustration is necessary or how it would enhance the understanding of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, specifically suggesting that the authors should illustrate the results of the latter loss term of Eqn 13 directly. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and comprehensibility of the paper. By addressing this point, the authors can enhance the transparency and understanding of their results, which is valuable for improving the draft. However, the comment could be more helpful if it explained why this illustration is important or how it would benefit the reader. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning AB. It suggests that a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of robustness in video action recognition and the lack of comparison with testtime adaptation (TTA) methods, such as AB. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a comparison with TTA methods to prove the superiority of data processing over model parameter adjustment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with testtime adaptation (TTA) methods, specifically mentioning AB. The reviewer suggests that such a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. However, the comment does not provide specific examples or references to support the claim that TTA methods are relevant or how they could be applied to the paper. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, such as AB, which are relevant to the issue of robustness in video action recognition. It suggests that a comparison with these methods could provide valuable insights into the effectiveness of data processing versus model parameter adjustment. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct such a comparison or what specific aspects to focus on. This limits the comment\"s helpfulness, as it provides a clear direction but lacks detailed instructions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a mistake in the first expression for J (\u03b8) and suggests it should be Q (s t 0, \u03c0\u03b8(s t 0)). This provides a clear and direct action for the authors to take, specifying the correct expression to use. The comment is specific and actionable, giving the authors a precise correction to make in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J (\u03b8), suggesting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J (\u03b8) is incorrect and should be Q (s t 0, \u03c0\u03b8(s t 0)). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific mistake in the first expression for J (\u03b8) in Section 3.2.1, noting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This is a clear and actionable piece of feedback that can help the authors correct an error in their draft. However, the comment could be more helpful if it provided additional context or explanation on why this mistake occurred or how it affects the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area needing correction. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with capitalization in the paper, including specific references that need capitalization. It also mentions that various words in the references need capitalization. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues. The authors are left to infer that they should review and correct the capitalization in the references and in the paper itself. The action is implicit and somewhat vague, as it lacks detailed guidance on how to implement the corrections. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p. 8\" and \"Various words in many of the references need capitalization,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the capitalization issues in the references and provides examples of specific words that need capitalization, such as \"ai\" and \"Advances in neural information processing systems.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about capitalization issues in the paper and references. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several capitalization errors in the paper and references, which is a clear and actionable piece of feedback. It provides specific examples of words that need capitalization, such as \"ai\" and \"Advances in neural information processing systems,\" and points out capitalization inconsistencies in the references. This level of detail and specificity is valuable for the authors, as it allows them to easily correct these errors and improve the presentation of their work. However, the comment could be more helpful if it included suggestions on how to ensure consistent capitalization throughout the paper. Overall, the comment is 4 as it effectively guides the authors on a specific area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the missing parameter values for task 1 and the Boltzmann policy, specifically asking about the model parameters and the method used to choose them. While it does not explicitly instruct the authors to provide these details, the questions are clear and specific, indicating what information is missing and what the authors should include in their draft. The action is implicit but concrete, as the authors can infer that they need to provide the missing information. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"task 1\" and \"Boltzmann policy,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on the model parameters and the method used to choose them, as well as how the parameters were chosen (e.g., maximum likelihood estimates). This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification on specific parameters and methods used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of certain parameter values for task 1 and the Boltzmann policy. It asks for clarification on the model parameters and the method used to choose them, as well as how the parameters were chosen (e.g., maximum likelihood estimates). This feedback is clear and actionable, as it directs the authors to provide missing information that could improve the clarity and completeness of their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar details have been presented in other works. Overall, the comment is 4 as it guides the authors toward improving the transparency and comprehensiveness of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors claim to achieve stateoftheart results on challenging scene text recognition tasks, but the reviewer finds this claim unconvincing. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. While the comment implies that the authors should conduct such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct comparisons experiments to validate their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It also mentions the need for comparisons experiments with existing detection methods. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or claims presented in the paper. The comment is specific in its critique of the authors\" claims and the need for comparisons experiments, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks are unconvincing. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct additional experiments to validate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks. It suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. This feedback is 3 as it points out a potential weakness in the authors\" claims and provides a direction for further investigation. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why they believe applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 deteriorates performance compared to only applying it to layers 3 and 4. It provides a clear and direct action for the authors to take, which is to provide an explanation or rationale for this observation. The comment is specific and actionable, as it guides the authors on how to address the issue by offering a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the deterioration in performance when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4 compared to only layers 3 and 4. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2 deteriorates performance compared to only applying it to layers 3 and 4. However, the comment lacks specific details or evidence to support this claim, such as data or analysis results. Without such information, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2, noting that this deteriorates performance compared to only applying it to layers 3 and 4. It prompts the authors to explain why this might be happening and suggests that the authors provide an analysis or explanation to clarify this observation. This feedback is clear and actionable, as it directs the authors to address a specific issue in their paper that could impact the results and conclusions. However, the comment could be more helpful if it included suggestions on how to conduct the analysis or what aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the lack of comparison with a highly relevant method, specifically mentioning 1 and its proposed approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. The reviewer clearly states that the authors should include a comparison of their method with the one proposed in 1. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, specifically mentioning 1 and its proposed approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with the method proposed in 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning 1 and its approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of comparison with a highly relevant method, 1, which proposes a method for utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. By highlighting this omission, the comment provides the authors with a clear and actionable suggestion to include a comparison with the method proposed in 1. This feedback is valuable as it directs the authors to a potential enhancement that could strengthen their work. However, the comment could be more helpful if it included specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it effectively points out a gap in the paper and offers a concrete suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or suggesting a specific approach to improve the clarity. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the Witness oracle is confusing or how it could be clarified. The comment lacks specificity regarding the issue and does not provide guidance on how to address it. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the confusion caused by the implicit call to the Witness oracle. However, it does not provide any guidance or suggestions on how the authors might clarify this confusion or improve the explanation. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of enhancing the clarity or comprehensibility of their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed method\"s inability to handle headpose and questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The comment implies that the authors should consider incorporating headpose control into their method, but it lacks concrete steps or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"headpose,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the method cannot handle headpose and why it cannot be conditioned like a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that a previous work has already demonstrated control over both facial expression and headpose. The comment suggests that the authors should consider conditioning the headpose parameters in the NeRF beyond facial expression, similar to the previous work. However, the comment lacks specific references or detailed reasoning to support why this is a significant issue or how it could be addressed. While it highlights a potential gap in the methodology, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it cannot handle headpose while deferring this problem to future work. It questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. This feedback is 3 as it points out a gap in the methodology and suggests a potential area for improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or incorporate headpose control into their method. While it highlights an important area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns that appear only a few times in the training set. It references Chen et al. (2017) and Gu et al. (2019) to provide examples of such triggers. The comment suggests that a few training examples with these triggers could have a significant impact on the trained model. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps to take to mitigate the impact of these triggers. The action is implicit and somewhat vague, as the authors can infer that they need to consider the potential impact of these spurious features but are not given clear instructions on how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the spurious features, comparing them to backdoor triggers and referencing specific examples from Chen et al. (2017) and Gu et al. (2019). This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns that only appear a few times in the training set. The reviewer supports this claim by referencing Chen et al. (2017) and Gu et al. (2019), both of which use random noise patterns and singlepixel triggers, respectively, as examples of backdoor triggers. This provides a solid foundation for the claim, as it references wellknown practices in the field. However, the comment could be strengthened by providing more detailed examples or additional references to further substantiate the claim. Overall, the claim is 4, as it is supported by relevant references but could be improved with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers. It provides a clear and specific comparison to wellknown examples from Chen et al. (2017) and Gu et al. (2019), which helps the authors understand the nature of the issue. The comment suggests that a few training examples with such triggers could have a significant impact on the trained model. However, it does not offer specific suggestions or guidance on how the authors might address this issue or mitigate its impact. While the feedback is valuable in pointing out a potential problem, it lacks actionable advice, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization component is emphasized several times but notes that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific improvements. The comment lacks concrete actions or detailed suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the structural optimization component, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper discusses this component, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm seems to be directly from previous works, which could be confusing and reduce the contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization component is emphasized several times but that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the emphasis on structural optimization and the direct use of an optimization algorithm from previous works. This observation highlights a potential confusion in the contribution of the paper, which could be clarified or addressed by the authors. However, the comment lacks specific suggestions or guidance on how to improve the clarity or originality of the contribution. While it points out a potential weakness, it does not provide actionable feedback for the authors to enhance the paper. Therefore, the comment is 3, as it offers insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these issues. It lacks guidance on what specific improvements could be made or how to introduce the baseline models more effectively. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the pipeline style method, which includes two models, and notes that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for better introduction of baseline models and the lack of improved results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the pipeline style method, which includes two models, not yielding better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. While the comment highlights these areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. Without specific recommendations or examples, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their methodology. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" However, it does not specify which part of the paper this observation is made in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what needs to be addressed or improved in the methodology. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors are reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. However, the comment lacks specific examples or references to support the claim that this observation is unnecessary or redundant. Without such evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. While the comment identifies a potential redundancy in the authors\" work, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing A. This direct suggestion provides a clear and concrete action for the authors to take, ensuring they are aware of the relevant literature and can incorporate it into their discussion. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section discussing related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of related work on modular networks for VQA, such as A. This provides clear guidance on how to improve the introduction by acknowledging existing work in the field. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is crucial to mention related work on modular networks for VQA, such as A, to avoid painting a picture that no one does modular architectures for VQA. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion of related work in the paper, noting that it is crucial to mention related work on modular networks for VQA, such as A. This feedback is clear and actionable, as it directs the authors to include relevant literature that could enhance the introduction and context of their work. By addressing this point, the authors can ensure their work is better grounded in the existing literature and more comprehensive in its discussion. However, the comment could be more helpful if it provided additional context or examples of how this related work could be integrated into the discussion. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not compare their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add comparisons to other methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on SSC and the need to contrast the method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being compared. Without detailed comparisons or references, the claim is not fully substantiated, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. This feedback is 3 as it points out a gap in the paper\"s comparative analysis, suggesting that the authors should include such comparisons to provide a more comprehensive evaluation of their method. However, the comment lacks specific guidance on how to incorporate these comparisons or what aspects to focus on, making it 3 but not fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. The reviewer suggests renaming the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect this distinction. Additionally, the reviewer proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. These suggestions are clear and provide specific guidance on how to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semisupervised training and the renaming of the column in Table 1. The comment also provides a detailed suggestion for improving the clarity of the table by suggesting the creation of two columns for data sources. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between weak supervision and semisupervised training, specifically in Table 1. The reviewer provides a specific example of the proposed framework row in Table 1, suggesting that it refers to the semisupervised version of the method and recommends renaming the column to \"Fully supervised\" from \"Supervised.\" The reviewer also proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This suggestion is based on logical reasoning and provides a clear rationale for the change. Therefore, the claim is 4, as it is supported by a logical argument and specific suggestions for improvement.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on improving the clarity of the paper. It identifies a specific issue with the distinction between weak supervision and semisupervised training, particularly in Table 1, and suggests renaming the column to \"Fully supervised\" from \"Supervised.\" The reviewer also proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This feedback is 5 as it offers concrete steps for the authors to take to enhance the clarity and comprehensibility of their work. By addressing these suggestions, the authors can significantly improve the clarity and accessibility of their paper, making it more valuable to both reviewers and readers. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet 6 and Sparse NCNet 21) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment implies that the authors should consider how to differentiate their work from previous methods, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of differentiation but may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper makes small contributions over previous methods (NCNet 6 and Sparse NCNet 21) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. However, the comment does not specify which part of the paper discusses these contributions or differentiates from previous methods, making it weakly grounded. The comment is specific in its critique of the paper\"s contributions and differentiation from previous work, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper makes small contributions over previous methods (NCNet 6 and Sparse NCNet 21) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. However, the comment lacks specific examples or references to support these claims, making it challenging for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique from the limited information provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet 6 and Sparse NCNet 21) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment identifies a potential weakness in the paper\"s differentiation from previous work, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove the statement about semantic segmentation being a lowlevel cue, as it is not accurate given that categories are specified for each pixel. This feedback is clear and concrete, providing a direct action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the term \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the statement about semantic segmentation being a lowlevel cue is incorrect, given that categories are specified for each pixel. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about semantic segmentation being a lowlevel cue is incorrect, as categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the use of the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, making the statement about semantic segmentation being a lowlevel cue inaccurate. This feedback is clear and actionable, as it directs the authors to remove or revise the statement to avoid misleading the reader. However, the comment could be more helpful if it provided additional context or suggestions on how to rephrase the statement to be more accurate. Overall, the comment is 4 as it effectively guides the authors on how to improve the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the tables. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or correct the results, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy in performance without reinforcement learning (RL) dropping lower than without dependency tree and highlights the missing cases in the tables where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning (RL) dropped lower than without dependency tree in the ablation experiment. However, it does not provide any supporting evidence, such as data or comparisons, to substantiate this claim. Additionally, the comment mentions that the two tables do not list the cases where dependency tree and RL are not used, but it does not explain why this is a concern or how it affects the results. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the results of the ablation experiment, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is 3 as it highlights an area where the authors need to clarify or correct their results. However, the comment lacks specific suggestions on how to address the discrepancy or what additional information should be included in the tables. While it provides some direction, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies the main weakness of the paper as the lack of comprehensive experimental evaluation, specifically the limited consideration of datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. While the comment provides a clear direction for improvement by recommending specific works to consider, it does not explicitly instruct the authors on how to incorporate these works into their evaluation or how to address the identified weakness. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the main weakness of the paper, which is the lack of comprehensive experimental evaluation on different datasets and model types. The comment suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main weakness of the paper is the limited scope of the experiments, specifically the use of only the CIFAR10 dataset and the lack of consideration of other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. While the comment provides a logical reasoning for the need to consider additional datasets, it lacks specific examples or references to the works mentioned, which would strengthen the claim. Therefore, the comment is 3, as it provides a clear direction for improvement but requires more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which only consider the CIFAR10 dataset and do not consider other datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance the comprehensiveness and relevance of their experiments. By addressing this feedback, the authors can significantly improve the quality and impact of their paper. However, the comment could be more helpful if it provided additional details on how these works could be integrated or what specific aspects of the experiments should be expanded. Overall, the comment is 4 as it effectively directs the authors to a meaningful area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the validity of the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to verify the claim. The comment implies that the authors should consider using another dataset, but it lacks concrete instructions or detailed suggestions on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the table and the claim about accuracy and completeness, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the claim and suggests using another dataset for the ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. This is a constructive suggestion that could help the authors strengthen their argument by providing additional evidence or comparisons. However, the comment lacks specific guidance on which dataset to use or how to conduct the ablation study, which would make it more actionable. Overall, the comment is 3 as it identifies a potential weakness and offers a direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and questions the ecological validity of such a study. The reviewer also mentions that previous work has considered multiple vulnerabilities or weaknesses simultaneously and asks if the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment concludes by stating that the results are difficult to interpret or may only show marginal improvements. While the comment identifies a potential issue with the methodology, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their approach to vulnerability discovery. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vulnerability discovery methodology\" and the \"single vulnerability\" approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the ecological validity of the study and the results\" interpretability, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. The reviewer acknowledges the data imbalance issue and questions the ecological validity of such a study. The comment references previous work that considered multiple vulnerabilities or weaknesses simultaneously, suggesting that the authors\" approach may not be appropriate. However, the comment lacks specific examples or references to support the claim that previous work considered multiple vulnerabilities. This makes the claim 3, as the authors would need to infer the relevance of the reference to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the methodology used for vulnerability discovery, specifically questioning the authors\" approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and questions the ecological validity of such a study. The reviewer also references previous work that considered multiple vulnerabilities or weaknesses simultaneously, suggesting that the authors\" approach may not be appropriate. The comment highlights the difficulty in interpreting the results and notes that they may only show marginal improvements. While the comment provides a clear critique of the methodology, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. This limits the comment\"s helpfulness, as it points out a potential issue but does not fully support the authors in resolving it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It suggests that additional explanations are needed to address this issue. However, the comment does not provide specific guidance on how to provide these explanations or what aspects of the relationship should be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by the theorems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2 is not intuitive enough. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It points out that while the theorems prove conformity to a clearer community structure, the relationship with degree bias is not intuitive. This feedback is valuable as it highlights a potential gap in the paper\"s explanation, which the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this relationship or examples of how it might be explained more effectively. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this question. The authors are left to infer that they need to clarify this aspect of their work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182183, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the construction of clean exemplar manifolds for a nonstochastic network and how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. The comment is 3 as it highlights a potential inconsistency in the authors\" explanation, but it lacks specific examples or references to support the claim that the construction of clean exemplar manifolds is unclear. The authors may need to provide additional clarification or examples to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the construction of clean exemplar manifolds for a nonstochastic network. It raises a specific question about how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks, which is a critical aspect of the methodology. By pointing out this discrepancy, the comment provides the authors with a clear and actionable step to address a potential weakness in their work. However, the comment could be more helpful if it offered suggestions on how to clarify this issue or provided examples of how similar questions have been addressed in related literature. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, it does not provide explicit guidance on what additional information is needed or how to clarify this notation. The comment implies that the authors should provide more information, but it lacks concrete steps or suggestions on how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it is confusing. However, it does not specify which part of the paper this notation is used in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does provide some specificity by indicating that more information is required, such as what S and Xt represent. However, without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, the comment does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for how the authors might clarify the notation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the notation used to separate \"static\" and temporal features into two variables. It points out that this notation is confusing and requires more information than what is provided in the paper. While the comment highlights an important issue, it lacks specific guidance or suggestions on how the authors might clarify this notation or provide additional information. The feedback is 3 as it directs the authors to a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be more detailed, particularly in the definitions of the resistance distance and explanations of Algorithm 1. While it implies that more details should be provided, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s content, specifically mentioning the \"graph notions\" and the difficulty in understanding them. It also provides specific suggestions for improvement, such as defining the resistance distance and providing more explanations on Algorithm 1. However, the comment does not explicitly mention which sections or parts of the paper these issues are related to, making it weakly grounded. The suggestions are specific, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is difficult to understand due to the many graph notions and provides a general observation that more details could be added, such as definitions of the resistance distance and explanations of Algorithm 1. However, the comment lacks specific examples or references to support the claim that the paper is difficult to understand or that more details are needed. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand the basis of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s complexity, noting that it deals with many graph notions and is challenging to understand. It also acknowledges that the writing is generally good but suggests that more details could be provided, such as definitions of the resistance distance and explanations of Algorithm 1. While the comment provides some insight into areas where the paper could be improved, it lacks specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out potential areas for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the originality or suggest alternative approaches to improve the paper. As a result, the authors are left without any clear direction on how to improve the originality of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of originality, specifically mentioning that the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered unoriginal, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the originality of the paper, specifically noting that the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the evaluation of shape model invariance, specifically asking whether there are quantitative results on testing images. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide quantitative results on testing images. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the evaluation on transformations of training images and asks for quantitative results on testing images. This provides clear guidance on what additional information is needed to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the evaluation on transformations of training images for the shape model invariance study. It suggests that quantitative results on testing images might be needed to fully prove the point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the evaluation of shape model invariance, specifically questioning the use of transformations of training images to prove the point. It suggests that quantitative results on testing images might be necessary to fully substantiate the claim. This feedback is 3 as it identifies a potential gap in the evaluation process and prompts the authors to consider additional evidence. However, the comment could be more helpful if it provided specific suggestions on how to conduct the testing or what types of quantitative results might be relevant. Overall, the comment offers a constructive critique that could guide the authors in improving their draft, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the omission of a related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. The action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of this related work and its potential impact on the understanding of the stateoftheart. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared with the current work. The reviewer provides a logical reasoning by suggesting that the AAAI15 paper deals with hypergraph data with tensors, which is relevant to the current work. However, the comment lacks specific examples or references to the content of the AAAI15 paper, making it 3. The authors would need to conduct additional research to fully understand the relevance and potential contributions of the AAAI15 paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is relevant to the current work but has been overlooked. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a relevant reference and comparison that could enhance the paper\"s comprehensiveness and depth. However, the comment could be more helpful if it provided specific guidance on how to integrate this reference into the paper or what aspects to focus on for comparison. Overall, the comment is 4 as it points out a valuable addition to the literature review but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it would be beneficial to test its scalability on normal machines with a few cores. It also questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific tests should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should test scalability and provide more details on the computation of optimal transport. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Approach\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions how the authors compute the optimal transport distance, suggesting that they should test it on normal machines with a few cores. Additionally, it questions how the Sinkhorn method relates to the computation of optimal transport. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it is not clear how scalable the method is. The reviewer questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the method is not scalable or how it could be improved. The lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of the method and the computation of optimal transport distance. It raises questions about how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. This feedback is valuable as it prompts the authors to consider the scalability of their method on normal machines with a few cores, which is an important aspect for practical applications. Additionally, the comment highlights a potential gap in the explanation of the computation process, which could be addressed by providing more detailed information or examples. However, the comment could be more helpful if it offered specific suggestions on how to test scalability or how to clarify the computation process. Overall, the comment is 4 as it directs the authors to important areas for improvement and provides a clear direction for enhancing the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is extremely hard to follow, indicating that the authors need to improve the clarity and comprehensibility of their work. However, it does not provide any specific guidance on how to achieve this improvement. There are no explicit suggestions for reorganizing the content, simplifying the language, or providing more detailed explanations. The lack of actionable advice makes it difficult for the authors to know exactly what steps to take to enhance the readability of their paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is difficult to follow, but it does not specify which parts of the paper are particularly challenging to understand. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment lacks specificity regarding what aspects of the paper are confusing or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"extremely hard to follow,\" indicating that the reviewer had difficulty understanding the experimental procedures and evaluations. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without specific examples or references, the claim lacks verifiability, making it challenging for the authors to improve their draft based on this feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a significant issue with the paper, noting that it is extremely hard to follow. This feedback is valuable as it identifies a critical weakness in the clarity and comprehensibility of the paper, which is essential for effective communication of the authors\" work. However, the comment lacks specific suggestions or guidance on how the authors might improve the readability or structure of their paper. Without actionable advice or detailed feedback, the authors may struggle to address this issue effectively. Therefore, the comment is 3, as it points out a significant problem but does not provide detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide specific guidance on what aspect of the claim is questionable or how it could be improved. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. The reviewer provides a logical reasoning by stating that a model that can only handle a single time series data is almost useless. However, the comment lacks specific examples or references to support the claim that this is not an advantage. Without additional context or evidence, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is 3, as it provides a logical argument but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment questions the claim made in section 2 regarding the perdatainstance basis of INRs, suggesting that this is not an advantage. The reviewer provides a logical reasoning by stating that a model that can only handle a single time series data is almost useless. However, the comment lacks specificity and does not offer any suggestions or guidance on how the authors might address this concern or improve the claim. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward. Therefore, the comment is 3, as it identifies a potential weakness but does not provide enough detail for the authors to effectively improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to consider introducing specific aspects of their model that are specific to the example model. It provides a clear and concrete action for the authors to take, specifying that they should clarify the model\"s parameters and settings, such as the boundedness of acceleration and scaling parameters. This guidance is direct and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of specific aspects of the model that are specific to the example model, such as the boundedness of certain parameters. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should introduce specific aspects of their model that are specific to the example model, such as the boundedness of certain parameters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce specific aspects of their model that are specific to the example model. It highlights the importance of clarifying the boundedness of certain parameters, such as acceleration and scaling, which are crucial for understanding the context of the model. This guidance is clear and constructive, as it directs the authors to enhance the clarity and comprehensiveness of their paper. By addressing these points, the authors can improve the transparency and effectiveness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. Additionally, it recommends including more analysis and discussion for GPT2, specifically asking for the results of Figure 2 for GPT2. While the comment provides explicit actions and concrete details on what to investigate and include, it could be more helpful if it explicitly instructed the authors on how to conduct these analyses or provided examples of what such analyses might entail. Overall, the comment is 4 as it clearly outlines specific areas for improvement and provides concrete guidance on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to investigate whether the results can be generalized to other models, differences in model size, objective function, and architecture, and the inclusion of more analysis and discussion for GPT2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. The reviewer provides a logical reasoning by pointing out that the experiments should be expanded to include more models, such as GPT2, to test generalizability. However, the comment lacks specific examples or references to support the claim that these differences would significantly impact the results. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, and recommends including more analysis and discussion for GPT2. The comment provides clear and actionable feedback by specifying what aspects of the experiments need to be expanded and clarified. By suggesting additional analyses and discussions, the reviewer offers a concrete path for the authors to enhance the robustness and generalizability of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct these analyses or examples of what such analyses might entail. Overall, the comment is 4 as it directs the authors to important areas for improvement and enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. While the comment implies that the authors should explore these applications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their work to include these other areas. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the model and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. However, the comment lacks specific examples or references to support the claim that the model and experiments are limited to image data and ViT. Without such evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. This feedback is valuable as it encourages the authors to expand their work beyond the current focus on image data and ViT, which could enhance the method\"s versatility and broader applicability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might explore these other areas. Overall, the comment is 4 as it prompts the authors to consider a broader scope for their work, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should evaluate TTA methods on more conditions of natural distribution shift, like WILDS 9, to strengthen the paper. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA methods on more conditions of natural distribution shift, like WILDS, to strengthen the paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using nonstandard benchmarks breaks popular TTA methods and recommends evaluating TTA on more conditions of natural distribution shift, like WILDS. However, the comment does not provide specific examples or references to support this claim, nor does it explain why using nonstandard benchmarks is significant or how it affects the performance of TTA methods. Without additional context or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the suggestion without further elaboration.", "helpfulness_rationale": "The review comment identifies an interesting observation about the performance of TTA methods under nonstandard benchmarks, suggesting that evaluating these methods on more conditions of natural distribution shift, like WILDS, could strengthen the paper. This feedback is 3 as it points out a potential area for improvement and provides a specific suggestion for enhancing the paper. However, it lacks detailed guidance on how to implement this suggestion or what specific aspects of the TTA methods should be evaluated. While it offers a direction for improvement, the comment could be more actionable with additional details. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. The reviewer suggests that this condition is not realistic and may lead to unreasonably large learning rates when learning on largescale datasets. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on whether the authors should adjust the condition, provide a rationale for its necessity, or explore alternative approaches. As a result, the authors are left without actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. It provides a clear rationale for why this condition is not realistic, as it leads to unreasonably large learning rates when learning on largescale datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the learning rate condition and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the condition on the learning rate is not scalable, as it does not grow with the number of samples in practice. The reviewer provides a logical reasoning by explaining that this condition leads to unreasonably large learning rates when learning on largescale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not realistic. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. This is a critical observation, as it highlights a potential flaw in the methodology that could lead to unreasonably large learning rates when learning on largescale datasets. The reviewer provides a logical reasoning for why this condition is not realistic and suggests that the authors need a way to precisely characterize the benefit of large learning rates. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or explore alternative approaches. Despite this, the feedback is still valuable as it points out a critical aspect of the methodology that the authors should consider improving. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the paper need clarification. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of tensor networks to represent PMF of discrete variables and questions the significance of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of clarity regarding the utility of tensor networks and the significance of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. It highlights a potential weakness in the paper\"s contribution, which could impact its impact and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper\"s significance. While it points out a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use a more convincing setting for training, similar to what was done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. It provides a specific reference to the paper by He et al. (EMNLP 2018) as an example of a convincing setting. This feedback is explicit and provides a clear action for the authors to take, which is to adopt a more convincing training approach. The suggestion is concrete and provides a direct path for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)\" and suggests that the label distribution of unlabeled data during training is impractical in realworld applications. It also references a specific paper, \"Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018,\" which provides a more convincing setting for training. This level of detail allows the authors to accurately identify the part of the paper being addressed and the specific issue being raised. The comment is also specific, as it clearly specifies what needs to be addressed regarding the label distribution and suggests a more convincing approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in realworld applications. The reviewer suggests that the authors should use a more convincing setting, like the one described in the paper \"Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018,\" which directly samples unlabeled data from millions of reviews. The comment provides a specific reference to a relevant paper, which supports the claim by offering a practical example of a more convincing setting. This makes the claim 4, as it provides a logical basis and a concrete example for the authors to consider.", "helpfulness_rationale": "The review comment identifies a specific issue with the unlabeled data from the preprocessed Amazon review dataset, noting that it is perfectly balanced, which is impractical in realworld applications. It suggests that the authors should use a more convincing setting, like the one described in the paper \"Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018,\" which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving their approach. By addressing this issue, the authors can enhance the realism and applicability of their work. Therefore, the comment is 4, as it offers a specific and constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding how to sample from the DPP if the eigenfunctions e_n are inaccessible, referencing a specific line in the paper (line 130). It also mentions a similar issue with sampling from the leverage score in a previous work. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the clarity of their explanation. The action is implicit and vague, as the authors are left to infer that they need to clarify their sampling process, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 130\" and \"Eq (10),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a specific line and a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a specific line in the paper (line 130) and a previous work. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that sampling from the DPP is easier than sampling from the leverage score. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper regarding the sampling process from the DPP when the eigenfunctions e_n are inaccessible. It references a specific line in the paper (line 130) and compares it to a previous work, highlighting a potential inconsistency in the authors\" explanation. This feedback is valuable as it points out a potential gap in the paper\"s explanation, which could confuse readers. However, the comment could be more helpful if it provided suggestions on how to clarify this issue or improve the explanation. Overall, the comment is 3 as it directs the authors\" attention to a specific area needing clarification, but it lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the evaluation of the generalizability of observations to fewshot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the submission\"s contributions regarding understanding the properties of episodic training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation to include other fewshot learners, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation on the generalizability of observations to fewshot learners beyond Prototypical Networks. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the evaluation section. However, the comment is not specific as it does not detail what specific aspects of the evaluation are missing or how the authors could address this gap. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the observations presented do not evaluate the generalizability to fewshot learners beyond Prototypical Networks, which may limit the scope of the paper\"s contributions regarding understanding the properties of episodic training. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the significance of the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that the observations presented do not evaluate the generalizability of fewshot learners beyond Prototypical Networks. This is a relevant point as it pertains to the scope of the paper\"s contributions regarding understanding the properties of episodic training. However, the comment lacks specific suggestions or guidance on how the authors might address this gap or what additional evaluations could be conducted. While it points out an area for improvement, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address this issue, specifically asking for guidance on how to deal with the problem. However, the comment does not provide explicit instructions or concrete suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the contribution of different modalities and address the problem, but the comment lacks detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the contribution of different modalities of different instances, specifically mentioning modalities A and B and their performance in different instances. It raises a question about how to deal with the problem of removing the modal subset of all instances, as described in Equation 3. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of modalities and their contributions. The comment is specific in detailing the issue and suggesting a potential solution, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address the problem, suggesting that Equation 3 directly removes the modal subset of all instances. However, the comment lacks specific examples or detailed reasoning to support the claim that the contribution of different modalities is different. Without additional context or evidence, the claim remains 3, as it provides a logical basis but lacks detailed justification. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the contribution of different modalities of different instances. It highlights that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address this issue, specifically mentioning Equation 3, which directly removes the modal subset of all instances. While the comment points out a potential problem, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it identifies a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback provides clear and concrete actions for the authors to take, such as adding a description of the evaluation process and addressing language issues. The comment is specific and direct, giving the authors a clear understanding of what needs to be added or improved. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues on page, providing specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. While the comment highlights an important area for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are given a clear direction to enhance the abstract but are left without specific steps or examples on how to do so. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the absence of experiments on specific settings. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. While the comment identifies a specific issue with the experimental section, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should include experiments on these settings, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific settings used in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the absence of experiments on certain settings and the lack of simulated experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the validity of the experimental results by pointing out the absence of experiments on specific settings, such as surveillance in museums with thresholded rewards and privacypreserving data collection. The reviewer suggests that this lack of experiments makes the experimental section not useful. However, the comment does not provide specific examples or references to support the claim that these settings are necessary or how the absence of experiments affects the validity of the results. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, questioning the relevance and usefulness of the examples used to motivate the solution. It points out the absence of experiments on specific settings, such as surveillance in museums with thresholded rewards and privacypreserving data collection, which are relevant to the paper\"s topic. This feedback highlights a critical gap in the experimental section that the authors need to address to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific experiments or modifications to the existing ones. Overall, the comment is 4 as it directs the authors\" attention to a crucial area for improvement, but it lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment implies that the authors should clarify this confusion by providing more detailed explanations or examples. However, it does not explicitly instruct the authors to make these changes or suggest specific ways to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should address the confusion and provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the use of sparse labels and the notation for target domain \u03c4. The comment further questions the use of unlabeled data in source domains and references the original MFDA paper by Yue et al. (2021a) for clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. The reviewer questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper by Yue et al. (2021a). The comment is 3 as it provides a logical basis for the confusion, referencing the original paper for clarification. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for target domain \u03c4 is unlabeled and questions the use of sparse labels, which is not consistent with the original MFDA paper by Yue et al. (2021a). The comment also highlights the confusion regarding the use of unlabeled data in source domains during training. By pointing out these discrepancies and referencing the original paper, the comment provides clear and actionable feedback for the authors to improve the clarity and consistency of their description. This guidance is valuable for enhancing the understanding of the problem setting and the methodology, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear rationale for why epochwise analysis could be valuable, it does not explicitly instruct the authors on how to implement this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The suggestion is specific, as it clearly outlines the potential benefits of epochwise analysis and how it could be applied to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a logical reasoning for the potential benefits of epochwise analysis, it lacks specific examples or references to support the claim. The suggestion is 3, as it provides a clear rationale but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It suggests that epochwise analysis, particularly in finite sum settings, could offer insights into the behavior of optimization algorithms. This analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it proposes that this approach could aid in comparative analysis of deterministic and stochastic methods. The comment is specific and provides a clear direction for the authors to enhance their analysis and understanding of the algorithms. By offering a concrete suggestion for improving the paper, the comment is 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific details to include. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the code and details in the article, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issues with the workload being immense and the contribution being incremental, as well as the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the absence of essential RAG algorithms like MedRetriever and KGRAG. The reviewer also mentions that the paper focuses on RAG for EHR, which should include these algorithms. The claim is 3 as it provides a logical reasoning based on the combination of existing works and the focus of the paper. However, it lacks specific references to MedRetriever and KGRAG, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the immense workload and the incremental contribution, which are noteworthy observations. It also points out the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG, which are relevant to the focus on RAG for EHR. The comment provides specific suggestions for improvement by recommending the inclusion of these algorithms and baselines. However, it could be more helpful if it offered guidance on how to integrate these elements effectively into the paper. Overall, the comment is 4 as it highlights areas for improvement and provides actionable suggestions, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. The reviewer implies that the authors should provide more detailed explanations or examples to clarify this distinction. While the comment does not explicitly instruct the authors to make changes, it implies a clear action for the authors to take, such as providing additional context or examples to clarify the distinction. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the \"sample data file,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the distinction between derogatory and exclusionary extreme speech, and it provides a specific example from the sample data file to illustrate the confusion. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the distinction between the three classes of extreme speech, specifically questioning the classification of a specific instance as exclusionary extreme speech. The reviewer provides a specific example from the sample data file to illustrate the confusion, asking for clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. While the comment identifies a specific issue, it lacks detailed reasoning or references to support the claim that the distinction is unclear. The authors are left with a clear direction for improvement but without the necessary evidence or explanation to fully understand the basis of the claim. Therefore, the comment is 3, as it provides a starting point for the authors to address the issue but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the distinction between the three classes of extreme speech, particularly in the context of the sample data file provided. It questions the classification of a specific instance as exclusionary extreme speech and highlights the potential influence of local regulation on the classification. The comment is 4 as it prompts the authors to clarify the distinction and provide additional context or examples to support their classification. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of how the distinction could be clarified. Overall, the comment is 3 as it directs the authors to a specific area needing clarification, but it lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be included in the graph and why it is important. The comment also offers a rationale for why this graph is necessary, helping the authors understand the potential sources of performance improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included in the graph and why it is important to understand the sources of performance improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This claim is 3 as it logically suggests that such a graph would help clarify whether the performance improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by instructing the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This suggestion is important as it can help the authors understand whether the performance improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. The comment also highlights the potential advantage of algorithms with lower resolution, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided additional context or examples to support the rationale behind the graph. Overall, the comment is 4 as it offers clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper needs to be mathematically correct and provides a specific example by questioning the notation \"L_l\" instead of just \"L.\" It also suggests that the notation should be introduced beforehand. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make these changes or what specific changes should be made. The authors are left to infer that they need to make these corrections, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"L_l\" notation and suggests that it should be changed to be mathematically correct. It also mentions the need to introduce the notation beforehand, providing clear guidance on what needs to be addressed. However, the comment does not specify why this notation is problematic or how it affects the overall paper. Therefore, while the comment is specific about the issue with the notation, it lacks detailed guidance on how to implement the suggested changes. This makes the comment fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point suggests that the paper needs to be mathematically correct and questions the notation \"L_l\" instead of \"L.\" It provides a specific example of the notation issue and suggests that it should be introduced beforehand. However, the comment lacks detailed reasoning or references to support why this change is necessary or how it would improve the paper. The suggestion is 3 as it identifies a specific issue but does not provide a comprehensive rationale or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"L_l\" and suggests that it should be changed to be mathematically correct. It also questions why the notation is used instead of \"L\" and suggests that it should be introduced beforehand. This feedback is clear and actionable, as it provides the authors with a concrete suggestion for improving the mathematical correctness of their work. However, the comment could be more helpful if it explained why this change is necessary or how it would impact the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also notes that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to study the effect of noise accumulation. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sequential ensembling\" and \"homomorphic encryption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of noise accumulation in the context of homomorphic encryption, which prevents the use of even single deep neural networks on homomorphically encrypted data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that noise accumulation in the context of homomorphic encryption is a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper regarding the use of deep neural networks on homomorphically encrypted data due to noise accumulation. It highlights the importance of studying this effect in the context of homomorphic encryption. While the comment points out a potential issue, it lacks specific suggestions or guidance on how the authors might address this limitation or what specific experiments could be conducted to study the effect of noise accumulation. The feedback is 3 as it directs the authors\" attention to a relevant area for further exploration, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should consider different timesteps for training and evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the relevance of different timesteps and how they might impact the effectiveness of the proposed methods. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of the proposed methods, noting that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep. This observation raises questions about the novelty and practical relevance of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or explore different timesteps. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the disentanglement aspect of the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed. The reviewer suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Broader Impacts and Limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how disentanglement is achieved and guaranteed without certain bias types. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that disentanglement is not clearly explained and questions how it is achieved and guaranteed without certain bias types. While the comment references the \"Broader Impacts and Limitations\" section, it does not provide specific examples or detailed reasoning to support the claim that disentanglement is unclear. The reference to the \"Broader Impacts and Limitations\" section suggests that the authors have acknowledged the limitation, but the comment lacks further elaboration or evidence to substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the disentanglement aspect in the paper. It points out that while the \"Broader Impacts and Limitations\" section acknowledges a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed without certain bias types. The comment suggests that the authors should clarify this aspect to enhance the clarity and comprehensiveness of their work. This feedback is clear and actionable, as it directs the authors to address a specific gap in their explanation of disentanglement. However, it could be more helpful if it provided examples or additional guidance on how to effectively present this information. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case, the authors should use a standard regularization trick. While the comment implies that the authors should apply this standard technique, it does not provide explicit instructions on how to implement it or which specific regularization trick to use. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the use of a standard regularization trick, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this standard technique is necessary or how it would improve the comparison. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. This feedback is 3 as it identifies a specific area for improvement, namely the need to standardize the regularization technique to ensure a fair comparison. However, the comment lacks depth and does not provide detailed guidance on which specific regularization trick to use or how to implement it effectively. Additionally, it does not address other aspects of the paper, such as clarity or coherence. While the comment points out a potential issue, it could be more helpful with additional context and suggestions for improvement. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a clear and concrete action for the authors to take, as it provides a specific enhancement to the figure that would help clarify the impact of mean teacher on learning. The suggestion is direct and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3\" and \"left graph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is a learning curve for a model without mean teacher or pi regularization. This provides clear guidance on how to enhance the figure and compare the impact of mean teacher on learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a request for additional data or analysis, which is a factual observation rather than an opinion or claim. Therefore, it should be classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This additional information would help clarify the impact of mean teacher on learning, providing valuable insights for the authors. The comment is clear and direct, offering a concrete way to enhance the figure and improve the draft. Therefore, it is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and the disorderly citation style. While the first point suggests a specific area for improvement, it does not provide explicit guidance on how to address it, such as recommending a particular approach or method. The second point about the citation style is more of a general observation, and while it highlights an issue, it does not offer specific suggestions for improvement. Therefore, the comment is 3, as it identifies areas for improvement but lacks concrete details on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and suggests that the citation style is disordered. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need to discuss solutions for handling different input types and the disorderly citation style. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the need to discuss how to handle different types of inputs and the disorderly citation style. The first claim is 3 as it suggests a potential area for improvement, but it lacks specific examples or detailed reasoning on how to address the issue. The second claim about the citation style is more vague, as it does not specify which citations are disordered or how they could be improved. Overall, the comment provides some direction but lacks detailed justification or examples, making it 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement: discussing how to handle different types of inputs, such as biomedical signals or speech, and addressing the disorderly citation style. While it highlights these issues, it does not provide specific guidance or suggestions on how to address them. The comment could be more helpful by offering examples of how to handle different input types or providing examples of how to improve the citation style. As it stands, the feedback is 3, as it points out areas for improvement but lacks detailed guidance for the authors to act upon. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or discuss the implications of Eq. 4 and the lack of significant improvement in Table 5. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether the u^l in Eq. 3 tends to be 1 and noting the lack of significant improvement in the designed solutions in Table 5, particularly on the OfficeHome dataset. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This claim is 3 as it provides some logical reasoning and specific examples to support the observation. However, it could be strengthened by providing more detailed analysis or references to substantiate the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This feedback is 3 as it points out a potential issue with the results and suggests that the authors might need to reconsider their approach. However, it lacks specific suggestions or guidance on how to address the issue or improve the results. To be more helpful, the comment could provide suggestions on how to improve the design solutions or clarify the implications of the results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of specific stateoftheart references in the face recognition experiment, particularly mentioning \"Baidu\"s work\" and its reported results. It also highlights the use of the triplet loss and the similarity to the Webface dataset. The comment provides a clear and specific action for the authors to include these references in their work. Additionally, it suggests that the VRF achieved a better result than reported in Table 3, which could be a valuable comparison for the authors to make. The action is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the specific references that are missing, such as \"Baidu\"s work\" and \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" It also provides specific details about the triplet loss and the reported results, which allows the authors to identify the exact parts of the paper being addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the face recognition experiment, specifically mentioning \"Baidu\"s work\" and its reported results. The reviewer provides a specific reference to the work, which is a clear and verifiable claim. Additionally, the comment provides details about the triplet loss and the reported results, which further strengthens the claim. This level of detail and specificity makes the claim 4, as it provides a clear rationale for the claim and supports it with relevant information. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup in the paper, noting the absence of certain stateoftheart references, such as \"Baidu\"s work\" and its reported results. It provides a clear and actionable suggestion by recommending the inclusion of these references, which could enhance the paper\"s credibility and comprehensiveness. Additionally, the comment highlights the use of the triplet loss and the reported results, which could be valuable comparisons for the authors to make. However, the comment could be more helpful if it offered additional insights or suggestions on how to incorporate these references or what specific aspects of the work could be improved. Overall, the comment is 4 as it identifies a clear area for improvement and provides actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the generalization. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to question answering, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the question answering process, specifically the use of template mapping to transform questions into masked statements. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with poor generalization to questions that are not \"Whtypes\" or transformable. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process, specifically the use of template mapping, might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. While the comment highlights a potential problem, it lacks specific guidance or suggestions on how the authors might address this issue or improve their question answering process. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform 1 as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VolumeDeform 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the issue is: the use of a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform 1. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform 1 as an example. However, the comment does not provide specific details or references to VolumeDeform to support the claim that this idea is not novel. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform 1 as an example. However, it does not provide any constructive feedback or suggestions for improvement. It lacks depth and actionable guidance, leaving the authors without a clear understanding of how to address the issue or enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the ICLHAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. It suggests that this issue should be discussed or at least acknowledged in the main text in more detail. This provides a clear and direct action for the authors to take, as they are instructed to address this issue in their draft. The comment is specific and provides concrete guidance on how to improve the paper by discussing or acknowledging the impact of the ICLHAR on accuracy scores. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLHAR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ICLHAR, stating that it has impeded accuracy scores and dropping them from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the paper, namely the discussion or acknowledgment of this issue in more detail. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This claim is supported by the provided data, which shows a significant decline in accuracy scores. However, the comment could be strengthened by providing more detailed analysis or explanation of why this decline occurred or how it affects the overall contribution of the paper. While the data provides some support, the comment could be more 5 with additional context or reasoning. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the ICLHAR, noting that it has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This is a clear and actionable observation that the authors should address in their draft. The comment suggests discussing or acknowledging this issue in more detail, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as potential reasons for the decline in accuracy or ways to mitigate its impact. Overall, the comment is 4 as it highlights a significant issue that the authors should address, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by previous work. This is a direct and concrete action, as it specifies the exact source that needs to be cited. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to cite the source of the example. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by previous work and suggests that the source should be cited appropriately. However, the comment does not provide specific examples or references to the previous work that inspired the example, making it difficult for the authors to verify the claim. Without additional context or evidence, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by previous work and should be appropriately cited. This is a clear and actionable piece of feedback, as it directly instructs the authors to cite the source of the example. By addressing this point, the authors can ensure that their work is properly credited and that they are not plagiarizing others\" work. Therefore, the comment is 5, as it provides a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the innovations or how to mitigate the constraints. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the innovations in network architecture design and constraint embedding are limited, and that the performance is constrained by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or the performance constraints, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of limited innovation and the constraint on performance, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically that the innovations in network architecture design and constraint embedding are limited, and that the performance is constrained by the performance of the oracle expert. While the comment highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is 3 as it points out a limitation but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that comparing the performance of a model pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors instead. It further suggests that the authors should provide the performance of the model pretrained on synthetic data but finetuned on realworld datasets with different losses. While the comment provides a clear action\u2014to demonstrate the importance of the projection errors and finetune the model on realworld datasets\u2014it does not specify how to implement this action or what specific steps to take. The authors are left with a general idea of what needs to be done but without detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of comparing the performance of a model pretrained on synthetic data, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need to demonstrate the importance of the proposed three projection errors and suggests providing performance metrics for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that comparing the performance of a model pretrained on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors instead. The comment provides a logical reasoning by suggesting that finetuning the model on realworld datasets with different losses is necessary to showcase the model\"s performance. However, the comment lacks specific examples or references to support the claim that the current comparison is unfair. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s comparison of model performance, suggesting that comparing a model pretrained on synthetic data is unfair. It recommends demonstrating the importance of the proposed three projection errors and provides a clear suggestion for improvement by suggesting that the authors should provide performance metrics for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is actionable and offers a clear direction for the authors to enhance their analysis and presentation of results. However, it could be more helpful if it provided additional guidance on how to implement this suggestion or what specific metrics to use. Overall, the comment is 4 as it effectively points out a weakness and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, it does not explicitly instruct the authors to average over the subword representations or provide guidance on how to implement this suggestion. The action is implied and somewhat vague, as the authors need to infer that they should consider averaging over subword representations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the common practice of averaging over subword representations in similar cases, as demonstrated by Hewitt and Manning (2019, footnote 4). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim that it is common practice to average over subword representations in similar cases, citing Hewitt and Manning (2019, footnote 4) as an example. However, the comment does not provide a detailed explanation or reasoning for why this is a common practice or how it would benefit the current work. The reference to Hewitt and Manning is provided, but it does not fully substantiate the claim without additional context or explanation. Therefore, the comment is 3, as it provides a reference but lacks detailed justification or explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in the paper, noting that it is common practice to average over subword representations in similar cases. It provides a reference to Hewitt and Manning (2019, footnote 4) as an example of this practice. While the comment highlights a potential area for improvement, it does not offer detailed guidance or suggestions on how the authors might incorporate this practice into their work. The feedback is 3 as it points out a potential issue but lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear action to take, it lacks specific guidance on how to conduct the calibration curves or what aspects of the traditional method should be discussed. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model AUC and its ability to assess model discriminant ability, as well as the consistency between predicted scores and actual risks. It suggests conducting calibration curves to demonstrate this consistency, which is crucial for the clinical scoring system. The comment also mentions the difference between the traditional method and the authors\" method, which could be discussed in the paper. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as conducting calibration curves and discussing the difference between traditional and novel methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model AUC can assess the model discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It suggests that this consistency is crucial for the clinical scoring system and recommends conducting calibration curves to show the agreement. The comment also mentions the importance of discussing the difference between the traditional method and the authors\" method. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim about the importance of calibration curves. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of demonstrating consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. The comment suggests conducting calibration curves to show this consistency, offering a specific and concrete step for the authors to take. Additionally, it encourages the authors to discuss the difference between their method and traditional methods, providing a direction for further exploration. While the comment could be more helpful by offering examples of how to conduct calibration curves or suggesting specific aspects of the traditional method to discuss, it still provides valuable guidance for improving the draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the lack of discussion on crucial conditions for DICE and the need to ensure that these conditions are met. It explicitly mentions that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. However, the comment does not provide specific guidance on how to ensure DICE meets these conditions or what aspects of the discussion should be expanded. While the authors can infer that they need to address these issues, the lack of concrete steps or examples makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on crucial conditions for DICE and how to ensure these conditions are met. The comment provides specific examples of the conditions that need to be discussed, such as the range of ID and OOD and the requirement for an identical mean in Lemma 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These claims are 3 as they are based on observations from Figure 4 and the text, respectively. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claims. Providing more detailed evidence or references could strengthen the verifiability of the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of discussion on crucial conditions for DICE and the need to ensure these conditions are met. It points out that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These observations are important for the authors to address, as they highlight areas where the paper could be strengthened. However, the comment does not provide detailed guidance on how to ensure DICE meets these conditions or what specific aspects of the discussion should be expanded. While it highlights important issues, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment implies that the authors should consider these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these changes to improve the readability and clarity of their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. However, it does not specify which part of the paper these sections are located in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these sections are, the comment lacks full grounding. It is specific about the need for breaking out the sections and improving readability, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the integration of updates across all possible environments and suggests that it might be for space reasons. It also suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment provides a logical reasoning for the suggestion to break out the sections, it lacks specific examples or references to support the claim about the integration of updates. The suggestion for formatting improvements is more straightforward and verifiable. Therefore, the comment is 3, as it provides a logical basis for the suggestions but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the integration of updates across all possible environments, suggesting that it might be for space reasons. It also points out that the bolded sections in page 6 are currently a large wall of text and should be broken out into paragraphs for better readability. While the comment raises valid points, it lacks specific suggestions or guidance on how to address these issues, such as recommending a specific formatting or content improvement. The feedback is 3 as it highlights areas for potential improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but without specific guidance on how to do so, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the strength and fairness of the experiments, questioning the use of position kernels and the absence of certain baselines. It also suggests that the paper lacks discussion on limitations and societal impacts. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique to address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. It provides specific suggestions for addressing these issues, such as using default settings of baselines in the literature and comparing the proposed approach with other baselines. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how similar studies have addressed these concerns. Overall, the comment is 4 as it provides actionable feedback that can help the authors improve their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or improve their draft. There is no guidance on whether this drop is a concern, what factors might be contributing to it, or how the authors might mitigate it. As a result, the comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the correlation drop need to be addressed or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation about the correlation drop after a short period of training, which increases with more training iterations. This is a clear and actionable insight that could prompt the authors to investigate the reasons behind this phenomenon and consider ways to address it. However, the comment lacks depth and does not provide suggestions on how to investigate or mitigate the issue. While it points out a potential area for improvement, it could be more helpful with additional guidance or context. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of insight into the performance of sparsity patterns and questions whether this is unique to the sparsity detection problem or applies to GNNs in general. It suggests that the authors should provide more insight into this observation. However, the comment does not specify what kind of insight is needed or how the authors should present it. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or analysis but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of sparsity patterns and asking for more insight into whether this is unique to the sparsity detection problem or applies to GNNs in general. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the performance of sparsity patterns and whether this is unique to the sparsity detection problem or applies to GNNs in general. It suggests that the authors should provide more insight into this observation. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the performance is unexpected or noteworthy. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 3, as it provides a direction for further exploration but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance of sparsity patterns, noting that they seem to perform equally well across different patterns. It questions whether this is unique to the sparsity detection problem or applies to GNNs in general. The comment suggests that the authors should provide more insight into this observation, which could be a valuable contribution to the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide the requested insight. While it points out an area for improvement, it does not offer detailed advice on how to achieve it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. This provides a clear and direct action for the authors to take, ensuring that they either include the temperature or acknowledge its absence in the paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing temperature parameter, \u03c4, and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on how to improve the derivation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. The reviewer suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the temperature should be included or why its absence is problematic. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation from Equation 3 to Equation 4, noting that the temperature parameter, \u03c4, is missing. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this issue, the authors can enhance the rigor and clarity of their derivation, which is valuable for the overall quality of the paper. However, the comment could be more helpful if it included additional context or explanation on why the temperature parameter is important or how its inclusion would impact the paper\"s conclusions. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add a citation on differential privacy, specifically mentioning a standard work like 2. This is a clear and direct action for the authors to take, as it provides a specific reference to include in the paper. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, such as a standard work like 2. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like 2. This is a factual suggestion that does not involve an opinion, judgment, or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by suggesting the addition of a citation on differential privacy. By mentioning a standard work like 2, the reviewer provides a clear and actionable suggestion that can enhance the paper\"s credibility and comprehensiveness. However, the comment could be more helpful if it explained why differential privacy is relevant to the paper or how it could be integrated into the existing content. Despite this, the feedback is valuable as it directs the authors to a specific area for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. The reviewer provides a specific example of an additional assumption (the test set being drawn from the same distribution as the query set) and points out that this assumption is natural in many machine learning settings. The reviewer also notes an issue with the inequality on line 310, suggesting that it has the wrong sign. While the comment identifies specific areas of concern, it does not provide explicit guidance on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and correct the inequality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of Section 3.2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim, suggesting that it is too extreme and provides a specific example of an additional assumption that is natural in many machine learning settings. Additionally, it points out an issue with the inequality on line 310, which is incorrect. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the additional assumption of using the same distribution for the test and query sets is natural in many machine learning settings. The reviewer provides a logical reasoning by pointing out that this assumption is common in practice. However, the comment lacks specific examples or references to support the claim that this assumption is not significant. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. The reviewer offers a logical reasoning by pointing out that the additional assumption of using the same distribution for the test and query sets is natural in many machine learning settings. This feedback is valuable as it challenges the authors to reconsider their claim and potentially revise it to align with common practices in the field. Additionally, the comment identifies an issue with the inequality on line 310, which is incorrect. However, the comment could be more helpful if it provided suggestions on how to address these issues or improve the draft. Overall, the comment is 4 as it offers actionable feedback on the claim and the inequality, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. Additionally, it recommends including a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. While the comment provides explicit actions, it lacks concrete details on how to conduct these comparisons or what specific aspects of the advantages and disadvantages should be discussed. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of Shapely values over other methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for experimental comparisons with other methods and a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. It also recommends a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that Shapely values are superior to other methods. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the need for experimental comparisons with other methods, such as CaCE or raw gradients, to support the authors\" argument for using Shapely values over other methods. Additionally, it recommends a significant discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space, which could enhance the paper\"s comprehensiveness and depth. While the comment identifies specific areas for improvement, it could be more helpful if it provided examples of how these comparisons or discussions might be structured or conducted. Overall, the feedback is 4 as it guides the authors toward making meaningful enhancements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 needs this comparison or what aspects of the prior efforts should be compared. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the prior efforts should be compared or how this comparison would enhance the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in Section 6 by suggesting that the perspective taken in the manuscript could be compared to the contributions of prior efforts. This feedback is 3 as it points out a specific area where the authors could enhance their work by providing a more comprehensive comparison. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but not detailed steps for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact change needed (examining performance with different numbers of scenarios), but it is somewhat vague because it does not provide detailed guidance on how to conduct the experiment or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the training process or results, but this inference is not direct. The comment is specific in suggesting the need for an experiment with different scenario numbers, but it lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how it could be tested. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential relationship between the performance and the number of scenarios used for training, suggesting that examining performance with different numbers of scenarios could be interesting. This is a valuable observation that could lead to a meaningful experiment or analysis. However, the comment lacks specific guidance on how to conduct this experiment or what aspects of the performance to focus on. While it points out a potential area for improvement, it does not provide detailed instructions or suggestions for the authors to follow. Therefore, the comment is 3, as it highlights an interesting area for exploration but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or test their model under such disturbances. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s ability to generate the correct quality label. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue is discussed. The authors can infer that it relates to the model evaluation or training process, but this inference is not direct. The comment is specific in its inquiry about the model\"s ability to predict quality labels, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or test their model under disturbances. The feedback is 3 as it prompts the authors to consider the robustness of their model, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, additional experiments, or guidance on how to enhance the validation process. As a result, the authors are left without any clear direction on how to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the types of experiments conducted, but it lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that these experiments are comprehensive. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and crossdomain imitation. However, it lacks specificity and actionable feedback. It does not provide guidance on how the authors could improve or expand upon these experiments, nor does it offer suggestions for further validation or analysis. As a result, the comment is 3, as it identifies a strength but does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting described in the paper is only partially strategic or game theoretic, as the opponent does not behave strategically. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the strategic nature of the setting or what specific changes should be made to make it more game theoretic. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the setting described in the paper, suggesting that it is only partially strategic or game theoretic due to the opponent not behaving strategically. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the setting but lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the setting described in the paper is only partially strategic or game theoretic because the opponent does not behave strategically. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s setting, noting that it is only partially strategic or game theoretic due to the opponent not behaving strategically. This is a relevant observation that could prompt the authors to reconsider the nature of their setting and explore ways to enhance its strategic depth. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional strategic elements or gametheoretic approaches. While it points out a potential weakness, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a direct and concrete action for the authors to take, which is to improve the clarity of the illustration in Appendix A.2. The comment is specific about what needs to be addressed, making it 5. Authors know exactly what needs to be done to enhance the clarity of their illustration.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be improved in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. It points out that the illustration is not clear, which is a critical aspect of the paper\"s presentation. This feedback is actionable as it directs the authors to improve the clarity of the illustration, ensuring that readers can better understand the environment\"s state space. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or offered examples of how other similar illustrations have been effectively presented. Despite this, the comment is 4 as it highlights a specific area for improvement, which is valuable for the authors to address."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors\" approach is only applicable to small or mediumscale problems, suggesting that it may not be effective for truly large problems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to adapt the approach for larger problems or what specific steps to consider. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the authors\" approach is only applicable to small or mediumscale problems, implying that it may not be effective for truly large problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the applicability of the approach to large problems, but without clear references to sections or details, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems, suggesting that it may not be effective for truly large problems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the applicability of the authors\" approach, suggesting that it is only applicable to small or mediumscale problems. This is a relevant observation that could impact the scope and impact of the work. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this limitation or expand their approach to larger problems. Without detailed feedback or constructive advice, the authors are left with a general understanding of the issue but without clear steps to improve their draft. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the bounded noise assumption in the context of stochastic optimization literature, noting its restrictiveness and suggesting that it has been extended in recent works. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or incorporate these extensions into their work. The references to specific papers and authors are provided, but they do not directly instruct the authors on how to apply this information to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should explore these references and potentially incorporate them into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bounded noise assumption, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The references to specific papers, A. Khaled and P. Richt\"arik, R. Gower, O. Sebbouh, and N. Loizou, provide clear guidance on where the authors can find more information and how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The reviewer supports this claim by referencing specific works, such as A. Khaled and P. Richt\"arik, R. Gower, O. Sebbouh, and N. Loizou, which have explored sgd in the nonconvex world and provided better theory for stochastic optimization. These references provide a solid foundation for the claim, making it 4. However, the comment could be strengthened by further elaborating on how these extensions impact the bounded noise assumption or how the authors might incorporate them into their work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the bounded noise assumption, which is common in stochastic optimization literature but somewhat restrictive. It suggests that there have been efforts to extend these noise conditions, as evidenced by references to specific works. This feedback is 3 as it points out a potential area for improvement and provides references to relevant literature. However, it could be more helpful if it offered specific suggestions on how the authors might incorporate these extensions into their work or how they might address the restrictiveness of the bounded noise assumption. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might clarify this motivation or what specific aspects of the motivation are unclear. Without guidance on how to address this issue, the authors are left without a clear action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the motivation for using characteristic function regularization is not clear, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a lack of clarity in the motivation for using characteristic function regularization, which is an important aspect of the paper. However, it does not provide specific guidance or suggestions on how the authors might clarify this motivation or what aspects of the methodology are unclear. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it points out an area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the contribution is incremental because these techniques are not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to differentiate their work from existing techniques or how to enhance the contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is problematic: the fact that the results are a combination of existing techniques, which makes the contribution incremental. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. However, the comment lacks specific examples or references to these existing techniques to substantiate the claim. Without detailed evidence or comparisons, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 3, as it provides a general idea but lacks the necessary evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. While the comment highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or differentiate their work from existing techniques. The feedback lacks actionable advice or detailed insights, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and concrete, as it specifies exactly what needs to be added or clarified in the paper. The authors know exactly what information is missing and how to address it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"aggregation operation after \"Integration,\"\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the details of the aggregation operation and the acknowledgment of other architectures if they are referred to. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification and that the authors should provide more details in the main paper. It also mentions that if other architectures are referred to, they should be acknowledged properly. However, the comment does not provide specific examples or detailed reasoning to support why the aggregation operation is unclear or why it needs clarification. The suggestion to acknowledge other architectures is vague without further explanation. Therefore, the claim is 3, as it provides a general direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the aggregation operation after \"Integration.\" It suggests that the authors provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This feedback is clear and actionable, as it directs the authors to a specific area that needs improvement and provides a concrete suggestion for how to address it. However, the comment could be more helpful if it offered additional guidance on what specific details should be included or how to structure the clarification. Overall, the comment is 4 as it effectively points out a weakness and provides a direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to improve their writing quality, but without concrete steps or examples, they may struggle to know where to focus their efforts. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in detailing what exactly is unclear or needs improvement in the writing. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address them effectively. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies significant writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights these problems, it does not provide specific examples or suggestions on how to address them. The comment lacks actionable guidance or detailed feedback that would help the authors improve their draft. Without specific examples or constructive advice, the authors are left with a general understanding of the problems but no clear path to improvement. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to run the corresponding experiments and add the results to the figures and Table 1, clarifying specific aspects of the data used in the experiments. The comment also asks for clarification on the nature of the random data used in Figures 3c and 3, specifically whether the network was trained on random data or unaltered data, and whether the data was normalized. Additionally, it suggests including examples of random data in the appendix. These actions are clear and specific, providing the authors with a clear path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3c\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as running the corresponding experiments and adding the results to the figures and Table 1. The comment also asks for clarification on the nature of the random data used in Figures 3c and 3, and suggests including examples in the appendix. This level of detail provides clear guidance for the authors to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification and additional experiments, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying areas where the paper could be improved. It points out that the figures do not show results for untrained networks and suggests running the corresponding experiments and adding them to the figures and Table 1. Additionally, it clarifies specific aspects of the random data used in the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also suggests including examples of the random data in the appendix. This level of detail and guidance is highly beneficial for the authors, as it helps them address potential weaknesses and improve the clarity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or address this issue. Without guidance or direction, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on what \"100 steps\" means in the context of the search model comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically in section 5.1. This question highlights a potential area of confusion or ambiguity in the paper, which could be clarified to enhance the reader\"s understanding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the potential of exploring energy models for image generation and suggests that it is less explored compared to GANs and VAEs. However, it also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. While the comment implies that the authors should consider this similarity and potentially address it in their work, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the similarity to the prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it acknowledges that the motivation and goals of the model are similar to a prior VAE paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the comparison to the prior work. The lack of specific examples or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the potential of exploring energy models for image generation and notes that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model, which involve compositional generation through logical combination of concepts learned through data subsets, are similar to a prior VAE paper. This feedback is 3 as it highlights an area of potential interest and a similarity to prior work, which the authors could consider addressing. However, the comment lacks specific suggestions or guidance on how to address the similarity or improve the paper in this context. While it provides some insight, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. This feedback is explicit and provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is also concrete, as it specifies the need for statistical analysis and the need to repeat the experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the improvement over previous methods, specifically mentioning the results in Table 1 and Fig. 5. It also suggests repeating the experiments and conducting statistical significance analysis on the numbers. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting the need for statistical analysis and repeating the experiments, but without clear references to specific sections, the authors may struggle to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation. Additionally, it suggests that determining statistical significance is difficult due to the limited novelty and marginal improvement. The comment provides some logical reasoning by pointing out the lack of detailed reporting and statistical analysis, but it lacks specific examples or references to support the claim about the size of the improvement. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the limited improvement over previous methods and the lack of detailed reporting in the results. It suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving their draft. However, the comment could be more helpful if it explained why statistical significance analysis is necessary or how it would enhance the paper\"s contribution. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends conducting experiments on a different benchmark, such as Atari, to verify the generalizability of the method. This suggestion is clear and provides a specific action for the authors to take. Additionally, it highlights the importance of evaluating the method on a diverse set of domains to ensure its applicability beyond the Meta World domain. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation on a single domain, Meta World, and suggests running experiments on a different benchmark, such as Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for generalizability testing and the importance of evaluating the method on a diverse set of domains. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is evaluated only on the tasks from Meta World, a robotic manipulation domain, which makes it difficult to judge whether the results will generalize to other domains. The reviewer suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is based on the need to verify whether the method works with discrete action spaces and highdimensional observations. The claim is 3 as it provides a logical reasoning for the need to test generalizability, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is evaluated only on the tasks from Meta World, a robotic manipulation domain. This observation highlights the need for generalizability testing to ensure that the results can be applied to other domains. The comment provides a specific recommendation to conduct experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is actionable and offers a clear path for the authors to improve their draft by expanding the evaluation to a more diverse set of domains. However, the comment could be more helpful if it included examples of how the Atari benchmark could be used or why it is particularly relevant for the method under consideration. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The comment implies that the authors should add more depth to the explanation of the model, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what aspects of the model should be analyzed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is specific in suggesting the need for an analysis but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that while the method is presented well and the experiments are thorough, there is a lack of analysis on what the model does. This feedback highlights an area for improvement, suggesting that the authors should include an analysis of the model\"s functionality, which could be interesting. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on, leaving the authors with a general direction but without detailed instructions. Therefore, the comment is 3, as it points out a potential area for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the task setup is not described clearly, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issue and how to address it. Therefore, the claim is considered 2, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the task setup, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This feedback is clear and actionable, as it points out a specific area where the authors need to provide more detail or clarification. By addressing these points, the authors can improve the clarity and comprehensibility of their task setup, which is crucial for the success of their work. However, the comment could be more helpful if it offered suggestions on how to present this information more effectively or provided examples of how similar tasks have been described in other works. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of the approach section in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the approach section. The comment implies that the authors should include the approach section in the main paper, but it lacks concrete details on how to integrate it or what specific content should be included. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" and the \"supplementary material,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the approach section in the main paper and the use of supplementary material as additional information rather than an extension to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the approach section should be included or how the supplementary material should be used. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the approach section is missing in the main paper. It suggests that the supplementary material should be used as additional information rather than an extension to the paper. While the comment highlights an important oversight, it lacks specific guidance on how to address this issue or what content should be included in the approach section. The feedback is 3 as it points out a critical gap in the paper, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the statement regarding the biological plausibility of backpropagation in the introduction may be too weak and points out that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to strengthen the statement. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the statement and provide more robust evidence or reasoning to support it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the weakness of the statement and the need to provide more robust evidence or reasoning to support it. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation in the introduction is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation. It points out that the statement may be too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is 3 as it highlights an area where the authors may need to provide more robust evidence or reasoning to support their claims. However, the comment could be more helpful if it suggested specific ways to strengthen the statement or provided examples of alternative arguments or evidence that could be used. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the modulator is heuristically designed and questions the scalability issue, suggesting that there might be a need for tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of scalability in the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the scalability issue and the potential need for hyperparameter tuning, but without clear grounding, the authors cannot confidently determine which part of the paper this pertains to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the modulator is heuristically designed and questions the scalability issue, suggesting that there might be a need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some indication of a potential problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. This is a relevant concern that could impact the practicality and efficiency of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of the modulator. Without actionable advice or detailed feedback, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail for the authors to effectively address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that f_R and f_P can be adapted over time but notes that the experiments performed here incorporate a significant amount of domain knowledge. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to consider. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges that f_R and f_P can be adapted over time but notes that the experiments performed here incorporate a significant amount of domain knowledge. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the amount of domain knowledge required for less informed f_R/f_P, but without clear grounding, the authors cannot confidently determine which part of the paper this pertains to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments performed here incorporate a significant amount of domain knowledge, which could lead to an impractical amount of data required for less informed f_R/f_P. However, the comment does not provide specific examples or references to support this claim. It lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that f_R and f_P can be adapted over time but notes that the experiments performed here incorporate a significant amount of domain knowledge. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. While the comment identifies a potential issue with the model\"s reliance on domain knowledge, it lacks specific suggestions or guidance on how the authors might address this concern. The feedback highlights a potential limitation but does not provide actionable steps for improvement, making it 3. The authors are given insight into a potential weakness but are not provided with detailed guidance on how to address it. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should conduct experiments to explore these aspects, but it lacks concrete guidance on what specific experiments to conduct or how to analyze the results. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for experiments on data acquisition and performance changes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is necessary to obtain labeled data for imitation learning and suggests that experiments should be conducted to explore difficulties in data acquisition and performance changes with data size. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. It highlights the need for experiments to explore these aspects, which is a crucial aspect of imitation learning. However, the comment lacks specific suggestions on how to conduct these experiments or what specific aspects to focus on. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection between the necessary conditions and generalization bounds, suggesting that the constructions of ReLU networks for robust memorization may not lead to robust generalization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the connection between necessary conditions and generalization bounds, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of overparameterization and its implications on generalization bounds, suggesting that the necessary conditions may have stronger implications if they are connected to generalization. It mentions the constructions of ReLU networks for robust memorization and questions whether this leads to robust generalization. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the connection between necessary conditions and generalization bounds, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connection between necessary conditions and generalization bounds, suggesting that overparameterization can lead to powerful memorization and good generalization performance. The reviewer acknowledges that the authors acknowledge this in the conclusion but questions whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are given a direction to explore, but the comment is 3 as it requires further elaboration to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the connection between necessary conditions and generalization bounds, suggesting that overparameterization can lead to powerful memorization and good generalization performance. It raises a serious question about whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the comment acknowledges that the authors acknowledge this in the conclusion, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or detailed guidance for the authors to improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. However, it does not provide specific guidance on how the authors should address this issue or what additional exploration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the generalizability of their results. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s exploration of the implications of the proposed method for other NLP tasks, suggesting that the paper\"s generalizability is somewhat limited due to this lack of exploration. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which somewhat limits its generalizability. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. This observation highlights a potential weakness in the generalizability of the results, which could impact the paper\"s impact and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional exploration could be conducted. While it points out an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the terminology \"certificate\" in the paper, as it has a strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to avoid confusion. The action is implicit and vague, as the authors are left to infer that they need to reconsider the use of this terminology and possibly provide clarification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the terminology \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the terminology \"certificate\" in some contexts could be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the terminology \"certificate\" in the paper, noting that it has a strong meaning in complexity theory. This is a valuable observation that could lead to confusion or misinterpretation by readers. However, the comment does not provide specific guidance on how the authors should address this issue or suggest alternative terminology. While it highlights a potential problem, it lacks actionable advice or detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems in imaging, specifically mentioning the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with these methods. While the comment provides a clear action\u2014mentioning the relevant work and potentially comparing the current method\u2014it does not specify how to integrate this information into the paper or what specific aspects of the work should be compared. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" for inverse problems in imaging, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work by Ulyanov et al. (CVPR 2018) and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. This provides clear guidance on how to enhance the paper by incorporating relevant references and comparisons. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the current work is interesting because the trained network can provide strong OOD generalization. However, it also mentions that untrained NNs, like those used in the Ulyanov et al. (CVPR 2018) paper, can be used for inverse problems across a wide range of images. The reviewer suggests that the current work should be placed in context by mentioning these existing methods and potentially comparing them. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to the Ulyanov et al. paper or other relevant works that could strengthen the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a constructive suggestion by pointing out that the current work on OOD experiments is interesting due to the strong generalization capabilities of the trained network. However, it also highlights a potential limitation by mentioning that untrained NNs, like those used in the Ulyanov et al. (CVPR 2018) paper, can be used for inverse problems across a wide range of images. The comment suggests that the current work should be placed in context by mentioning these existing methods and potentially comparing them. This feedback is valuable as it encourages the authors to consider the broader context of their work and potentially enhance its impact by incorporating these comparisons. However, the comment could be more helpful if it provided specific guidance on how to integrate these comparisons or which aspects of the work should be highlighted. Overall, the comment is 4 as it offers actionable suggestions for improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. It explicitly states that there is a range of problems with real data where barycenters can be used and suggests that the method\"s performance should be demonstrated in those settings. This feedback provides a clear and concrete action for the authors to take, as it specifies the need to include real data experiments and the potential benefits of doing so. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests expanding the scope of the experiments to include real data, which implies that the current experiments are limited to toy data. However, it does not specify which part of the paper discusses the experiments or where the limitation is mentioned, making it weakly grounded. The comment is specific in suggesting that real data experiments could be beneficial and highlighting the potential use of barycenters in realworld scenarios. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. However, the comment does not provide any specific examples or references to support the claim that real data experiments would be beneficial or necessary. Without such evidence or reasoning, the authors may find it challenging to understand the basis of the suggestion and how it could improve their work. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the recommendation.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are currently limited to toy data. It suggests expanding the scope to include real data, which could provide a more comprehensive understanding of the method\"s performance in various settings. This feedback is clear and actionable, as it directs the authors to consider incorporating realworld data experiments to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these experiments or what aspects of realworld data would be most relevant. Overall, the comment is 4 as it points out a significant area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment implies that additional experiments are necessary, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions on how to implement the suggested experiments. The action is implicit and somewhat vague, as the authors need to infer the specific details of how to proceed with the additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. The references provided are relevant but do not directly address the comment. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. The comment provides references to relevant works, which supports the claim that these experiments could enhance the paper. However, the comment lacks specific details on why these additional experiments are necessary or how they would contribute to the paper\"s strength. The references are helpful but do not fully substantiate the claim, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions or suggestions for implementation. Therefore, the comment is 3 as it points out a potential area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sample selection mechanism is not clearly explained in terms of how it preserves the label distribution. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific ways to clarify the mechanism or suggesting alternative explanations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed sample selection mechanism, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding why the proposed mechanism preserves the label distribution. This provides clear guidance on what the authors need to clarify or improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the proposed sample selection mechanism and its effect on preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the proposed sample selection mechanism and its effect on preserving the label distribution. This is a relevant point that could impact the clarity and understanding of the paper. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the explanation of their method. Without actionable feedback or additional context, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any explicit or implicit suggestions for improvement or additional models to consider. The authors are left without guidance on how to enhance the scope or relevance of their evaluation. As a result, the comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the results and analysis, noting that they are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not specify which part of the paper this critique pertains to, such as the results or analysis sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the evaluation are limited by the choice of models. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to other models or studies that could be considered, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are considered. This feedback highlights an area where the authors could potentially expand the scope and relevance of their evaluation by including more diverse or contemporary models. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional models or methods to consider. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer implies that this makes the motivation for Algorithm 1 unclear. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. It lacks actionable details, such as suggesting how to clarify the motivation or how to incorporate this insight into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation of Algorithm 1 being unclear due to the equivalence of the proxlinear subproblem with the subproblem in Algorithm 1. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This suggests that the motivation for Algorithm 1 is unclear due to this equivalence. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is based on logical reasoning and common knowledge, but without detailed evidence or references, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the motivation of Algorithm 1, noting that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This suggests that the motivation for Algorithm 1 is unclear due to this equivalence. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or clarify the motivation for Algorithm 1. While it points out a potential problem, it lacks depth and specificity, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS, particularly when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take based on this observation. There is no guidance on how to incorporate this understanding into the paper or what specific aspects of the paper should be revised to reflect this perspective. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion that LS and KD are equivalent under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD can be considered a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without additional context or evidence, the claim remains 1, as it does not provide sufficient justification for the authors to address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. It provides a specific example of when this equivalence occurs, which is when the teacher network is uniformly distributed and the temperature is set at 1. This feedback is 3 as it offers a potential insight into the relationship between KD and LS, which could be useful for the authors to consider when discussing their method. However, the comment could be more helpful if it provided suggestions on how to incorporate this understanding into the paper or how to address any implications of this equivalence. Overall, the comment offers a valuable perspective but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results on largescale datasets, such as ImageNet, to verify the effectiveness of their proposed method. This feedback is explicit and provides a clear action for the authors to take, which is to include results on larger datasets. The comment also mentions that competing dynamicpruning methods are outdated, implying that the authors should consider more recent works. However, it does not specify which recent works should be included or how to incorporate them into the paper. While the action is clear, the lack of detailed guidance on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamicpruning methods are kind of outofdate,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of results on largescale datasets, such as ImageNet, to verify the effectiveness of the proposed method. Additionally, it suggests that the authors should consider more recent works on dynamicpruning methods. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"Competing dynamicpruning methods are kind of outofdate\" and suggests that more recent works should be included. However, the comment does not provide specific examples of outdated methods or recent works that should be considered, nor does it explain why these changes would be beneficial. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include results on largescale datasets, such as ImageNet, to verify the effectiveness of their proposed method. It also points out that competing dynamicpruning methods are outdated, implying that the authors should consider more recent works. This feedback is specific and offers a concrete direction for improvement, making it 4. However, it could be more helpful if it provided examples of recent works or detailed guidance on how to incorporate these changes into the paper. Overall, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to provide an explanation for why the performance degrades when using additional information about missing, wrong, or redundant data. This is a clear and direct request, giving the authors a specific action to take. The comment is specific in its request for an explanation, which provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the performance degrades when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance degradation when using additional information about missing, wrong, or redundant data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance degradation when using additional information about missing, wrong, or redundant data. It prompts the authors to provide an explanation for this phenomenon, which is a clear and actionable request. This feedback is valuable as it directs the authors to clarify an aspect of their results that may be confusing or misleading. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have handled similar challenges. Overall, the comment is 4 as it guides the authors to improve the clarity and understanding of their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. The reviewer explicitly asks for clarification on these points, providing a clear direction for the authors to improve the clarity of their explanations. The action is explicit and concrete, as it specifies exactly what needs to be addressed to improve the readability of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail helps the authors understand what needs to be addressed to improve the clarity of their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are hard to read due to unclear explanations of previous approaches. It provides specific examples of unclear statements, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. These examples are detailed and provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to support the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity and readability of the first two sections of the paper. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96, and asks for clarification on these points. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their explanations. By addressing these issues, the authors can enhance the readability and accessibility of their paper, which is valuable guidance for improving the draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the captions should be more descriptive and provides a specific example of the issue, noting that it is annoying to have to search through the text for the interpretation of figures, which is usually on a different page. Additionally, it requests an explanation of the scramble network. While the comment provides a clear action to make the captions more descriptive and an explicit request for an explanation of the scramble network, it does not offer detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specifics of how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the captions and the scramble network, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as making the captions more descriptive and explaining the scramble network better. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions are not descriptive and that it is annoying to search through the text for the interpretation of figures, which are usually on a different page. The comment also requests an explanation of the scramble network. While the comment identifies a specific issue with the captions, it lacks detailed reasoning or examples to support why this is a problem or how it could be improved. The suggestion to make the captions more descriptive is somewhat vague, and the explanation of the scramble network is not provided. Therefore, the claim is 3, as it provides some direction but lacks sufficient detail for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies specific areas for improvement, namely the need for more descriptive captions and an explanation of the scramble network. By pointing out that the captions are not descriptive and that it is frustrating to search through the text for interpretations, the comment provides clear guidance on how to enhance the clarity and accessibility of the paper. Additionally, it suggests that the scramble network should be explained better, which is a valuable suggestion for improving the paper\"s technical content. However, the comment could be more helpful if it offered specific examples or suggestions on how to make the captions more descriptive or how to explain the scramble network. Overall, the comment is 4 as it provides actionable feedback that can significantly improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It raises a valid point about the interest in this particular dimension of difficulty, but it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment lacks actionable details, such as recommending alternative methods or explaining why this choice might be problematic. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and seeks clarification on why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that this choice is not wellmotivated and raises a valid point about the interest in this particular dimension of difficulty. However, the comment lacks specific examples or references to support the claim that this choice is not wellmotivated. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 3, as it provides a logical argument but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. It raises a valid point about the interest in this particular dimension of difficulty, which could be an important aspect for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might better justify or explain their choice. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is explicit and provides a clear action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (3)\" and \"the analysis about flatness,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the losses of the noiseinjected models after training to substantiate the claim about the flatness of the minima found by the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis about the flatness of the minima is missing, and it suggests that minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima. The reviewer provides a logical reasoning by explaining that the loss used for training the base model is the averaged loss for the noiseinjected models, and that the convergence analysis on this loss does not guarantee the flatness of the minima. However, the comment lacks specific examples or references to support the claim that the analysis on the losses of the noiseinjected models after training is necessary to substantiate the claim about the flatness of the minima. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer provides a logical explanation of why minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima, and suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is clear and actionable, guiding the authors to address a crucial aspect of their argument that could significantly impact the paper\"s credibility. Therefore, the comment is 4, as it provides a concrete direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to make the text inside the figure and labels roughly the same size as the manuscript text. This is a clear and direct action that the authors can take to improve the readability of their figures. The comment provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the size of the text compared to the manuscript text. This provides clear guidance on how to improve the readability of the figures. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and labels is too small to read without zooming, suggesting that it should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the readability of the figures. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the figures, noting that the text inside the figure and the labels are too small to read without zooming. It provides a clear and actionable suggestion to make the text roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a usability concern that could impact the accessibility and comprehension of the figures. However, the comment could be more helpful if it included examples or additional guidance on how to achieve this improvement. Overall, the comment is 4 as it effectively points out a specific issue and offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a direct and concrete action for the authors to take, which is to revise the introduction to clarify the motivation. The comment also implies that the current introduction may be confusing or difficult to understand, which further guides the authors on what aspects need improvement. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the motivation and the need for a revised introduction to make the paper easier to follow. This provides clear guidance on what aspects of the paper need improvement, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of clarity in the motivation. It suggests that the introduction should be revised to make the paper easier to follow, which is a crucial point for the authors to address. However, the comment does not provide specific guidance on how to revise the introduction or what aspects of the motivation are unclear. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not offer actionable steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the paper. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the features or positions differ across categories, leaving the authors without clear guidance on how to address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps to take to ensure its validity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the alignment of relabeled reward data with human annotator judgments, indicating that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficient validation of the alignment between relabeled reward data and human annotator judgments. This is a critical point that could impact the reliability and robustness of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model is somewhat complicated and recommends improving its presentation in Section 4, possibly by referring to the supplement. It also provides specific suggestions for enhancing the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These actions are explicit and concrete, providing clear guidance on how to improve the presentation of the model. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as suggesting the use of notation and breakout diagrams to enhance the presentation of the model. This level of detail provides the authors with a clear understanding of what changes are needed to improve the presentation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model is somewhat complicated and recommends improving its presentation in Section 4. It provides a specific suggestion to replace natural language descriptions with notation and adds breakout diagrams to illustrate the attention mechanisms. This claim is 3 as it offers a logical suggestion for improving the presentation, but it lacks detailed justification or examples to fully substantiate the claim. The authors might need to explore the specific benefits of using notation and diagrams to enhance the presentation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It provides specific suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These suggestions are actionable and can help the authors enhance the clarity and accessibility of their presentation. However, the comment could be more helpful if it explained why these changes are necessary or provided examples of how they might be implemented. Overall, the comment is 4 as it offers clear and constructive guidance for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or expand their experiments to include more molecules. The action is implicit and vague, as the authors are left to infer that they should consider expanding their experiments to include more molecules. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limited scope of the experiments conducted in the paper, specifically mentioning that only a few molecules are tested and that indistribution testing is provided for these samples. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limited scope of the experiments and the potential limitations of the method if it requires training for each molecule individually. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. This feedback is 3 as it points out a potential weakness in the paper\"s scope and suggests an area for improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments to include more molecules. While it highlights an important issue, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any explicit or implicit suggestions for how the authors might simplify these symbols or make them more accessible to readers. There is no guidance on whether the symbols should be explained more clearly, simplified, or presented in a different manner. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions the complexity of the symbols used in the paper, suggesting that they are difficult to understand. However, it does not specify which symbols or parts of the paper are causing this issue, making it difficult for the authors to pinpoint the exact areas that need attention. Additionally, the comment lacks specificity regarding what aspects of the symbols are causing the complexity or how they could be simplified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the complexity of the symbols used in the paper, suggesting that they are difficult to understand and take a lot of time to comprehend. While this feedback identifies a potential weakness, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed advice on how to simplify the symbols or improve their clarity, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the source of the red line and the ground truth, but it lacks specific instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the origin of the red line and whether there is a ground truth for the test data. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. This is a relevant point that could help the authors clarify their methodology and ensure the validity of their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to take. It lacks actionable details, such as recommending specific modifications or experiments to address this concern. As a result, the authors are left without a clear path forward, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as specific experiments or sections where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the role of periodicity in the results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a logical basis for the question but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending experiments or modifications to the model. While it provides a thoughtprovoking insight, it could be more helpful with additional actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper is not wellwritten and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues, such as suggesting particular formatting changes or improvements to the figures and tables. The authors are left to infer that they need to improve the writing and formatting, but without concrete steps, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s writing quality, suggesting that it may be rushed and difficult to read. It mentions specific areas for improvement, such as presentation and formatting, particularly in figures and tables. However, the comment does not specify which parts of the paper are particularly problematic or how the formatting issues affect the readability. While the authors can infer that the issues are related to figures and tables, the comment lacks full grounding as it does not explicitly mention these sections. The specificity of the comment is limited, as it does not provide detailed guidance on what changes are needed to improve the writing and formatting. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of specificity and detailed evidence or references makes the claim 2, as it provides some indication but not enough detail for the authors to fully understand and act upon the feedback.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s writing quality, suggesting that it may be rushed and difficult to read. It highlights specific areas for improvement, such as presentation and formatting, particularly in figures and tables. While the comment provides some insight into the areas needing attention, it lacks detailed guidance or specific suggestions on how to improve the writing and formatting. The authors are left with a general understanding of the issues but without actionable steps to address them. Therefore, the comment is 3, as it points out areas for improvement but does not provide comprehensive guidance for the authors to make significant improvements to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the introduction to orthogonality in Part 2 could be more detailed. This provides a clear and direct action for the authors to take, which is to expand or clarify the introduction to make it more comprehensive. The comment is specific in identifying the need for more detail, making it 5. Authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Part 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction to orthogonality. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning or examples to support why this detail is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the authors to understand the need for more detail. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the introduction to orthogonality in Part 2. It suggests that the introduction could be more detailed, providing a clear direction for the authors to enhance their draft. However, the comment lacks depth and does not offer specific suggestions or examples of what additional details might be beneficial. While it points out a potential weakness, it does not provide actionable guidance on how to address it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should highlight the novelty of its result in relation to prior work, particularly regarding the removal of double descent in certain anisotropic settings. While the comment implies that the authors should clarify the novelty of their contribution, it does not provide specific guidance on how to do so or what aspects of the paper should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the novelty of their result. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical results of prior work that show samplewise multiple descent in linear regression, which provides a clear reference point for the authors to address. It also specifies the main contribution of the paper, which is the result that optimal regularization can remove double descent in certain anisotropic settings. The comment suggests that if this is not the case, the paper should better highlight the novelty of their result in relation to prior results. However, it does not provide specific guidance on how to achieve this or what aspects of the paper should be emphasized. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the paper\"s main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, which is based on prior work that theoretically shows samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper but suggests that the claims seem correct. This provides a logical basis for the claim but lacks specific references or detailed evidence to fully substantiate it. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed evidence or references to fully support it.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s contribution, noting that the main result about removing double descent in certain anisotropic settings is based on prior work that theoretically shows samplewise multiple descent in linear regression. The reviewer suggests that the paper should better highlight the novelty of its result in relation to prior results, as the theoretical basis is already established. While the comment provides a clear direction for improvement, it lacks specific guidance on how to effectively highlight the novelty or what aspects of the paper should be emphasized. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed suggestions for enhancing the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to integrate the methods or improve their connection. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically contrastive training objective and contrastive search, and notes that they are independent methods with little inner connection on both the intuition and the algorithm. However, it does not specify which part of the paper these methods are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of lack of connection between the methods, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods, contrastive training objective and contrastive search, noting that they are independent and lack a clear connection on both the intuition and the algorithm. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights a potential area for improvement, but without actionable advice or detailed analysis, it does not fully support the authors in enhancing their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern regarding the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. While the comment implies that the authors should provide a comparison and justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the goal of the paper and the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. It also suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. While the comment identifies a potential issue with the paper\"s goal and suggests a need for comparison and justification, it lacks specific examples or references to support the claim that existing DAS earthquake detectors exist. This makes the claim 3, as the authors would need to infer the need for comparison and justification based on the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s goal, noting the absence of a comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the lack of justification for the benefits of the proposed method over these existing methods. It suggests that if the paper is to establish a foundation model, the authors should clarify this and demonstrate a future useful application. This feedback is clear and actionable, as it points out a critical area for improvement in the paper\"s justification and comparison with existing work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how similar comparisons have been conducted in similar works. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what about the ablation studies of MCT without the adaptive metrics. While these questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to clarify the discrepancy in the results and potentially include ablation studies, but the comment lacks specific details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the alignment of results and asking about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two questions that are relevant to the paper\"s content and methodology. First, it questions the alignment of results between Table 6 and Table 1 (MCTpair), which could indicate a discrepancy or inconsistency in the data. Second, it asks about the ablation studies of MCT without the adaptive metrics, suggesting that this could provide valuable insights into the model\"s performance. While the comment identifies areas for clarification and potential enhancement, it does not offer specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of the need for clarification but without detailed instructions on how to proceed. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR10 models on distribution shifts. It references specific works that have already explored these topics, such as RobustBench and A, B. The comment suggests that the authors should consider these existing works and potentially expand their analysis to include other models or datasets. However, it does not provide explicit instructions on how to incorporate these references or what specific aspects of the prior work should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific analyses and prior works, such as RobustBench and A, B, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses have been conducted in prior works, which may not be surprising due to the limited scale of the current work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR10 models on distribution shifts. It references specific works, such as RobustBench and A, B, which have explored these topics. The comment also mentions that the results are not particularly surprising, as they align with prior work. This provides a logical reasoning and references to support the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and surprise of the current work, noting that similar analyses have been conducted in prior works. It specifically references existing studies, such as RobustBench and A, B, which have explored the robustness of CIFAR10 models on distribution shifts. The comment suggests that the current work may not provide significant new insights or contributions due to the overlap with prior work. However, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing studies. While the comment highlights a potential weakness, it lacks actionable advice or detailed feedback to help the authors improve their draft. Therefore, it is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not provide any specific guidance on what kind of discussions are needed or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not specify which part of the paper these subtasks are discussed in or where the discussions are lacking. Without explicit references to sections or specific subtasks, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples to substantiate the assertion that the subtasks are simplistic or why additional discussions are necessary. Without such support, the claim remains 1, as it does not provide sufficient evidence or justification for the authors to understand and address the critique. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The comment identifies a potential issue with the 10 subtasks being simplistic for bAbi, suggesting that they could solve all the subtasks with their final model. However, it lacks specificity and does not provide any guidance on how the authors might address this issue or what kind of discussions are needed. Without actionable suggestions or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider this limitation and potentially explore alternatives, it does not provide explicit instructions or concrete suggestions on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider extending the approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether the limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual observation seeking clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a valid concern about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It questions whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. This feedback prompts the authors to consider whether their approach is limited by the specific windowing method or if it can be extended to accommodate different windowing methods. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how to address this limitation or explore alternative approaches. Therefore, the comment is 3, as it points out an area for improvement but does not provide detailed guidance for the authors to act upon."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper and suggests that related work might be relevant but not necessarily detrimental to the novelty of the paper. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sequence of episodes\" and suggesting that related work might be relevant but not detrimental to the novelty of the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and observations about the definition of \"sequence of episodes\" and the relevance of related work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper, which is a relevant point for clarity. It also suggests that related work might be relevant but not detrimental to the novelty of the paper. While the comment identifies a potential area for improvement by suggesting the inclusion of related work, it lacks specific guidance or suggestions on how to address this issue or incorporate related work into the paper. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable and detailed to be fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes should be made to the study. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the study\"s classification but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. While the comment identifies a potential issue with the study\"s designation, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or reframe their study. The feedback is 3 as it points out a potential misclassification, but it could be more beneficial if it offered actionable advice or alternative terminology. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps the authors should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the inclusion of AccNet in a larger predictor. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation. It suggests that it might make sense to include AccNet in this context. However, the comment lacks depth and does not provide any specific guidance or suggestions on how the authors might address this question or integrate AccNet into their work. Without actionable advice or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any guidance on how the authors should address this issue or suggest ways to expand the testing to other datasets. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment points out that the proposed metric is only tested on a single dataset, which is a specific issue. However, it does not specify which dataset or which part of the paper discusses the metric testing. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of testing on a single dataset, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed metric is only tested on a single dataset. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it affects the paper\"s validity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the paper, specifically that the proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue, such as recommending additional datasets for testing or discussing the implications of this limitation. While it identifies a potential weakness, the feedback does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm (TN) architecture to similar competitors like AutoDial and AdaBN. This feedback provides a clear and explicit action for the authors to take, which is to extend the evaluation to include these additional competitors. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"comparing several base DA methods with and without the proposed TransferNorm architecture.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN. This provides clear guidance on what additional comparisons should be made to enhance the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN. However, the comment does not provide specific reasoning or evidence to support why these competitors are necessary or how they would enhance the evaluation. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the evaluation section by suggesting that the base DA methods should be evaluated with and without the proposed TransferNorm (TN) architecture, as well as with other architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation by including additional comparisons. By doing so, the authors can better demonstrate the strengths and weaknesses of their proposed method in relation to other stateoftheart approaches. However, the comment could be more helpful if it explained why these additional comparisons are important or how they would impact the evaluation\"s conclusions. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6. It also mentions that the lack of definitions hindered understanding in an initial read. The reviewer provides specific references to similar works that have defined these terms, which offers a clear direction for the authors to address these issues. By explicitly mentioning the undefined terms and providing examples of how they have been defined in other works, the comment offers concrete guidance on how to improve the clarity and accessibility of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"L73\" and \"L166,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that some abbreviations are not defined and that the superscript notation in Equation 6 is not defined until later, which hinders understanding. The comment provides examples of similar works that have defined these terms, offering clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6. It provides examples of similar works that have defined these terms, which helps to substantiate the claim that these issues hinder understanding. However, the comment could be strengthened by providing more detailed explanations or references to the specific sections where these issues occur, which would enhance the verifiability. As it stands, the comment is 4, as it provides some evidence but lacks detailed justification or examples. Therefore, the score is 4.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. It provides examples of similar works that have defined these terms, offering clear guidance on how the authors can improve the clarity and accessibility of their paper. By pointing out these specific issues and providing references to similar works, the comment offers actionable feedback that can help the authors enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it suggested ways to address these issues, such as providing definitions or examples of how the terms are used in the context of the paper. Overall, the comment is 4 as it identifies important areas for improvement and offers concrete suggestions for addressing them."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue. There is no guidance on what specific changes or improvements could be made to the evaluation or baselines. Without actionable advice or concrete steps, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"evaluation\" and \"baselines used in the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation being weak and the baselines not being designed for fair classification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, noting that the baselines used in the paper are not designed for fair classification. This is a critical observation that highlights a potential weakness in the paper\"s methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the evaluation. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the setting but may not be entirely sure of the exact details to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting needs to be spelled out more clearly and suggesting that the authors may be trying to present something in greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. The reviewer suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to understand the exact issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors may be presenting something in greater generality than what is actually shown, which muddles the exposition. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their work to improve the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the setting or what specific aspects need to be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the convincing nature of the experiments and questions the choice of the old baseline, R3D and C3D. It suggests that the authors should consider using more recent baselines or 3D CNNs, such as X3D, SlowFast, etc., to test the proposed method. The comment implies that the authors should compare their method with these baselines to demonstrate its advantage. While the action is implicit, it is clear that the authors need to address these points to improve the draft. However, the comment does not provide specific guidance on how to implement these changes or what specific aspects to focus on, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of baseline and suggesting that the proposed method should be tested against more recent 3D CNNs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the convincing nature of the experiments and suggests that the authors should consider using more recent baselines or 3D CNNs, such as X3D and SlowFast. The comment provides a logical reasoning by pointing out that many papers have proposed methods for reducing computation complexity in 3D CNNs. However, it lacks specific examples or references to these papers, which would strengthen the claim. The suggestion to compare the proposed method with these baselines is a valid point, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experiments, questioning their convincing nature and suggesting that the authors should consider using more recent baselines or 3D CNNs, such as X3D and SlowFast. This feedback is valuable as it prompts the authors to reconsider their choice of baselines and potentially strengthen their experimental setup. However, the comment could be more helpful if it provided specific guidance on how to address this issue or what aspects of the proposed method should be compared with these baselines. Overall, the comment is 3 as it points out a potential area for improvement but lacks detailed guidance for the authors to fully address the concern."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the attention module is attached to the backbone ResNet20 architecture, including the number of attention modules used, their placement (after each block or stage), and how they are integrated into the overall architecture. This feedback provides clear and specific guidance on what the authors need to address to improve the clarity of their draft. The action is concrete, as it details the exact information that needs to be clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module attached to the backbone ResNet20 architecture\" and asks for clarification on the number of attention modules, their placement, and how they are integrated into the architecture. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules and their placement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how the attention module is attached to the backbone ResNet20 architecture, specifically asking for clarification on the number of attention modules, their placement, and how they are integrated into the architecture. This is a request for more detailed information, which is not a claim but rather a request for clarification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the integration of the attention module with the backbone ResNet20 architecture. It asks for clarification on the number of attention modules used, their placement, and how they are integrated into the architecture. This feedback is clear and actionable, as it provides the authors with specific questions to address in order to improve the clarity of their draft. By addressing these points, the authors can enhance the understanding of their method and its implementation. However, the comment could be more helpful if it offered suggestions on how to present this information in a clearer manner. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. It also asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work on implementing contentadaptive algorithms in learned video compression. While the comment provides a clear direction for improvement by suggesting a specific area for comparison and a related work to consider, it does not explicitly instruct the authors on how to implement these changes or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BDrate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance at low bitrates and the need for clarification on the bitrate range used for comparison. Additionally, it suggests a related work for discussion or comparison, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. The reviewer asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work on implementing contentadaptive algorithms in learned video compression. While the comment identifies a potential issue with the method\"s performance, it lacks specific examples or detailed reasoning to support the claim that the method is close to the baselines at low bitrates. The suggestion to discuss a related work is helpful but does not fully address the initial concern. Therefore, the claim is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it performs stronger at high bitrates but is close to the baselines at low bitrates. This is a valuable observation that prompts the authors to reconsider their method\"s performance at different bitrates. The comment also suggests clarifying the precise bitrate range used for BDrate comparison and provides a related work for discussion or comparison. This feedback is actionable and constructive, as it guides the authors to address a specific area of concern and offers a potential direction for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to implement the suggested changes or what specific aspects of the method need further exploration. Overall, the comment is 4 as it directs the authors to a critical area for improvement and offers a relevant reference for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should make this distinction, it does not provide explicit instructions on how to do so or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they need to make a distinction between the two concepts. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide detailed guidance on how to make this distinction. The authors can infer that it relates to the discussion or analysis of the results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. This feedback is 3 as it identifies a potential area for clarification and differentiation in the paper. However, the comment lacks specific guidance on how to make this distinction or what aspects of the paper need to be revised to achieve this clarity. While it points out a potential issue, it does not provide detailed suggestions or examples to help the authors fully understand and address the concern. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or what additional analysis could be conducted. The comment lacks concrete details or specific actions for the authors to take, leaving them uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not specify which tasks, previous works, or selfimplemented baselines are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what additional analysis should be conducted or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide any specific examples, comparisons, or references to support these claims. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide specific examples or details on what aspects of the analysis are lacking or how the authors might address these issues. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without clear guidance on how to enhance their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should make the proof of Theorem 8 clearer, but it lacks specific instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to improve the clarity of the proof, but without concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the linear convergence rates relying on Theorem 8, which is buried in the appendix and whose proof is unclear. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that all linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that all linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This is a clear and actionable point that the authors can address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the proof or how to better integrate Theorem 8 into the main text. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. The comment explicitly instructs the authors to correct the inaccuracy regarding the Walkman algorithm, specifying that it is solved by ADMM with two versions. It also points out the lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors clarify the intended reference. These actions are explicit and provide concrete guidance on what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about the Walkman algorithm, noting that it is solved by ADMM with two versions, and it points out the lack of clarity in the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed in these parts of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization.\" It does so by pointing out that the Walkman algorithm is solved by ADMM with two versions, one for local optimization and the other for gradient approximation. This provides a logical reasoning that challenges the initial claim, making the comment 4. However, the comment could be strengthened by providing specific examples or references to the ADMM versions or the Walkman algorithm, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 4 as it identifies specific inaccuracies in the paper regarding the Walkman algorithm and its solution by ADMM. It provides clear and actionable feedback by instructing the authors to correct the statement about the Walkman algorithm, noting that it is solved by ADMM with two versions. Additionally, it points out the lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors clarify the intended reference. This feedback is valuable as it helps the authors improve the accuracy and clarity of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the reference to \"it\" or offered additional guidance on how to address the inaccuracy regarding the Walkman algorithm. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the theoretical result, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the result only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. Additionally, it suggests that the authors should compare their rates to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. The reviewer suggests that this assumption is not necessary for previous algorithms and that the authors should compare their rates to existing rates in the literature. The claim is 3 as it provides a logical reasoning for the requirement and suggests a potential area for improvement. However, it lacks specific examples or references to existing works that support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical result of the paper, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. This is a critical observation that highlights a potential weakness in the paper\"s theoretical foundation. Additionally, the comment suggests that the authors should compare their rates to existing rates in the literature, which is a valuable suggestion for improving the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided specific examples or references to existing works that demonstrate the importance of this comparison. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This implies that the authors should include such a comparison in their paper. However, the comment does not specify how to conduct this comparison or what specific aspects to focus on, leaving some ambiguity. While the action is clear in principle, the lack of detailed guidance on execution makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a potential comparison that could enhance the paper, but without clear guidance on where to integrate it, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be useful to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\"s credibility and rigor. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its usefulness. While it points out a potential improvement, the authors are left to determine the exact details and execution of the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should include additional experiments, it does not specify which specific baselines or comparisons should be included. The action is clear but lacks concrete details on which additional experiments to conduct or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it references specific works that focus on similar questions, it does not provide detailed reasoning or evidence to support why these additional comparisons are necessary or how they would enhance the paper. The reference to specific works is a helpful starting point, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed explanation to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works that focus on similar questions, providing a clear direction for the authors to expand their experimental analysis. However, the comment could be more helpful by offering specific suggestions on which additional baselines or comparisons to include, or how to present the results in a more comprehensive manner. While it provides a valuable direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This is a clear and explicit action for the authors to take, as it provides a specific direction for improving the presentation of results. The comment is concrete because it specifies the exact changes needed to be made, such as presenting average results on the test set and defining error bars under different random seeds. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the presentation of results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not present convincing results due to the reporting of best results on the development set with hyperparameter search and model selection on the development set. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it provides a logical reasoning for why the current presentation of results is insufficient, but it lacks specific examples or references to support the claim. The suggestion to present results on the test set is a reasonable one, but the comment could be strengthened by providing more detailed guidance on how to present these results effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that the authors report the best results on the development set with hyperparameter search and model selection on the development set, which is not enough to be convincing. The comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results, which is crucial for the credibility and impact of the paper. By addressing this point, the authors can significantly enhance the clarity and persuasiveness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors include more values of the parameter \u03b1 in their ablation study. It specifies that at least 1e2 and 1e3 should be considered, providing clear guidance on what additional values to include. This feedback is concrete and actionable, as it directly instructs the authors on how to enhance their study by adding more values of \u03b1. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more values of \u03b1 in the ablation study. The comment provides a clear rationale for why additional values are necessary, such as the large gap between 1e4 and 1e1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation study on \u03b1 is insufficient, as it only considers values of 1e4, 1e1, and 5e1 with a large gap between 1e4 and 1e1. The reviewer recommends adding more values, such as 1e2 and 1e3, to provide a more comprehensive analysis. This claim is 3 as it provides a logical reasoning for why additional values are needed, but it lacks specific examples or detailed justification for why these particular values are necessary. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation study on the parameter \u03b1, noting that it only considers a limited range of values with a large gap between 1e4 and 1e1. The reviewer recommends adding more values, such as 1e2 and 1e3, to provide a more comprehensive analysis. This feedback is clear and actionable, as it directly instructs the authors on how to enhance their study by expanding the range of \u03b1 values. By addressing this point, the authors can improve the robustness and comprehensiveness of their ablation study. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are explicit, the comment lacks concrete guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the dataset, but the specific actions to take are not clearly stated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset and methodology sections. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are relevant and could guide the authors in improving their draft, the comment lacks specific suggestions or actionable advice on how to address these issues. The authors are left with a general understanding of what needs to be clarified but without detailed guidance on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not provide comprehensive guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback implies that the authors should expand their analysis to include more comparisons and consider additional NAS approaches. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on which NAS approaches to include or how to conduct the analysis. While the action is implied, it is not as clear as it could be, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis on BRPNAS, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is barebones because it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. However, the comment does not provide specific examples or references to these other approaches, nor does it explain why they are relevant or how they would enhance the analysis. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the analysis section of the paper, specifically noting that the BRPNAS analysis only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback highlights an area where the paper could be expanded to provide a more comprehensive analysis. However, the comment does not offer specific suggestions on how to address this issue or which NAS approaches to consider, leaving the authors with a general direction but without detailed guidance on how to improve their draft. While it points out a relevant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, stating that it distracts from the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, should be made to the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the distraction but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the zeroshot version and its connection to density estimation are distracting from the main point of the paper, which is about learning effective prototypes for fewshot learning. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks specificity and does not guide the authors on how to address the issue or improve the paper. As a result, it offers limited value to the authors in terms of enhancing the draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors need to provide more information on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for details on the translation and filtering methodology to assess the dataset quality. This feedback is clear and concrete, as it specifies exactly what information is missing and what needs to be added. The authors know exactly what steps to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of details on the filtering process used to create the dataset and the need for more information on the translation and filtering methodology to assess dataset quality. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking.\" This is a factual observation about the paper, as it highlights a specific area where more information is needed. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would impact the assessment of the dataset quality. As a result, the claim is considered 2, as it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the lack of details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results could be enriched by adding attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that these additions would improve the results, it does not provide specific guidance on how to implement these changes or what specific types of attacks or threshold analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or figures where these additions could be made. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these additions would improve the results. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 2, as it provides a general direction but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment results by suggesting the addition of attacks with different strengths and an exploration of how different thresholds influence detection performance. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific types of attacks or threshold analyses should be considered. Despite this, the feedback is 4 as it directs the authors toward improving their experimental design and results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer notes that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. While the comment provides a clear action\u2014to evaluate the claim by training a discriminator\u2014it does not offer specific guidance on how to implement this evaluation or what metrics to use. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the claim to reduce exposure bias and the need to train a discriminator on generations from the learned model. The comment provides a clear direction for the authors to follow, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer explains that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. This claim is 3 as it provides a logical reasoning for the need to evaluate the claim and explains the difference between Figure 1 and Figure 4. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of the paper, which is to train a discriminator on generations from the learned model to confirm if the paper successfully reduces exposure bias. The reviewer explains the difference between Figure 1 and Figure 4, noting that the former involves coadaptation between the discriminator and generator, while the latter is a static representation. This feedback is valuable as it guides the authors on how to test their claim and provides a specific method for evaluation. However, the comment could be more helpful if it offered additional insights or examples on how to implement this evaluation or what metrics to use. Overall, the comment is 4 as it provides a clear direction for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. While the action is implicit, it is clear and concrete, as it specifies what additional information is needed to be included in the paper. The authors know exactly what to do to address the comment, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance difference resulting from using different image sizes and variations of ResNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. This feedback is 3 as it identifies a specific area where the paper could be improved by including additional data or analysis. However, the comment lacks depth and does not provide specific guidance on how to present this information or what specific metrics or analyses would be most relevant. While it points out a potential area for improvement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to present and describe the Algorithm in detail, which is helpful for understanding the proposed method. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to present and describe the algorithm in detail, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this suggestion, the authors can improve the reader\"s ability to understand and evaluate the proposed method. However, the comment could be more helpful if it included specific examples or guidance on how to present and describe the algorithm in detail. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper. While it implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a runtime comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the comparison could be included. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential addition. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific comparison that could enhance the paper\"s contribution. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. While it points out a potential improvement, it does not fully support the authors in making that enhancement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this question. The authors can infer that they need to consider the applicability of their method to a broader range of image types, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this limitation is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its question about the applicability of the method to natural images, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, the comment lacks any supporting evidence, reasoning, or references to justify why the method might not be applicable to natural images. Without such information, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. This is an important consideration for the broader applicability of the method in the real world. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or expand the applicability of their method. While it points out a potential limitation, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a relevant issue but lacks comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the organization or presentation of the prompts, nor are there suggestions for alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the prompts being poorly organized, with all sentences squeezed together. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a clear area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the organization. While it highlights a potential problem, it does not offer actionable guidance or detailed advice for the authors to enhance their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the clarity of the figures and label the modules, but the comment lacks concrete details on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"CMAF, L_BT, VoLTA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the clarity of the figures, particularly the confusion regarding the relation between subfigures and the lack of labeling for certain modules. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning Figure 2 and the confusion regarding the relation between subfigures. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the confusion and the importance of labeling the modules. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This feedback is clear and actionable, as it directs the authors to improve the clarity and labeling of the figures to enhance the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered examples of how similar issues have been addressed in other works. Overall, the comment is 4 as it effectively guides the authors on how to enhance the visual presentation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that if FFNs are omitted due to a linear decomposition issue, the authors should consider whether there is existing work that offers a way around this limitation. If not, the comment recommends adding a line or two acknowledging the lack of a solution and describing it as an open (hard) problem. This feedback provides a clear and explicit action for the authors to take, ensuring they know exactly what steps to consider to improve their draft. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of FFNs being omitted due to a linear decomposition problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering existing work for a way around the issue and proposes adding a line or two to acknowledge the problem as an open (hard) problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that FFNs are omitted due to a linear decomposition issue and questions whether there is existing work that offers a way around this limitation. The comment suggests that if not, a line or two should be added acknowledging the problem as an open (hard) problem. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. The authors might need to conduct additional research to verify the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the omission of FFNs due to a linear decomposition problem. It suggests that the authors should consider whether there is existing work that offers a way around this limitation or if it is an open (hard) problem. The comment provides a clear and actionable suggestion for improving the paper by acknowledging the issue and offering a potential solution. This feedback is valuable as it guides the authors in enhancing the clarity and completeness of their work. However, it could be more helpful if it included specific references or examples of existing work that addresses this issue. Overall, the comment is 4 as it provides a constructive direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to control domain drift. The comment lacks actionable details, such as recommending specific methods or experiments to explore, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the use of perplexity and the need to control domain drift, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, the comment does not provide specific examples or references to support the claim that perplexity is an inappropriate measure or that domain drift is a significant issue. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. This is an important point that could impact the validity and reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or control domain drift. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. While these questions imply that the authors should investigate the effect of image number and provide an explanation for BYOL, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide an explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific questions about the cluster structure and its impact on model performance, as well as the first appearance of BYOL in the abstract. However, it does not explicitly mention which part of the paper these questions pertain to, such as specific sections or figures. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for an explanation of BYOL and the impact of the number of images on performance, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that more training images might worsen performance. However, it does not provide any supporting evidence, examples, or references to substantiate these claims. The comment also requests an explanation of BYOL in the abstract, but it does not provide any reasoning or evidence to support the need for this explanation. As a result, the claim is 1, as it lacks the necessary justification and evidence to be considered valid. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and suggests that more training images might worsen performance. It also requests an explanation of BYOL in the abstract, which is a relevant point for clarity. While the comment identifies potential areas for improvement and provides a clear direction for the authors to explore, it lacks specific guidance or examples on how to conduct the analysis or explain BYOL. This limits the comment\"s helpfulness, as it points out important areas for consideration but does not fully support the authors in making those improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the effectiveness of the method, particularly regarding the L_pixel component. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors provide stronger arguments or intuitions to explain why the method works, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the understanding of why the method works, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples or references to support the claim that the current explanation is insufficient. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of why the method works, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions to support the effectiveness of the method would be beneficial. This feedback is 3 as it points out an area where the authors could enhance their explanation, but it lacks specific guidance on how to provide these arguments or intuitions. The comment highlights a potential weakness in the paper but does not offer detailed suggestions on how to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. The comment is clear and concrete, giving the authors specific details to include in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more comprehensive overview of existing methods and their limitations, including sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This provides clear guidance on what needs to be improved in the Related Work section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations. The reviewer provides a list of specific methods to consider, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This detailed list of examples and references provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these methods are relevant to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the Related Work section, noting that it lacks details and suggesting that the authors should provide a more comprehensive overview of existing methods and their limitations. The comment lists several specific approaches, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, which should be discussed in the context of the paper. This detailed guidance helps the authors understand what aspects of the related work are important to include and how to present them effectively. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their Related Work section, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and points out that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to improve the dataset. The action is implicit and somewhat vague, as the authors can infer that they need to consider the size and diversity of their training data but are not given specific instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and compares them to the typical training data for LLMs, which is typically on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. The authors can infer that it relates to the dataset used for training, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the concern about the training data. This aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, comparing them to the typical training data for LLMs, which is typically on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that 44k dialogues are insufficient. This makes the claim 3, as the authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, given that LLMs are typically trained on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains, which is a critical consideration for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might improve the dataset or what additional data sources might be considered. While it identifies a potential weakness, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what alternative metrics or approaches might be more suitable. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of binary classification as a baseline metric and expresses skepticism about its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the binary classification are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\" understanding of finegrained errors like technique errors. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to alternative metrics or methods that could be used instead. As a result, the claim is not 5, making it difficult for the authors to understand and address the concern. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide any specific suggestions or alternatives for how the authors might address this issue or improve their baseline metrics. The comment lacks actionable guidance or detailed feedback, leaving the authors without clear direction on how to improve their draft. As a result, the comment is 2, as it identifies a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work only uses binary features and questions whether the method is applicable to real and categorical features. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to consider real and categorical features. The comment lacks concrete details on how to incorporate these features or what specific modifications are needed. As a result, the authors are left without clear instructions on how to improve their draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of binary features in the work and questions whether the method is applicable to real and categorical features. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of binary features and suggesting that the method may not be applicable to real and categorical features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work only uses binary features, which is a factual observation. However, it questions whether the method is applicable to real and categorical features, suggesting that this limitation needs to be addressed. The comment does not provide specific examples or references to support this claim, making it 3. The authors may need to infer the importance of considering real and categorical features, but the lack of detailed evidence or reasoning makes the claim 3.", "helpfulness_rationale": "The review comment identifies a limitation in the work, noting that it only uses binary features while realworld data typically includes a mix of binary, real, and categorical features. This is a relevant observation that could impact the applicability and generalizability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate real and categorical features into their analysis. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. The comment lacks explicit guidance on how to address the issues, leaving the authors without a clear understanding of what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of what needs to be clarified. Without specific references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support why the writing is unclear or how it could be improved. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they could be improved. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of what changes to make to enhance the clarity and readability of their paper. Therefore, the comment is 2, as it identifies an area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback provides a clear and explicit action for the authors to take, which is to consider using additional metrics for evaluating their results. The suggestion is concrete, as it specifies a specific metric to use, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation of results, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting the use of BERTScore as an alternative metric, providing some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, the comment does not provide any reasoning or evidence to support why BERTScore is a better choice or why the current metrics are insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the suggestion.", "helpfulness_rationale": "The review comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback is 3 as it identifies a potential area for improvement by suggesting the use of a different metric for evaluating the results. However, the comment lacks depth and does not provide detailed guidance on why BERTScore might be a better choice or how it could be integrated into the evaluation process. Additionally, it does not address other aspects of the paper, such as methodology or theoretical contributions. While the suggestion is a step in the right direction, it could be more helpful with additional context and explanation. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, specifically mentioning metrics like MMLU and Big Bench for language generation. While the comment does not explicitly instruct the authors to conduct this comparison, it provides a clear direction for how to enhance the evaluation of their metric. The action is implicit but concrete, as it specifies the metrics to compare and the conditions under which SynTextBench should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"large amount of work on LLM evaluation\" and references specific metrics like MMLU and Big Bench, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of SynTextBench to other metrics proposed in the literature and how to use SynTextBench under specific conditions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there has been a large amount of work on LLM evaluation and that some of the metrics do not satisfy the proposed desiderata. It also mentions that it would be beneficial to compare SynTextBench to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. The comment provides a logical reasoning for why this comparison is important, but it lacks specific examples or references to support the claim that some metrics do not satisfy the desiderata. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare their SynTextBench metric to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. This feedback is valuable as it guides the authors in demonstrating the strengths and limitations of their metric in the context of existing evaluations. By addressing this suggestion, the authors can enhance the clarity and robustness of their evaluation, which is essential for the credibility and impact of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific conditions should be considered. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, it does not provide any guidance on how the authors should address this issue or what specific changes could be made to enhance the novelty of their work. The comment lacks explicit or implicit actions, leaving the authors without direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"algorithm for construction of coresets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, stating that the algorithm is not novel because it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the algorithm for constructing coresets is not novel because it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the novelty of the paper, noting that the algorithm for constructing coresets is not novel as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This feedback is clear and actionable, as it points out a weakness in the paper\"s originality and suggests that the authors should consider how to enhance the novelty of their work. However, the comment could be more helpful if it provided suggestions on how to differentiate the algorithm or how to address this issue in the context of the paper. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the writing and annotations are difficult to follow, but it does not provide any specific guidance on how to improve them. It lacks actionable advice or suggestions on how to make the writing and annotations clearer or more accessible. Without concrete steps or examples, the authors are left without a clear understanding of what changes to make to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by this issue. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing and annotations are difficult to follow. This makes the comment 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the writing and annotations are difficult to follow. However, it does not provide any specific examples or detailed reasoning to support this claim. Without such evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations being difficult to follow. However, it lacks specificity and does not provide any guidance on how to improve the clarity or accessibility of the content. Without actionable suggestions or examples, the authors are left without a clear understanding of what changes to make to enhance the quality of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should provide an explanation or analysis to clarify this discrepancy. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically noting that only 8 of the 14 evaluation metrics achieve SOTA performances and questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. The comment does not provide specific examples or references to support the claim that the results are unexpected or unexplained. While it raises a valid point, the lack of detailed evidence or reasoning makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment raises a specific concern about the results in Table 2, questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This feedback is 3 as it identifies a potential issue with the results, prompting the authors to consider whether the method is performing as expected or if there are discrepancies that need to be addressed. However, the comment lacks depth and does not provide suggestions on how the authors might investigate or explain this discrepancy. To be more helpful, the comment could offer guidance on how to analyze or interpret the results, or suggest potential reasons for the observed differences. As it stands, the feedback is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this methodology is discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the methodology but lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a valid question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. This feedback prompts the authors to reconsider their experimental setup and potentially explore alternative methods for data selection. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what potential improvements could be made. While it identifies a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to enhance the paper. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this acknowledgment pertains to, making it weakly grounded. The comment does provide a specific suggestion for improvement, which is to consider the relaxation proposed by Guzman et al. This provides some level of specificity, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a minor suggestion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. It identifies a minor suggestion, but without further elaboration or guidance, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on the scalability bounds of FedDES, specifically mentioning the need for a clear discussion on memory requirements and computational complexity. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include a discussion on scalability bounds, but the comment lacks concrete suggestions on what aspects to focus on or how to present this information. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper limits of FedDES\"s scalability\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the scalability bounds, memory requirements, and computational complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough exploration of the upper limits of FedDES\"s scalability and does not provide a clear discussion on memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a thorough exploration of the scalability bounds of FedDES. It points out that there is no clear discussion on memory requirements or computational complexity, which are crucial aspects of the system\"s performance. This feedback is valuable as it highlights an area where the authors can enhance their draft by providing a more comprehensive analysis of the system\"s scalability. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps or provided examples of how similar studies have approached this issue. Overall, the comment is 4 as it directs the authors\" attention to an important area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should generate instances with more constraints and variables, as the paper currently has few instances with more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a clear and explicit action. The comment also raises a concern about LLMs\" ability to model problems with large instance sizes, providing a specific direction for improvement. However, it does not offer detailed guidance on how to implement this suggestion or what specific constraints and variables should be included. While the action is clear, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a specific suggestion for improvement. However, the comment does not explicitly mention which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for more variables and constraints, but without clear grounding, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks instances with more constraints and variables, as few instances have more than 7 variables. This claim is based on the observation that the paper currently has few instances with large instance sizes, which raises concerns about LLMs\" ability to model such problems. However, the comment does not provide specific examples or references to support the claim that larger instances are necessary or how they would impact the model\"s performance. The reasoning is 3, as it highlights a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that few instances have more than 7 variables, which raises concerns about LLMs\" ability to model problems with large instance sizes. This feedback is valuable as it highlights an area where the paper could be strengthened by expanding the dataset to include more instances with larger variable counts. However, the comment could be more helpful if it provided specific suggestions on how to generate these instances or what constraints and variables should be considered. While it points out a relevant issue, the lack of detailed guidance limits its utility for the authors. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the presentation of results, such as labeling the yaxis in Figures 2 and 3 and using a scatter plot with runtime/performance axes. It also recommends highlighting the best results in tables. These actions are explicit and concrete, providing clear guidance on how to enhance the clarity and interpretability of the results. The authors know exactly what changes to make to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as labeling the yaxis and using a scatter plot with runtime/performance axes. The comment also suggests highlighting the best results in tables, providing clear guidance on how to enhance the presentation of results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results presentation in Figures 2 and 3 could be improved by labeling the yaxis more clearly and using a scatter plot with runtime/performance axes. It also recommends highlighting the best results in tables. While the comment provides a logical suggestion for improving the clarity of the results, it lacks specific examples or references to support the claim that these changes would indeed improve the presentation. The suggestion is 3, as it provides a reasonable direction for improvement but could be strengthened with more detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It identifies ambiguities in the yaxis labeling in Figures 2 and 3 and suggests using a scatter plot with runtime/performance axes to enhance clarity. Additionally, it recommends highlighting the best results in tables, which is a helpful suggestion for readers. The comment is clear and provides detailed guidance, making it 4 for the authors to improve the clarity and interpretability of their results. However, it could be more helpful if it included examples of how the suggested changes would enhance the results presentation. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It seeks clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment implies that the authors should provide more information or clarification on this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implications of this statement, including whether the base node affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the implications of a statement regarding \"NodeSort differentially sorting nodes depending on the base node.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node,\" seeking clarification on whether the base node affects the ordering, key nodes for attention, and model performance. This is a relevant question that could help the authors better understand the potential impact of their method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. This question implies that the authors should clarify or correct the figure to better align with the intended purpose. However, the comment does not explicitly instruct the authors to make this change, leaving it somewhat vague. While the action is implied, the authors can infer that they need to address the figure, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the direction of the arrow in the figure, which is a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer expresses confusion about the purpose of the arrow, which seems to be to influence n^(i). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim or clarify the authors\" intentions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be fully understood and addressed by the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the direction of the arrow in Figure 2, specifically questioning why it goes from a Gaussian space into the latent space rather than the other way around. This feedback highlights a potential inconsistency in the figure and prompts the authors to clarify or correct the direction of the arrow to better align with the intended purpose. While the comment identifies a specific issue, it does not provide detailed guidance or suggestions on how to address it, leaving the authors with a clear direction but without comprehensive support. Therefore, the comment is 3, as it points out a potential problem but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. It provides a clear and specific action for the authors to take, which is to define these abbreviations in the text or provide a glossary. This guidance is direct and concrete, leaving no ambiguity about what needs to be done to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviation \"AR\" in Table 5, noting that it stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definitions and cause confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This claim is 3 as it points out a specific issue with the clarity of the paper, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to infer the extent of the issue and the impact on the clarity of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that many abbreviations lack definitions and cause confusion. It provides a clear example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is actionable as it directs the authors to clarify these abbreviations to improve the clarity and accessibility of their work. However, the comment could be more helpful if it suggested ways to standardize the use of abbreviations throughout the paper or provided examples of how to define them. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific technical considerations should be explored or how to address them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what technical considerations are being questioned or how they might impact the analysis. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not present any claims, opinions, or suggestions that require verification. It is a request for clarification, which is not a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, which is a relevant point for the authors to address. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might explore or justify their choice of using advantage over q value. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting of Unsupervised Online Adaptation is strange, as it requires a training set, including documents, queries, and labels. The reviewer suggests that this is not \"Unsupervised\" because the training set also requires annotations. While the comment identifies a potential issue with the labeling process, it does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the clarity or accuracy of the description. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the nature of the training set and its annotation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The reviewer supports this claim by referencing Section 3.1, where the model\"s training requirements are described. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the critique, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. This is a relevant observation that could help the authors clarify their methodology and improve the clarity of their paper. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the description of the adaptation process. While it points out a potential problem, it does not provide actionable feedback for the authors to make improvements. Therefore, the comment is 3, as it highlights an area for clarification but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an issue with the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This implies that the comparison is unfair and suggests that the authors should address this issue to ensure fairness in their evaluation. However, the comment does not provide explicit guidance on how to rectify this issue, such as suggesting specific changes to the experimental setup or methodology. While the action is implied, it is not as clear as it could be, leaving the authors to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights while most baselines use a uniform weight of 1. This claim is 3 as it provides a logical reasoning for the unfairness, but it lacks specific examples or references to support the assertion that this difference significantly impacts the comparison. The authors would need to further investigate and substantiate the claim themselves to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This is a relevant observation that could impact the fairness and validity of the comparison. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending a standardized weighting scheme or explaining the potential impact of this difference. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the time complexity of the system if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the time complexity or suggestions for adjusting the buffer size. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"reply buffer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of high time complexity if the buffer is too large, providing clear guidance on what needs to be addressed. However, the comment could be more specific by suggesting ways to mitigate the time complexity or providing examples of how other similar systems have handled this issue. Therefore, the comment is 4, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the system if the reply buffer is too large. This is a relevant concern that could impact the performance and scalability of the system. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue. It does not offer actionable advice or examples of how to mitigate the time complexity, leaving the authors without a clear path forward. Therefore, the comment is 3 as it points out a potential problem but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a specific direction for improvement, it does not offer concrete guidance on how to implement these changes or which specific baselines to consider. The authors are left to infer the necessary steps to take, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to consider, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these alternative approaches would be beneficial or how they would improve the paper. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a specific direction for improvement by suggesting alternative approaches to consider. However, the comment lacks detailed guidance on how to implement these changes or which specific baselines to use. While it points out a potential area for enhancement, the authors are left with a general idea of what to do but without detailed steps or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a brief conclusion and a summary of the article\"s contributions are needed. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact content that needs to be included in the conclusion and summary. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a brief conclusion and a summary of the article\"s contributions, providing full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the need for a conclusion and a summary of the paper\"s contributions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the article\"s contributions are needed. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how they would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a brief conclusion and a summary of the paper\"s contributions. This feedback is clear and actionable, as it directly guides the authors on how to enhance the final section of their paper. By providing a concrete suggestion for improving the paper\"s conclusion, the comment offers valuable insight that can help the authors better communicate the significance and impact of their work. However, the comment could be more helpful if it included specific examples or suggestions on how to structure the conclusion and summary. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or experiments to be conducted, or suggesting ways to clarify the explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the synthetic experiment in a nonseparable case, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the synthetic experiment in a nonseparable case, specifically questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to similar studies that might have addressed this issue, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. This is a valid point that could lead to a deeper understanding of the model\"s behavior and limitations. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify their explanation. It does not provide actionable feedback or detailed advice on how to improve the draft. As a result, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. This feedback implies that the authors should include this comparison in their paper to enhance the results\" meaningfulness. While the action is implied, it is clear and concrete, as it specifies the need for a specific comparison and provides a direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a potential comparison that could enhance the results\" meaningfulness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. While the comment provides a logical reasoning for why this comparison could enhance the results\" meaningfulness, it lacks specific examples or references to support the claim that such a comparison is necessary or beneficial. This makes the claim 3, as the authors would need to infer the relevance and potential impact of this comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion for enhancing the paper\"s contribution by recommending a comparison with a method designed to defend against multiple attacks. This feedback is actionable as it points out a specific area for improvement that could enhance the paper\"s impact and relevance. By including this comparison, the authors could demonstrate the effectiveness of their framework against a broader range of attacks, which would be valuable for the field. However, the comment could be more helpful if it provided specific examples or references to the defense against multiple attacks, which would guide the authors in selecting the appropriate method for comparison. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. However, it does not provide any guidance on how to address this issue or suggest improvements to the presentation. The comment lacks explicit instructions or concrete details on what changes should be made to improve the clarity or comprehensiveness of the results. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and the \"first 1000 episodes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes and questioning the reason for presenting them in this way. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way, specifically mentioning that the results disregard safety violations of the agent in the first 1000 episodes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this presentation is problematic or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. It highlights the unclear reason for presenting the results in this way, which is a critical observation that could impact the clarity and comprehensiveness of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the presentation of results. While it points out a potential problem, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \tau_i^l, which is important for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment requests the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. However, it does not provide any supporting evidence or reasoning to justify why this definition is necessary or how it would impact the understanding of the function. Without additional context or explanation, the claim is not 5, as it lacks the necessary justification to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is specific and actionable, as it directly instructs the authors to define the bounds for \tau_i^l, which is important for understanding the timewarp function. This feedback is clear and provides a concrete step for the authors to take in order to improve their draft. However, the comment could be more helpful if it explained why defining these bounds is crucial or how it would enhance the clarity of the paper. Despite this, the feedback is 4 as it guides the authors toward a specific improvement that can significantly impact the comprehensibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment identifies these errors, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to revise these sections to correct the errors and add a title. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be corrected, namely the writing errors and the lack of a title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it points out specific areas that need correction to improve the clarity and professionalism of the paper. However, the comment could be more helpful if it provided suggestions on how to correct these errors or offered guidance on how to improve the overall writing quality. Despite this, the feedback is 4 as it directs the authors to specific areas for improvement, which can enhance the clarity and professionalism of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests elaborating on the reasoning behind the statement on line 134, which pertains to the theorem about the standard sigmoid function. It also mentions that elaborating on why this theorem holds would be useful, particularly in the context of the RNN and URNN convergence. While the comment provides a clear direction for the authors to expand on the explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detail, but it is concrete in that it specifies what needs to be elaborated. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the reasoning behind the statement regarding the standard sigmoid function and its relation to the RNN and URNN convergence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests elaborating on the reasoning behind a statement on line 134 and Theorem 4.1. It provides a logical basis for the suggestion by explaining that the RNN will converge to the nearest FP, unlike the URNN. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the reasoning themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors elaborate on the reasoning behind a statement on line 134 and Theorem 4.1. It highlights the importance of elaborating on why the theorem holds, particularly in the context of the RNN and URNN convergence. This feedback is clear and constructive, as it guides the authors to enhance the clarity and depth of their explanation. By addressing this suggestion, the authors can improve the understanding and comprehensibility of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their pairwise matching. There is no guidance on potential solutions, such as optimizing algorithms or data structures, or on how to present this information in the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, which is a specific aspect of the paper. However, it does not explicitly mention which section of the paper discusses this efficiency, making it weakly grounded. The comment is specific in pointing out the issue of low efficiency and its implications for practical application systems. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. This feedback is valuable as it highlights a potential weakness in the paper that could impact its practical applicability. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the efficiency of their pairwise matching. While it points out a relevant concern, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks concrete details on how to address the issue, leaving the authors uncertain about how to apply the feedback. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the critique, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or suggestions on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to address the issue. As a result, the feedback is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the planbased method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to improve the generalizability of their method. The authors are left to infer that they need to consider this issue and find ways to improve their method, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it highlights an area for improvement but does not provide explicit instructions on how to implement it.", "grounding_specificity_rationale": "The comment addresses the planbased method, specifically mentioning the requirement for manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. However, the comment does not specify which part of the paper discusses the planbased method or where the comparison to Table 2 is made. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue with the planbased method and its limitations, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the planbased method is unrealistic in realworld scenarios due to the requirement for manually designing a plan based on the ground truth in advance. It also compares the learned plan methods to those with predefined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the planbased method is unrealistic or that the learned plan methods are not comparable to those with predefined plans. This makes the claim 3, as it provides some logical reasoning but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the planbased method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also highlights a limitation in the learned plan methods compared to those with predefined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. This feedback is 3 as it points out a critical issue that the authors need to address to improve the realworld applicability of their method. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to improve the generalizability of the method. Overall, the comment offers valuable insights but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the first sentence of the abstract needs to be rewritten. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact part of the paper that needs attention, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. However, it does not provide specific details on what is wrong with the sentence or how it could be rewritten. The comment is specific in identifying the issue but lacks detailed guidance on how to address it. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any reasoning, evidence, or examples to support why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim is not verifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a specific issue with the first sentence of the abstract, suggesting that it needs to be rewritten. While this feedback is clear and actionable, it lacks depth and does not provide any further explanation or guidance on what aspects of the sentence need improvement or how to rewrite it effectively. The comment is 3 as it points out a potential area for improvement, but it could be more beneficial with additional context or suggestions for enhancing the revised sentence. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. While the comment implies that this is a necessary step, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this exercise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the experimental setup, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a change. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the results. The suggestion is based on a general understanding of standard practices in the field, but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup by noting that the results are reported for a single heldout test set. It suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance. While the comment highlights an area for improvement, it lacks specific guidance on how to implement this change or what specific benefits it would bring. The authors are given a clear direction but are not provided with detailed instructions or examples on how to execute this suggestion. Therefore, the comment is 3, as it points out a potential improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the method or what specific aspects of the method are overly complex. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as specific sections, figures, or experiments. Without explicit references to these elements, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method are considered overly complex or how they might be simplified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide specific guidance or suggestions on how to simplify the method or what aspects might be overly complex. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to determine what constitutes a significant contribution or how to improve the transferability of the method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, method, or result. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method or transferability need improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might improve the transferability of their method or what aspects of the contribution are lacking. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the motivation or clarify the architecture. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated, but it does not specify which part of the paper discusses this architecture. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered adhoc or poorly motivated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to support the assertion, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated, which could be a valid concern for the authors to address. However, the comment lacks specificity and does not provide any detailed reasoning or examples to support this claim. Without actionable feedback or suggestions on how to improve the motivation or clarity of the architecture, the authors are left without a clear path forward. Therefore, the comment is not helpful, as it does not guide the authors in making improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and suggests that the authors should provide average return results with more env steps. While the comment implies that the authors should make a change to Line 8 and potentially include additional results, it does not explicitly instruct them to do so. The action is concrete, as it specifies the change to be made and the additional information to be provided, but it is somewhat vague because it does not provide detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 8 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of s_t instead of s_n and suggests providing average return results with more env steps. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and a request for average return results with more env steps. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the use of s_t instead of s_n on Line 8 of Algorithm 1, which is a clear and actionable point for the authors to address. It also suggests providing average return results with more env steps, which could be beneficial for understanding the performance of the proposed method. However, the comment could be more helpful if it provided additional context or examples to guide the authors in implementing these changes. Overall, the comment is 4 as it identifies a specific area for improvement and offers actionable suggestions, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain the challenges and the differences between this analysis and that of Zhang et al. While the comment implies that the authors should provide more detail, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Adam under the (L0,L1)smoothness condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the challenges and differences between this analysis and that of Zhang et al. This provides clear guidance on what the authors need to clarify or improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of Adam under the (L0,L1)smoothness condition is unclear and suggests that the authors should explain the challenges and differences with Zhang et al. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the analysis of Adam under the (L0,L1)smoothness condition. It points out that the challenges in this analysis are not clearly explained and suggests that the authors should clarify these challenges, especially in comparison to Zhang et al. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and comparisons to enhance the clarity and comprehensiveness of their analysis. However, the comment could be more helpful if it offered specific suggestions on how to address these challenges or what aspects of the analysis should be emphasized. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as it is not accurate according to the reviewer\"s understanding. Additionally, it advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, focusing on plurals and articles. These are clear and specific actions that the authors can take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests compressing the method section for essential definitions. Additionally, it points out grammatical errors and provides specific examples, such as \"l.\" This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about the neural network memorizing critical points is inaccurate, as it does not memorize exact points as in TopoNet 24. The reviewer provides a logical reasoning by referencing TopoNet, which suggests that the neural network does not memorize exact points. However, the comment lacks specific examples or references to support the claim that the neural network does not memorize exact points in TopoNet. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the manuscript. It identifies a misleading statement about the neural network memorizing critical points, suggesting that the authors should tone down this claim. This is a clear and important correction that can improve the accuracy of the paper. Additionally, the comment advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, particularly with plurals and articles. This detailed feedback is 5 as it guides the authors on how to improve the clarity and accuracy of their work. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides a factual statement about the common basis of person reID methods, which is built on the foundation of pedestrian detectors. It also mentions a specific reference to an endtoend method that combines detection and reID. However, the comment does not offer any explicit or implicit actions for the authors to take. It does not suggest improvements, provide guidance on how to address this information, or offer suggestions for further exploration. As a result, the authors are left without any actionable steps to improve their draft based on this information. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment provides a factual statement about the basis of person reID methods, which is built on the foundation of pedestrian detectors. It also mentions a specific reference to an endtoend method that combines detection and reID. However, the comment does not specify which part of the paper this information pertains to, making it weakly grounded. The comment is specific in detailing the common basis of person reID methods and the reference to an endtoend method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point provides a factual statement about the common basis of person reID methods, which is built on the foundation of pedestrian detectors. It also mentions a specific reference to an endtoend method that combines detection and reID. This information is presented as a factual observation without any subjective claims or suggestions for improvement. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual statement about the common basis of person reID methods, which is built on the foundation of pedestrian detectors. It also mentions a specific reference to an endtoend method that combines detection and reID. While this information is relevant, it does not offer any actionable feedback or suggestions for improvement. It does not guide the authors on how to incorporate this information into their work or how to address any potential limitations or gaps in their approach. As a result, the comment is informative but lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce what the section is about, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests adding a first sentence to introduce what Section 3.2 is about. However, it does not provide any reasoning, evidence, or examples to support why this addition is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their paper. By providing a specific and direct recommendation, the comment offers a straightforward way for the authors to enhance the organization and flow of their content. However, the comment could be more helpful if it explained why this introduction is important or how it would benefit the reader. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide explicit guidance on what the authors should do to address this issue or how to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of the term, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this statement is problematic or unclear. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback highlights a potential inconsistency or confusion in the paper, which could be clarified to improve the clarity and coherence of the text. However, the comment lacks specific guidance or suggestions on how the authors might clarify this point or address the issue. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. The reviewer provides a clear and specific action for the authors to take, which is to update the description of uncertainty to align with the suggested clarification. This feedback is explicit and concrete, as it directly instructs the authors on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"uncertainty\" being defined based on the posterior distribution, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for clarifying the definition of epistemic model uncertainty, suggesting that it is represented in the prior distribution and updated in the form of a posterior distribution upon observing data. This provides a clear direction for the authors to improve the clarity of their explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests clarifying the definition of uncertainty by specifying that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution upon observing data. This claim is 3 as it provides a logical explanation of how uncertainty is modeled in the context of the paper. However, it lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for clarifying the definition of uncertainty in the paper. It suggests updating the description to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution upon observing data. This feedback is clear and constructive, as it offers a precise way for the authors to enhance the clarity and accuracy of their explanation. By following this suggestion, the authors can improve the comprehensibility of their work, making it more accessible to readers. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors experimented with using domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for clarification on the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide more information about their experimental setup, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about their experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they could impact the paper\"s findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the usage of domain ontologies to avoid placeholder generation in the evaluated responses, which is a relevant and potentially valuable aspect to explore. It also seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy, which could provide valuable insights into the robustness and performance of the system. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for potential enhancement, it does not provide actionable feedback that would help the authors make significant improvements to their draft. Therefore, the comment is 3, as it points out areas for further exploration but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which could be used to enhance the context of the paper. This feedback is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for citations to set the paper in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which are relevant to the context. This level of detail allows the authors to accurately identify the parts of the paper that need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. The reviewer provides specific examples of recent papers, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which are relevant to the context. This provides a clear and specific justification for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper lacks citations to set it in the context of other MARL work, particularly selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which could be used to enhance the context of the paper. This feedback is clear and actionable, as it directs the authors to include relevant references to strengthen the paper\"s position in the field. However, it could be more helpful if it explained why these specific papers are relevant or how they could be integrated into the paper. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. While the suggestion is clear, it lacks specific guidance on which methods to compare with or how to conduct the comparison. The authors are left to infer that they should explore other methods, but without detailed instructions or examples, the action remains vague. Therefore, the comment is 3, as it provides a direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be made. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with other methods, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or beneficial. Without such details, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. This is a valuable suggestion as it could help the authors broaden the scope of their work and demonstrate the applicability of their method in a wider context. However, the comment lacks specificity and does not provide guidance on which methods to compare with or how to conduct the comparison. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. While the comment implies that the authors should provide a clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the abstention process and decision thresholds. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the abstention process differs from a decision threshold used by the models, and it suggests that the authors clarify this distinction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the abstention process, asking for clarification on how it differs from a decision threshold used by the models. This is a clear and actionable request for the authors to provide additional explanation or clarification in their draft. By addressing this question, the authors can improve the clarity and understanding of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the comparison with Megatron, suggesting that it is overrated and points out that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer also raises a question about the authors\" claim of parameter efficiency, suggesting that if this claim is valid, it could apply to other related works as well. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The questions for the authors are more of an inquiry than actionable advice, as they do not directly instruct the authors on what to do. Therefore, the comment is 3, as it points out areas for improvement but lacks concrete details on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with Megatron and the performance of COCOLM compared to other approaches like RoBERTa, ELECTRA, and DeBERTa. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the validity of the comparison with Megatron and raises a concern about the authors\" claim of parameter efficiency. It provides a clear direction for the authors to address by asking why the types of BPE vocabulary were switched and whether this change affects performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the comparison with Megatron, suggesting that it is overrated and that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer provides a logical reasoning by pointing out that if the authors claim COCOLM is parameterefficient, the same conclusion could apply to these other approaches. However, the comment lacks specific examples or references to support the claim that the comparison with Megatron is overrated. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison with Megatron, suggesting that it is overrated and that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This feedback is valuable as it challenges the authors to reconsider the significance of their comparison and potentially adjust their conclusions accordingly. Additionally, the comment raises a question about the authors\" claim of parameter efficiency, suggesting that if this claim is valid, it could apply to other related works as well. While the comment does not provide specific suggestions for improvement, it does prompt the authors to reevaluate their claims and consider alternative perspectives. Overall, the feedback is 3 as it highlights areas for improvement and encourages the authors to reconsider their conclusions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis from lines 128 to 149 is not convincing and suggests that the GSP50 model has smaller class selectivity score, which means it shares more features with ResNet50. The reviewer also hypothesizes that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the analysis. The reference to external works, while helpful, does not offer detailed instructions on how to apply this information to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of convincingness and consider the implications of the external references. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 128 to 149,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the analysis, noting that the GSP50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet50. The comment further hypothesizes that additional context may allow the network to reduce its dependency. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis from lines 128 to 149 is not convincing enough, based on the histogram in Figure 3, which shows that the GSP50 model has a smaller class selectivity score compared to ResNet50. The reviewer references external works 1 and 2 to support the claim that GSP50 shares more features with ResNet50, which could indicate that GSP50 learns better representation. However, the comment does not provide detailed reasoning or examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment lacks sufficient explanation and evidence to fully verify the claim. Therefore, the comment is 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from lines 128 to 149 is not convincing enough. It points out that the GSP50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet50. The reviewer hypothesizes that additional context may allow the network to reduce its dependency. While the comment provides a clear direction for improvement by suggesting that the authors address the issue of convincingness, it lacks specific guidance on how to improve the analysis or what aspects of the analysis are lacking. The reference to external works is helpful but does not fully address the critique. Overall, the comment is 3 as it identifies a critical area for improvement but could be more comprehensive with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of convincing evidence in the paper\"s conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be due to limited exploration of combination methods and points to recent works that have shown the potential of feature replay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data and the claim that it accumulates noise, which is detrimental to representation quality. It also references specific works, such as R1, R2, and R3, to support the claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works that have shown the potential of feature replay methods in continual learning, such as R1, R2, and R3. These references provide a logical basis for the claim, as they demonstrate the effectiveness of feature replay methods in continual learning scenarios. However, the comment could be strengthened by providing more detailed analysis or specific examples from these references to further substantiate the claim. Overall, the claim is 4, as it is supported by relevant references, but it could be more fully substantiated with additional details.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s conclusions, noting that some are not convincing. It provides a detailed example by referencing recent works that have shown the potential of feature replay methods in continual learning, such as R1, R2, and R3. This feedback is 5 as it not only points out a weakness in the paper\"s conclusions but also offers specific examples of alternative approaches that could be considered to strengthen the paper\"s arguments. By suggesting the exploration of combination methods and referencing relevant literature, the comment provides actionable guidance for the authors to enhance the robustness and credibility of their conclusions. Therefore, it aligns with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare their work with a chainofthought prompting approach, which is a specific suggestion for improvement. While the comment implies that the authors should add this comparison, it does not explicitly instruct them to do so. The action is concrete, as it specifies a specific baseline to include, but it is somewhat vague because it does not provide detailed guidance on how to implement this comparison. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of meaningful baselines and the suggestion to compare with a chainofthought prompting approach. This provides clear guidance on what the authors need to improve in their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors should compare their work with a chainofthought prompting approach. However, the comment does not provide specific examples or references to support the claim that the current baselines are insufficient or inadequate. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to understand the basis of the critique without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors mention various model criticism techniques in Section 2 but limit their comparisons to simple naive baselines. It suggests that the authors should consider comparing their work with a chainofthought prompting approach, which could provide a more meaningful baseline for evaluation. This feedback is clear and actionable, as it points out a specific area for improvement and offers a concrete suggestion for enhancing the paper\"s comparative analysis. However, the comment could be more helpful if it explained why the chainofthought prompting approach is particularly relevant or how it might benefit the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also inquires about the generalizability of this approach when labels are not available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the pretraining of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the generalizability of the approach when labels are not available. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the pretraining of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalizability of this approach when labels are not available. This feedback is 3 as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and applicability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to improve the generalizability of the model. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to ensure that the observations and design decisions are not dependent on specific hardware or software. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine which sections or elements of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are dependent on hardware or software. Without clear guidance on what needs to be addressed or improved, the authors cannot effectively address the comment. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While it identifies a potential problem, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the paper might be affected. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to investigate the accuracy of the ground truth and the noticeability of the differences, but the comment lacks specific guidance on how to conduct this investigation or what specific aspects to focus on. Therefore, the comment is 3, as it identifies areas for consideration but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, it does not specify which part of the paper these questions pertain to, such as a particular section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry about the accuracy and noticeability of the differences, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the accuracy and reliability of the results presented in the paper. It questions whether the small differences observed are actually noticeable or due to noise or randomness in the training process. Additionally, it points out a lack of difference between the results reported in the ablation study table. While the comment identifies potential issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve the accuracy of their results. The feedback is 3 as it prompts the authors to consider the reliability of their findings, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of important experimental details in the main text and the lack of explanations or interpretations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8 as examples of missing information. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text and Appendix, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of explanations or interpretations for the PCA experiments in these figures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. The reviewer provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by providing additional examples or references to similar studies that demonstrate the importance of including detailed explanations and interpretations. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it highlights specific areas where the authors need to improve the clarity and completeness of their experimental details. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending a specific structure or approach for presenting the experimental details in the main text. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of new evaluation metrics and the limited exploration of existing metrics in the experimental analysis section. It suggests that the authors should provide an indepth exploration of the reasons for the experimental results. While the comment implies that the authors should add more depth to their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of new evaluation metrics and the limited exploration of existing metrics. The comment suggests that an indepth exploration of the reasons for experimental results is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are linearly combined. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. However, the comment does not provide specific examples or references to support the claim that existing metrics are insufficient or that the exploration is lacking. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of new evaluation metrics and the limited exploration of existing metrics. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. This feedback is clear and actionable, as it points out a specific area where the authors can enhance their work by providing a more comprehensive analysis of the evaluation metrics. However, the comment could be more helpful if it offered suggestions on how to conduct this exploration or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, it does not provide explicit guidance on how to resolve this issue or suggest alternative notations. The action is implicit and vague, as the authors are left to infer that they need to clarify or change the notation to avoid confusion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L166\" and \"L176,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"K,\" which is being used for both a known kernel function and the number of layers, causing confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" noting that it is being used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176), which can cause confusion. This feedback is clear and actionable, as it points out a potential source of confusion in the paper and suggests a way to clarify the notation. However, the comment could be more helpful if it provided examples of how the notation could be clarified or revised. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern about the practical impact or suggestions for improving the paper to better demonstrate its relevance. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the theoretical interest and the potential practical impact, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the weak recovery problem studied is primarily of theoretical interest and questioning the practical impact of the AMP algorithm for nonGaussian problems. This feedback highlights a potential limitation in the paper\"s relevance and applicability, which could impact its impact on the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or demonstrate the practical relevance of their work. While it points out a potential weakness, it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their argument. The suggestion for more citation is implied but not directly stated, leaving the authors with a vague understanding of what steps to take. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the connection to human cognition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the connection, questioning whether it makes sense given the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation. The comment suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization. However, it does not provide specific examples or references to support this claim, which would make it more actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. While it raises a valid point, the lack of supporting evidence or detailed justification makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 3, as it provides a logical basis for the claim but lacks sufficient evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment raises a valid concern about the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization. This feedback is 3 as it prompts the authors to reconsider the relevance of their connection to human cognition and offers a potential direction for further exploration. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or what additional evidence or comparisons might be needed. Overall, the comment provides a valuable insight but lacks detailed guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, it does not provide specific guidance on how to tone down the language or suggest alternative phrasing. The comment lacks explicit instructions or concrete examples of what constitutes overly exaggerated or flamboyant language, making it difficult for the authors to know exactly how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, describing it as overly exaggerated and flamboyant. This provides clear guidance on what needs to be addressed in the conclusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or references to overly exaggerated or flamboyant language, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant in multiple places. This feedback is 3 as it points out a potential weakness in the language used, which could be revised to be more appropriate and professional. However, the comment lacks specific examples or suggestions on how to tone down the language or rephrase the sentences in a more appropriate manner. While it highlights an area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific direction for the experiments, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides full grounding as it clearly identifies the part of the paper that needs revision. The comment is also specific because it specifies the exact comparison that needs to be made, which is the number of learnable parameters and GFLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. By addressing this suggestion, the authors can enhance the comprehensiveness and rigor of their evaluation, which could lead to a stronger manuscript. However, the comment could be more helpful if it included additional details or suggestions on how to design and conduct these experiments. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to compare against or detailing the expected utility measure. The comment lacks concrete steps for the authors to take, leaving them uncertain about how to improve their draft. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for comparison to baselines. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility or some other measure, which is a significant weakness. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure to prove the effectiveness of the proposed approach. This is a critical oversight that could impact the credibility and impact of the paper. However, the comment does not provide specific guidance on how to address this issue or suggest potential baselines to compare against. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it does not provide explicit instructions or concrete actions for the authors to take. The comment mentions that Figure 5a seems strange and asks for more explanations, but it does not specify what aspects of the figure are problematic or how to address them. Similarly, it mentions the handling of DVS input when the input is in AER format but does not offer guidance on how to improve this aspect. The comment also suggests analyzing energy consumption like reference 15 did, but it does not provide details on how to implement this analysis or what specific aspects to focus on. Overall, the comment lacks explicit instructions or concrete steps for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a\" and \"11,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with \"Fig. 5a\" and suggests providing more explanations, as well as questions about handling DVS input and analyzing energy consumption like reference 15 did. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of several questions and suggestions for improvement, rather than making subjective claims or judgments. It does not contain any claims or opinions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several pieces of feedback that can help the authors improve their draft. It points out that Figure 5a seems strange and suggests that more explanations are needed. It also questions how the authors handled DVS input when the input is in AER format, which could be a significant area for improvement. Additionally, the comment suggests analyzing energy consumption like reference 15 did, which could strengthen the paper\"s foundation. While the comment identifies several areas for improvement, it lacks specific guidance or examples on how to address these issues. Therefore, the authors are left with a general sense of what needs to be improved but may not have a clear path forward. Overall, the comment is 3 as it provides direction but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifically mentions the use of separate embeddings and positional encoding, but it does not provide explicit guidance on how the embeddings are combined or how they are fed into the CSCM. The comment implies that the authors should provide more detailed information on this process, but it does not specify exactly what needs to be clarified or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text\" and \"CSCM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, how historical observations are combined with inputs known over all time given differences in sequence lengths. The comment provides a clear direction for the authors to address the issue by asking for clarifications on the embedding and positional encoding methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It mentions the use of separate embeddings and positional encoding, but it does not provide any supporting evidence, reasoning, or references to justify the claim that clarification is needed. The comment lacks specific examples or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embeddings and positional encoding but lacks clarity on how these are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the embedding and positional encoding methods. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects should be clarified. Overall, the comment is 4 as it effectively guides the authors toward improving the clarity and comprehensibility of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not provide any explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how to improve the innovation or how to better justify the contribution of the paper. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what is considered a common approach and what is lacking in the paper\"s contribution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks, and that merely migrating this approach to the field of MLMs is not innovative. The reviewer supports this claim by referencing the article itself, which implies that the authors should have known this. However, the comment lacks specific examples or references to support the claim that merely migrating this approach is not innovative. This makes the claim 3, as it provides some evidence but could be strengthened with more detailed examples or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is 3 as it highlights a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to address the concerns raised. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the transfer performance of the model. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the concerns about the model\"s generalization and suggesting additional experiments, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment is 3 as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments to validate the claim, making the comment 3. Therefore, the score is 3.", "helpfulness_rationale": "The review comment raises important concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment also highlights the need for additional experiments across different downstream tasks and domains to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these additional experiments or what specific downstream tasks should be considered. This limits the comment\"s helpfulness, as it provides insight but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that there should be more discussion on the power of different architectures. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and vague, as the authors are left to infer that they need to provide more discussion on the power of different architectures. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that there should be more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the architectures should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification about the expressiveness of fast SMP compared to SMP. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that there should be more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the architectures should be discussed. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. This feedback provides a clear and explicit action for the authors to take, which is to consider using different splits of the training, validation, and testing datasets to test the robustness of their methods. The comment is specific in detailing what needs to be done to improve the robustness of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the evaluation or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would be more robust than simply using different initialisation seeds. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be more robust. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the robustness of their results. By suggesting a more comprehensive evaluation approach, the comment offers a concrete way for the authors to enhance the quality and reliability of their findings. However, the comment could be more helpful if it explained why this change would improve robustness or provided examples of how it could be implemented. Overall, the comment is 4 as it provides a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction should be combined together. This is an explicit action that the authors can directly implement by merging the two bullets. The comment provides a clear and concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests combining the first two bullets about contributions at the end of the introduction. However, it does not specify which part of the introduction this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a potential improvement by combining the two bullets, but without explicit references to the sections, the authors may struggle to identify the exact parts being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any supporting evidence, reasoning, or examples to justify why this combination would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction could be combined together. This is a specific and actionable suggestion that could streamline the introduction and make it more concise. However, the comment lacks further explanation or justification for why this combination would be beneficial or how it would enhance the clarity or impact of the introduction. While it provides a clear direction for improvement, it could be more helpful if it included additional context or examples to guide the authors in implementing this change. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or what specific changes should be made to improve the clarity. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the need for clarification on the types of situations and social norms, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the paper, noting that the types of situations and social norms, such as physical and psychological safety, are not clearly defined. This feedback is 3 as it points out a potential area for improvement, but it lacks depth and does not provide specific suggestions on how to clarify these concepts or what aspects of the paper need further explanation. While it highlights an important issue, the comment could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. However, it points out the need to demonstrate the algorithm\"s improvement over existing solutions by addressing robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment implies that the authors should provide more evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence to substantiate their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s focus on a specific problem and its potential benefits to the neuroscience community. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The comment suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where the algorithm\"s performance is discussed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment identifies a critical area for improvement, it lacks specific examples or references to support the claim about the algorithm\"s improvement over existing solutions. This makes the claim 3, as the authors would need to make a concerted effort to address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem in the neuroscience community. It identifies a critical area for improvement, namely the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on how to address the issue of demonstrating improvement. This limits the comment\"s helpfulness, as it points out a critical area for improvement but does not fully guide the authors on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more baselines should be compared and more domains should be tested. It also mentions that the choices of weighting and learning density functions are not strongly motivated, and that stronger empirical results are needed. However, the comment does not provide specific guidance on which baselines to compare or how to test the additional domains. The authors are left to infer that they need to expand their experimental setup, but without concrete suggestions on which baselines or domains to include, the action remains vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that more baselines should be compared and more domains should be tested, and it mentions the choices of weighting and learning density functions as areas for improvement. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments where these improvements could be made. Additionally, the comment lacks specific guidance on which baselines or domains should be included, making it weakly grounded. The suggestion to provide stronger empirical results is somewhat specific, as it highlights the need for more comparisons and additional domains, but it does not detail how to achieve this. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more baselines should be compared and more domains should be tested, and it critiques the choices of weighting and learning density functions as not being strongly motivated. However, the comment lacks specific examples or references to support the claim that these choices are not justified or that the current results are insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that more baselines should be compared and more domains should be tested. It also critiques the choices of weighting and learning density functions as not being strongly motivated, implying that stronger empirical results are needed. While the comment highlights areas for improvement, it lacks specific suggestions on which baselines or domains to include or how to strengthen the empirical results. This limits the comment\"s helpfulness, as it provides a general direction but does not offer actionable guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete request, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB\" and \"fig. 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification about the dashed lines in figures 2AB and 4B. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it directly addresses a specific issue by requesting clarification on the definition of the dashed lines in figures 2AB and 4B. This feedback is clear and actionable, as it guides the authors to provide a necessary explanation for their figures, which could improve the clarity and understanding of their work. By addressing this point, the authors can enhance the readability and comprehensibility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the comparability of the results or what specific aspects need to be improved. As a result, the authors are left without any clear direction on how to enhance the significance of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, which suggests that the significance of the proposed methods is questionable. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods may be questionable. However, it does not provide any specific examples or guidance on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment implies that the authors should provide more insights into these challenges, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of overcorrelation, but the comment does not provide specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DeCorr 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems, despite being a straightforward application of existing literature. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer supports this claim by mentioning that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also acknowledges that modifications like different penalty coefficients for users and items are proposed. While the claim is 3 due to the mention of DeCorr and the transposition of insights, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to understand and address the critique, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically DeCorr. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment provides some insight into the paper\"s limitations, it does not offer specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their work. The feedback is 3 as it identifies a critical area for improvement, but it lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the clarity of the symbols or the explanation of the process. The authors are left to infer that they need to clarify the symbols and provide more information on the process, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed in the figure and the process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support the claim of ambiguity or the need for clarification. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This feedback is 3 as it points out a potential area for clarification and improvement in the figure, which could enhance the reader\"s understanding of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify the symbols or address the questions about information redundancy and interference. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, noting that this assumption excludes popular classes of kernels like Matern kernels. The reviewer suggests that the results could be restrictive due to this assumption. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to broaden the scope of the results. The action is implicit and somewhat vague, as the authors need to infer that they should consider broadening the scope of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption regarding the spectrum of a kernel being subgaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the assumption excludes popular classes of kernels like Matern kernels, which could limit the scope of the results. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the assumption of the spectrum of a kernel being subgaussian is a limitation, as it excludes popular classes of kernels like Matern kernels. The reviewer supports this claim by noting that Matern kernels have a polynomially decaying spectrum, which is not included in the assumption. However, the comment lacks specific examples or references to Matern kernels or other relevant literature to fully substantiate the claim. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, which excludes popular classes of kernels like Matern kernels. This is a relevant point that could impact the scope and applicability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or broaden the scope of their results. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain. While the comment explicitly states the action to take, it lacks concrete details on how to implement this suggestion. It does not provide specific guidance on what aspects of the pretraining method should be discussed or how to integrate it into the main paper. The authors are left with a clear action to take but without detailed instructions on how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"unsupervised pretraining,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on the unsupervised pretraining in the main paper and its importance compared to other modules. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, based on data from Table 4. However, it does not provide specific evidence or detailed reasoning to support this claim, such as data analysis or comparisons with other methods. The comment suggests that the unsupervised pretraining should be discussed more in the main paper, but it lacks the necessary justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed evidence or reasoning to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the unsupervised pretraining is a key factor in performance gain but is not discussed in detail in the main paper. It suggests that the authors should focus more on the pretraining method, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific guidance on how to integrate the discussion of the unsupervised pretraining into the main paper or what aspects of the pretraining method should be emphasized. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they might need to consider this aspect in their methodology or experimental design, but the comment lacks concrete steps or detailed advice on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors might have an idea of where this discussion might occur, the comment lacks full grounding. It is specific in its critique of the methodology but does not provide detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment lacks specific examples or references to support the claim that this is a drawback or how it affects the methodology. The reasoning is based on logical reasoning and common sense, but it does not provide detailed evidence or references to substantiate the claim. Therefore, the comment is 3, as it provides a logical argument but lacks the depth and specificity needed for full verifiability.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is 3 as it identifies a potential issue with the methodology that the authors may not have considered. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to incorporate gender detection models into the pipeline. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the writing is difficult to follow in many places and suggests simplifying it. However, it does not provide specific examples or guidance on how to achieve this simplification. The authors are left to infer that they need to make their writing more accessible, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and suggests simplifying it. However, it does not specify which parts of the paper are particularly challenging or where the simplification is needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests simplifying it. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or examples, the authors may find it challenging to understand where the writing is difficult to follow and how to simplify it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper\"s writing, noting that it is difficult to follow in many places and suggests simplifying it. While this feedback highlights a potential problem, it lacks specificity and does not provide actionable guidance on how to improve the writing or which sections are particularly challenging. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the paper is incremental and lacks technical substance, suggesting that it only adds a new loss to an existing work. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical substance or what specific aspects of the paper need to be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to an existing work. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. Without explicit references to these sections, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or lacking in technical substance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, suggesting that it only adds a new loss to an existing work. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without detailed explanation or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to an existing work. However, it does not provide any specific examples or detailed feedback on what aspects of the paper are considered incremental or lacking in technical substance. Without actionable suggestions or guidance on how to improve the paper, the authors are left without a clear path forward. The comment identifies a potential weakness but does not offer constructive advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the proof of Theorem 1 and suggests that it would be helpful to provide some intuition. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. While the comment implies that the authors should provide more detailed explanations or examples, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more intuition and examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"the invertible function $f^*$,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the proof of Theorem 1 and the dependence of $f^*$ on the fixed $P^*$. The comment suggests providing intuition and inquires about the determination of $P^*$ in practice. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification regarding the proof of Theorem 1 and the dependence of the invertible function $f^*$ on the fixed $P^*$. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the proof of Theorem 1 and the dependence of the invertible function $f^*$ on the fixed $P^*$. It suggests that providing intuition for the proof and exploring the impact of different distributions on $P^*$ could be beneficial. Additionally, it inquires about how to determine which $P^*$ to fix in practice. While the comment identifies areas for improvement and provides some guidance, it lacks specific suggestions or examples on how to address these issues. Therefore, the comment is 3, as it points out potential areas for enhancement but does not fully guide the authors on how to implement these improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks guidance on how the authors might clarify or justify the notation choices, leaving the authors uncertain about how to proceed. Since the action is not stated or implied, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of notation, expecting them to be analogous but noting a discrepancy. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, the comment does not provide any reasoning, explanation, or evidence to support why the notation should be analogous or why the discrepancy exists. Without additional context or justification, the claim is not verifiable, as it lacks the necessary information to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the notation used in equations (7) and (10), expecting them to be analogous but noting a discrepancy. This feedback highlights a potential issue in the clarity or consistency of the paper, prompting the authors to reconsider their notation choices. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the equations. While it identifies a potential problem, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to demonstrate the applicability of their model to realworld diffusion processes. While the comment implies that the authors should conduct experiments or provide examples to support their claims, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide empirical evidence but may not be entirely sure of the specifics of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the applicability of the model to realworld diffusion processes is a concern, and it provides a logical reasoning by stating that the authors should provide empirical evidence to demonstrate its effectiveness. However, the comment lacks specific examples or references to support the claim that the model captures diffusion phenomena in realworld scenarios. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the proposed model to realworld diffusion processes. It acknowledges the elegance of the solutions presented but suggests that empirical evidence is needed to demonstrate the model\"s effectiveness in realworld scenarios. This feedback is clear and actionable, as it provides a specific direction for the authors to address the applicability issue by providing empirical evidence. However, the comment could be more helpful if it offered suggestions on how to conduct such experiments or what specific aspects of the diffusion process should be examined. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is implicit, it is clear that the authors need to expand their testing to include more datasets. The comment provides a specific suggestion for improvement, which is to test on additional datasets. However, it does not offer detailed guidance on which datasets to use or how to conduct the additional testing. Therefore, the action is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the testing and evaluation of the method, but this inference is not direct. The comment is specific in suggesting the need for additional testing, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any supporting evidence, reasoning, or references to justify why testing on more datasets would be beneficial or necessary. The claim is based on a logical assumption, but without additional context or examples, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. This is a reasonable suggestion that could improve the robustness and generalizability of the results. However, the comment lacks specificity and does not provide guidance on which datasets to use or how to conduct the additional testing. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, and that alternatives already exist. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to differentiate their contribution from existing work. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the main contribution, which is the combination of attention with other linear mechanisms. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what alternatives are mentioned or how the authors could address the issue of novelty. Without clear guidance on where to focus improvement efforts, the authors may struggle to effectively respond to this feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, the comment does not provide specific examples or references to these alternatives, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, it does not provide specific examples or suggestions on how the authors might address this issue or differentiate their work from existing alternatives. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and concrete action that the authors can take to improve their draft. The comment provides a specific direction for visualizing the results, which is a direct and actionable step. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing a plot of how different weights of the model move, specifically after unlearning, to see which layers are affected the most. However, it does not specify which part of the paper this plot should be included in, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular visualization, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a request for additional visualization to support the understanding of the method. However, the comment does not provide any specific reasoning or evidence to justify why this plot is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and constructive piece of feedback that can help the authors better understand and communicate the impact of their method. By addressing this suggestion, the authors can enhance the clarity and comprehensiveness of their results, making the paper more informative and valuable to the reader. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide more novelty or depth in their methodology section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"methodology aspect\" and \"ENCODE part,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The reviewer further suggests that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific references or detailed reasoning to support the claim that the ENCODE part is already proposed. The suggestion about the decomposition part is somewhat vague, as it does not provide a clear explanation of what the authors should do to address this issue. Therefore, the claim is 3, as it requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which involves factoring M_v into factor D and slicing Phi_v. While the comment highlights a potential weakness in the paper\"s novelty, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice or detailed insights to fully support the authors in improving their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific information should be included in the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the inputs are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or clarified regarding the domain of the inputs. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\"s validity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what additional information might be needed. Without actionable feedback or detailed advice, the authors are left with a vague understanding of the problem but no clear path to improvement. Therefore, the comment is rated as 2, as it identifies a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare the performance of their proposed CLN (region proposal generation algorithm) with that of another work. While the comment implies that the authors should conduct a performance comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not specify which part of the paper discusses the CLN or where the performance comparison should be included. The authors cannot confidently determine which section or part of the paper is being addressed, making this comment 1. Additionally, the comment lacks specificity regarding what aspects of the performance comparison should be considered or how it should be conducted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work, which could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks specificity and does not offer guidance on how to conduct this comparison or what aspects to focus on. Without detailed instructions or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also recommends the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment provides a clear action\u2014adding an illustrative figure\u2014it does not specify which concepts should be illustrated or how the figure should be designed. The authors are given a clear direction to add an illustrative figure but are left to determine the specifics of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation, specifically mentioning that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also suggests the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the presentation and notation in chapter 3. The suggestion to include an illustrative figure is specific, providing a clear action for the authors to take. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. While the comment identifies specific issues with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for an illustrative figure is a logical point, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation by adding an illustrative figure. However, the comment could be more helpful if it offered specific guidance on what elements should be illustrated or how the figure should be designed to enhance clarity. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and the independence of x and y given W. The reviewer suggests that taking Z\u00e2\u0080\u0099 to be the empty set would lead to a contradiction with Eq. (7), which claims otherwise. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to resolve the conflict. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the definition of Z\u00e2\u0080\u0099 and potentially revise the equation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, particularly regarding the definition of Z' and the independence of x and y given W. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z' and the independence of x and y given W. The reviewer provides a logical reasoning by taking Z' to be the empty set, which would lead to a contradiction with Eq. (7). However, the comment lacks specific references or examples to support the claim, making it 3. The authors would need to further explore the issue to fully understand and address the conflict. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z' and the independence of x and y given W. By pointing out this contradiction, the reviewer highlights an area where the authors may need to clarify or revise their definitions to ensure consistency. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular resolution or offering alternative interpretations. While it alerts the authors to a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out that the visual presentation, specifically the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide explicit guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the subscripts, but without specific suggestions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual presentation of the subscripts, for better readability and aesthetic appeal. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the comprehensive nature of the data presented in Figure 3 but suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide specific examples or detailed reasoning to support why the subscripts are problematic or how they could be improved. Without such examples or references, the claim is not 5, as it lacks the necessary evidence or justification to substantiate the suggestion. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out a specific area for improvement. It suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. While the comment identifies a clear area for improvement, it lacks depth and does not provide specific suggestions or examples on how to enhance the visual presentation. This limits the comment\"s usefulness in guiding the authors toward actionable improvements. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify their explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the problem of gradient bias in Batch Normalization and the potential of Online Normalization. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the difference between Online Normalization and Batch Normalization, asking why Online Normalization is unbiased while Batch Normalization is biased. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that Online Normalization is unbiased and Batch Normalization is biased, suggesting that the authors have not adequately explained this difference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. This is a relevant point that could help the authors clarify their explanation or provide additional context to readers. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in cramped equations and captions too close to the figures. This is considered a grounding comment as it clearly identifies the issue with the spacing. However, the comment does not provide any guidance on how to address this issue, such as suggesting specific adjustments or improvements to the spacing. The action is implicit and vague, leaving the authors without clear direction on how to improve the spacing to meet the 9page paper limit. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of whitespace throughout the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly states that this issue violates the 9page paper limit, providing a clear rationale for the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper violates the 9page limit due to the cramped spacing of equations and captions too close to the figures. This claim is 3 as it provides a logical reasoning based on the observation of the paper layout. However, it lacks specific examples or references to support the claim, such as how the spacing affects the readability or comprehension of the paper. Providing such details would strengthen the claim and make it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the layout of the paper, noting that equations are crammed together and captions are too close to the figures, which violates the 9page paper limit. This is a clear and actionable observation that the authors can address to improve the readability and adherence to the page limit. However, the comment could be more helpful if it provided suggestions on how to improve the spacing or offered examples of how other papers have successfully addressed similar issues. Despite this, the feedback is 4 as it highlights a critical aspect of the paper that needs attention."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the paper is in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical details or formulations, nor are there suggestions for additional exploration or elaboration. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical details and formulations are limited, implying that the main novelty of the paper is in the scheme or procedure novelty. However, it does not specify which part of the paper this issue pertains to, such as specific sections, figures, or equations. Without explicit references, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are lacking or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the technical details and formulations are limited, implying that the main novelty of the paper is in the scheme or procedure novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the paper is in the scheme or procedure novelty. However, it does not provide any specific guidance or suggestions on how the authors might improve the technical details or formulations to enhance the paper\"s clarity or impact. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the concept of local interactions, asking whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area for clarification, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the concept of local interactions in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its questioning of the concept, providing clear guidance on what needs to be clarified. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the concept of local interactions, specifically asking whether it refers to interactions within a time window or within the same modality. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the confusion. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is 3 as it identifies a potential area for improvement in the paper, namely the need to clarify the concept of local interactions. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending a specific definition or example to clarify the concept. While it points out a potential weakness, the lack of actionable advice limits its usefulness for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper claims better results in the Molecule generation experiment but notes that adding the proposed constrained method actually yields lower validity and diversity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment, as stated in Table.3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims regarding the Molecule generation experiment, specifically noting that the addition of the proposed constrained method actually yields lower validity and diversity. This is a critical observation that could impact the paper\"s conclusions and credibility. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their results. While it points out a potential problem, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the archetype positions are updated after initialisation in Algorithm 2. It explicitly asks the authors to clarify this aspect, providing a clear action for the authors to take. The comment is explicit in its request for clarification, making it 5. The authors know exactly what needs to be addressed and how to implement the action, as they are instructed to provide a comment on the update process. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"the query Q consists of the archetypes z_1, \u00e2\u0080\u00a6, z_k,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the update process of the archetype positions after initialisation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the update process for the archetype positions in Algorithm 2. It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is a factual statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the update process of the archetype positions in Algorithm 2. It asks the authors to clarify this aspect, which is important for understanding the methodology. This feedback is clear and actionable, as it directs the authors to provide a comment on the update process. However, the comment could be more helpful if it offered suggestions on how to clarify this aspect or provided examples of how the update process might be explained. Overall, the comment is 4 as it points out a critical area for clarification, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These are all clear and concrete actions that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the sections being addressed. It also specifies what is missing, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point makes several claims about the missing information in the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These claims are 3 as they are based on logical reasoning and common knowledge about empirical studies. However, the comment could be strengthened by providing specific references or examples to support the claims or by offering more detailed explanations of the missing information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the transparency and completeness of their empirical study. By addressing these points, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can differ across datasets. It suggests that the paper should perform crossdataset experiments to test the generalization of the work. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for crossdataset experiments and determine how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential risk of methods that exploit relationships between action units, noting that the relationships can differ across datasets. The comment suggests that the paper lacks crossdataset experiments to test the generalization of the work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that methods that exploit relationships between action units can suffer from differences in relationships across datasets, as seen in Figure 1. The reviewer suggests that crossdataset experiments are necessary to test the generalization of such work. While the comment provides a logical reasoning for the need to test generalization, it lacks specific examples or references to datasets or studies that demonstrate these differences. This makes the claim 3, as the authors would need to infer the significance of the differences in Figure 1 and understand the implications of performing crossdataset experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a potential issue with the generalization of such work, as demonstrated by the differences in cooccurrences of action units in Figure 1. The comment suggests that crossdataset experiments are necessary to test the generalization of the work. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to conduct these experiments or what aspects of the dataset differences should be considered. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to add more details about the Starcraft environment, but the comment lacks concrete guidance on how to present this information or what specific aspects to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what aspects of the environment should be described. This lack of specificity makes it difficult for the authors to pinpoint the exact sections that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not provide any reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without such justification, the claim is 1, as it lacks the necessary evidence or explanation to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. This feedback is 3 as it identifies a specific area where the paper could be improved by providing additional context or background information. However, the comment lacks depth and does not offer specific suggestions on what aspects of the Starcraft environment should be described or how this information could enhance the paper. While it points out a potential area for improvement, it does not provide actionable guidance or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should reconsider their statement about overparameterization, which is currently presented as a negative aspect. The reviewer provides a rationale by pointing out that overparameterization can be beneficial for supervised learning of deep neural networks in practice, and references a theoretical work that supports this claim. However, the comment does not explicitly instruct the authors to change their stance or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their position. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the authors\" claim about overparameterization and provides a rationale by pointing out its benefits in practice and referencing theoretical work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that overparameterization is beneficial for supervised learning of deep neural networks in practice, citing theoretical work to support this claim. However, the comment does not provide specific references to the theoretical work or detailed reasoning behind the benefits of overparameterization. This lack of explicit references or detailed justification makes the claim 3, as the authors would need to seek out the references themselves to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment challenges the authors\" claim about overparameterization, suggesting that it can be beneficial for supervised learning of deep neural networks in practice. It provides a rationale by referencing theoretical work that supports this claim, which is a valuable contribution to the discussion. However, the comment could be more helpful if it offered specific examples or references to this theoretical work, as this would provide the authors with a clear path to explore and substantiate their argument. Despite this, the comment still offers a constructive critique that can guide the authors in refining their perspective on overparameterization. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects of the training and testing process should be described or compared. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed description and comparison with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of training the shape model and the complexity of the parsing model, suggesting that the processing efficiency of training and testing should be described and compared with existing work. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the training and testing process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its training in pixel level (though sparsity by landmark) and the complexity of the parsing model, which is described as a highorder factor graph with four types of factors. The reviewer suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment provides some logical reasoning by pointing out the timeconsuming nature of the training process, it lacks specific examples or references to existing work that could substantiate the claim. This makes the claim 3, as it provides a general idea but requires more detailed evidence or references to fully support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what aspects of the training and testing process should be described or compared. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional details or suggestions on how to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of domain adaptation methods that are not novel. It suggests that the authors should consider using more recent domain adaptation methods to improve performance. While the comment implies that the authors should explore other methods, it does not provide specific guidance on which methods to use or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore other domain adaptation methods to enhance their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of domain adaptation methods that are not novel. It suggests that the authors should consider using more recent domain adaptation methods to improve performance. However, the comment does not specify which parts of the paper these critiques pertain to, such as sections or specific techniques. This makes it difficult for the authors to pinpoint the exact areas needing revision. While the comment provides some specificity in suggesting the use of more recent domain adaptation methods, it lacks full grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors combine two existing techniques without innovation, specifically mentioning the use of domain adaptation methods that are not novel. The reviewer suggests that the authors should consider using more recent domain adaptation methods to improve performance. While the comment provides a logical reasoning for the critique, it lacks specific examples or references to recent domain adaptation methods that could be considered. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of domain adaptation methods that are not novel. It suggests that the authors should consider using more recent domain adaptation methods to improve performance. While the comment identifies a potential weakness in the paper\"s innovation, it lacks specific suggestions or guidance on which recent domain adaptation methods could be considered or how to implement them. This limits the comment\"s helpfulness, as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on what to discuss. The comment is specific and leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the discussion. The comment is specific in suggesting what needs to be addressed, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. This feedback is 3 as it identifies a specific area that could enhance the paper by providing more context and detail about the dataset creation process. However, the comment lacks depth and does not offer suggestions on how to structure or present this discussion, nor does it provide examples of what could be included. While it points out a potential improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from incremental engineering papers. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is problematic or where the motivation is unclear. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation or the paper are unclear or how they could be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or originality of their work. Without actionable feedback or detailed insights into what aspects of the paper are unclear or lacking, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be useful to see how it affects performance in a scenario where the game has repetitive background sounds. The reviewer also points out that the authors note that their method underperforms in this scenario, implying that the weighting might have helped remedy the issue. While the comment provides a clear action\u2014conducting an ablation study\u2014it does not offer specific guidance on how to implement this study or what specific aspects to focus on. The authors are left to infer the details of how to conduct the ablation, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be useful to see how it affects performance in a scenario where the game has repetitive background sounds. This provides a clear suggestion for an additional experiment, which is specific to the paper\"s methodology. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be useful to see how it affects performance in a scenario where the game has repetitive background sounds. The reviewer provides a logical reasoning by pointing out that the weighting might have helped remedy the issue. However, the comment lacks specific examples or references to support the claim that the weighting method could have improved performance in this scenario. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be useful to see how it affects performance in a scenario where the game has repetitive background sounds. This is a clear and actionable suggestion that could help the authors improve their draft by providing additional insights into the effectiveness of their method. The comment also references the authors\" previous work, noting that the weighting might have helped remedy the issue in the Atlantis game. However, the comment could be more helpful if it provided specific guidance on how to conduct the ablation or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to demonstrate novelty and incremental improvements, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of the lack of novelty and incremental nature of the work, as well as the problem of column operations in designing semantic parsers for TexttoSQL. It also mentions the design of a new dataset, which is a different train/test split of an existing dataset, SQUALL. Additionally, it points out a synthetic benchmark paper based on a single question template. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be improved, such as demonstrating novelty and incremental improvements, and providing suggestions for addressing the issue of column operations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically addressing a problem of column operations in designing semantic parsers for TexttoSQL. The reviewer provides some justification by mentioning that the proposed dataset is a different train/test split of an existing dataset, SQUALL, and that the synthetic benchmark paper is based on a single question template. However, the comment could be strengthened by providing more detailed examples or references to support the claim of lack of novelty. As it stands, the comment is 3, as it provides some evidence but lacks comprehensive justification. Therefore, the score is 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template, which further highlights the lack of novelty. This feedback is clear and actionable, as it directs the authors to address the issue of novelty and incremental nature in their work. However, the comment could be more helpful if it provided suggestions on how to demonstrate novelty or incremental improvements, such as by suggesting alternative approaches or datasets. Overall, the comment is 4 as it effectively identifies a critical weakness and offers direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the experiments are limited to one game environment and suggests that more experiments are necessary. This provides a clear and direct action for the authors to take, which is to expand their experimental scope to include additional game environments. The comment is specific in its request for additional experiments, making it 5.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to conduct more experiments, but without clear references to specific sections or experiments, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are conducted on only one game environment. It suggests that more experiments are necessary to provide a broader perspective. While this feedback highlights an area for improvement, it lacks specific guidance on which additional environments should be considered or how to conduct these experiments. The comment is 3 as it points out a potential weakness but does not offer detailed suggestions for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This is a clear and direct action for the authors to take, as it specifies the need for a detailed explanation with examples. The comment provides a concrete direction for improvement, ensuring that the authors know exactly what needs to be done to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a detailed explanation with examples. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are important or how removing them would contribute to the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This feedback is clear and actionable, as it directs the authors to provide a detailed explanation with examples to strengthen their argument. By addressing this point, the authors can enhance the clarity and impact of their paper. However, the comment could be more helpful if it provided specific examples or guidance on how to present these explanations. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific information about the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This explicit comparison and concrete data provide the authors with a clear action to take: they need to address the issue of slow speed and low accuracy by improving their implementation. The comment is explicit and provides concrete details on how to apply the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the implementation of ImageNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of slow speed and low accuracy, providing specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, citing specific examples of time and accuracy. However, the comment does not provide any supporting evidence or references to substantiate these claims. Without additional context or detailed analysis, the authors may find it challenging to understand the basis of these claims and address them effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This feedback is clear and actionable, as it highlights a critical issue that the authors need to address to improve the credibility and effectiveness of their work. By addressing these points, the authors can enhance the robustness and reliability of their implementation. However, the comment could be more helpful if it offered suggestions on how to improve the speed and accuracy, such as potential optimizations or alternative approaches. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning, and it explicitly asks for an explanation of the correspondence between the learning curves and MPHATE in Figure 3. The reviewer also questions the rationale behind the learning curves and the accuracy numbers, providing specific questions that the authors should address. These actions are clear and detailed, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the need for an explanation of the experimental setting for continual learning, the correspondence between the learning curves and MPHATE, and the accuracy numbers. The comment provides detailed questions that guide the authors on what aspects of the paper need clarification or expansion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add a few more sentences to explain the experimental setting for continual learning. It also requests an explanation of the correspondence between the learning curves and MPHATE in Figure 3, questioning the rationale behind the learning curves and the accuracy numbers. This feedback is clear and constructive, as it guides the authors on how to enhance the clarity and understanding of their experimental setup. By addressing these points, the authors can improve the comprehensibility and rigor of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer any explicit guidance or actionable steps for the authors to take. The comment lacks specific instructions or suggestions on how to incorporate this idea into the paper. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that labeled data might provide effective information for consistency training and provides examples of relevant works, such as \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation.\" Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. The reviewer supports this suggestion by referencing two external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which demonstrate the effectiveness of using labeled data for this purpose. However, the comment lacks detailed reasoning or specific examples from the works to fully substantiate the claim. While the references provide some support, the comment could be strengthened by further elaboration on why labeled data might be beneficial and how it could be integrated into the paper. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer specific guidance or actionable steps for the authors to explore this idea further. The comment references two external works, which could be useful for the authors to consider, but the lack of detailed suggestions or examples limits its helpfulness. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific suggestions for how to do so. It suggests that the experimental content listed in the main text should highlight the superiority of the method, and it provides a list of experimental suggestions that should be included in the main text. These suggestions are concrete and provide clear guidance on what changes the authors should make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental part\" and the \"experimental section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the reorganization and highlighting of the experimental content to showcase the superiority of the method. The suggestions for reorganization and the inclusion of specific experimental content are detailed, providing clear guidance for the authors to make improvements. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part needs to be reorganized and improved, suggesting that the experimental content listed in the main text does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to specific sections of the paper where the issue is apparent, making it difficult for the authors to understand and address the critique. As a result, the claim is considered 2, as it provides some basis but lacks the necessary detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental part of the paper, noting that the experimental content listed in the main text does not effectively highlight the superiority of the method. It provides a clear and actionable suggestion to reorganize the experimental section and includes specific experimental suggestions that should be included in the main text. This feedback is valuable as it guides the authors on how to improve the clarity and effectiveness of their experimental results, which is crucial for the paper\"s credibility. However, the comment could be more helpful if it provided additional details or examples of how to implement these suggestions. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. It also requests theoretical justifications, if possible. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should report the classification accuracy and provide theoretical justifications. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed classification network, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. Additionally, it requests theoretical justifications, if possible, which provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. The reviewer suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. However, the comment lacks specific examples or references to support the claim that the proposed network\"s classification error is universally as good as the standard softmax network. This makes the claim 3, as the authors would need to provide additional evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. It suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. This feedback is 3 as it prompts the authors to address a potential weakness in their model and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to improve the classification accuracy or provided examples of theoretical justifications. Overall, the comment is 3 as it identifies a critical area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific changes could be made to improve the argument or simulations. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It questions the practicality of this argument, noting that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. However, the comment does not specify which part of the paper this argument is discussed in, nor does it provide specific guidance on how the authors might address this issue. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. The reviewer points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. This claim is 3 as it provides a logical reasoning based on common practices, but it lacks specific examples or references to support the assertion that such an implementation would be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the argument presented regarding the recall of recognition lists based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. While the comment highlights a relevant issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their argument. The feedback is 3 as it prompts the authors to consider the practicality of their argument, but it could be more beneficial with additional actionable advice or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pretrained model as the compared methods. It points out that if not, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly rerun experiments with different initialization methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the initialization of the proposed method before the finetuning stage. The comment suggests that if the compared methods were not initialized with the same or similar pretrained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pretrained model as the compared methods. The reviewer supports this claim by referencing Table 1, which shows the inferior performance of the proposed method without SSL compared to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential issue in the experimental setup that could affect the results. However, the comment could be strengthened by providing more detailed reasoning or examples of how this initialization might impact the results. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method before the finetuning stage. It points out that if the compared methods were not initialized with the same or similar pretrained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This feedback is 3 as it highlights a potential weakness in the experimental setup that the authors should address. However, the comment could be more helpful if it provided suggestions on how to address this issue or clarified the implications of the initialization on the results. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion to use better metadata embeddings and provides a specific reference to a related work. However, it does not provide detailed guidance on how to implement this suggestion or what specific steps to take. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. The comment provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the authors should consider this approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The reviewer provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" This reference provides a clear rationale for the suggestion, as it demonstrates that better metadata embeddings can lead to improved performance. However, the comment could be strengthened by providing more detailed analysis or specific examples of how the proposed method could benefit from these embeddings. Overall, the claim is 4, as it is supported by a specific example and logical reasoning, but it could be further substantiated with additional evidence or detailed analysis.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by recommending the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. It references a specific example from a related work, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which demonstrates the potential for better performance using better metadata embeddings. This feedback is clear and actionable, as it guides the authors on how to enhance their results and potentially improve their paper\"s impact. However, the comment could be more helpful if it provided additional context or detailed guidance on how to implement this suggestion. Overall, the comment is 4 as it offers a concrete direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This explicit action provides a clear and concrete step for the authors to take, as it specifies the exact visualization needed to demonstrate the practical benefits of SGC. The comment is 5 because it directly instructs the authors on how to enhance their draft with a specific visualization, ensuring that the authors know exactly what to do to improve their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the limited applicability of SGC and the need for a plot to compare its flexibility with LoRA. It specifies the issue by suggesting a visualization with sparsity on the xaxis and performance on the yaxis. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff but is limited in practicality due to the need for extra tuning. The reviewer suggests including a plot to demonstrate the flexibility of SGC compared to LoRA. This claim is 3 as it provides a logical reasoning for the need to visualize the tradeoff, but it lacks specific examples or references to support the claim about the limitations of SGC. The suggestion for a plot is a helpful direction, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s claim about the flexibility and performance of SGC, specifically in the context of computeconstrained scenarios. It suggests including a plot to demonstrate the flexibility of SGC compared to LoRA, which could help clarify the practical benefits of SGC\"s finegrained control. This feedback is clear and actionable, providing a specific suggestion for improving the paper by adding a visualization that could enhance the authors\" understanding of their results. However, the comment could be more helpful if it explained why this visualization is necessary or how it would contribute to the paper\"s overall argument. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, and suggests that the code should be published if the main advantage is its computation time. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the shorter training time or consider publishing the code. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reason for the shorter training time in Gerrymandering compared to Independent, and suggests that the code should be published if the main advantage is its computation time. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might be unreasonable. It also mentions that the code should be published if the main advantage is its computation time. However, the comment lacks specific evidence or references to support the claim that the shorter training time is unreasonable or that the code should be published. Without additional context or justification, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without more detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might be unreasonable. It also suggests that if the main advantage of the code is its computation time, it would be beneficial to publish the code. While the comment identifies a potential issue with the experimental setup, it lacks specific guidance or suggestions on how to address this concern or improve the paper. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information that CD captures beyond Predictive Uncertainty. It also questions the use of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" (line 115). However, the comment does not provide explicit instructions on how to implement these suggestions or what specific formulations should be considered. The action is implicit and somewhat vague, as the authors need to infer the specific formulations and how to address the entropy question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the additional information captured by Confidence Diversity (CD) beyond Predictive Uncertainty and the use of entropy as a measure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the additional information captured by Confidence Diversity (CD) beyond Predictive Uncertainty and the use of entropy as a measure. It suggests that the current formulation of CD is unclear and lacks clarity. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also questions the additional information captured by CD beyond Predictive Uncertainty and the use of entropy as a measure. The reviewer points out that line 113 did not clarify this point, providing a clear direction for the authors to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions or examples of alternate formulations or provided additional context on why entropy is not a suitable measure. Overall, the comment is 3 as it highlights a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. It also points out that the abstract statement about beating a human who learned from the same resources is misleading due to the limited human data. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is 3, as it identifies a problem but does not offer concrete steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the human baseline, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. Additionally, it points out that the abstract statement about beating a human who learned from the same resources is misleading due to the limited human data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is considerably weaker than the model baseline due to the limited amount of speech recordings followed by the human. The comment supports this claim by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, while the model baseline is evaluated on the full 15 hours. Additionally, the comment notes that the abstract statement about beating a human who learned from the same resources is misleading due to the limited human data. This provides a logical reasoning and specific examples to support the claim, making it 4. However, the comment could be strengthened by providing more detailed evidence or references to similar studies that demonstrate the impact of limited human data on baseline comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. This is a critical observation that could impact the validity and applicability of the human baseline. Additionally, the comment points out that the abstract statement about beating a human who learned from the same resources is misleading due to the limited human data. This feedback is valuable as it highlights a potential misrepresentation in the paper, which the authors should address to ensure the accuracy and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the human baseline. Overall, the comment is 3 as it identifies a critical weakness and offers a constructive critique, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the assumption for termination states of instructions is quite strong, particularly when it comes to labeling a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, particularly in the context of labeling a large number of data manually. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue of the assumption being too strong, but it lacks detailed guidance on how to address this issue or what specific changes could be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is \"quite strong,\" particularly when it comes to labeling a large number of data manually. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the assumption for termination states of instructions, particularly when it comes to labeling a large number of data manually. This is a relevant point that could impact the feasibility and costeffectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the nature of the contribution with respect to ECE_sweep. It explicitly states that the contribution is not clearly described and suggests that the authors should be upfront about it. The reviewer provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate. This feedback is specific and provides a clear direction for the authors to improve their draft by clarifying the contribution. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ECE_sweep\" and the issue with the contribution being unclearly described. It specifies the problem by pointing out that the contribution involves autotuning a hyperparameter in the estimate, which leads to a different estimator. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution with respect to ECE_sweep is not clearly described in the text. It provides a specific example of the issue, which is the autotuning of a hyperparameter in the estimate, leading to a different estimator. The reviewer acknowledges that this is not fundamentally different from the contribution. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the contribution regarding ECE_sweep. It points out that the contribution is not clearly described in the text, particularly regarding the autotuning of a hyperparameter in the estimate. The reviewer acknowledges that this leads to a different estimator but notes that it is not fundamentally different. The comment provides a concrete example of what is missing, which is a clear description of the contribution. This feedback is actionable and offers a clear direction for the authors to improve the clarity of their contribution. However, the comment could be more helpful if it suggested ways to enhance the clarity or provided additional examples to illustrate the issue. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, it does not provide explicit guidance on which methods should be used as a baseline or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to consider using these methods as a baseline but are not given specific instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This provides clear guidance on what needs to be addressed in the paper, namely the inclusion of these methods as baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the related work section, noting that it discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This feedback is 3 as it points out a potential gap in the paper\"s analysis, which could be addressed by including these methods as baselines. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these methods or why they are important. Additionally, it does not address other aspects of the paper, such as its originality or contributions. Therefore, the comment is 3, as it highlights an area for improvement but does not fully guide the authors on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the authors\" use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests that it might refer to a family of efficient proxies. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should clarify this ambiguity or what specific actions they should take to address it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the use of \"efficient proxy\" or \"efficient proxies\" in their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"efficient proxy\" or \"efficient proxies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ambiguity in the use of these terms, suggesting that \"is\" might imply a particular proxy but that the lack of a specific \"Efficient Proxy\" suggests a broader family of efficient proxies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the ambiguity in the use of the term \"efficient proxy\" or \"efficient proxies\" in the paper. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests a broader family of efficient proxies. This reasoning is based on logical deduction from the text and the use of the term \"is,\" but it does not provide specific examples or references to support the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the authors\" use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests a broader family of efficient proxies. This feedback is 3 as it points out a potential source of confusion in the paper, which could be clarified to improve the clarity and consistency of the work. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this ambiguity or what specific terms or definitions might be used to avoid confusion. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the authors stacking methods from Mirzasoleiman et al., 2020 and using a grouplearning setting, followed by a classical method like DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the grouplearning setting, followed by the use of a classical method like DBSCAN for clustering. However, it does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the methodology, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors stack methods from Mirzasoleiman et al., 2020 and use a grouplearning setting, followed by a classical method like DBSCAN for clustering. However, the comment lacks any supporting evidence, reasoning, or references to justify why this approach is problematic or inappropriate. Without additional context or explanation, the claim remains 1, as it does not provide sufficient justification for the authors to understand or address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the grouplearning setting, followed by the use of a classical method like DBSCAN for clustering. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the authors are left without a clear path forward. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. It also mentions that the authors might have missed this in the appendix. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the resilience of the metric to the choice of random projection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the chosen random projection matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. The comment also mentions that the authors might have missed this in the appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. However, the comment lacks specific examples or references to support the claim that such pathological projection matrices are unlikely with random projections. While it highlights a potential concern, the lack of detailed evidence or examples makes the claim 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results obtained using the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. It also points out that the authors might have missed this in the appendix. While the comment highlights an important area for investigation, it lacks specific guidance or suggestions on how to address this issue or what specific tests could be conducted to verify the resilience of the metric. The feedback is 3 as it prompts the authors to consider this aspect, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests that the authors explicitly state the model used in the paper, suggesting that this information could be added to the appendix. While the comment provides some guidance on what the authors should include, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide examples and model details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the clarification of \"support data\" and \"predicted training count data\" in Figure 1 and the explicit mention of the model used in the paper. This level of detail provides clear guidance on what needs to be clarified or added, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific terms and data used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the clarity and specificity of the synthetic data used in the paper. It specifically asks for examples of what \"support data\" and \"predicted training count data\" might look like, as well as requests that the model used be explicitly stated in the appendix. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and transparency of the paper. By addressing these points, the authors can enhance the understandability and reproducibility of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. While the comment implies that the authors should expand the evaluation to include additional comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden the evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited use of FGT for evaluating the performance of the proposed method and comparative methods. This provides clear guidance on how to improve the evaluation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of FGT is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the paper\"s conclusions. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of FGT, noting that it is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for expanding the evaluation to include additional comparisons. By addressing this point, the authors can enhance the robustness and comprehensiveness of their evaluation, which is valuable for improving the draft. However, the comment could be more helpful if it provided specific examples or guidance on which comparative methods to include. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to enhance the model\"s complexity or complexity analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as the model description, results, or analysis. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the model seems overly simple, which is both a feature and a bug. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed analysis or examples to substantiate the assertion that the model is overly simple, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model\"s complexity. Without actionable feedback or detailed analysis, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the scope of the work or how to demonstrate its broader impact. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the narrow focus, but it lacks grounding as it does not identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and how it affects the paper\"s impact. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation of the work, specifically its narrow focus on a specific task (climate change QA) in a specific language (Arabic), which could limit its broader impact. While this observation is relevant, the comment lacks specific suggestions or guidance on how the authors might address this limitation or broaden the scope of their work. Without actionable advice or examples, the authors are left without a clear path forward to enhance the impact and relevance of their research. Therefore, the comment is rated as 2, as it identifies a potential issue but does not provide sufficient direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not contribute novelly to the understanding of the winnertakeall property, as it uses extremely simplified settings and reports findings that have been previously reported in other works. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or how to present the findings in a more novel or innovative way. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"winnertakeall property\" and \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not contribute novelly to the understanding of this behavior due to the use of extremely simplified settings and the repetition of findings from previous works. This provides clear guidance on what needs to be addressed to improve the originality of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. However, the comment lacks specific references to these previous works or detailed examples of how the findings have been reported. Without such references or evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the winnertakeall property has been widely used in previous works and that the paper does not contribute novelly to the understanding of this behavior with its extremely simplified settings. It points out that most of the findings have been reported in previous works, particularly in the context of NNbased clustering algorithms. While the comment highlights a potential weakness in the paper\"s originality, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice or detailed insights to fully support the authors in improving their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the action is explicit, it is somewhat vague as it does not specify which part of the main paper should include the mention of computational cost or how to present the runtime examples. However, the authors can infer that they need to add this information to the main paper and provide examples, making the comment 4.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and providing a rough example of runtimes in the experiments. However, it does not specify which part of the paper should include this information or where the computational cost is discussed in the appendix. The authors can infer that it relates to the main paper, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of computational cost information and providing an example, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests mentioning the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim about the computational cost. The recommendation for runtime examples is 3, as it provides a clear direction for improvement but could be strengthened with more detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends mentioning the negligible computational cost of CHR in the main paper, which is currently discussed in the appendix, to help motivate the method. Additionally, it suggests providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. This feedback is specific and offers concrete steps for the authors to enhance the clarity and accessibility of their work. By addressing these points, the authors can significantly improve the clarity and appeal of their paper, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors elucidate the EEG token quantization process in greater detail, specifically addressing the ambiguity in interpretation. It suggests that the authors should clarify whether the spatial arrangement of the EEG sensors played a role in this process. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity in the interpretation of the EEG topography plots and the need to clarify the role of the spatial arrangement of the EEG sensors in the EEG token quantization process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents ambiguity in interpretation due to the EEG topography plots for both the input and output during the EEG token quantization process. The reviewer suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role. While the comment identifies a potential issue with interpretation, it lacks specific examples or references to support the claim that the spatial arrangement of the sensors is relevant. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to improve the clarity and understanding of their results. By addressing this issue, the authors can enhance the comprehensibility and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes could be made to improve the directness of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" approach to addressing the problem, specifically mentioning the use of the Witness oracle and its complexity. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where this issue is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspect of the complexity issue is problematic or how it could be addressed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not address the problem directly by leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach, specifically the use of the Witness oracle and its complexity. It suggests that the authors may not be addressing the problem directly, as the oracle is described as \"polynomial time\" in the tabular case. While the comment identifies a potential weakness, it lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning the paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This provides a clear and direct action for the authors to take, as they are instructed to include this discussion in their paper. The comment is specific and provides concrete guidance on how to enhance the literature review section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph (lines 2230) and discusses the use of moment matching in distributional RL. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on moment matching and its relevance to distributional RL. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL. The reviewer supports this claim by referencing a specific paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This reference provides a clear and specific example of relevant literature that could be included in the paper. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be beneficial in the context of distributional RL. Despite this, the reference to the specific paper is sufficient to make the claim 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area where the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL. By referencing a specific paper by NguyenTang et al. AAAI'21, the reviewer provides a clear and actionable suggestion for the authors to include this discussion in their paper. This feedback is valuable as it encourages the authors to expand their literature review and enhance the depth of their analysis. By addressing this point, the authors can improve the comprehensiveness and relevance of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their work with existing code completion commercial applications, such as Copilot, as a baseline. It provides a specific suggestion for testing on a smaller subset of RepoEval and highlights the importance of comparing with stateoftheart code completion systems. This feedback is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. It specifies that this comparison should be tested on a smaller subset of RepoEval and is essential for comparing with stateoftheart code completion systems. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. This claim is 3 as it provides a logical reasoning for the suggestion, which is to test the performance of the proposed system against stateoftheart code completion systems. However, the comment lacks specific examples or references to these existing applications, making it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of baselines, specifically comparing the proposed work with existing code completion commercial applications like Copilot. This feedback is valuable as it highlights a potential gap in the evaluation and offers a specific direction for the authors to enhance their work. By including this comparison, the authors can demonstrate the effectiveness of their approach against existing stateoftheart systems, which is crucial for the credibility and impact of their research. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. While the comment implies that the authors should consider expanding their evaluation to include more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that understanding the criteria behind the selection and exploring other tasks or datasets might yield different insights. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the concern. This makes the claim 3, as it requires further elaboration to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. This feedback is 3 as it prompts the authors to consider the broader implications of their evaluation approach and how it might impact the generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional tasks or datasets might be relevant to include. Overall, the comment offers a valuable direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled (presumably tumour growth). While the comment identifies a potential issue with the clarity of the introduction, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to clarify the modelled curves, but the comment lacks specific suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the content is not immediately obvious and suggests that the modelled curves are likely related to tumour growth. This provides clear guidance on what needs to be clarified in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled. This is a subjective claim as it requires the reviewer to interpret the content and determine the lack of clarity. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact issue and address it. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue in the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. It points out that the mention of modelling curves is not immediately obvious and suggests that the modelled curves are likely related to tumour growth. While the comment highlights an area for improvement, it does not provide specific suggestions or guidance on how to clarify the content or improve the introduction. This limits the comment\"s helpfulness, as it offers insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of the model and baselines on test samples from the observational (in) distribution. It suggests that showing this performance would be useful. However, the comment does not provide explicit instructions or concrete steps for the authors to take. The action is implied, as the authors can infer that they should include performance results on test samples from the observational (in) distribution, but it is not stated explicitly. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind why shift=0 is better than shift~N (0, \u03c32) and suggests showing performance on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind why shift=0 is better than shift~N (0, \u03c32) in the context of \"shiftedMNIST.\" It suggests that both cases incorporate a domain shift, but does not provide any evidence or reasoning to support this claim. The comment also suggests showing the performance of the model and baselines on test samples from the observational (in) distribution, but does not provide any supporting evidence or references to justify this suggestion. Therefore, the claim is considered 2, as it lacks detailed justification or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment raises a question about the rationale behind why shift=0 is considered better than shift~N (0, \u03c32) in the context of \"shiftedMNIST.\" It suggests that both cases incorporate a domain shift, which is an important point for the authors to consider. The comment also recommends showing the performance of the model and baselines on test samples from the observational (in) distribution, which could provide valuable insights into the model\"s robustness. While the comment identifies a potential weakness and offers a constructive suggestion, it could be more helpful if it provided specific examples or detailed reasoning for why the current explanation is insufficient. Overall, the comment is 3 as it directs the authors to consider a specific aspect of their work and offers a potential improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of detail in the experimental description, suggesting that increased clarity would be beneficial. It explicitly states that the current description is insufficient and points to a specific section (\"Questions\") for further details. This provides a clear and direct action for the authors to take, which is to enhance the clarity of the experimental details. The comment also offers a reference point for additional information, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental details\" and the \"Questions\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the experimental details and the need for increased clarity to better judge the results. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental description lacks detail and clarity, which hinders the reader\"s ability to judge the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It references \"Questions\" for further details, but this does not fully substantiate the claim. The lack of specific examples or detailed reasoning makes the claim 3, as the authors would need to infer the specific issues and address them based on the reference to \"Questions.\" Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of detail in the experimental description, which hinders the reader\"s ability to fully understand and evaluate the results. It suggests that increased clarity in the experimental details would be beneficial, providing a clear direction for improvement. However, the comment does not offer specific suggestions or examples of what additional details could be included, nor does it provide guidance on how to improve the clarity of the existing description. While it highlights an important area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is 3, as it points out a critical issue but lacks actionable guidance for the authors to address it effectively."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more explanation to clarify the main contributions of the paper, specifically regarding the optimization strategies and their corresponding results. It suggests discussing different scenarios, such as minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is clear and concrete, as it specifies exactly what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more explanation regarding the optimization strategies and their corresponding results. The comment provides a clear direction for the authors to improve their draft by discussing different scenarios and their implications. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks clarity regarding the optimization strategies and their corresponding results, specifically mentioning the contribution of the CBR. The reviewer provides a specific example of what could be discussed, such as the consequences of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This suggestion is based on logical reasoning and a clear understanding of the paper\"s content, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the importance of these discussions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of clarity regarding the optimization strategies and their corresponding results. It suggests that the paper should provide more explanation to make these contributions clearer. The reviewer provides a concrete example by asking what would happen by minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is actionable and constructive, as it guides the authors on how to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional suggestions or examples of how to present this information effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is an explicit action, as it clearly instructs the authors to include a definition of treewidth. The comment also provides a specific suggestion for how to improve the paper by including a definition, making it concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the proofs, but this inference is not direct. The comment is specific in suggesting the inclusion of a definition, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their work. By including a definition, the authors can provide a foundation for understanding the concept and its importance, which could enhance the overall comprehensibility of their paper. However, the comment could be more helpful if it explained why a formal definition is necessary or how it would benefit the paper. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. This feedback provides a clear and explicit action for the authors to take, which is to analyze the quality of the local minima. The comment is specific in detailing what needs to be added, making it 5. The authors know exactly what additional analysis is required to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper only analyzed, under which cases will the Algorithm 1 converges to permutations as local minima,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of the local minima, including the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the analysis of the quality of the local minima. It suggests that the authors should analyze the approximation ratio of these local minima under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and improve the paper. By addressing this suggestion, the authors can strengthen their work and provide more comprehensive insights into the behavior of their algorithm. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper is not selfcontained and suggests that the supplementary material is necessary to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment identifies a specific issue with the selfcontainment and provides a clear action for the authors to take, it does not offer detailed guidance on how to improve the selfcontainment or what specific aspects of the supplementary material should be included. The action is explicit but somewhat vague, as the authors need to determine which parts of the supplementary material are most critical for selfcontainment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplementary\" material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the selfcontainment of the paper and the need for the authors to release the source code of their experiments for reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and suggests that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. The reviewer also requests the authors to release the source code of their experiments. While the comment identifies a potential issue with the selfcontainment of the paper, it lacks specific examples or detailed reasoning to support the claim. The suggestion to release the source code is logical but could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides a clear direction but lacks comprehensive evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the selfcontainment of the paper, noting that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. It also requests the authors to release the source code of their experiments to allow for reproduction of their results. This feedback is clear and actionable, as it provides specific guidance on how to improve the selfcontainment and reproducibility of the paper. However, the comment could be more helpful if it offered suggestions on how to improve the supplementary material or provided examples of what should be included. Overall, the comment is 4 as it directs the authors to address a critical aspect of their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, and references a specific sentence regarding the performance of the secret model with or without fusion. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms should be clarified or how the authors might address the issue of information redundancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and the specific sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it asks for clarification on how information redundancy is built into the algorithms and how it affects the performance of the secret model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how information redundancy is built into the Fill, Propagate, Decode algorithms. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms, specifically asking for clarification on how this redundancy is built into the algorithms. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithms need clarification. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It implies that the authors should consider ablating this feature to determine its impact on the model\"s performance. However, the comment does not provide explicit instructions or concrete suggestions on how to conduct this ablation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study to address the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not specify which part of the paper this feature is discussed in, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and suggesting an ablation study to determine whether one IN would suffice. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model\"s performance. However, the comment lacks any supporting evidence, reasoning, or references to justify why this feature is important or how it affects the model. Without such information, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model\"s performance. This feedback is 3 as it prompts the authors to consider an important aspect of their model that could affect its efficiency and effectiveness. However, the comment could be more helpful if it provided specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment offers a valuable direction for improvement but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is a surprise. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their experimental design. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the opponent does not aim to maximize the multiagent payoff proposed by the authors, which is a clear and specific critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is a surprise. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the experimental setup, specifically noting that the opponent does not aim to maximize the multiagent payoff proposed by the authors. This observation highlights a potential weakness in the experimental design, as it suggests that the opponent\"s behavior may not accurately reflect the proposed method. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their experimental design. Without specific advice or constructive feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. It implies that the authors should clarify the reasoning behind these choices, specifically mentioning the attention model paper that the algorithm iterates on. While the comment does not explicitly instruct the authors to provide this rationale, it clearly points out what needs to be added to improve the draft. The action is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"REINFORCE algorithm\" and \"PPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors provide a rationale for why certain choices were made, such as the use of REINFORCE versus PPO. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. The reviewer implies that this choice might be related to the attention model paper that the algorithm iterates on, but does not provide specific evidence or references to support this claim. While the suggestion is logical, it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It points out that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. By doing so, the authors can clarify their methodology and provide a more transparent explanation of their decisions. This feedback is clear and constructive, as it directly addresses a potential area of confusion and offers a straightforward way to enhance the clarity and comprehensibility of the paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, specifically regarding the potential disadvantage of MMD DRO compared to the variance regularized problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this confusion or clarify the statement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement in the theorem, which could indicate a disadvantage of MMD DRO compared to the variance regularized problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO compared to the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO compared to the variance regularized problem. This is a clear and actionable observation that could prompt the authors to reconsider the implications of their results. However, the comment lacks depth and does not provide specific suggestions on how to address this issue or clarify the statement. While it points out a potential problem, it could be more helpful if it offered guidance on how to resolve the confusion or improve the clarity of the theorem. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more information on how to use morphologic segmentation across domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on morphologic segmentation across domains. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"morphologic segmentation\" and \"domain\" aspects, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of morphologic segmentation across domains and how it should differ for different domains. The comment also raises important questions about the assumption of morphologic segmentation invariance across domains, which adds depth to the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information on how to use morphologic segmentation across domains and how it should differ for different domains. It questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. The comment suggests that these questions are important and implies that the paper assumes morphologic segmentation to be invariant, which is not fully justified. However, the comment does not provide specific examples or references to support the claim that the paper lacks insight into these aspects. The reasoning is 3, as it highlights a potential gap in the paper but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the use of morphologic segmentation across domains and how it should differ for different domains. It questions the assumption of morphologic segmentation invariance across domains, given the task of domain adaptation. This feedback is valuable as it highlights an important area for improvement in the paper, particularly regarding the applicability of the method across different domains. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or how to conduct morphologic segmentation differently for different domains. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique used in LUMP. This is a clear and direct action, as it specifies exactly what needs to be done to improve the draft. The authors know exactly what additional experiments are needed and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results demonstrating the pure contribution of the proposed method without the mixup technique used in LUMP. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mixup technique used in LUMP should be excluded from the proposed method to demonstrate its pure contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the mixup technique used in LUMP is also adopted for the proposed method in the experiments on SplitCIFAR100 and SplitTinyImageNet. It suggests that the authors should include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by including additional experiments that would better illustrate the method\"s pure contribution. However, the comment could be more helpful if it explained why the mixup technique is important or how it might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention being performed on the image or on some convolutional feature map. It suggests clarifying this point and potentially rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the object detectionbased attention, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on whether the attention is performed on the image or on some convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the object detectionbased attention and its implementation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention, specifically asking whether it is performed on the image or on some convolutional feature map. It also suggests that rescaling might be necessary based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how to clarify or address this issue. The feedback is 3 as it points out a potential area for clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a discussion about Set Transformer and other related works that use summary tokens. This provides a clear and direct action for the authors to take, which is to include a discussion on these topics. The comment is specific in identifying the missing content and provides a concrete action for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and \"other related works that also use summary tokens,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the use of summary tokens and related works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there is a missing discussion about Set Transformer and other related works that use summary tokens. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a discussion about Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to expand their literature review to include relevant works that could enhance their understanding and analysis. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the paper. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide explicit guidance on how to address this issue or what specific analysis should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical support but are not given specific steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure where this analysis is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. This feedback is valuable as it prompts the authors to consider a potential gap in their analysis and provides a direction for further exploration. However, the comment lacks specific guidance or suggestions on how to address this issue or what kind of theoretical analysis should be conducted. While it points out an important area for improvement, it could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the lack of details regarding how the network fits the residual instead of learning the inputoutput mapping directly. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information about the network\"s training process, but it lacks concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of detail regarding how the network fits the residual instead of learning the inputoutput mapping directly. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking details regarding the network\"s training process, but without clear grounding, the authors cannot confidently determine which section or part of the paper needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of details regarding how the network fits the residual instead of learning the inputoutput mapping directly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this is a significant issue or a problem that needs to be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of details on how the network fits the residual instead of learning the inputoutput mapping directly. This is a relevant point that could impact the understanding and interpretation of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details might be needed. While it highlights a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the experiment setup in Section 3.3, specifically asking about data augmentation methods, learning rate, and other aspects. While the comment implies that the authors should provide more details about these aspects, it does not explicitly instruct them to do so or offer specific guidance on how to present this information. The reference to an external paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" suggests that the authors should consider similar methods, but it does not provide detailed instructions on how to implement them. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for details on the experiment setup, such as data augmentation methods, learning rate, and other aspects. The reference to an external paper, \"1 BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" provides a clear context for the question, further specifying what the authors should address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically mentioning data augmentation methods, learning rate, and other aspects. It also references an external paper, \"1 BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" which suggests that the authors should consider similar methods. However, the comment does not provide any reasoning, evidence, or examples to support why these aspects are relevant or how they could be applied. As a result, the claim is 1, as it lacks sufficient justification or explanation. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods, learning rate, and other aspects. While it identifies a potential area for improvement, it does not provide any suggestions or guidance on how the authors might address these questions or improve their experimental setup. The reference to an external paper, \"1 BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" suggests that the authors should consider similar methods, but this alone is not enough to guide the authors in making improvements. Overall, the comment is 3 as it points out a potential area for improvement but lacks actionable advice or detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider an error in the initial calibration steps (steps 1 and 2) as a possible explanation for the speed disparities observed between the RSPs and FDs. However, it does not provide explicit instructions or concrete guidance on how to investigate or address this potential error. The authors are left to infer that they should look into the initial calibration steps, but without specific suggestions on how to do so or what specific aspects to focus on, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d\u2014RVC paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the claim, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the initial calibration steps, suggesting that an error might explain the speed disparities observed between the RSPs and FDs. While it highlights an area for further investigation, it lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the initial calibration steps should be examined. The comment is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of artificial networks trained using ASAP (and similar methods) not necessarily resembling biological networks, except for the weight transport problem. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the resemblance of artificial and biological networks, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any actionable feedback or suggestions for improvement. The comment does not guide the authors on how to address this issue or improve the resemblance between artificial and biological networks. Without specific guidance or constructive feedback, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors conducted statistical significance tests for the numbers presented in the comparison between the proposed method and baselines. While it implies that the authors should consider conducting such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in its request for statistical significance tests, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. However, it does not provide any evidence, reasoning, or examples to support the claim that statistical significance tests should be conducted. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. It prompts the authors to consider whether they conducted statistical significance tests, which is an important aspect of evaluating the effectiveness of their method. This feedback is 3 as it identifies a potential area for improvement and encourages the authors to consider conducting statistical significance tests. However, the comment could be more helpful if it provided specific guidance on how to conduct these tests or what statistical tests might be appropriate. Overall, the comment is 3 as it points out a potential gap in the analysis but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the paper\"s focus on learning HMMs with nonparametric emission distributions but questions how these distributions affect inference. It specifically asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the inference tasks should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the impact of emission distributions on inference tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on learning HMMs with nonparametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how these emission distributions affect inference and asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It asks which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that these tasks are affected by the emission distributions. This makes the claim 3, as the authors would need to make a logical deduction to understand the implications of the emission distributions on inference tasks. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically questions which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This feedback is valuable as it prompts the authors to clarify and expand on the implications of their model for inference tasks. However, the comment could be more helpful if it provided specific suggestions on how to address this gap or examples of how the emission distributions affect inference tasks. Overall, the comment is 4 as it directs the authors to a critical area needing further exploration and explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results, including identifying the reasons behind the poor performance. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, leaving some ambiguity about the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for a more detailed analysis themselves, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the results. By pointing out the lack of analysis, the comment empowers the authors to enhance their draft by including a more detailed explanation of the underlying reasons for the observed performance. However, the comment could be more helpful if it suggested specific areas to explore or provided examples of how to conduct a more thorough analysis. Overall, the comment is 4 as it directs the authors to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. While the comment implies that the authors should expand their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper, \"Section 2,\" allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the limited consideration of only 10 out of 120 datasets and suggesting that the authors should compare batch and greedy algorithms in the remaining 110 datasets. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This feedback is 3 as it identifies a potential area for improvement in the paper\"s analysis. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on. While it points out a potential gap in the analysis, it does not provide detailed instructions or examples on how to address it. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. It also implies that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of the lowrank factorization in the context of the main result. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"lowrank factorization\" in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary nature of the lowrank factorization and the potential implications for lowrank matrix factorization. This provides clear guidance on what the authors should consider and discuss in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. The reviewer suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the need for discussing lowrank matrix factorization based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation in the introduction, specifically the lowrank factorization, which may not be necessary given the main result about polytopes. It suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. This feedback is 3 as it points out a potential area for improvement in the paper\"s motivation and alignment with the main results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the lowrank factorization should be discussed in the context of the main result. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. While the comment implies that the authors should clarify these labels, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the labels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the labels for each dataset, including \"caspealr1\" and \"mugshot.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the labels for each dataset in 4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. This is a relevant inquiry that could help the authors clarify their methodology and provide more transparency about their dataset selection process. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address this issue. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference 31 and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of incrementalism or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes or enhancements are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental with respect to a specific reference 31 and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not specify which part of the paper this assessment is based on, such as the methodology or results sections. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. The comment is specific in detailing the issue of incrementalism and the adaptation of an existing architecture, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to a specific reference 31 and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any specific details or references to support this claim, such as how the paper is incremental or how the adaptation affects the results. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference 31 and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. While the comment identifies a potential issue with the paper\"s incremental nature, it lacks specificity and actionable feedback. It does not provide guidance on how the authors might address this issue or improve their work to differentiate themselves from the reference. Without detailed suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to the \u03bb parameters, and questions how \u03bb is calculated. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but does not fully understand the implications. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to improve the explanation or calculations. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the process of calculating \u03bb and improve the explanation of the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines on pages 8 and 9, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters, questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific examples or detailed reasoning to support the claim that performance and sample efficiency are sensitive to \u03bb parameters. The references are provided as a means of context, but they do not fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the sensitivity of performance and sample efficiency to \u03bb parameters, which is a critical aspect of the paper. It raises questions about how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment, which are important areas for clarification. The reviewer also provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the explanation. While it points out areas for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. However, it does not provide any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete details on what the authors should do to clarify or expand on this aspect of their work. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve the minmin problem, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding this method, making it underspecific. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking for clarification about the specific method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve the explanation. The comment lacks depth and actionable feedback, leaving the authors with only a vague idea of what needs to be clarified. Therefore, the comment is 2, as it points out a potential weakness but does not offer concrete steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in other environments. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these concerns or improve the draft. The authors are left without any clear direction on how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure2\" and \"MsPacman,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of lower bound double qlearning, particularly in the context of convergence and overestimation of true maximum values. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, based on observations from Figure 2 and specific environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. The reviewer provides some evidence by mentioning the slight performance decrease in MsPacman and the convergence of algorithms in other environments. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some support, the lack of detailed evidence or references makes the claim 3, as the authors would need to further explore the data or literature to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of lower bound double qlearning, specifically questioning its performance in certain environments and its tendency to overestimate true maximum values. It provides specific examples from Figure 2 and other environments, which helps the authors understand the basis of the critique. However, the comment could be more helpful if it offered suggestions on how to address these concerns or improve the algorithm. While it highlights a relevant area for improvement, it lacks actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or suggest alternative approaches to explore. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the novelty is lacking or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. This feedback highlights a potential weakness in the paper\"s contribution, which could impact its impact and originality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should clarify this aspect of the results, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and suggests that it should approach vanilla methods from above but from below. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. This feedback identifies a potential discrepancy in the results that the authors may need to address. However, the comment lacks specific guidance or suggestions on how to clarify this issue or what aspects of the results are unclear. While it points out a potential problem, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the paper, noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not doing so in the author response, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback provides a clear and explicit action for the authors to take, which is to include comparisons with these systems. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors have explained their reasons for not comparing their results with some earlier research work from 2020. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the comparison with earlier systems with worse performances, such as Taghipour and Ng (2016). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer suggests that the authors should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). While the comment provides a logical reasoning for why the comparison is necessary, it lacks specific examples or references to the earlier works that could be used for comparison. This makes the claim 3, as the authors would need to infer the specific systems to compare and might not be familiar with them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that it does not compare its results with some earlier research work from 2020. While the authors have explained their reasons for not doing so, the comment suggests that the paper should include comparisons with earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by including comparisons that could strengthen their claims. However, the comment could be more helpful if it offered additional guidance on how to select and present these comparisons. Overall, the comment is 4 as it points out a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of significance testing method used in the paper, suggesting that a paired test setting like the Wilcoxon signedranked test might be more appropriate. While the comment implies that the authors should consider using a different test, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of significance testing method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of significance testing method used in the paper, specifically questioning the appropriateness of the current method. However, it does not specify which part of the paper discusses this choice, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in suggesting an alternative test, the Wilcoxon signedranked test, but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of why the current test might be inappropriate or how the suggested test would be more suitable. As a result, the claim is not 5, as it relies on a vague suggestion without sufficient justification or evidence. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. While it identifies a potential issue with the current choice, it does not provide specific guidance or examples of alternative tests that could be considered. The comment lacks depth and does not offer actionable steps for the authors to address the concern, making it 3 but incomplete. The authors are given a direction to consider, but the feedback could be more comprehensive to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not provide specific guidance on how to expand the experiments or what additional aspects to consider. While it highlights an area for improvement, it lacks concrete steps or suggestions on how to achieve this expansion. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in identifying the need for more comprehensive and general experiments, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It highlights the limitation of the model size and the restrictive baselines, which constrain the scope of the experiments. However, the comment does not provide specific examples or references to support the claim that the experiments are limited or uncomprehensive. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which constrains the comprehensiveness and generality of the experiments. This feedback is valuable as it highlights an area where the authors could expand their work to provide a more comprehensive analysis. However, the comment does not offer specific suggestions or guidance on how to address this limitation, such as suggesting alternative models or methodologies to explore. While it provides a clear direction for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. It provides a clear and specific action for the authors to take, which is to elaborate on the topic. The comment is explicit and provides concrete guidance on what needs to be added to the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the Hoeffding\"s bound and its implications for stochastic algorithms. This provides clear guidance on what the authors need to address in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Hoeffding\"s bound holds true for any w as long as samples are drawn independently, and that stochastic algorithms impose conditioning on the previous iterate to guarantee the inequality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (Line 124125) and suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. This feedback is clear and actionable, as it directs the authors to provide additional explanation or context that could enhance the understanding of the paper\"s content. By addressing this suggestion, the authors can improve the clarity and depth of their discussion, making the comment 4. However, it could be more helpful if it provided specific examples or references to support the claim about the Hoeffding\"s bound. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. While the comment implies that the authors should consider adding this information, it does not provide explicit instructions on how to implement this suggestion or what specific details should be included. The action is clear but lacks concrete guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this addition would be relevant. The authors can infer that it relates to the table or data presentation, but this inference is not direct. The comment is specific in suggesting the addition of a particular approach, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. This is a specific and actionable suggestion that could enhance the paper by providing additional context and comparison to existing methods. However, the comment lacks depth and does not explain why this addition would be beneficial or how it would impact the paper\"s overall contribution. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This feedback provides a clear and direct action for the authors to take, which is to include an ablation study to address this issue. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of an ablation study, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of an ablation study to explain why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This provides clear guidance on what the authors need to add to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this ablation study is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting the inclusion of an ablation study to explain why the prompt was chosen in a particular way, such as using fewshot examples for CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by addressing a gap in the experimental design. However, the comment could be more helpful if it included examples or detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to be careful with the terms \"causal mechanisms\" and \"temporal relationship,\" as they are not interchangeable. This feedback is clear and provides a specific action for the authors to take, ensuring that they use the terms correctly. The comment is concrete, as it specifies the exact issue and offers a direct way to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms like \"causal mechanisms\" and \"temporal relationship,\" providing guidance on how to avoid confusion and ensure clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the use of terms \"causal mechanisms\" and \"temporal relationship,\" suggesting that they are not interchangeable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it points out a specific issue with the use of terms like \"causal mechanisms\" and \"temporal relationship\" in the paper. It provides a clear and actionable suggestion to avoid confusion by using these terms carefully. However, the comment could be more helpful if it offered additional guidance on how to effectively use these terms or provided examples of how they might be misused. Overall, the feedback is valuable but could be more comprehensive to fully support the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what alternative demonstrations could be used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific statement from the paper, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what aspect of the demonstration is questionable or how it could be improved. It suggests that \"better than random\" may not be a strong demonstration of capability, but without further explanation or examples, the authors are left without clear guidance on how to address this concern. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why \"better than random\" might not be a strong demonstration. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any specific reasoning or examples to support this claim or offer alternative demonstrations that could be used. The comment lacks depth and actionable guidance, leaving the authors without clear direction on how to address the concern or improve their demonstration. As a result, the feedback is not helpful, as it does not provide the authors with meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a desire for a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they should include a discussion on this topic. Without concrete instructions or examples, the authors may find it challenging to know exactly how to incorporate this discussion into their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation should be included. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for a discussion on the relationship between the results and the lower bounds, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation should be included. However, it does not provide any supporting evidence, references, or detailed reasoning to justify why this discussion is necessary or how it would enhance the paper. Without specific examples or logical reasoning, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels,\" would be beneficial. This feedback is 3 as it identifies a potential area for further exploration and discussion, which could enhance the paper\"s contribution. However, the comment lacks specific guidance or suggestions on how to incorporate this discussion into the paper, such as which sections or aspects should be addressed. While it points out a relevant topic, the lack of detailed instructions limits its utility for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to clarify the assumptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and the significance of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. The reviewer provides a reference to a related work by Dombrowski et al. (2022) to support their claim about the use of PCA. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the use of PCA is not novel or significant. While the reference provides some context, the comment could be strengthened by offering more detailed analysis or examples to support the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. It references a related work by Dombrowski et al. (2022) to support its claim. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their assumptions. The reference to the external work is helpful, but the comment could be more beneficial if it provided more detailed feedback or suggestions for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It asks a question about how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the fewshot RC models considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of these models compared to relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, referencing external sources. However, it does not provide specific details or comparisons to support this claim, such as which models are considered stateoftheart or how the performance of the models in question compares to those mentioned. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the claim and potentially conduct their own analysis to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the fewshot RC models considered are not stateoftheart models. It raises a relevant question about how the performance of these models compares to relation extraction/generation models in fewshot settings. This feedback is 3 as it prompts the authors to consider the relevance and impact of their model selection, which could influence the paper\"s contribution and significance. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or improve their model selection. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. However, it does not provide any guidance on how the authors should address this limitation or suggest ways to expand the results to include other network architectures. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results only apply to shallow fullyconnected ReLU networks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand their results to include other network architectures. While it points out an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the background knowledge and literature description. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it weakly grounded. The comment is specific in suggesting that the background knowledge and literature description should be brought forward, but without explicit references to sections or parts of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the paper. Without concrete evidence or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s organization, suggesting that it could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and does not provide detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specific steps to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it identifies a potential gap in the comparison, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific models, \"PanopticFPN\" and \"Mask2Former,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these models in the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these models should be included in the comparison. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is valuable as it highlights an area where the paper could be expanded to include more comprehensive comparisons. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these models or what aspects of their performance should be compared. While it points out a potential weakness, it does not offer actionable guidance for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide results or observations regarding the use of sequential MCB versus a single MCT layer for the decision head. This is a clear and direct request, as it specifies exactly what the authors need to include in their discussion. The action is concrete, as it specifies the exact information that should be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB versus a single MCT layer for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation or results regarding the observed differences between the two approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the discussion of using sequential MCB versus a single MCT layer for the decision head, noting that no results were shown. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is important or how it could be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of interest in the paper, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It points out that while the discussion is interesting, no results or observations are presented, prompting the authors to provide more details. This feedback is 3 as it highlights a gap in the paper that could be addressed with additional information or analysis. However, it lacks specific suggestions on what kind of results or observations would be beneficial, leaving the authors with a general direction but not detailed guidance on how to proceed. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment provides specific language issues to address, such as \"we typically considers\" and \"two permutation\" in various sections. It also encourages the authors to proofread the entire paper for language problems. While the comment identifies specific areas that need attention, it does not provide detailed guidance on how to correct these issues or improve the language. The actions are explicit but somewhat vague, as the authors know what needs to be fixed but may not be entirely sure of the exact process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"the above of (7),\" \"the above of Theorem 1,\" and \"the above of (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the language issues, such as \"we typically considers\" and \"two permutation,\" providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of comments on language usage, such as \"we typically considers\" and \"two permutation,\" without any subjective claims or opinions. It does not present any arguments or evidence to support the need for changes or improvements in the language. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" which are minor but still important to correct. It also encourages the authors to proofread the entire paper for language problems. While the comment provides actionable feedback, it could be more helpful if it offered suggestions on how to improve the language or provided examples of better phrasing. Overall, the comment is 3 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address these questions. The authors are left to infer that they need to consider these aspects, but the comment lacks specific guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of 20 distribution sets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the number of distribution sets for each class can be controlled and what the implications would be if only a few distribution sets are selected. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or how it could be improved. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of 20 distribution sets and questions whether the authors can control the number of distribution sets for each class. It also inquires about the implications of selecting only a few distribution sets. This feedback is 3 as it prompts the authors to consider the potential limitations and consequences of their choice. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending alternative approaches or providing examples of how other studies have handled similar concerns. While it points out a relevant area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models. However, the comment does not provide explicit guidance on how the authors should address this limitation or expand the scope of their framework. The action is implicit and somewhat vague, as the authors can infer that they need to consider broader applicability but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the scope of the evaluative framework, specifically noting that it is limited to three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the limitations and potential applicability concerns, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, restricted to only three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models. However, the comment lacks specific examples or references to substantiate these claims, making it 3. The authors would need to infer the potential applicability issues and address them themselves, rather than having clear guidance on how to improve their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models. This feedback is 3 as it points out a potential limitation in the framework\"s applicability, which the authors should consider when expanding its scope. However, the comment could be more helpful if it provided specific suggestions on how to address this limitation or examples of other tasks or models that could be considered. Overall, the comment offers some insight but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also highlights the issue with using obsolete language models, which adds context and guidance for the authors. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the specific language models used, such as ngram HMM and RNN, which are considered obsolete. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are carried out on obsolete language models, specifically ngram HMM and RNN, which are not commonly used nowadays. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to align the paper with current NLP trends. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to current NLP trends or the relevance of transformerbased models. The authors would need to make an effort to understand and address the suggestion, which justifies a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are carried out on obsolete language models (ngram HMM, RNN) that are no longer commonly used in NLP. It suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the relevance and impact of the paper. However, it could be more helpful if it included specific examples or references to current NLP trends or the benefits of using transformerbased models. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments or citing relevant literature. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplified selfattention model\" and \"theoretical analysis,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The mention of Kaplan et al. 2020 provides additional context and guidance for the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The reviewer references Kaplan et al. 2020 as a potential source of validation. However, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient or how additional experiments would address the issue. The reference to Kaplan et al. 2020 provides some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental setup, noting that the experiments are insufficient to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that more empirical experiments or toy experiments are needed to address this gap. Additionally, it references the result in Kaplan et al. 2020 as a potential source of validation. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their experimental setup and substantiate their theoretical analysis. However, the comment could be more helpful if it offered suggestions on how to design these additional experiments or what specific aspects of the theoretical analysis need validation. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, making it unclear how it can be estimated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify this issue or what specific steps they should take to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion on the misestimation of mu, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the issue with the estimation of mu, as it is the proportion of missing observations, and how this affects the clarity of the discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the discussion is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated at all. This feedback highlights a gap in the clarity of the discussion, which could be confusing for readers. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this issue or improve the discussion. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests presenting the performance as a function of the distance of initialization, M^0, to the groundtruth, M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This feedback is explicit and provides concrete guidance on how to implement the suggestion. The authors know exactly what steps to take to address the issue of sensitivity to initialization. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sensitivity to initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for presenting the performance as a function of the distance of initialization, M^0, to the groundtruth, M^*. The comment specifies the approach to take, which is to randomly sample a matrix M^0 within a certain distance range and report the performance accordingly. This level of detail provides the authors with a clear direction for addressing the issue of sensitivity to initialization. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization, M^0, to the groundtruth, M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This claim is 4 as it logically follows the suggestion to present the performance in this way, and it provides a clear rationale for why this approach could be beneficial. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for addressing the issue of sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization, M^0, to the groundtruth, M^*, by randomly sampling a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and reporting the performance accordingly. This feedback is clear and provides a concrete method for evaluating the performance of the model under different initialization conditions. By following this suggestion, the authors can gain a deeper understanding of how their model behaves under different initialization scenarios, which could lead to improved robustness and generalization. Therefore, the comment is 5, as it offers a clear and actionable path for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary use of the absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This is a factual observation about the mathematical definition of the Frobenius norm, which does not require an opinion or subjective judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the Frobenius norm in line 77, noting that the absolute value operation is unnecessary because tensor entries are real numbers. This is a clear and actionable point that can help the authors improve the clarity and accuracy of their draft. By pointing out this oversight, the comment provides the authors with a concrete step to take in revising their manuscript. However, the comment could be more helpful if it offered suggestions on how to better explain or justify the use of the absolute value operation in the context of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the use of ensemble methods and robustness measures, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to ensemble methods or robustness measures that have been successfully used in similar contexts. This makes the claim 3, as the authors would need to infer the specifics of how to implement these suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends adding highprobability bounds by using ensemble methods, as performed in the experiments, and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is specific and offers a concrete direction for enhancing the paper\"s rigor and comprehensiveness. By addressing these points, the authors can significantly improve the quality and credibility of their work. However, the comment could be more helpful if it provided examples of how these suggestions have been implemented successfully in other works or detailed guidance on how to implement them in the current context. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation for the work is good but that the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so or provide specific guidance on how to implement these evaluations. The action is implicit and somewhat vague, as the authors need to infer the need for these additional evaluations and determine how to incorporate them into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation for the work is good but the results are less impressive, and it recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specific areas for improvement, it lacks full grounding as it does not explicitly mention where these aspects should be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation for the work is good but the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, the comment lacks specific examples or detailed reasoning to support why the results are less impressive or how these additional aspects should be evaluated. Without specific examples or references, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, suggesting that they are less impressive despite a good motivation. It recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these additional evaluations or what specific metrics should be considered. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed instructions on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might incorporate diversity into their model or what specific steps they could take to ensure that their model enforces diversity. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s motivation for diversity, specifically mentioning that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the model\"s lack of diversity enforcement, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity in the model. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. This is a critical point as it undermines the paper\"s claims about promoting diversity. However, the comment lacks specificity and actionable suggestions on how the authors might address this issue or improve their model to enforce diversity. Without detailed guidance or examples, the authors may struggle to understand the exact areas needing improvement or how to implement changes. Therefore, the comment is 3, as it points out a critical weakness but does not provide enough direction for the authors to effectively address it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on how the authors should address this issue or what specific experiments should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence affects the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is 3 as it highlights a potential gap in the experimental setup, which the authors should address to provide a more comprehensive evaluation of their work. However, the comment lacks depth and does not offer suggestions on how to incorporate these experiments or what specific aspects of the paper would benefit from their inclusion. While it points out a potential area for improvement, it does not fully guide the authors on how to address it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion to use DinoV2 Frechet Distances is specific and provides a concrete detail for the authors to implement, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplistic Inception network\" and \"FIDs,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of DinoV2 Frechet Distances for comparisons in addition to the widely used FID metric. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are \"clear flaws associated with FIDs and the simplistic Inception network,\" but it does not provide specific examples or references to support this claim. The suggestion to use DinoV2 Frechet Distances is made without further explanation or justification, leaving the authors without a clear understanding of why this alternative metric is preferred or how it addresses the flaws mentioned. The lack of detailed reasoning or evidence makes the claim 1, as it does not provide sufficient support for the authors to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of FIDs and the simplistic Inception network, noting that there are clear flaws associated with these methods. It provides a clear and actionable suggestion by recommending the use of DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is valuable as it directs the authors to consider an alternative method that could potentially improve the robustness and accuracy of their evaluations. However, the comment could be more helpful if it explained why DinoV2 Frechet Distances are preferred over FIDs or provided examples of their use in similar contexts. Overall, the comment is 4 as it offers a concrete suggestion for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the novelty of the paper and asks for clarification on how it differs from a specific reference. While it implies that the authors should provide a comparison with the reference, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed comparison to justify the novelty of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not specify which part of the paper should be addressed or where the comparison with the reference is made. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the comparison is made, the comment lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the novelty is incremental. Without such information, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. While it identifies a potential issue with the paper\"s novelty, it does not provide specific guidance or suggestions on how the authors might address this concern. The comment lacks depth and does not offer actionable feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them without a clear path forward. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"CUB and SOP datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the reported ablation studies, where the complete loss function performed worse than those with missing terms. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. This observation raises a valid concern about the validity of the results and prompts the authors to question why this might be the case. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions that this would allow for inspection of the longrange inference capacity of the model. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. The action is explicit and concrete, as it clearly specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions the need to inspect the longrange inference capacity of the model. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for the experiment. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the longrange inference capacity of the model. The reviewer provides a logical reasoning for why this experiment would be beneficial, noting that it would help address issues like keypoint detection failure in some mice or frames. However, the comment lacks specific examples or references to similar experiments in the literature, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for an experiment that would enhance the paper\"s contribution. It proposes an experiment where the image is occluded to simulate irregularity in neural/behavioral data, which would allow for inspection of the longrange inference capacity of the model. This suggestion is specific and offers a concrete way to improve the paper by adding a new dimension to the evaluation. The reviewer also indicates that these experiments should be included in the final version unless the authors can provide a convincing reason not to. This feedback is 5 as it guides the authors on how to enhance their experimental design and substantiate their claims. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer recommends using a second yaxis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not specify which alternative visualization should be used or how to implement the change. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests using a second yaxis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why Figure 6C is awkward or why the current visualization is inaccurate. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the accuracy and clarity of their visual representation. However, the comment could be more helpful if it included additional context or examples of alternative visualizations that could be used. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their method. While the comment implies that the authors should conduct these tests, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental setup, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting a potential area for further exploration, but without clear grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be useful in other embedding models besides CP, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to other models where this approach might be beneficial, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors test inverse triples in other embedding models besides CP. This is a relevant point as it could provide additional insights into the effectiveness of their method. However, the comment lacks depth and does not offer specific guidance on how to implement this suggestion or what other models to consider. While it highlights a potential area for exploration, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential area for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. It also implies that technical details are not necessary for the abstract. While the comment provides a clear action\u2014to clarify the statement and simplify the abstract\u2014it does not offer specific guidance on how to achieve this clarity or what aspects of the statement are unclear. The authors are left to infer the necessary changes, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement regarding the lowrank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technical details are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. The reviewer provides a specific example of the unclear statement, \"with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions,\" and argues that technical details are not necessary for the abstract. However, the comment lacks specific reasoning or examples to support why these technicalities are not necessary or how they might hinder the reader\"s understanding. This makes the claim 3, as the authors would need to infer the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and suggests that it should be revised to be more highlevel. It also points out that technical details are not necessary for the abstract. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accessibility of the abstract. However, the comment could be more helpful if it offered additional guidance on how to simplify the statement or what aspects of the technical details are not necessary. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left to infer that they need to make changes to the algorithm, but without concrete instructions or examples, they may struggle to determine the exact steps to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper discusses Algorithm 2 or where it is located. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of Algorithm 2 need improvement or how to achieve this improvement. Without clear guidance or examples, the authors may struggle to understand and address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that there is room to improve the complexity of Algorithm 2, which is a valuable observation. However, it lacks specificity and does not provide any guidance on how to achieve this improvement or what aspects of Algorithm 2 need attention. Without actionable advice or examples, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, as it identifies an area for improvement but does not offer sufficient guidance for the authors to act upon it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as relevant. However, the comment does not provide explicit guidance on which modalities to include or how to present these results. While it suggests a direction for improvement, the lack of concrete steps or detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, specifically mentioning languagerelated tasks. It also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. However, the comment does not specify which part of the paper should include these results or how they should be presented. While the authors might have an idea of where to integrate these suggestions, the lack of explicit guidance makes it weakly grounded. The comment is specific in suggesting the inclusion of results in other modalities and the potential relevance of OOD performance, but it lacks detailed guidance on implementation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. The comment also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. However, the comment lacks specific examples or references to support the claim that OOD performance is more important for languagerelated tasks. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It also points out that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of results in other modalities. However, the comment lacks specific guidance on how to implement this suggestion or what specific modalities should be considered. While it provides a direction for improvement, the lack of detailed instructions or examples limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. It highlights the importance of considering how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment implies that the authors should provide more detailed justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot situation for graph link prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not consider how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. The reviewer suggests that the paper defines and creates a fewshot situation but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the method does not effectively use \"fewshot.\" This makes the claim 3, as the authors would need to further develop the reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the motivation of the work, specifically in the context of fewshot learning. It points out that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. This feedback is valuable as it highlights a gap in the paper that the authors need to address to strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to effectively use \"fewshot\" or how to ensure generalizability. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not provide explicit guidance on how the authors should address this critique or improve their approach. It lacks actionable details, such as recommending specific ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not specify which part of the paper discusses the use of GP, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where GP is discussed, the comment lacks full grounding. It is specific in pointing out the issue of novelty, but without detailed guidance on how to address it, the authors may struggle to make the necessary changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of Gaussian Processes (GP) is straightforward and naive, suggesting that the approach is not novel. The reviewer supports this claim by referencing the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. This reference provides a basis for the claim, but it does not offer detailed reasoning or examples to fully substantiate the critique. The authors might need to explore the literature themselves to understand the specific aspects of the critique. Therefore, the comment is 3, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. While the comment identifies a potential weakness in the paper\"s novelty, it lacks specific guidance on how the authors might address this critique or improve their approach. It does not provide actionable suggestions or examples of how to enhance the novelty or innovation of the GP approach. As a result, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the statement in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. It points out that this claim is not supported by the authors\" experience, as evidenced by the training of 1500dimensional LSTMs on PTB. The reviewer also asks about the application of dropout to both embeddings and hidden states. While the comment identifies a specific issue with the statement, it does not provide explicit guidance on how to address it or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and provide evidence or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that smaller architectures are necessary for LM compared to GAN models, suggesting that the baseline models are not properly regularized. The reviewer also asks about the application of dropout to both embeddings and hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer challenges this claim by citing their own experience, specifically mentioning the training of 1500dimensional LSTMs on PTB. This provides a logical counterpoint to the claim, suggesting that the baseline models are not properly regularized. However, the comment lacks specific references or detailed evidence to fully substantiate the reviewer\"s argument. While it provides a reasonable basis for questioning the claim, it could be strengthened with additional examples or references to support the counterargument. Therefore, the comment is 3, as it provides a logical basis for questioning the claim but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a specific claim in the supplemental section D.4 that is questionable, suggesting that the statement about smaller architectures being necessary for LM compared to GAN models is not supported by the authors\" experience. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, which challenges the claim that baseline models are not properly regularized. Additionally, the comment asks about the application of dropout to both embeddings and hidden states, which could be a relevant consideration for the authors to address. While the comment highlights a potential issue with the claim, it does not provide detailed guidance or suggestions on how the authors might address it. This limits its helpfulness, as it points out a problem but does not fully support the authors in resolving it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to locate. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of the writing, but without concrete steps on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"previous sections\" and \"the following contents,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that some ablations are difficult to locate in the following contents, suggesting that the writing could be improved in this part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues or how to address them. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. It suggests that the writing could be improved in this part. While the comment highlights a potential problem, it lacks specific guidance or suggestions on how to improve the clarity of the writing or where the ablations should be better integrated. This limits the comment\"s helpfulness, as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty of the online algorithm and robustness, which should be integrated into the main paper. However, the comment does not provide specific guidance on how to improve the differential privacy application or what aspects need more clarity. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to address the issues. As a result, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also mentions the online algorithm and robustness as being interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application, making it weakly grounded. The comment is specific in its critique of the differential privacy application and the suggestion to integrate the online algorithm and robustness into the main paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. However, the comment does not provide specific reasoning or examples to support this claim. It mentions the online algorithm and robustness as being interesting and novel, but this does not address the issue of the differential privacy application being \"halfbaked.\" The lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to understand and address the issue without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the differential privacy application, suggesting that it is currently \"halfbaked.\" It encourages the authors to think through it more clearly and integrate the online algorithm and robustness into the main paper. This feedback is 3 as it points out a specific area for improvement, but it lacks detailed guidance or suggestions on how to address the issue. The authors are given a general direction but may need to infer more specific steps to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their work. There is no explicit or implicit action for the authors to take, such as suggesting ways to enhance the contribution or providing examples of how to differentiate the two approaches. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, but it does not specify which part of the paper this comparison is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered incremental or how the authors might address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this comparison and how it affects the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, suggesting that the former is incremental. However, it does not provide any context or explanation for this comparison, nor does it offer suggestions or guidance on how the authors might address this issue or improve their work. Without additional information or actionable feedback, the comment lacks depth and does not assist the authors in enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the methodology need to be adjusted. The action is implied and somewhat vague, as the authors need to infer that they should consider using robotic manipulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to use robotic manipulation, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current methodology is insufficient or why robotic manipulation would be more appropriate. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential weakness in the paper by suggesting that the proposed methodology may not be specific to bimanual manipulation. It recommends using robotic manipulation instead, which could be more appropriate. This feedback is 3 as it points out a potential limitation in the methodology and provides a suggestion for improvement. However, the comment lacks specificity and does not explain why robotic manipulation is more appropriate or how it would address the issue. To be more helpful, the comment could provide additional context or examples to support the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include the METEOR results, which are reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the inclusion of METEOR results, which provides full grounding as it specifies the part of the paper being addressed. It also specifies the issue by suggesting the inclusion of results reported in recent works, making the comment specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include the METEOR results, which are reported in recent works. However, the comment does not provide any supporting evidence, references, or reasoning to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable suggestion for improvement. By recommending the inclusion of METEOR results, which are reported in recent works, the reviewer offers a clear and concrete way for the authors to enhance their draft. This feedback is valuable as it directly addresses a potential gap in the paper and provides a straightforward path for improvement. However, the comment could be more helpful if it explained why the inclusion of these results is important or how they might impact the paper\"s overall contribution. Despite this, the suggestion is still actionable and beneficial, making the comment 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the comparability of Geffect values or recommending specific analyses to be conducted. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. It points out that studying the Geffect of each learning objective in isolation raises questions about the validity of these comparisons. This feedback is 3 as it highlights an area where the authors may need to provide additional analysis or discussion to address the issue of comparability. However, the comment could be more helpful if it suggested specific ways to improve the comparability or provided examples of how other studies have addressed this concern. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting. The comment also praises the clarity and welldesigned experiments, providing a clear direction for the authors to address the issue with UNIFORM in the 1shot setting. The explicit request for clarification and the concrete suggestion to address the issue make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"tables\" and the \"1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the advantage of UNIFORM over other procedures and the need for a theory to explain its effectiveness in the 1shot setting. The comment also praises the clarity and welldesigned experiments, providing a clear direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting. The comment also praises the clarity and welldesigned experiments, providing a positive assessment of the paper. However, the claim about the inconsistency in the advantage of UNIFORM is not fully substantiated by specific examples or detailed reasoning, making it 3. The authors would need to further explore the data or provide additional analysis to fully address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting, which is a critical area for improvement. The comment also praises the clarity and welldesigned experiments, providing constructive feedback that can help the authors enhance their draft. However, the comment could be more helpful if it offered specific suggestions on how to address the issue with UNIFORM in the 1shot setting or provided examples of how other methods have successfully addressed similar challenges. Overall, the comment is 4 as it highlights a critical area for improvement and provides some guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain this. It also implies that adding this information would strengthen the paper. While the comment provides a clear direction for the authors to explore and potentially include additional information, it does not specify how to integrate this into the paper or what specific linguistic theories should be considered. The action is explicit but somewhat vague in terms of execution, as the authors need to determine the exact approach to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This provides clear guidance on what the authors need to consider and explore in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. The comment implies that adding this information would strengthen the paper. However, it does not provide specific examples or references to existing linguistic theories or studies that could support this claim. Without such evidence or detailed reasoning, the claim is 3, as it requires the authors to make a significant effort to explore and substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a potential area for improvement by suggesting that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This feedback is clear and actionable, as it prompts the authors to explore a specific aspect of their work that could enhance its theoretical foundation and rigor. However, the comment could be more helpful if it provided specific examples or references to existing linguistic theories that might be relevant to the discussion. Overall, the comment offers valuable guidance for improving the paper, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance, specifically mentioning the extraction of hints for future network architecture design. It explicitly suggests that the authors should spend more time discussing these aspects, such as the biggest takeaways from the found architecture. This feedback provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AutoML approaches and the potential benefits beyond raw performance, such as extracting hints for future network architecture design. It also specifies the issue by pointing out that the authors did not spend much time discussing these aspects, providing clear guidance on what needs to be addressed. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main reason for using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper does not adequately discuss the potential benefits of using AutoML approaches beyond improving raw performance. It suggests that the authors should spend more time discussing the extraction of hints for future network architecture design, which could be a valuable contribution to the field. While the comment highlights an important aspect that could enhance the paper, it lacks specific suggestions or guidance on how to address this issue. The authors are given a direction to consider but are not provided with detailed steps or examples to follow. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is an explicit observation that the authors can directly address by providing the definition in the appropriate section. The comment is clear and concrete, as it specifies the exact issue and where it should be resolved. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that T_a(t) is used in Section 3.1 but only defined in Section 4. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation that does not require any subjective judgment or opinion. It is a statement of fact that can be verified by the authors themselves, as it is directly observable from the paper. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper regarding the definition of T_a(t), which is used in Section 3.1 but only defined in Section 4. This is a clear and actionable observation that the authors can address to improve the consistency and clarity of their work. By pointing out this issue, the comment provides the authors with a specific area to focus on for revision, ensuring that the definition is properly integrated into the appropriate section. However, the comment could be more helpful if it offered suggestions on how to improve the presentation or clarity of the definition. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While the action is implicit, it is clear that the authors should aim to make their introduction more concise and include empirical results. However, the comment does not provide specific guidance on how to achieve this concision or what specific empirical results should be included. The action is somewhat vague, as the authors need to infer the exact steps to take, but it is still 3.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, it does not specify which part of the introduction is too long or where empirical results should be included. The authors can infer that the introduction and empirical results sections might be the focus, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, the comment does not provide any specific examples, reasoning, or references to support why the current introduction is too long or how empirical results could enhance it. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While it identifies a potential area for improvement, it lacks specific guidance on how to achieve this concision or what empirical results should be included. The comment provides a general direction for improvement but does not offer detailed suggestions or examples to help the authors effectively address the issue. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a confusion regarding the empirical analysis in Figure 3 and requests additional clarification on the adjustments made to the input series and forecasting target based on the Frequency Stability score. It also asks for an explanation of why these adjustments enhance the model\"s performance. While the comment provides a clear direction for the authors to provide additional clarification and explanation, it does not specify how to implement these changes or what specific details should be included. The action is explicit but somewhat vague in terms of execution, as the authors know they need to provide clarification but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the confusion regarding the empirical analysis and the adjustments made to the input series and forecasting target based on the Frequency Stability score. The comment also requests clarification on why these adjustments enhance the model\"s performance and provides a reference to a related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the empirical analysis in Figure 3, specifically questioning the adjustments made to the input series and forecasting target based on the Frequency Stability score. The reviewer requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also references a specific work by Liu et al. (2022) to provide context. While the comment identifies a potential issue and requests clarification, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a starting point for the authors to address the issue but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the empirical analysis in Figure 3, particularly the adjustments made to the input series and forecasting target based on the Frequency Stability score. It requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also points out that Equations (9) and (10) have large spacing from the preceding text, which could be improved. While the comment provides clear and actionable feedback, it could be more helpful if it offered suggestions on how to present the additional clarification or provided examples of how similar adjustments have been addressed in related works. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensibility of their empirical analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the recent related work, CoCoOp, should be compared in the experiments. It provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and provides concrete guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the related work \"CoCoOp\" and its comparison to the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the comparison of CoCoOp to the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work, CoCoOp, should be compared in the experiments. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting that the recent related work CoCoOp, which is a CVPR\"22 work, should be compared in the experiments. This is a clear and actionable suggestion that could significantly enhance the paper\"s comprehensiveness and relevance. By addressing this point, the authors can demonstrate a more thorough understanding of the stateoftheart and provide a more comprehensive analysis of their work. However, the comment could be more helpful if it provided additional context or examples of how CoCoOp could be integrated into the experiments. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, automatic scoring, and where model training is used to optimize the selection modules. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to make these changes or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance the figure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, including suggestions for enhancing the figure to show the processing pipeline more clearly. The comment details the steps to be taken, such as including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with model training. This level of detail provides clear instructions for the authors to follow. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with model training. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these additions would improve the figure or how they would enhance the understanding of the processing pipeline. Without such evidence or justification, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with model training. This feedback is 3 as it identifies a specific area for improvement and provides a clear direction for enhancing the figure. However, the comment could be more helpful if it offered additional guidance on how to effectively present these elements or what specific details should be included in each step. While the authors gain some insight into what changes could be made, the comment could be more actionable with more detailed suggestions. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of huge inputs for the value and policy function. While the comment implies that the authors should conduct additional experiments, it does not provide explicit instructions on which specific games or complex problems to test. The action is clear but lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the author should consider testing ReBeL on games with larger depth to address the issue of huge inputs for the value and policy function. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems, specifically mentioning the issue of huge inputs for the value and policy function. However, the comment lacks specific examples or references to support the claim that these complex problems are necessary for testing ReBeL. Without detailed evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of huge inputs for the value and policy function. While the comment highlights an important area for improvement, it lacks specific guidance on which complex games or problems to test or how to implement these tests. This limits the comment\"s helpfulness, as it provides a direction for improvement but does not offer detailed instructions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove abbreviations like \"MoCo\" from section headers, as they might not be familiar to readers. This is a clear and direct action that the authors can take to improve the clarity of their draft. The comment provides concrete guidance on what to remove, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of abbreviations like \"MoCo\" in section headers. This provides clear guidance on what the authors need to change to improve the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it affects the reader\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper. By pointing out that abbreviations like \"MoCo\" should not appear in section headers, the reviewer highlights a potential source of confusion for readers who might not be familiar with the term. This feedback is clear and direct, offering a straightforward way for the authors to enhance the accessibility of their work. However, the comment could be more helpful if it provided additional context or examples of how to effectively communicate the meaning of these abbreviations in the text. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors could clarify the technical contribution or make the analysis more novel. There is no explicit or implicit action for the authors to take, such as recommending specific improvements or suggesting alternative approaches. As a result, the comment lacks actionability, leaving the authors without direction on how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are unclear or where the analysis is standard, making it difficult for the authors to pinpoint the exact areas that need clarification or improvement. The lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide specific examples or detailed feedback on how the authors could clarify the technical contribution or make the analysis more novel. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors should present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence or arguments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not specify which part of the paper discusses this advancement or where the authors should provide additional evidence or arguments. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in suggesting the need for more substantial evidence or arguments, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s contribution, suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. It acknowledges the need for more substantial evidence or arguments to establish this as a significant contribution to the field. However, the comment does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors might present them. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities is incremental and does not provide a clear direction for improvement. However, the comment does not offer specific guidance on how to address these concerns or what additional aspects could be explored to enhance the novelty of the paper. The lack of explicit suggestions or concrete actions makes it difficult for the authors to know how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, it does not specify which datasets or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the novelty could be enhanced. Without clear guidance on what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities seems incremental and does not provide a clear direction for improvement. However, the comment lacks specific suggestions or examples of how the authors could enhance the novelty or impact of their work. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but does not offer sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it does not specify what aspects of the discussion should be included or how it should be structured. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO, allowing the authors to accurately identify the part of the paper being addressed. However, the comment does not specify what aspects of the theoretical guarantee are missing or how the authors should address this issue. This makes the comment specific but weakly grounded, as the authors can infer the relevant part but may not be able to pinpoint it exactly. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper lacks discussion, specifically regarding the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a relevant point that could enhance the paper\"s theoretical foundation. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the theoretical guarantee should be discussed. While it points out a gap in the paper, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate quantitative measures or what specific metrics should be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to include quantitative measures but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a quantitative measure to evaluate the generated VCEs, and notes that evaluation is mainly performed with visual inspection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by noting the lack of quantitative measures to evaluate the generated VCEs. It highlights that the evaluation is mainly performed with visual inspection, which is a relevant point for the authors to consider. However, the comment does not provide detailed guidance on how to incorporate quantitative measures or what specific metrics should be used. While it points out a weakness, it lacks actionable suggestions or examples that would help the authors address the issue effectively. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method only provides marginal improvements over baselines, with most improvements within the error bar range. It also notes that the authors claim the method performs better than the baselines, but the high error range suggests that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of their method. The action is implicit and vague, as the authors are left to infer that they need to improve the performance of their method, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, suggesting that the improvements are marginal and within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the high error range suggests otherwise. However, the comment does not specify which part of the paper discusses these claims or the baselines, making it weakly grounded. The comment is specific in its critique of the performance improvements and the high error range, but without clear references to specific sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method provides only marginal improvements over baselines, with most improvements within the error bar range. The reviewer questions the authors\" claim that the method performs better than the baselines, noting the high error range. This claim is 3 as it provides a logical reasoning for questioning the authors\" claims, but it lacks specific examples or detailed evidence to fully substantiate the argument. The authors would need to further explore the data or methodology to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It questions the authors\" claim that the method performs better than the baselines, given the high error range. This feedback is 3 as it points out a potential weakness in the paper\"s claims, but it lacks specific suggestions or guidance on how the authors might address this issue or improve the performance of their method. While it highlights an area for improvement, the comment could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights issues with the generated videos, specifically noting significant artifacts and questioning the action recognition performance compared to stateoftheart methods. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it guide the authors on how to address the issues or improve the quality of the videos. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the generated videos, specifically mentioning artifacts and the action recognition performance on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment does provide some specificity by questioning the action recognition performance compared to stateoftheart methods, which suggests that the authors should address this aspect. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and questions the action recognition performance compared to stateoftheart methods. However, it does not provide specific examples or detailed reasoning to support these claims. The mention of artifacts and action recognition performance is somewhat vague, and the comparison to stateoftheart methods is not fully explained. This makes the claim 3, as it requires more detailed evidence or explanation to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the generated videos, noting significant artifacts and questioning the action recognition performance compared to stateoftheart methods. It highlights the need for improvement in both aspects. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending specific techniques or improvements to the video generation process. While it points out areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the proposed evaluation set more diverse and representative than the previous method and how to select representative images. However, it does not provide any explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more details or examples, but it does not specify what exactly is missing or how to improve the evaluation set. As a result, the authors are left without clear direction on how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the issue of diversity and representation in the proposed evaluation set, specifically mentioning the need for clarity on how to make the set more diverse and representative than the previous method and how to select representative images. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the evaluation set is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what needs to be clarified regarding the evaluation set, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed evaluation set is unclear in terms of diversity and representation compared to the previous method, and that the selection of representative images is unclear. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without such evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed evaluation set, specifically the lack of clarity on how to make it more diverse and representative than the previous method and how to select representative images. This is an important point that could significantly impact the validity and applicability of the evaluation results. However, the comment does not provide specific suggestions or examples on how to address these issues, nor does it offer guidance on how to improve the diversity and representation of the evaluation set. While it highlights a significant area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, as it points out a critical issue but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also suggests providing a brief overview of the original DPO algorithm to help distinguish the modifications proposed in the methods section. These actions are clear and concrete, as they specify exactly what needs to be added to the paper. The authors know exactly how to apply these suggestions to improve the clarity and comprehensibility of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, and suggests providing a brief overview of the original DPO algorithm. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included in the background section and how it can improve the clarity of the subsequent sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This claim is 3 as it logically suggests that a background section would enhance the clarity and comprehensibility of the paper. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting the inclusion of a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is valuable as it directly addresses the need for a more comprehensive introduction to the RL context, which can significantly improve the clarity and accessibility of the paper. By addressing these points, the authors can enhance the reader\"s understanding of the work and its contributions. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method to accommodate continuous language addition. The comment lacks actionable guidance or specific steps for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a potential limitation of the proposed method, specifically the issue of handling continuous addition of new languages due to the limited model capacity. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the method, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may encounter a limitation due to the limited model capacity when users continuously add new languages. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. This is a relevant point that could impact the scalability and practicality of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or improve the method to accommodate continuous language addition. Without actionable advice or detailed feedback, the comment offers some insight but does not fully support the authors in improving their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). While it does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it implies that the authors should consider the relevance of the term in the context of their work. The action is implicit but clear, as the authors can infer that they need to evaluate the relevance of the term and potentially revise their work accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), providing a clear direction for the authors to consider the applicability of this term in their context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it points out a potential weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, it does not provide specific guidance on which additional datasets should be considered or how to implement this expansion. The action is implicit and somewhat vague, as the authors can infer that they need to broaden their dataset selection but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, but it does not specify which part of the paper this limitation is discussed in. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, it is specific in identifying the issue of limited datasets being used for experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the experiments, specifically that they are limited to MNIST and a single realworld dataset. This feedback highlights an area where the authors could potentially expand their experiments to include a broader range of datasets, which could enhance the generalizability and relevance of their findings. However, the comment lacks specific suggestions or guidance on which datasets to consider or how to implement this expansion. While it identifies a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is 3, as it points out an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should provide more information about the parameters and their relationship to the kernel height/width and depth, but it lacks concrete steps or examples to follow. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. The comment provides a clear direction for the authors to address the issue by explaining the relationship between the kernel height/width, depth, and parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of parameters should change or how the efficiency could be improved. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure regarding the number of parameters and suggests that more details are expected regarding the efficiency improvements. It acknowledges that the FLOP is quadratic on the activation side length but points out that the number of parameters could increase due to the depth of the structure. This feedback is 3 as it highlights a potential area for improvement and encourages the authors to provide more details regarding the efficiency improvements. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this issue or what additional details should be included. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in 10, suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or differentiate their method from 10. The comment lacks actionable details, such as recommending specific modifications or discussions to be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"approach in 10,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the approach in 10 cannot use the additional information, such as scoring causal predictions and interventional data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the similarity between the proposed method and an existing approach in 10, suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in 10, suggesting that the latter could also incorporate scoring causal predictions and interventional data. It questions why 10 cannot use these side information. While the comment identifies a potential issue with the novelty of the proposed method, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from 10. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results from the Atari game are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the interpretability of their results. There is no guidance on whether they should expand the experiment to include more games or baselines, or how they might present their findings more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the interpretation of the Atari game results, specifically noting that the results are limited to a single game and a single baseline. This feedback highlights an area where the authors could improve the clarity and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional experiments or analyses. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This implies that the model may not be incentivized to use fewer factors, leading to increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to implement a sparsity constraint. The authors are left to infer that they need to consider this aspect, but without concrete steps or examples, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"factorized model with an IBP prior,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of a sparsity constraint in the number of factors used by subsequent tasks, which is a critical aspect of the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to increased computation with more tasks. The comment provides a logical reasoning by explaining the potential consequences of this lack of constraint, but it does not provide specific examples or references to substantiate the claim. The authors might find it challenging to understand the exact impact of this issue without additional context or evidence. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation highlights a potential limitation of the model, which could lead to increased computation with more tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate a sparsity constraint. While it points out a relevant concern, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that this is due to the bandit feedback and not using information about the form of the cost function. This feedback provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be addressed in the paper. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of commentary on why the GPC (benchmark) is performing better than BPC (their method) and the importance of the bandit feedback. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study does not provide a favorable comparison between the GPC (benchmark) and BPC (the authors\" method). It suggests that the GPC performs better due to bandit feedback and not using information about the form of the cost function. The comment provides a logical reasoning by explaining the potential cause of the performance difference. However, it lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable explanation but could be further substantiated with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that this is due to the bandit feedback and not using information about the form of the cost function. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to address the issue by reiterating the importance of the bandit feedback. By doing so, the authors can improve the clarity and completeness of their analysis. However, the comment could be more helpful if it included specific examples or references to support the claim about the bandit feedback. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep at the time, to provide context. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim. While it implies that the authors should provide more detailed information or examples, it lacks concrete guidance on what specific aspects to address or how to present the information. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks.\" It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting that quantifying and clarifying the claim could be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim, but it does not offer specific examples or detailed reasoning to fully substantiate the claim. The comment is 3, as it provides a logical connection to the original work but lacks detailed evidence or examples to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be beneficial. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim, but the comment lacks specific guidance on how to quantify or clarify the claim. While it points out a potential area for improvement, it does not offer detailed suggestions or examples on how to address the issue. Therefore, the comment is 3, as it identifies a potential weakness but lacks depth and actionable advice for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It implies that the authors should provide more information about the calculation method or clarify the discrepancy between the reported perplexities and the better BLEU scores. While the comment does not explicitly instruct the authors to provide this information, it clearly points out a potential issue that needs to be addressed. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks explicit instructions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexities, which are over 30, and asks for clarification on how they were calculated. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the reported perplexities in Figure 1, which are over 30, and suggests that this high perplexity contradicts better BLEU scores. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the overall quality of the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be fully understood and addressed by the authors. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. This is a relevant observation that could impact the interpretation and validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their methodology. While it points out a potential problem, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the evaluation should include experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, specifying exactly what additional experiments are needed to improve the draft. The comment is specific and concrete, giving the authors a clear path to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for additional experiments, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or examples to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is 3 as it identifies a potential area for improvement in the evaluation section. However, it lacks specific guidance on how to conduct these experiments or what aspects of the evaluation would be enhanced by including them. While it points out a potential gap in the evaluation, the comment could be more helpful if it provided more detailed suggestions or examples of how to implement these changes. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors need to elaborate on the importance of rooted patterns and how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback provides clear and concrete actions for the authors to take, such as elaborating on the importance of rooted patterns or discussing nonrooted patterns in the supplementary material. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concept of \"rooted patterns\" and how they are defined, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of elaboration on why rooted patterns are important and how they are chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not elaborate on the importance of rooted patterns or how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, that the discussion should be moved to the supplementary material. The comment provides a logical reasoning for the need to clarify these aspects, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more detail or clarification. It points out that the concept of rooted patterns is defined in a similar way to orbit counting in GSN, but it does not elaborate on why rooted patterns are important or how they are chosen. The comment suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and completeness of their explanation. However, it could be more helpful if it provided specific suggestions on how to elaborate on the importance of rooted patterns or how to choose the roots. Overall, the comment is 4 as it directs the authors to a critical area needing further explanation and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more explanations on the consistency between training and inference, specifically mentioning lines 9597 and 308310. While the comment implies that the authors should elaborate on the smoothness of neural models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the lack of explanation regarding the consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks explanations regarding the consistency between training and inference due to the smoothness of neural models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it overly emphasizes the consistency between training and inference due to the smoothness of neural models. It suggests that the authors should provide more explanations on this topic, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific examples or guidance on what kind of explanations would be beneficial. Overall, the feedback is 3 as it points out a potential weakness and offers a direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It asks for clarification on whether the proposed model improves with larger word embedding and LSTM parameters. While the comment implies that the authors should provide evidence or experiments to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional experiments or evidence to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about superior performance with fewer parameters, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have tested the model with standard parameter settings in the baseline model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. The reviewer requests evidence or experiments to support the claim, indicating a need for further clarification. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to make a significant effort to address the concern, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It questions whether the proposed model improves with larger word embedding and LSTM parameters, which is a relevant and important point for the authors to address. The comment provides a clear direction for the authors to provide evidence or experiments to support their claim, which could significantly impact the paper\"s credibility and impact. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the availability of the environment or a good OPE method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these hyperparameters are introduced, the comment lacks full grounding. It is specific about the issue of finetuning and the dependence on the environment or OPE method, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains 1, as it does not provide sufficient justification for the authors to make improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. This feedback is 3 as it points out a potential problem that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to ensure the availability of the environment or a good OPE method. Without actionable advice or detailed explanation, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the application of regularization between the LN model and GLMs. It suggests that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al., to ensure a fair comparison. While the comment implies that the authors should make an effort to replicate the previous model, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the LN model and the application of regularization, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the application of regularization between the LN model and GLMs, and suggests that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors apply regularization to both LN models and GLMs, which is not consistent with the GLM presented by Pillow et al. The reviewer suggests that the authors should try to reproduce the main features of previous models, particularly the GLM, to ensure a fair comparison. However, the comment lacks specific examples or references to the GLM by Pillow et al. to fully substantiate the claim. While the reviewer provides a logical reasoning, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the application of regularization between the LN model and GLMs, suggesting that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al. This feedback is 3 as it points out a potential issue with the comparison between models, which could impact the validity of the results. However, the comment lacks specific guidance on how to reproduce the GLM or what specific features should be replicated. While it highlights an area for improvement, it does not provide detailed instructions or examples, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include failure cases and related discussions. While it implies that the authors should consider including these elements, it does not provide specific guidance on how to implement this suggestion or what aspects of the failure cases should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should include failure cases and related discussions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including failure cases and related discussions, but it does not specify which part of the paper should include these elements. The authors cannot confidently determine which sections or parts of the paper would benefit from this addition. Additionally, the comment lacks specificity regarding what aspects of the failure cases should be discussed or how they should be integrated into the paper. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including failure cases and related discussions would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including failure cases and related discussions would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what types of failure cases should be included or how they should be integrated into the paper. The comment is 3 as it points out a potential enhancement, but it does not offer actionable advice or detailed suggestions for implementation. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that an ablation study on the necessity of the base layer GNN encoding would be helpful. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to understand the role of the base layer GNN encoding in the proposed method. The comment is specific in its request, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the necessity of the base layer GNN encoding and the need for an ablation study. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to understand its role. However, the comment does not provide specific reasoning or evidence to support why the base layer GNN encoding is unnecessary or how an ablation study would benefit the paper. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the suggestion without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to understand the role of this layer and its impact on the overall performance. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to improve their draft by conducting an ablation study. By addressing this point, the authors can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a discrepancy in the use of \u03b4 in equations (10) and (11) and suggests introducing \u03b4 when (11) is discussed. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"equation (11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent use of \u03b4 in equations (10) and (11) and suggests introducing \u03b4 when (11) is discussed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \u03b4 is not used in equation (10) but is used in equation (11). This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue in the paper regarding the inconsistent use of \u03b4 in equations (10) and (11). It suggests that introducing \u03b4 when (11) is discussed might improve clarity. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by ensuring consistency in the notation used. However, the comment could be more helpful if it explained why this inconsistency is problematic or how it affects the reader\"s understanding. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added and how it could enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section where the authors discuss the computational complexity of counting homomorphisms, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, providing a specific example of a brief statement made in the paper. The reviewer suggests that adding the upper bounds of counting and potentially elaborating on empirical runtimes would be beneficial. However, the comment lacks specific examples or references to support the claim that these additions would improve the paper. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper, namely the discussion of computational complexity in counting homomorphisms. It points out that the current discussion is brief and suggests that adding the upper bounds of counting and potentially elaborating on empirical runtimes would enhance the paper. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue, which would further guide the authors in their enhancement efforts. Overall, the comment is 4 as it effectively directs the authors to a meaningful area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a typographical error in the first \"f\" in \"we fixed the form of\" and an extra period in a sentence. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. While the comment provides specific corrections and a question, it does not offer guidance on how to address the question or improve the paper. The action is clear but lacks detailed instructions on how to implement the corrections or respond to the question. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (108 and 115), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the typographical errors in these lines and raises a question about the baseline MCL with deep learning. The comment provides clear guidance on what needs to be corrected and offers a question for further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual corrections and a question about the baseline MCL with deep learning. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific typographical errors in the manuscript, which are important to correct for accuracy. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This question is relevant and could prompt the authors to provide more detailed explanations or evidence regarding the convergence of their networks. However, the comment could be more helpful if it offered suggestions on how to address the convergence issue or provided examples of best practices in this area. Overall, the feedback is actionable and provides valuable insights, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. While the comment implies that the authors should conduct this study, it does not provide explicit instructions or concrete steps on how to conduct the study or what specific aspects to focus on. The action is clear but lacks detailed guidance, making it 3.", "grounding_specificity_rationale": "The comment suggests studying the inference time of the pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not specify which part of the paper should include this analysis or where the inference time is currently discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific about the need for an inference time comparison but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a study of inference time for the pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer provides a logical reasoning by stating that since the method is direct, it should be compared to previous topdown and bottomup pose estimation methods in terms of inference speed. This claim is 3 as it provides a logical basis for the suggestion, but it could be strengthened with specific references or examples to support the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including a study of inference time and benchmarking their method against others. However, the comment could be more helpful if it offered suggestions on how to conduct this study or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about a mathematical error in Theorem A.3 proof, specifically regarding the input x having two indices when it is a vector. It also points out a potential mathematical mistake in the equation involving the sum of k(Wk(2))^2. The comment implies that the authors should correct these errors, but it does not provide explicit instructions or detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should correct the errors, but the comment lacks concrete steps or examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a mathematical error regarding the input x having two indices when it is a vector, and it questions the correctness of the equation involving the sum of k(Wk(2))^2. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual observations and questions about the mathematical content of the paper. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific mathematical error in the proof of Theorem A.3, pointing out that the input x is a vector, not a matrix, and that the equation involving the sum of k(Wk(2))^2 should be corrected to \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This feedback is clear and actionable, as it provides the authors with precise guidance on how to correct a mistake in their mathematical derivations. By addressing these errors, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it included suggestions on how to better present the corrected equations or explained the implications of the corrections. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in section 4.3 and 4.4, questioning the effectiveness of beam search in ensuring the correctness of the results. It suggests that the authors should address this issue by providing more detailed information on how they ensure the correctness of the pluggedin entities and relationships. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to address the concern. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information on the effectiveness of beam search. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the use of words like \"somewhat\" and \"good generative ability\" in the description, and it raises concerns about the effectiveness of beam search in ensuring the correctness of the results. The comment further asks how the authors ensure the correctness of the pluggedin entities/relationships and suggests that the percentage of correct entities/relationships might be lower without ground truth. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of beam search in ensuring the correctness of the results, questioning the use of words like \"somewhat\" and \"good generative ability\" in the description. It suggests that only 77% of the result lists contain the ground truth logical forms, and it asks how the authors ensure the correctness of the pluggedin entities/relationships without ground truth. The comment provides a logical reasoning by questioning the reliability of the results and suggesting that the authors should address this issue. However, it lacks specific examples or references to support the claim that beam search is insufficient. Therefore, the comment is 3, as it provides a logical basis for the concern but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of results in sections 4.3 and 4.4, noting the use of words like \"somewhat\" and \"good generative ability\" and questioning the effectiveness of beam search in ensuring the correctness of the results. It raises a valid concern about the reliability of the results and suggests that the authors should address this issue by providing more detailed information on how they ensure the correctness of the pluggedin entities and relationships. The comment is 3 as it prompts the authors to consider the robustness of their results and provides a direction for improvement. However, it could be more helpful if it offered specific suggestions on how to address the issue or provided examples of how other studies have handled similar concerns. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding batch normalization. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or what aspects should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and its limitations in addressing internal covariate shift. It also specifies the issue with batch normalization, which standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the paper. However, the comment could be more specific by suggesting how the authors should discuss these limitations or what aspects should be emphasized. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer supports this claim by comparing it to batch normalization, which standardizes the variance and centers the activation. However, the comment lacks specific examples or references to substantiate the claim fully. While it provides a logical reasoning, it could be strengthened with more detailed evidence or examples to fully support the assertion. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a limitation in the claim about evolutional dropout addressing internal covariate shift. It suggests that the claim is limited because it can only increase the variance of some lowvariance units, while batch normalization standardizes the variance and centers the activation. This feedback is clear and actionable, as it explicitly instructs the authors to discuss these limitations explicitly in their paper. However, the comment could be more helpful if it provided specific suggestions on how to address these limitations or what aspects of the claim should be emphasized. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their discussion on this topic."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the limitations of FedPCL due to its reliance on pretrained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pretrained models. However, the comment does not provide explicit guidance on how the authors should further improve their work or what specific aspects of the framework should be refined. It lacks actionable details, such as suggestions for additional experiments or modifications to the framework. As a result, the authors are left without clear direction on how to enhance their draft based on this feedback. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of FedPCL, which relies heavily on pretrained models, and how the authors have addressed this limitation by developing a lightweight federated learning framework and integrating pretrained models. This provides clear guidance on what needs to be improved or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of FedPCL is sensitive to pretrained models, which limits its applications to more wide areas. The comment supports this claim by referencing Table 4, which shows the model accuracy is affected by the choice of pretrained models. However, the comment does not provide further details or analysis on why this sensitivity is a limitation or how it affects the applicability of FedPCL. While the reference to Table 4 provides some support, the comment could be strengthened by offering more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment acknowledges the limitations of FedPCL due to its reliance on pretrained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pretrained models. However, the comment does not provide specific suggestions or guidance on how the authors could further improve their work or what aspects of the framework should be refined. While it highlights a potential area for improvement, the lack of actionable feedback limits its usefulness for the authors. Therefore, the comment is 3, as it identifies a limitation but does not offer detailed guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include tentative attention maps in the qualitative figures to provide a more comprehensive understanding of the attention mechanism. While the comment implies that the authors should add these maps, it does not explicitly instruct them to do so. The action is concrete, as it specifies what additional information should be included, but it is somewhat vague because it does not provide detailed guidance on how to present these maps. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, which implies that it relates to the visualization or discussion of the attention mechanism. However, it does not explicitly mention a specific section or figure where this suggestion should be applied, making it weakly grounded. The comment is specific in suggesting the inclusion of tentative attention maps, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including tentative attention maps in the qualitative figures would be beneficial for understanding the attention mechanism. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the understanding of the attention mechanism. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that including tentative attention maps in the qualitative figures would provide a more comprehensive understanding of the attention mechanism. This feedback is 3 as it identifies a potential area for improvement in the visualization of the attention mechanism. However, the comment lacks specific guidance on how to incorporate these maps or what aspects of the attention mechanism should be highlighted. While it points out a potential enhancement, it does not offer detailed suggestions or examples on how to effectively present the tentative attention maps. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the author to add more description about the contribution of the paper. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment provides a specific suggestion for enhancing the paper\"s contribution section, making it 5. The authors know exactly what is expected of them, and the feedback is concrete, making it easy to implement the suggested changes. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the author should add more description about the contribution of the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, results, or discussion sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to make these additions. Additionally, the comment lacks specificity regarding what kind of additional description is needed or how it should be presented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper lacks a detailed description of its contribution. However, it does not provide any specific examples or reasoning to support why this is an issue or how it could be improved. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper lacks a detailed description of its contribution, which is a valid point. However, it does not provide specific guidance on what aspects of the contribution should be elaborated on or how the authors might enhance the description. While it identifies a potential area for improvement, the feedback is incomplete and lacks depth, making it 3. The authors are given a general direction but are not provided with actionable steps or detailed suggestions for improvement, which limits its utility. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit suggestions for improving the paper. First, it recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models. This action is clear and concrete, as it specifies where the information should be placed and how it should be organized. Second, it suggests referencing tricks like normalization or feature scaling in a separate section, which is also a clear and concrete action. Finally, it mentions that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, providing a specific area for improvement. Overall, the comment is 5 as it provides clear and concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"2.3\" and \"2.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the two types of attention for deep VAEs in a separate section and referencing tricks like normalization or feature scaling in a separate section. The comment also suggests reorganizing the description of the layerwise attention mechanism to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides several suggestions for improvement, including describing the two types of attention for deep VAEs in a separate section, referencing tricks like normalization or feature scaling, and reorganizing the description of the layerwise attention mechanism. These suggestions are based on logical reasoning and common practices in the field, but they do not include specific examples or references to support the claims. While the suggestions are clear, they lack detailed justification or evidence to fully substantiate the claims. Therefore, the comment is 3, as it provides a solid foundation for improvement but requires more detailed explanation to be fully convincing.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models, which would improve the organization and clarity of the paper. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section, which could help the authors provide more detailed information on their methodology. The comment also points out that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, suggesting a reorganization to improve clarity. These suggestions are clear and actionable, providing the authors with specific steps to enhance the clarity and organization of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the understanding of Figure 5 or the labels being incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific steps to take to improve the figure or labels. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper, such as Figure 5, is being addressed. It lacks specificity because it does not provide details on what is unclear or incorrect about the figure or labels. Without explicit references or detailed feedback, the authors cannot effectively identify the issues or make improvements. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that either the reviewer does not understand Figure 5 or the labels are incorrect. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the clarity or accuracy of Figure 5 or the labels used in the figure. However, it does not provide any specific guidance or suggestions on how to address this issue or improve the figure. Without detailed feedback or actionable advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of supervised baselines in the paper and suggests that it is reasonable to assume that full annotation is available for datasets of scale ~100k images. It also notes that even if this is not the case, having an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. While the comment implies that the authors should include supervised baselines, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of supervised baselines in the paper, specifically mentioning that most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. It suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results sections. The comment is specific in its suggestion to include supervised baselines, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a significant issue, as most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. The reviewer suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This claim is 3 as it provides a logical reasoning for the inclusion of supervised baselines, but it lacks specific examples or references to support the assertion that full annotation is typically available for datasets of this scale. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which are crucial for understanding the performance of selfsupervised methods. It logically argues that since most experiments are conducted on datasets of scale ~100k images, it is reasonable to assume that full annotation is available. The comment suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This feedback is clear and actionable, providing the authors with a specific direction to enhance their experimental setup and analysis. However, it could be more helpful if it included examples of suitable supervised baselines or detailed guidance on how to implement them. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. It also notes that the benchmarks used are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or how to update the benchmarks. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance differences between methods, noting that they are minimal across evaluations and often less than 1 percentage point. It also mentions that the benchmarks used are outdated and likely saturated, referencing specific works. However, the comment does not specify which part of the paper discusses these performance differences or the benchmarks, making it weakly grounded. The comment is specific in detailing the issue of minimal performance differences and the need to update the benchmarks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point, which may be due to random variation. The reviewer supports this claim by referencing the outdated and likely saturated benchmarks used. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, it could be strengthened with more detailed analysis or references to specific studies that support the claim. Therefore, the comment is 3, as it provides some evidence but could be more fully substantiated with additional details or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. This observation suggests that the methods may be overfitting or that the benchmarks are saturated. The comment also points out that the benchmarks used are outdated, which could impact the relevance and applicability of the results. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples on how to update the benchmarks or improve the performance evaluation would make the comment more helpful. Therefore, the comment is 3, as it identifies a significant weakness but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the method and its applicability, suggesting that it may not be beneficial in certain domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and asks for evaluation on other domains. While the comment identifies areas for improvement and questions that need answers, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should evaluate the method on other domains and consider including BEAR in their baselines. The feedback is 3 as it points out areas for improvement but lacks detailed guidance on how to implement these changes.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests including it. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the method\"s applicability and the need for evaluation on other domains. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests including it. However, the comment lacks specific examples or references to support these claims or questions. The reasoning is based on logical assumptions and observations, but without detailed evidence or references, it is difficult for the authors to fully understand and address the critique. Therefore, the comment is categorized as 2, as it provides some basis for the claims but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises several questions and points of concern regarding the method\"s effectiveness and applicability. It questions why the method works on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics to assess its empirical efficacy. Additionally, it questions the absence of BEAR from baselines and suggests including it. While the comment identifies areas for improvement and provides a logical basis for the questions, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general sense of what needs to be improved but without actionable steps or detailed feedback. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. While the action is explicit, it lacks concrete details on how to present this justification or what specific aspects should be addressed. The authors are given a clear direction to provide theoretical justification, but without specific guidance on how to do so, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this justification should be provided in, nor does it provide details on what aspects of the results need justification. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its request for theoretical justification but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. This is a valid point as these techniques are important for performance, and theoretical justification can help the authors better understand and explain their impact. However, the comment lacks specific guidance on how to present this justification or what aspects of the results should be emphasized. While it identifies a potential area for improvement, it does not provide detailed instructions or examples on how to achieve it. Therefore, the comment is 3, as it points out a need for theoretical justification but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. While the comment provides a clear and explicit action\u2014changing \"X\" to a multiset\u2014it does not offer detailed guidance on how to implement this change or what specific considerations should be taken into account. The action is concrete, but the lack of additional context or explanation makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the change from a set to a multiset in the context of representing a graph with repeated vertex or edge labels. This provides clear guidance on what needs to be corrected or improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning based on the need to include multiplicities to ensure an honest representation of the graph. However, it lacks specific examples or references to support the claim, making it 3. The authors may need to further explore the rationale behind the suggestion, which could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It points out that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and constructive, as it directly addresses a potential issue with the accuracy of the representation. However, the comment could be more helpful if it included additional context or explanation on why this change is necessary or how it would impact the analysis. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors\" derivation is based on classical learning theorybased bounds, which are not realistic without Bayesian considerations. It suggests that the authors should consider BayesianPACbased bounds to make their derivation more realistic. While the comment implies that the authors should incorporate Bayesian considerations, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to understand the implications of the suggestion and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors\" derivation, specifically mentioning that it is based on classical learning theorybased bounds. However, it does not specify which part of the paper this critique pertains to, such as a particular section or equation. The authors can infer that it relates to the derivation or theoretical aspects of the paper, but this inference is not direct. The comment also suggests that Bayesian considerations should be taken into account, but it does not provide specific examples or guidance on how to incorporate these considerations. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is underspecific in terms of detailing what needs to be addressed.", "verifiability_rationale": "The review point claims that the authors\" derivation is based on classical learning theorybased bounds, which are not realistic without Bayesian considerations. The reviewer supports this claim by suggesting that BayesianPACbased bounds are more realistic. However, the comment lacks specific examples or references to classical learning theorybased bounds or BayesianPACbased bounds, making it 3. The authors would need to infer the relevance of these concepts and explore them further to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" derivation, noting that it is based on classical learning theorybased bounds that are not realistic without Bayesian considerations. The reviewer suggests that the authors should consider BayesianPACbased bounds to make their derivation more realistic. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a particular approach to enhance the validity and applicability of the derivation. However, the comment could be more helpful if it included examples or references to BayesianPACbased bounds or explained why these are more realistic. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or offer specific guidance on what details to include. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but may not be entirely sure of the exact content or structure of these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be added to, nor does it provide specific guidance on what aspects of the method should be elaborated on. While the authors might have an idea of where these details could be added, the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are necessary or how they would enhance the understanding of the method. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment identifies areas for improvement, it lacks specific guidance or examples on what details should be included or how they should be presented. The authors are given a general direction but are not provided with actionable steps or detailed suggestions to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer suggests that the method might struggle to detect inconsistencies in responses due to the variety of individuals being discussed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the method\"s detection capabilities. The action is implicit and somewhat vague, as the authors can infer that they need to consider this issue but are not given detailed instructions on how to address it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific example of a prompt like \"introduce a sports celebrity to me,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed method, namely that it might struggle to detect hallucinations in openended responses due to the variety of individuals being discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" This claim is 3 as it provides a logical reasoning for the potential issue, based on the nature of openended responses and the variety of individuals that could be discussed. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" This feedback highlights a specific challenge that the method might face in detecting inconsistencies in responses due to the variety of individuals being discussed. While the comment points out a potential weakness, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the method\"s detection capabilities. The feedback is 3 as it directs the authors\" attention to a specific area for improvement, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. While the comment does not explicitly instruct the authors to perform these experiments, it provides a clear direction for action. The authors can infer that they need to conduct these experiments to verify the conclusion, making the action implicit but still clear. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests verifying the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for verification on MNIST and CNN, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical findings are unclear in their relation to realworld deep learning models. It provides a specific suggestion to verify the conclusion about label noise and model size on MNIST and CNN. This claim is 3 as it logically suggests that verification is necessary to clarify the theoretical findings. However, the comment lacks detailed reasoning or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical findings and their relation to realworld deep learning models. It suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which could provide valuable insights into the practical implications of their theoretical findings. This feedback is clear and actionable, as it directs the authors to conduct additional experiments that could strengthen the paper\"s contribution. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on the paper\"s organization, writing, and content clarity. It suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. While the comment provides some guidance on potential areas for improvement, it does not offer concrete steps or examples on how to implement these improvements. The authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"writing\" and \"content clarity,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the weaknesses, such as the need for a table to compare different CoT prompting methods and the questionable assumption about the frequenterror cluster. Additionally, it raises questions about the selection criteria in section 4.2, providing specific feedback on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is wellorganized and the writing is good, but it also identifies areas for improvement. The reviewer suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, the reviewer questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. These points are supported by logical reasoning and specific questions, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides both positive and negative feedback. The positive aspect is that the paper is wellorganized and the writing is good, which is a clear indication that the authors have done a good job in presenting their work. However, the comment also identifies areas for improvement, specifically suggesting that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance their draft. While the comment could be more detailed in some areas, it offers valuable insights that can help the authors improve their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the probability distribution p(y|Hf(tn)) should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. It also mentions that this assumption is already made in the ELBOs. This comment provides a clear and direct action for the authors to take, ensuring that the probability distribution is chosen as Gaussian. The explicit nature of the suggestion and the concrete detail on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the probability distribution \"p(y|Hf(tn))\" and the need for it to be Gaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of not being able to perform Kalman Filtering, Smoothing, and CVI without this assumption. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian, as otherwise, Kalman Filtering, Smoothing, and CVI cannot be performed. The comment provides a logical reasoning by stating that this assumption is already made in the ELBOs, which supports the claim. However, the comment lacks specific examples or references to external works that demonstrate the necessity of Gaussian distributions in these contexts. This makes the claim 3, as the authors would need to understand the reasoning behind the claim and potentially conduct additional research to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the choice of probability distribution for the model. It points out that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian, as otherwise, Kalman Filtering, Smoothing, and CVI cannot be performed. This is a clear and actionable suggestion that can help the authors ensure their model is consistent and applicable. However, the comment could be more helpful if it provided additional context or examples of why this choice is important or how it affects the model\"s performance. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the use of suboptimally weight decay across all layers is expected to result in a large training loss and suboptimal cosine similarities, especially for large weight decay parameters. It also notes that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the results. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of suboptimally weight decay across all layers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that cosine similarities for large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of suboptimally weight decay across all layers is expected to result in a large training loss and suboptimal cosine similarities, especially for large weight decay parameters. The reviewer supports this claim by noting that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides a logical reasoning and specific examples to support the claim, making it 4. However, the comment could be strengthened by providing more detailed evidence or references to similar studies that have observed similar effects. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of suboptimally weight decay across all layers, which is expected to result in a large training loss and suboptimal cosine similarities, especially for large weight decay parameters. It points out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is clear and actionable, as it highlights a potential weakness in the paper\"s analysis and suggests that the authors should address this issue by reporting cosine similarities for larger weight decay strengths. By providing this guidance, the comment helps the authors improve the clarity and robustness of their results. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. It suggests that this omission could lead to incorrect conclusions by casual readers. The reviewer implies that the authors should fix this issue, but does not provide specific guidance on how to do so. The comment is explicit in identifying the problem but lacks concrete details on how to address it. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of explaining that the results are for unsupervised random forests. This provides clear guidance on what the authors need to correct to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This omission could lead to incorrect conclusions by casual readers. The reviewer suggests that this is a serious issue and implies that it should be addressed before publication. However, the comment does not provide specific examples or references to support the claim that this omission is a significant problem. While the claim is logical and somewhat supported by the mention of unsupervised random forests, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a serious omission in the paper, specifically the lack of explanation that the results are for unsupervised random forests. This is a critical issue that could lead to incorrect conclusions by casual readers. The comment suggests that the authors should fix this oversight, which is a clear and actionable piece of feedback. However, it could be more helpful if it provided specific guidance on how to address this issue, such as suggesting where in the paper this explanation should be added or how it should be framed. Despite this, the comment is 4 as it highlights a significant gap in the paper that the authors need to address to ensure accurate interpretation of their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. It also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. The comment provides specific actions for the authors to take, such as providing experimental results and visualization or schematic diagrams. These are explicit and concrete suggestions, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of qualitative experiments to demonstrate the validity of the conditional independence model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD and suggests using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. The reviewer also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. The comment is 4 as it provides logical reasoning and specific suggestions for improvement, such as using a toy dataset. However, it could be strengthened by referencing specific studies or examples that demonstrate the benefits of minimizing HSICcondi. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, namely the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides actionable suggestions for improvement, such as providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. The comment also recommends using a toy dataset to demonstrate the separability of inlier and outlier features, which is a valuable suggestion for clarifying the model\"s assumptions. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics, which are important aspects that could enhance the paper\"s rigor. Overall, the comment is 5 as it provides clear and actionable feedback that can significantly improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the computational complexity of the proposed method compared to other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a computational complexity comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"online version of the algorithm\" and the issue of training multiple iterations/epochs with large models and datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for a comparison of the computational complexity with other methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the proposed method requires more computation than other methods and suggests a comparison of computational complexity. However, it does not provide any evidence, examples, or references to support this claim. The comment lacks specific details or comparisons to other methods, making it difficult for the authors to understand the basis of the claim or how to address it. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid question about the computational complexity of the proposed method compared to other methods. It prompts the authors to provide a comparison, which is an important aspect of the paper\"s evaluation. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples to help the authors effectively address the issue. Therefore, the comment is 3, as it points out a relevant area for improvement but lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It points out a specific example from line 486 where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment provides a clear and explicit action for the authors to take, which is to conduct significance testing to support their claims. This guidance is concrete and leaves no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of significance testing to support claims about the differences between methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between methods without conducting significance testing. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment is 4 as it provides a logical reasoning and a specific example to support the claim. However, it could be strengthened by referencing external works or studies that demonstrate the importance of significance testing in similar contexts. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that without proper testing, it is difficult to determine whether these differences are significant. This feedback is clear and actionable, as it directs the authors to conduct significance testing to support their claims. By addressing this issue, the authors can significantly improve the rigor and credibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the approach description in Section 3 is difficult to follow and suggests that it should be revised. It also suggests using the additional page of the cameraready version to extend the approach description rather than adding more experiments. This provides clear and concrete guidance on what needs to be done to improve the draft. The authors know exactly what changes to make and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the approach description, suggesting that it is difficult to follow and recommending that the additional page of the cameraready version be used to extend the approach description rather than adding more experiments. This provides clear guidance on what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach description in Section 3 is difficult to follow and suggests revising it. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It suggests that the additional page of the cameraready version should be used to extend the approach description rather than adding more experiments. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the clarity and comprehensiveness of their approach description. However, the comment could be more helpful if it offered additional guidance on how to revise the approach description or provided examples of how to improve its clarity. Overall, the comment is 4 as it directs the authors to a specific area needing attention and provides a clear suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two main issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. While the comment highlights these gaps, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to include more interpretive insights and comparisons with other methods. The action is implicit and somewhat vague, as it lacks concrete details on how to implement these improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It also specifies the issues with the related discussion, noting the lack of interpretive insights and the need for comparison with other stateoftheart methods. The comment further highlights the absence of comparison with methods that do not rely on gyrostructures, which makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and that the paper lacks comparison with other stateoftheart methods that do not rely on gyrostructures. The comment suggests that this omission makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to infer the importance of these comparisons and the potential impact on the conclusions drawn. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the experimental section of the paper. First, it points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. This feedback highlights an important area for improvement, as it would help the authors better understand and communicate the strengths of their approach. Second, the comment notes the absence of comparison with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques. This omission is crucial for the paper\"s conclusions and impact, and the comment provides a clear and actionable suggestion for improvement. By addressing these issues, the authors can enhance the clarity and robustness of their experimental findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. While the comment implies that additional analysis is needed, it does not specify what kind of evidence or analysis is required or how it should be presented. The authors are left to infer that they need to provide more detailed information, but the comment lacks concrete guidance on what exactly is needed. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in its request for additional evidence or analysis, but it lacks full grounding as it does not explicitly mention the sections where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of evidence or analysis supporting the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it points out a critical area where the authors need to provide more detailed information to substantiate their claims. However, the comment could be more helpful if it offered specific suggestions on what kind of evidence or analysis would be beneficial or how it could be presented. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. While the comment provides a clear action for the authors to take, it does not specify which details should be added or how to extend CATER to other languages. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as its difficulty in comprehension and the need for more details about the two baselines presented. Additionally, it suggests extending CATER to other languages, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages. While the comment identifies specific issues with the figure and the study\"s scope, it lacks detailed reasoning or references to support the claim that Figure 5 is difficult to comprehend. The suggestion to extend CATER to other languages is logical but could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides some support but lacks full justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and comprehensiveness of the figure and the study\"s scope. By addressing these points, the authors can enhance the understandability and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the literature review, specifically regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment implies that the authors should make these improvements, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added (an explicit and comparative analysis of related work), but it is somewhat vague in terms of how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and \"GFlowNet for sequence generation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved: the clarity of the main contribution and the distinction from existing work. The comment provides a clear direction for the authors to enhance the literature review by suggesting a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear, particularly regarding the main contribution of the proposed method and its distinction from existing work. The reviewer suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment identifies a potential issue, it lacks specific examples or references to existing work that could clarify the distinction. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the literature review, specifically the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work, which is crucial for effectively communicating the novelty and significance of the proposed method. This feedback is clear and actionable, as it directs the authors to enhance the literature review section to better support their claims. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct a more comprehensive analysis of related work. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any explicit guidance on how to implement this suggestion or what specific changes should be made to the section. The action is implicit and vague, as the authors are left to infer that they should remove the section without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not specify which part of section 3.2 is problematic or how it relates to the distribution. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or how it affects the paper\"s content or clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any reasoning or explanation for why this section is unnecessary or how it might detract from the paper\"s overall clarity or contribution. Without additional context or suggestions for improvement, the comment lacks depth and does not offer actionable guidance for the authors to enhance their draft. Therefore, it is rated as 2, as it provides some insight but not enough to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It highlights the need for proper ablation studies to verify this claim. While the comment identifies a potential problem, it does not provide explicit instructions on how to conduct these studies or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct ablation studies to verify the claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It points out the need for proper ablation studies to verify this claim. However, the comment does not specify which part of the paper discusses the distillation process or the claim about its effectiveness. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claim and the need for ablation studies, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. The reviewer provides a logical reasoning by pointing out that the finetuning without earlystopping could lead to high variances, which would affect the validity of the claim. However, the comment lacks specific examples or references to support the argument, such as data or studies that demonstrate the impact of regularization on teacher performance. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that the improvements in teacher performance are due to distillation. It suggests that the improvements might be due to regularization effects instead, given the finetuning without earlystopping and the high variances that can occur. The comment highlights the need for proper ablation studies to verify the claim, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided specific suggestions on how to conduct these studies or what aspects to focus on. Overall, the comment is 3 as it points out a potential weakness and suggests a direction for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two specific actions for the authors to take: (i) to include performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework, and (ii) to include morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These are explicit actions that the authors can directly implement to improve their draft. The second point is a minor suggestion, but it is still clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of performance on word similarity and sentence translation tasks and the inclusion of morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. This provides clear guidance on how to enhance the robustness and effectiveness of the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that adding performance on word similarity and sentence translation tasks would enhance the credibility of the framework, similar to the MUSE paper and others. It also recommends including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These suggestions are based on common practices in the field and are logical, but the comment lacks specific examples or references to support the claim fully. The authors would need to infer the benefits of these additions themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the experiments section of the paper. First, it recommends adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, which would enhance the credibility and effectiveness of the framework. This is a clear and concrete suggestion that the authors can easily implement to improve their draft. Second, it suggests including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments, which would further diversify the evaluation and provide more robust results. While the second point is a minor suggestion, it is still actionable and could help the authors expand their experiments. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes should be made to include the 1shot setting. The comment lacks actionable details, such as recommending specific experiments or modifications to the paper, making it 1.", "grounding_specificity_rationale": "The comment addresses the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its critique of the absence of the 1shot setting in the experiment part, but it lacks grounding as it does not pinpoint the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\"s conclusions. The claim is based on a logical observation but lacks detailed justification or examples, making it 3. The authors would need to make a significant effort to understand and address the issue, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises a valid point about the absence of the 1shot setting in the experiment part of the paper, noting that related works like RALE have included this setting. This feedback highlights a potential gap in the paper\"s experimental evaluation, which could impact the authors\" conclusions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to fully explore the 1shot setting. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. While the comment implies that additional discussions are needed, it does not provide specific guidance on what aspects of these discussions should be included or how to structure them. The authors are left to infer that they need to expand on the existing discussions, but without concrete instructions on what to focus on or how to implement these changes, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. The authors can infer that it relates to the discussion of LLMs, but this inference is not direct. The comment is specific in suggesting the need for more discussions, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the limitations and challenges of LLMs. However, the comment lacks specific guidance or suggestions on what aspects of these discussions should be included or how to structure them. While it points out a gap in the paper, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of insight into the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more detailed explanations or justifications for this approach. However, the comment does not explicitly instruct the authors to add this information or specify what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but may not be entirely sure of the exact details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results, suggesting that the authors need to provide more insights into why selfsupervised learning is valuable for 360 video data with spatial audio. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of insights into the rationale behind the approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results suggest the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio but lacks insights into why this is necessary. The comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the lack of insights into the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It highlights that while the experimental results suggest the approach\"s value, the authors have not provided sufficient explanation for why this approach is necessary. This feedback is 3 as it points out an area where the paper could be improved by providing more detailed justification or context. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of what kind of insights would be beneficial. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the link between IP and the terms/equations should be explained more explicitly and prominently. It also requests that labels be included for subfigures in Figures 3 and 4, rather than just being mentioned in the captions. While the comment provides a clear action for the authors to take, it does not specify how to implement this improvement or what specific changes are needed to make the link more explicit. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for labels on subfigures and the clarification of the link between IP and the terms/equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. However, it does not provide any specific examples or reasoning to support this claim. The suggestion to include labels for subfigures in Figures 3 and 4 is also mentioned, but without further explanation or justification, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the link between IP and the terms/equations could be explained more explicitly and prominently. It also provides a clear and actionable suggestion to include labels for subfigures in Figures 3 and 4, rather than just mentioning them in the captions. This feedback is valuable as it directs the authors to enhance the clarity and accessibility of their work, which can significantly improve the reader\"s understanding. However, the comment could be more helpful if it included additional details or examples on how to effectively explain the link or how to implement the labeling suggestion. Overall, the comment is 4 as it provides clear and actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on how to enhance the robustness and reliability of their results, making it 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results over multiple runs, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their results. By suggesting a specific method for evaluating statistical significance, the comment provides a concrete step for the authors to take in enhancing the quality of their work. However, the comment could be more helpful if it explained why averaging over multiple runs is necessary or how it would impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only covers the SimCLR case and lacks analysis of the projection head, which is considered important. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include analysis of the projection head, but it does not specify which aspects of the projection head should be analyzed or how to conduct the analysis. The action is implicit and somewhat vague, as the authors are left to infer what specific aspects of the projection head should be analyzed and how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the \"projection head,\" which is a critical component of the SimCLR approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only covers the SimCLR case and lacks analysis of the projection head, which is considered important. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why the projection head is crucial or how it relates to the SimCLR case. Without such information, the claim remains 1, as it lacks the necessary context and justification to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the absence of analysis on the projection head component of the SimCLR approach. It points out that this component is considered important, as evidenced by recent papers like SimCLRv2 and others. This feedback is valuable as it highlights a potential gap in the paper that could be addressed to enhance its comprehensiveness and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might analyze the projection head or what aspects should be considered. While it identifies an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the observations and conclusions should be highlighted in the paper, particularly in the experimental section. This feedback implies that the authors should make the observations and conclusions more prominent or accessible to the reader, which is a clear and explicit action. However, the comment does not provide specific guidance on how to achieve this, such as recommending a particular section or method for highlighting the observations. While the action is clear, the lack of concrete details on execution makes it 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section, which is a specific critique. However, it does not explicitly mention which part of the experimental section is problematic, making it weakly grounded. The comment is specific in suggesting that highlighting these observations and conclusions would be beneficial for understanding the tradeoffs of annotation effort and training performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section, implying that they are not wellpresented or highlighted. However, the comment does not provide specific examples or detailed reasoning to support this claim. It suggests that highlighting these observations and conclusions would be beneficial, but without further elaboration, the claim remains 3. The authors may need to infer the specific observations and conclusions being referred to, making it challenging to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these elements would be beneficial for understanding the tradeoffs of annotation effort and corresponding training performance. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by making the observations and conclusions more prominent. However, the comment could be more helpful if it offered specific guidance on how to highlight these sections or what aspects should be emphasized. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is explicit and provides a clear action for the authors to take, which is to conduct ablation experiments. However, it does not specify which modifications should be tested or how to conduct the experiments, leaving some details to be inferred. While the action is clear, the lack of concrete guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that conducting ablation experiments would be beneficial to validate the model performance using the modifications mentioned in Section 3.4. However, the comment does not provide any specific examples or references to support the claim that these modifications are necessary or beneficial. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors conduct ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s validation and experimental analysis. By including ablation experiments, the authors can demonstrate the effectiveness of their model and strengthen the paper\"s claims. However, the comment could be more helpful if it provided specific guidance on which modifications to test or how to conduct the experiments. Overall, the feedback is 4 as it directs the authors to a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1\" and \"Zhang et. al.\" (presumably references to specific sections or figures in the paper), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed: a comparison of performance on datasets with a decision space beyond binary. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary, referencing Zhang et al. as an example. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary, which could provide valuable insights into the robustness of the approach. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what specific datasets should be considered. While it identifies an area for potential improvement, the feedback is somewhat vague and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions imply that the authors should investigate these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explore the impact of capacity on FID and consider potential artifacts in the pipeline, but the comment lacks specific details or suggestions on how to conduct these investigations. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, such as specific sections or experiments where these issues are discussed. The authors may infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for information about the impact of capacity and artifacts, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions themselves are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could be valuable for the authors to address. The first question asks how the capacity of the SR model affects the FID, which could provide insight into the relationship between model capacity and performance. The second question about unexpected artifacts due to the proposed method being pipelined could help the authors identify potential issues or limitations in their methodology. However, the comment lacks specific guidance or suggestions on how to investigate or address these questions, leaving the authors with a general direction but without detailed steps to follow. While it points out areas for further exploration, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the appendices, noting that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It questions whether the purpose is merely to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the absence of a \"proof\" for this proposition. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the purpose of Proposition B.1 and provide a proof, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer specific steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the appendices, questioning the purpose of Proposition B.1 and noting the absence of a \"proof\" for this proposition. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It questions whether the purpose is merely to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also notes the absence of a \"proof\" for this proposition. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the purpose is unclear or that the \"proof\" is missing. This makes the claim 3, as the authors would need to further explore the context and rationale behind these claims to fully understand and address them.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It questions whether the purpose is merely to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the absence of a \"proof\" for this proposition. This feedback is 3 as it highlights a potential gap in the paper that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to clarify the purpose or provide a proof, which would guide the authors in making improvements. Overall, the comment is 3 as it directs the authors to a specific area needing attention, but it lacks detailed guidance on how to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments. The comment is specific about the types of experiments that are missing, giving the authors a concrete understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing the types of experiments that are missing, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would enhance the paper. Without such evidence or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly points out areas where the paper could be strengthened by including these experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a concern about the use of approximations in the paper, specifically mentioning lines 107110. It suggests that the authors should expand on the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what additional information should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should expand on the possible vulnerability of the approximations, particularly regarding the assumption of attacks being in the feasible set only in those lines. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of approximations in the paper leaves \"loose ends\" and suggests that the possible vulnerability of these approximations needs to be expanded to reassure readers. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the concern about the vulnerability of the approximations. As a result, the claim is 3, as it requires further elaboration to be fully understood and actionable by the authors. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of approximations in the paper, specifically mentioning lines 107110. It points out that while approximations are necessary, the paper does not adequately address the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. The comment suggests that the authors should expand on this issue to reassure readers that it is not a real concern. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address it. However, it could be more helpful if it included suggestions on how to present this information or what additional details should be included. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses a subjective opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors might address this perception or improve the contribution of their work. There is no explicit or implicit action for the authors to take, such as suggesting alternative approaches or improvements to the model. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution of the paper and the approach of the proposed model, but it does not specify which part of the paper this perception is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution or approach are considered incremental or limited. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific reasoning or examples to support this claim or offer suggestions for improvement. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their work need attention or how to enhance its impact. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct a more careful analysis of the model\"s performance, especially on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis, it does not specify exactly how to do so or what additional details should be included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. However, the comment does not specify which part of the paper discusses the model\"s performance or the evaluation procedures, making it weakly grounded. The comment is specific in suggesting that more careful analysis is needed and that additional details about the evaluation procedures would be helpful. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. However, the comment lacks specific examples or references to support the claim that the model\"s performance is due to indirect exposure through data curation. Without such evidence or detailed reasoning, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides a logical suggestion but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It suggests that more careful analysis is needed, particularly for these benchmarks, and recommends providing more details about the evaluation procedures. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct the analysis or what additional details should be included in the evaluation procedures. This limits the comment\"s usefulness, as it points out a potential weakness but does not offer actionable steps for the authors to address it. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the experimental part of the paper, specifically noting that the different metrics used for different OPE methods are not consistent across the two sets of benchmarks presented in Figures 4 and 5. The reviewer explicitly requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The comment is concrete, as it specifies the issue and provides a clear direction for addressing it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy in the metrics used for different OPE methods across the two sets of benchmarks presented in the figures. This provides clear guidance on what needs to be addressed, namely the differences between the two sets of evaluation methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part of the paper verifies different metrics for different OPE methods but notes a discrepancy in the metrics used across the two sets of benchmarks presented in Figures 4 and 5. The reviewer suggests that the authors should provide comments on the differences between the two sets of evaluation methods. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental part of the paper, noting that the metrics used for different OPE methods are inconsistent across the two sets of benchmarks presented in Figures 4 and 5. It explicitly requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their experimental design that could impact the validity and reliability of their results. By providing a specific request for clarification, the comment offers valuable guidance for improving the draft. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method does not show any advantage without prior information, but only when using prior knowledge. The reviewer suggests that this comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. While the comment identifies an issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider the extra complexity and cost of using prior knowledge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not show any advantage without prior information but only when using prior knowledge. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not show any advantage without prior information but only when using prior knowledge. The reviewer supports this claim by explaining that the method essentially requires two separate representation models, which adds complexity and cost. This logical reasoning and the explanation of the additional complexity provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not show any advantage without prior information but only when using prior knowledge. The reviewer points out that this comparison is unfair because the proposed method essentially requires two separate representation models, which adds complexity and cost. This feedback is valuable as it highlights a potential weakness in the experimental setup and suggests that the authors should consider the impact of prior knowledge on the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or how to design a more fair comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include collaborative games in their experiments to explore how the evaluated methods behave in both collaborative and competitive settings. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to implement this suggestion or what specific collaborative games should be included. The authors are left to infer the details of how to incorporate collaborative games into their experiments, which could be improved with more concrete instructions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper this issue pertains to, such as the sections where the experiments are described or discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of collaborative games, but without grounding, it is difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of collaborative games in the experiments. It suggests that including such games would be beneficial to explore the behavior of the evaluated methods in both collaborative and competitive settings. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in their experiments. However, it could be more helpful if it offered examples of collaborative games or provided guidance on how to incorporate them into the existing experimental setup. Overall, the comment is 4 as it points out a meaningful area for improvement and provides a clear suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific settings to include or suggesting ways to improve the figures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of experimental settings for these figures, making them difficult to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the absence of experimental settings for figures 1 to 9. This is a critical observation that could impact the credibility and persuasiveness of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the figures. While it points out a problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment identifies a specific area for clarification, it does not provide explicit instructions on how to address this issue or what specific details should be included in the clarification. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the need for clarification on the proposed method\"s avoidance of impeding the learning of new task knowledge. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rationale behind the work is based on the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the need for clarification and address it themselves, rather than having a clear rationale provided by the reviewer. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment highlights an important area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential weakness in the rationale but lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the possibility of using other statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment implies that the authors should explore these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these alternatives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the regularization term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. Additionally, it provides a specific example of using the median instead of the mean in the regularization. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the possibility of using other statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment provides a logical reasoning for the need for more theoretical support, it lacks specific examples or references to substantiate the claim about the median. This makes the claim 3, as the authors would need to further explore the potential benefits of using the median in the regularization. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also provides a specific example of using the median instead of the mean in the regularization, which could improve the robustness of the method. This feedback is clear and actionable, as it points out a specific area for improvement and offers a concrete suggestion. However, it could be more helpful if it provided additional context or examples to guide the authors in implementing these changes. Overall, the comment is 4 as it directs the authors to a meaningful area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It clearly states the action needed, which is to integrate benchmark comparisons against stateoftheart fairness algorithms. This provides a concrete and specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of comparisons with existing fairness algorithms. The comment provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would significantly enhance the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that integrating benchmark comparisons with stateoftheart fairness algorithms would enhance the paper by providing tangible evidence of the proposed method\"s performance and positioning it within the existing FairML research landscape. This claim is 3 as it logically suggests that comparisons with existing algorithms would strengthen the paper, but it lacks specific examples or references to existing fairness algorithms that could be used for comparison. The authors would need to infer the specific algorithms to include, which adds a degree of uncertainty. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section, noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper by offering tangible evidence of the proposed method\"s performance and positioning it within the existing FairML research landscape. This feedback is 5 as it guides the authors on how to strengthen their experimental section and improve the overall quality of their work. By addressing this suggestion, the authors can significantly enhance the credibility and impact of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of their proposed method and to include the iteration cost of all related methods, including baseline methods. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and direct, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the iteration cost should be discussed, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and the iteration cost of all related methods, including baseline methods. This provides clear guidance on what the authors need to include in their discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the iteration cost is a critical aspect to discuss. The authors are left to infer the importance of this discussion themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a detailed discussion on computational efficiency. By addressing this point, the authors can improve the comprehensiveness and clarity of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It explicitly instructs them to report average results over multiple runs, which is a clear and actionable step. It also suggests discussing the decision boundaries in the toy dataset, which is another actionable point. Additionally, it asks for clarification on what information is in Fig. 9, which is a specific request for more detail. Each of these points is clearly stated and provides concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section\" and specific sections within it, such as \"Sec. 3.1\" and \"Sec. 3.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what needs to be addressed, such as reporting average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes several claims regarding the experimental section, including the need to report average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these suggestions. Therefore, the claims are considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental section, particularly regarding the need to report average results over multiple runs to clarify the results. It also suggests discussing the decision boundaries in the toy dataset and clarifying the information in Fig. 9. These points are clear and offer concrete suggestions for improvement, which can help the authors enhance the clarity and robustness of their experimental results. However, the comment could be more helpful if it provided additional context or examples on how to implement these suggestions effectively. Overall, the feedback is 4 as it guides the authors toward improving the experimental section, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the dimensionality problem or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed model, specifically that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\"s dimensionality, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a relevant observation that could impact the practicality and applicability of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate its impact on the model. Without actionable advice or additional context, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homolumo gap, suggesting that it may lead to negative transfer. It provides an example of TransformerM performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the model. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the use of supervised pretraining and its potential impact on downstream tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prediction of homolumo gap\" and the \"QM9 in downstream experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the TransformerM model performs poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, as evidenced by TransformerM\"s poor performance on most tasks except for homo, lumo, and gap. The reviewer provides an example from downstream experiments on QM9, which supports the claim. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have observed similar negative transfer effects. As it stands, the claim is 4 due to the example provided, but it could be further substantiated with additional evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homolumo gap, suggesting that it may lead to negative transfer. It provides an example of TransformerM performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. This feedback is 3 as it highlights a potential weakness in the paper\"s claims and suggests that the authors should reconsider their approach. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue or mitigate negative transfer. Overall, the comment is 3 as it points out a potential problem but lacks detailed guidance on how to resolve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" statement on lines 8082 regarding the center correlation not being insightful for discriminating model defenses, but then using it in figure 4 A&B. The reviewer questions why the metric was considered useful in one place but not another, or what the authors meant by their statement. This feedback implies that the authors should clarify their reasoning or explanation for using the center correlation in both places. However, it does not provide explicit instructions on how to address this issue, leaving the authors to infer the necessary actions. The comment is 3 as it identifies a potential inconsistency but lacks concrete guidance on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8082) and figures (A&B), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" reasoning for using the center correlation metric in figure 4 A&B, despite claiming it is not insightful for discriminating model defenses. This provides clear guidance on what needs to be addressed, namely the inconsistency in the authors\" reasoning or the clarification of their statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" statement on lines 8082 regarding the center correlation not being insightful for discriminating model defenses, but then using it in figure 4 A&B. The reviewer expresses confusion about the authors\" reasoning or what they meant by this statement. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim of inconsistency. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" reasoning regarding the center correlation metric. It points out that the authors claim it is not insightful for discriminating model defenses but then use it in figure 4 A&B. This feedback is valuable as it prompts the authors to clarify their reasoning or explanation for this inconsistency, which could lead to a more coherent and robust presentation of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the center correlation metric in a more consistent manner. Overall, the comment is 4 as it highlights an important area for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" may be too strong to accurately represent the empirical phenomenon presented. It points out that the total variation between the test and train distributions of the network\"s outputs might not be zero, and that this conclusion is difficult to draw from a few test functions where the outputs match. However, the comment does not provide explicit guidance on what term or phrasing would be more appropriate or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative terms or phrasing to better represent the phenomenon. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it might be too strong to capture the empirical phenomenon presented and suggesting that the total variation between the test and train distributions of the network\"s outputs might not be zero. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the appropriateness of the term \"distributional generalization\" to describe the phenomenon presented, suggesting that it might be too strong. The reviewer provides a logical reasoning by explaining that the total variation between the test and train distributions of the network\"s outputs might not be zero, which is a valid point. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the issue themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"distributional generalization\" used to describe the phenomenon presented in the paper. It points out that the term might be too strong and that the total variation between the test and train distributions of the network\"s outputs might not be zero, which could lead to a misleading conclusion. The comment provides a clear and actionable suggestion for the authors to reconsider the term and its implications, which is valuable feedback for improving the clarity and accuracy of the paper. However, the comment could be more helpful if it offered specific alternative terms or phrasing that would better capture the phenomenon. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges the theoretical contribution as \"ok but not particularly strong\" and points out that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It does not suggest specific ways to strengthen the theoretical contribution or offer guidance on how to make the proof more novel. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the theoretical contribution of the paper, specifically mentioning that it is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is considered weak or unoriginal, but without grounding, it lacks actionable guidance for the authors to improve their draft. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical contribution is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the theoretical contribution as \"ok but not particularly strong,\" indicating that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. While the comment identifies a potential weakness in the theoretical contribution, it does not provide specific suggestions or guidance on how the authors might strengthen their theoretical contribution or improve the proof. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper to ensure fairness and correctness. While the comment provides explicit actions to take, such as including ablation and using the same setup as in the DEN paper, it does not specify how to implement these actions. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental evaluation, such as the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. Additionally, it points out the need for a more comprehensive comparison with the DEN paper, including using the same setup. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks ablation for the \"picking\" step and that the comparison on CIFAR is not convincing. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper. The comment provides some reasoning by pointing out the extensive experiments in the continual learning literature and the need for a fair comparison. However, it lacks specific examples or references to support the claim that the comparison is not convincing. This makes the claim 3, as the authors would need to infer the need for ablation and a more comprehensive comparison based on the reasoning provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper to ensure fairness and correctness. This feedback is clear and actionable, as it provides specific guidance on how to improve the experimental evaluation section. However, it could be more helpful if it included examples of what ablation should entail or how to set up the comparison with the DEN paper. Overall, the comment is 4 as it directs the authors to make significant improvements in their experimental evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" to make the plot easier to interpret. While the comment provides a specific suggestion for clarity, it does not offer detailed guidance on how to implement this change or why it is necessary. The action is explicit but somewhat vague, as the authors know they need to make the change but may not be entirely sure of the exact implementation or rationale behind it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plot\" and suggests a specific change to \"above/below diagonal\" instead of \"above/below 45 degree.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the clarity of the plot labels. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer provides a logical reasoning that \"above/below diagonal\" is clearer because it refers to a visual aspect, while \"above/below 45 degree\" is more ambiguous. However, the comment lacks specific examples or references to support the claim that \"above/below diagonal\" is more interpretable. This makes the claim 3, as the authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to improve the clarity of the plot by using \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear and concise way for the authors to enhance the interpretability of their plot, which is a valuable contribution. However, the comment could be more helpful if it explained why \"above/below diagonal\" is more intuitive or provided examples of how this change might improve the plot. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear suggestion for enhancing the clarity of the plot."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with lines L240 and L428, questioning the phrase \"is sufficient\" and suggesting that the authors might want to clarify what is meant by \"the sum of the optimistic hoped for rewards is close to the expected actual rewards.\" While the comment identifies a potential area for clarification, it does not provide explicit instructions on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of the phrase. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the phrase \"is sufficient\" and suggests that the authors might want to clarify what is meant by the sum of the \"optimistic\" hopedfor rewards being close to the expected actual rewards. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"is sufficient\" in lines L240 and L428, suggesting that the authors might want to clarify what is meant by the sum of the \"optimistic\" hopedfor rewards being close to the expected actual rewards. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the phrasing in lines L240 and L428, questioning whether \"is sufficient\" is clear and suggesting that the authors might want to clarify what is meant by the sum of the \"optimistic\" hopedfor rewards being close to the expected actual rewards. While the comment highlights a potential area for clarification, it does not provide detailed guidance or suggestions on how to improve the clarity or what specific changes should be made. The feedback is 3 as it points out a potential issue, but it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism over prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior. The reviewer does not provide explicit guidance on how the authors should address this issue, but the implication is that they should provide a clearer explanation of the relationship between their work and prior taskoptimized approaches. The comment is 3 as it identifies a gap in understanding but lacks concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. The comment highlights a lack of clarity regarding the relationship between the model and nonlinear RNN models that exhibit emergent behavior. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the scientific insight provided by the model and formalism over prior taskoptimized approaches. It claims that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which is a critical point for understanding the contribution of the work. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide additional evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. It points out that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which raises concerns about the contribution of the work. The comment highlights a critical gap in understanding the relationship between the model and prior approaches, suggesting that the authors need to provide a clearer explanation of their work. While the comment identifies a crucial area for improvement, it could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how other works have successfully explained their contributions. Overall, the comment is 3 as it points out a significant weakness but lacks detailed guidance on how to resolve it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the texts in legends and axis labels larger, similar to the text size. It also clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. These actions are direct and concrete, providing clear guidance on how to improve the draft. The authors know exactly what changes to make, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the legends and axis labels, and the beginning of page 6, where Proposition (1) is discussed. It also provides specific suggestions for improvement, such as increasing the font size of captions and legends in Figures 2 and 3, and clarifying the confusion between Proposition (1) and Equation 1. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the texts in legends and axis labels should be larger, similar to the text size, and clarifies the confusion between Proposition (1) and Equation 1. It also provides specific suggestions for improving the font size of captions and legends in Figures 2 and 3. These claims are supported by logical reasoning and specific examples, making the comment 4. However, the comment could be strengthened by providing additional context or references to similar practices in the field. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the readability of the paper. It points out that the texts in legends and axis labels should be larger, similar to the text size, which is a clear and straightforward suggestion. Additionally, it clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. This feedback is 5 as it directly addresses issues related to the presentation and clarity of the paper, offering concrete steps for improvement. By addressing these points, the authors can enhance the readability and comprehensibility of their work, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments. It specifies that this comparison should be made at a particular step of the sampling trajectory, referring to Figure 2 in Journey TRAK. This provides a clear and concrete action for the authors to take, as they are given specific steps to follow in order to enhance their experimental analysis. The comment is 5 as it provides a direct and specific direction for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the counterfactual experiments and suggests a comparison against Journey TRAK, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be compared (the effect of removing highscoring images according to Journey TRAK) and provides a reference to Figure 2 in Journey TRAK. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison against Journey TRAK would be beneficial for the counterfactual experiments. It references Figure 2 in Journey TRAK, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This provides a logical basis for the claim, as it suggests that including such a comparison could enhance the understanding of the results. However, the comment could be strengthened by providing more detailed reasoning or examples from Journey TRAK to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments. It recommends including a comparison against Journey TRAK, which is a relevant work in the field, at a particular step of the sampling trajectory. This suggestion is based on a specific observation from Figure 2 in Journey TRAK, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. By suggesting this comparison, the reviewer offers a clear and constructive way for the authors to enhance their experimental analysis and validate their results. This feedback is 5 as it provides a concrete direction for improvement, making it easy for the authors to implement the suggestion. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It points out that Table 3 shows ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). The reviewer suggests that the placement of adaptive convolutions is important, but no analysis or comments are provided on this aspect of the technique. While the comment identifies a potential issue, it does not offer specific guidance on how the authors should address this issue or what kind of analysis or comments would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should include analysis or comments on the placement of adaptive convolutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3\" and \"ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of adaptive convolutions and suggests that the placement of adaptive convolutions is important, but it does not provide further details or suggestions on how to address this issue. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions does not always lead to better performance, based on the experimental results in Table 3. The reviewer provides a specific example, ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer), to support this claim. This provides a clear and concrete example, making the claim 4. However, the comment could be strengthened by providing additional analysis or references to similar studies that support this observation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It provides a specific example from Table 3, where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This observation highlights the importance of the placement of adaptive convolutions, which is a valuable insight for the authors. However, the comment lacks detailed analysis or suggestions on how the authors might address this issue or what aspects of the technique should be analyzed further. While it points out a potential area for improvement, it does not provide actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of the tradeoff and possibly explore ways to mitigate it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"ancestral graphs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. The comment further raises a question about the information encoded in the ancestral graph compared to the DAGs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the reduction in search space results in a loss of information. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph, highlighting a potential issue with the method. While the comment identifies a critical aspect of the paper, it lacks specific suggestions or guidance on how the authors might address this concern or improve their work. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional actionable advice or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. While the comment implies that the authors should include such results, it does not provide explicit instructions or concrete steps on how to achieve this. The authors are left to infer that they should include these results, but the comment lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not specify which part of the theoretical discussions needs improvement or which specific results should be included. The authors can infer that it relates to the theoretical sections, but the comment lacks full grounding as it does not explicitly mention the sections or elements being addressed. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on how to implement these changes. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. The reviewer provides a specific expectation, such as \"given confidence levels, what is the sufficient amount of training data points that would not return NSF.\" This suggestion is based on a logical expectation of what should be included in the theoretical discussions, but it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could benefit from additional results related to sample complexity. The reviewer provides a specific example of what they expected, which is a discussion on the necessary amount of training data points to avoid returning NSF based on confidence levels. This feedback is clear and actionable, as it points out a gap in the theoretical discussions and offers a concrete suggestion for improvement. However, the comment could be more helpful if it provided additional guidance on how to implement these changes or examples of similar results in related works. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear direction for enhancing their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of the VAD is puzzling and suggests that the authors should clarify what they mean by \"discarding TF bins with a magnitude of less than epsilon.\" It also notes that this approach is not consistent with a VAD, which is supposed to look for speech presence and is unlikely to be defined over frequency. The comment implies that the authors should reconsider their definition and approach to VAD. While the action is implicit, it is clear and concrete, as it provides a specific issue to address and suggests a potential correction. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the VAD description, which is that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The comment further explains that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that the authors are discarding TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer argues that a VAD should look for speech presence and is unlikely to be defined over frequency, which is a common understanding in the field. The comment provides a logical reasoning and references common knowledge about VADs, making it 4. However, it could be strengthened by providing specific references or examples to support the claim about VADs and their definition. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the description of the VAD, noting that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. It points out that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear understanding of what a VAD should entail. The comment offers a constructive suggestion by suggesting that the authors should reconsider their definition and approach to VAD, which is a valuable piece of feedback for improving the clarity and accuracy of the paper. However, the comment could be more helpful if it provided specific guidance on how to redefine or rephrase the VAD description to align with the reviewer\"s understanding. Overall, the comment is 4 as it highlights a critical issue and offers actionable advice for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. It provides a specific example of what could be discussed, namely the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is explicit and provides concrete guidance on what the authors should add to their discussion. The action is clear and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" and \"Section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the empirical motivation for a timevarying Q ^ t and S t , and provides an example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This suggestion is based on logical reasoning and provides a clear direction for the authors to consider. However, the comment could be strengthened by referencing specific studies or examples to support the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the draft. It highlights the need for a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer offers a specific example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is valuable as it directs the authors to consider a critical aspect of their work that could enhance its clarity and depth. By addressing this suggestion, the authors can improve the comprehensiveness and rigor of their discussion. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It also mentions that the literature has shown that regression methods do not significantly influence the results. The reviewer suggests that the authors clarify this issue and provides a potential solution by suggesting that direct regression to the center point is sufficient. However, the comment does not explicitly instruct the authors to clarify this issue or provide specific guidance on how to address it. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer provides a detailed explanation of the potential confusion regarding the methods and suggests that the authors clarify this issue. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer cites the literature to support their claim that regression methods do not significantly influence the results. However, the comment lacks specific references to the literature or detailed explanations of the differences between the methods. This makes it 3, as the authors would need to conduct further research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the definitions and differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It highlights a potential confusion regarding the methods and suggests that the authors clarify this issue to strengthen the motivations in their work. The comment is 3 as it identifies a specific area of concern and provides a direction for improvement. However, it could be more helpful if it offered more detailed guidance on how the authors might clarify these differences or what specific aspects of the definitions need clarification. Overall, the comment provides some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments lack something to hang on to. However, it does not provide specific guidance on how to improve the clarity or intuition of the paper. The authors are left to infer that they need to make their work more accessible and provide a clearer structure, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of intuition is most apparent. Without explicit references to sections, figures, or experiments, the authors cannot confidently determine which parts need attention. Additionally, the comment does not provide specific guidance on how to improve the clarity or intuition of the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that the experiments lack something to hang on to, but it does not specify what this \"something\" is or how it could be improved. Without concrete evidence or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is not easy to follow and lacks a clear intuition for how the pieces fit together. It also notes that the experiments lack something to hang on to, which further undermines the paper\"s clarity and impact. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or intuition of the paper. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network\"s performance may be improved by training them simultaneously. The reviewer explicitly requests KID/FID metrics for the teacher network, providing a clear and concrete action for the authors to take. This guidance is explicit and specific, leaving no ambiguity about what the authors need to do to address the concern. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"student and refinement networks\" and the \"teacher network,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of the comparison and requests KID/FID metrics for the teacher network. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network\"s performance may be improved by training them simultaneously. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. It explicitly requests KID/FID metrics for the teacher network, which is a clear and actionable request that can help the authors evaluate and improve their work. However, the comment could be more helpful if it provided additional context or examples of how these metrics could be used to assess the fairness of the comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a concrete action to take, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. The reviewer suggests that having a scaling variable before the attention weight might help. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding a scaling variable before the attention weight. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the refined region vector and suggests that having a scaling variable before the attention weight might help. The comment provides a clear direction for improvement by asking whether the refined vector scales only the most important regions before global pooling. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. The reviewer suggests that this might only scale the most important regions by a factor of two. The comment is based on logical reasoning and common knowledge about the attention weight and its application in the context of global pooling. However, it lacks specific examples or references to support the claim that having a scaling variable before the attention weight would help. This makes the claim 3, as it provides a logical basis but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. It suggests that this might only scale the most important regions by a factor of two before global pooling. The reviewer poses a question about whether having a scaling variable before the attention weight would help, providing a clear direction for improvement. This feedback is 3 as it prompts the authors to consider a potential modification that could enhance the effectiveness of their method. However, it could be more helpful if it offered specific suggestions or examples of how to implement this change. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the LLM\"s accuracy or how to handle ambiguities in human language. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of goal misspecification and the consequences of this, such as failures on the ALFRED benchmark. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue and how to address it. Without detailed evidence or reasoning, the claim is not 5, leaving the authors without a clear understanding of the problem or how to improve their draft. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. This is an important observation that could lead to significant improvements in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to conduct the analysis or what specific aspects of the analysis should be focused on. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"IGEV\" and \"SOTA methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. Additionally, it raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the improvement of the method over SOTA methods like IGEV is small, and it raises a concern about the multipeak distribution problem in iterative optimization schemes. The comment suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. However, the comment lacks specific examples or references to support the claim about the distribution of disparities or the difficulty of SamplingGaussian to improve iterative frameworks. While the suggestion to analyze the distribution is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This feedback is valuable as it guides the authors to conduct a specific analysis that could help them understand and address the issue. Additionally, the comment raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While this point is less directly actionable, it still provides a relevant area for consideration. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide modelspecific insights by investigating how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a clear action to take, it does not specify how to conduct the investigation or what specific aspects of the models should be analyzed. The authors are given a general direction but may need to infer the details of how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide modelspecific insights by investigating how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where model comparisons are discussed. The comment is specific in suggesting what additional insights could be added to enhance the paper\"s conclusions. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide modelspecific insights by investigating how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. The comment provides a specific suggestion for improvement by recommending presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This claim is 3 as it logically suggests that modelspecific insights could enhance the paper\"s conclusions. However, the comment lacks detailed reasoning or references to support why these specific models are important or how the FPR comparison would provide nuanced insights. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It suggests presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is valuable as it directs the authors to a specific area where they can enhance their analysis and provide more nuanced conclusions. However, the comment could be more helpful if it explained why these specific models were chosen or how the FPR comparison would contribute to the paper\"s overall contribution. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific in detailing what needs to be clarified, making it 5. Authors know exactly what needs to be done to improve their draft, ensuring that the action is concrete. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the Fourier modes as numbers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests clarifying whether these modes are real or complex numbers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is a specific and actionable suggestion that can help improve the clarity and precision of the paper. By addressing this point, the authors can ensure that their explanation is accurate and complete, which is beneficial for both the readers and the authors themselves. However, the comment could be more helpful if it provided additional context or examples to guide the clarification process. Overall, the comment is 4 as it identifies a specific area for improvement, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to supplement the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to be included in the paper. The comment provides concrete guidance on how to enhance the paper by adding a supplementary result comparison, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, which is the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure. This allows the authors to accurately identify the section that needs revision. The comment is also specific because it clearly specifies what needs to be supplemented, namely the result comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by adding a supplementary result comparison. By addressing this point, the authors can improve the clarity and comprehensiveness of their results, which is valuable guidance for improving the draft. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the overall understanding of the results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include results using the GCPG model without pretrained initializations to clarify the contribution of the task formulation and pretrained language models. This is a clear and direct action for the authors to take, as it provides a specific step to address the issue of attribution. The comment is specific in detailing what additional results are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for results using the GCPG model without pretrained initializations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the contribution due to the task formulation and pretrained language models. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks ablations, specifically the results without pretrained language models. The reviewer claims that it is unclear how much performance gain is due to the task formulation and how much is due to pretrained language models. The suggestion to include results using the GCPG model without pretrained initializations is a logical request to clarify the contribution of the task formulation. However, the comment does not provide specific examples or references to support the claim that the current results are unclear. This makes the claim 3, as the authors would need to make a logical inference to understand the basis of the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of ablations to clarify the contribution of the task formulation and pretrained language models. It provides a clear and actionable suggestion by recommending the use of the GCPG model without pretrained initializations. This feedback is valuable as it guides the authors to conduct additional experiments that can help clarify the impact of the task formulation on performance. However, the comment could be more helpful if it explained why the current results are unclear or how the additional ablations would enhance the understanding of the contribution. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is difficult to understand what the axes are for Figure 1. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the axes should be labeled more clearly or if additional explanations are needed. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve the clarity of the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes in Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand what the axes are for Figure 1. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is 3 as it points out a clear area for improvement in the paper, which is the labeling and explanation of the axes. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or offer alternative ways to present the data. While it highlights an important issue, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider presenting results on ImageNet to enhance the convincingness of their proposed method. While the comment implies that the authors should include these results, it does not provide specific guidance on how to implement this suggestion or what aspects of the results should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should include results on ImageNet to improve the paper\"s credibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not specify which part of the paper should include these results or how they should be presented. The authors cannot confidently determine which section of the paper this comment pertains to, making it weakly grounded. The suggestion is specific in terms of what could be added to enhance the paper\"s credibility, but without clear grounding, it is difficult for the authors to effectively address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this would be beneficial or how it would enhance the credibility of the work. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. While it provides a general direction for improvement, it lacks specific guidance or examples on how to achieve this or what aspects of the results on ImageNet would be most impactful. The feedback is 3 as it points out a potential area for enhancement, but it does not offer detailed advice or actionable steps for the authors to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. This implies that the authors should include direct runtime comparisons to demonstrate the efficiency of their proposed approach. The comment is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of implicit differentiation and its potential impact on runtime efficiency, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. The comment suggests that these comparisons are necessary to demonstrate the efficiency of the proposed approach. While the reasoning is logical and the claim is based on a common understanding of implicit differentiation and its computational implications, it lacks specific examples or references to support the claim fully. This makes the comment 3, as it provides a clear rationale but requires more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper, noting the absence of direct runtime comparisons with existing methods. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach, which is based on implicit differentiation. This feedback is clear and actionable, as it directs the authors to include these comparisons to strengthen their claims about the efficiency of their method. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or suggested potential methods for doing so. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the proposed framework is a simple combination of metalearning and federated learning and does not see any technical contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the framework need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework for being a simple combination of metalearning and federated learning, indicating a lack of technical contribution. However, it does not specify which part of the paper this critique is based on, such as specific sections or figures where the framework is discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity in detailing what aspects of the framework are considered unoriginal or lacking in technical contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, lacking any technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment critiques the proposed framework for being a simple combination of metalearning and federated learning, indicating a lack of technical contribution. However, it does not provide any specific examples or suggestions for improvement, nor does it explain why the combination is considered unoriginal or insufficient. Without actionable feedback or detailed reasoning, the authors are left without a clear understanding of what aspects of the framework need to be addressed or how to enhance its technical contribution. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the insufficiency of the contribution and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. While the comment implies that more insightful findings or solutions should be included, it does not provide specific guidance on what these findings or solutions should be. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to be more comprehensive. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically the connection between complementary and model robustness. It suggests that while the authors have studied this connection, they have not explored how to leverage these characteristics to improve model robustness. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, more insightful findings or solutions to improve model robustness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution is insufficient and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. The reviewer provides a logical reasoning by stating that the conclusion is easily and intuitively obtained, given the relationship between multimodal complementary and robustness. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or to suggest how to improve it. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant concern about the contribution of the paper, noting that while the authors have studied the connection between complementary and model robustness, they have not explored how to leverage this connection to improve model robustness. The reviewer suggests that the conclusion is easily and intuitively obtained, and that more insightful findings or solutions should be included. However, the comment does not provide specific guidance or suggestions on how the authors might expand their analysis or what additional insights or solutions could be explored. While it highlights a potential area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should focus on what the differences in representation are between clusters rather than on which clusters are \"best.\" However, it does not provide explicit guidance on how to implement this change or what specific aspects of the representation differences should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should prioritize the differences in representation over the selection of \"best\" clusters. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the focus on which clusters are \"best\" is an odd choice given the motivation of the paper. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this focus is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the representation differences should be prioritized over the selection of \"best\" clusters. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that focusing on which clusters are \"best\" rather than the differences in representation between them is an odd choice given the motivation of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unaligned with the paper\"s goals. Without specific examples or detailed explanations, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential inconsistency in the paper\"s focus, suggesting that the authors should prioritize the differences in representation between clusters rather than which clusters are considered \"best.\" This feedback is 3 as it identifies an area where the paper may not align with its stated motivation. However, the comment lacks specific guidance on how to address this issue or what aspects of the representation differences should be emphasized. While it highlights a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to correct the caption. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption for Figure 7, and provides the correct label (\"Edge Dynamics\"). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the caption for Figure 7 is incorrect and should be corrected. However, it does not provide any supporting evidence, reasoning, or references to justify why the current caption is incorrect or how it should be corrected. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the caption for Figure 7, noting that it should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and clarity of their paper. By correcting this mistake, the authors can enhance the quality and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment explicitly states the need for case studies and error studies, it does not provide specific guidance on how to implement them or what aspects to focus on. The action is clear but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Elementlevel Graph Pretraining\" and the \"complex structure\" mentioned in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that case studies and error studies could be beneficial in demonstrating the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits. However, the comment lacks specific examples or detailed reasoning to fully substantiate why case studies and error studies are necessary or how they would enhance the paper. While it provides a logical argument, the lack of detailed evidence or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of each proposed component. It highlights the importance of such studies by referencing an example from \"Graph pretraining for AMR parsing and generation,\" which illustrates the potential benefits of including these analyses. This feedback is valuable as it offers a concrete way for the authors to enhance the persuasiveness and credibility of their work. However, the comment could be more helpful if it provided specific guidance on how to design and conduct these studies, such as what aspects to focus on or how to present the results. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer requests clarification on the rationale for considering these factors as separate evaluations. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their evaluation criteria. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The comment is specific in its critique of the evaluation criteria and provides a logical explanation of how they might be entangled. However, it does not explicitly mention which part of the paper discusses these evaluation criteria, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific examples or references to support the claim that these factors are already considered within the framework. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their motivation for considering these factors as separate evaluations. While it identifies a potential area for clarification, the feedback is 3 as it points out a potential weakness in the paper but does not provide actionable steps for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies what needs to be clarified: the standard deviation after multiple experiments and the improvement brought by SoRA compared to the baseline. The comment provides guidance on how to address this issue by suggesting the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the improvement brought by the SoRA method is limited due to random fluctuations, suggesting that the standard deviation after multiple experiments is not provided. The comment provides a logical reasoning by pointing out that the improvement may be due to random fluctuations, but it lacks specific examples or references to support this claim. The authors are left to infer the significance of the standard deviation and its impact on the results, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, noting the absence of standard deviation after multiple experiments. It also points out that the improvement brought by the SoRA method is limited, which may be due to random fluctuations. The comment provides clear and actionable feedback by suggesting that the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This guidance is valuable as it helps the authors understand the significance of their results and how to present them more effectively. However, the comment could be more helpful if it offered suggestions on how to address the issue of standard deviation fluctuations or provided examples of how other studies have handled this challenge. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. While the comment provides explicit actions for the authors to take, such as increasing font size and ensuring proper placement, it does not offer detailed guidance on how to address these issues. The authors are left to infer the specific steps needed to improve the organization and layout of their paper. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figure 1,\" \"Figure 2,\" \"Table 2,\" and \"page 6,\" allowing the authors to accurately identify the areas being addressed. It also specifies the issues with the layout, such as the font size and placement of figures and tables, and the formatting of the top two lines on page 6. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and that the layout is rushed, providing specific examples such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These examples are detailed and provide clear justification for the claim, making the comment 4. However, the comment could be strengthened by providing additional context or references to similar issues in other papers, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the organization and layout of the paper. It identifies issues such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. By pointing out these specific problems, the comment empowers the authors to make improvements that enhance the clarity and professionalism of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing examples of better formatting or offering alternative layout options. Overall, the comment is 4 as it provides clear guidance on areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not provide specific guidance on how to assess or address these concerns. The authors are left to infer that they need to consider practicality and safety, but without concrete steps or examples on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not specify which part of the paper this issue pertains to, such as the intervention section or the results section. The authors can infer that it relates to the intervention or querying aspects, but this inference is not direct. The comment is specific in its suggestion to consider practicality and safety, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that while the types of interventions included are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. This feedback is valuable as it highlights a critical aspect that the authors may have overlooked, prompting them to consider the practical implications of their work. However, the comment could be more helpful if it provided specific examples or suggestions on how to assess and address these concerns. Overall, the comment is 3 as it directs the authors to consider a crucial aspect of their work, but it lacks depth and actionable guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or definitions, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper faces\" of the convex hull, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for better explanation of the dual subdivision and projection process, as well as the issue with the variable \"p\" not being explicitly defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the meaning of \"upper faces\" of the convex hull and the dual subdivision and projection process. It also points out the lack of explicit definition for the variable \"p,\" which has been used extensively throughout the paper. These are factual observations that do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several areas of confusion or lack of clarity in the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. These are important issues that could impact the understanding and interpretation of the paper. The comment suggests that these areas need to be explained better, which is a clear and actionable piece of feedback. However, it could be more helpful if it provided specific suggestions on how to clarify these concepts or offered examples of how they have been addressed in similar works. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they could make to support the integration of images and their augmentations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the idea are questionable or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting that they can be interchangeable. However, it does not provide any specific reasoning or evidence to support this claim or offer suggestions for how the authors might address this concern. Without actionable feedback or detailed guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their proposed method separately from baseline detection or parsing techniques to better support their claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. The suggestion is concrete, as it specifies the need for separate evaluations and provides a rationale for why this is important. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generative shape model\" and the \"word parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that it is unclear which component contributes to the performance gain and recommends evaluating the method separately from baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain, and suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. The comment provides a logical reasoning by suggesting that the proposed approach follows a detectionparsing paradigm, which implies that evaluating separately would be beneficial. However, the comment lacks specific examples or references to support the claim, such as mentioning which baseline techniques should be used or providing data to substantiate the claim. This makes the claim 3, as it provides a reasonable argument but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing the issue of component attribution. By following this suggestion, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it included examples of baseline techniques or detailed guidance on how to conduct the separate evaluations. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. While the comment implies that the authors should reconsider their approach, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their methodology and potentially revise the paper to include more automated disentangling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The comment suggests that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. However, the comment lacks specific examples or references to support the claim that manual disentangling is not necessary or beneficial. Without detailed reasoning or evidence, the claim remains 3, as it provides a logical suggestion but lacks the necessary support to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the manual disentangling process in the paper, questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it demonstrated everything being learned without manual disentangling. This feedback is 3 as it prompts the authors to consider alternative approaches or methods for automating the disentangling process. However, the comment lacks specific suggestions or guidance on how to achieve this, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of connection between the theoretical analysis and the proposed method, specifically regarding the use of selfattention mechanisms in the context of graph neural networks (GNNs). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to strengthen the connection between the theoretical analysis and the proposed method, or how to enhance the generalization for distant nodes. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical analysis and the proposed method, specifically mentioning the use of selfattention mechanisms in the context of graph neural networks (GNNs). However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing the issue of a lack of connection between the theoretical analysis and the proposed method, as well as the need for clarity on how the proposed method enhances generalization for distant nodes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical analysis does not have a strong connection to the proposed method, and that the method seems to simply adopt the selfattention mechanism from transformers. The reviewer questions how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a gap in the connection between the theoretical analysis and the proposed method, specifically regarding the use of selfattention mechanisms in the context of graph neural networks (GNNs). It points out that the proposed method seems to simply adopt the idea of selfattention from transformers and apply it to graphs, without explaining how it enhances generalization for distant nodes. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or strengthen the connection between the theoretical analysis and the proposed method. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether they should provide additional analysis, discuss the implications, or suggest alternative approaches. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Lipschitz Hessian assumption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the method\"s behavior without the Lipschitz Hessian assumption. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the method\"s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the robustness and generalizability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific aspects of the method might be affected. While it points out a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"equation (12)\" and \"the presentation of these methods,\" which provides some grounding by referencing specific parts of the paper. However, it does not specify which parts of the paper these references pertain to, such as sections or figures. This makes it weakly grounded, as the authors cannot confidently determine the exact parts being addressed. The comment is specific in pointing out the issue of vagueness in the presentation of existing methods, but it lacks detailed guidance on how to improve clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some pieces rely on existing methods, such as equation (12), and that the presentation of these methods is vague. This feedback is 3 as it points out a potential weakness in the paper\"s originality and clarity. However, the comment lacks specific suggestions or guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment implies that the authors should provide explanations for these choices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for these decisions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the main rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the experimental setup need clarification or explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification about the rationales behind certain experimental decisions. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the rationales behind certain experimental decisions, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While it identifies areas that need clarification, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these questions. The feedback is 3 as it points out potential areas for improvement, but it could be more beneficial with additional context or suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include the results for all four datasets in Table 4, which provides a clear and direct action for the authors to take. The comment is specific in identifying the missing information and offers a concrete step to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely the results for all four datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and should include results for all four datasets. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and concrete step to improve their draft. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their results, which is valuable guidance for improving the paper. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific guidance or suggestions on how to improve it. There is no explicit or implicit action for the authors to take, such as suggesting ways to clarify or organize the content. Without any concrete steps or advice, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not specify which parts of the paper are affected. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or presentation are jumbled, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references, the authors may find it challenging to understand the basis of the critique or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific examples or guidance on how to improve the clarity or organization of the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what aspects of their writing need attention or how to address the issue. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment does not explicitly instruct the authors to perform a computational complexity analysis or provide guidance on how to address the power demand concern, it implies that the authors should consider these aspects. The action is implicit but concrete, as it points to specific areas that need attention. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where computational complexity is discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific in its inquiry about computational complexity and power demand, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, the comment lacks specific examples or references to support the claim about computational complexity or power demand. Without detailed evidence or comparisons, the claim is not 5, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment identifies a relevant concern about computational complexity and power demand, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It explicitly states that these heads are active at the S2 token but do not primarily attend to it, referencing Section 3 of Wang et al., 2023. This provides a clear and concrete action for the authors to correct the statement in their draft. The comment is explicit and provides specific guidance on how to revise the text, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the incorrect claim about the attention of these heads and references Section 3 of Wang et al., 2023 to support its assertion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect, citing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to the external work, which provides a clear and verifiable basis for the assertion. The authors can easily verify the claim by consulting the referenced section, making the comment 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It points out that these heads are active at the S2 token but do not primarily attend to it, which is a critical correction for the authors to make. The comment is clear and actionable, providing the authors with specific guidance on how to correct their draft. By addressing this issue, the authors can improve the accuracy and clarity of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not provide any specific guidance or suggestions on how the authors could improve the contribution or make it more novel. The comment lacks actionable details, such as recommending new approaches or improvements to the pipeline. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not specify which part of the paper this assessment is based on, such as the methodology, results, or discussion sections. Without explicit references to specific sections, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of the pipeline are considered a \"pack of tricks\" or how the defense evaluation could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the pipeline is a \"pack of tricks\" or that the contribution is incremental. Without such support, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. It implies that the pipeline is a \"pack of tricks\" to improve defense evaluation. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not identify areas where the work could be expanded or enhanced, nor does it offer guidance on how to make the contribution more novel or impactful. As a result, the comment is not helpful, as it does not provide the authors with any meaningful insights or direction for improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, it does not provide explicit guidance on how to develop a distributed version or what specific aspects need to be considered. The action is implied and somewhat vague, as the authors can infer that they need to develop a distributed version but are not given concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, suggesting that it is not scalable without a distributed version. However, it does not specify which part of the paper discusses the method or where the scalability issue is discussed. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides a clear suggestion for improvement, it lacks specificity regarding the part of the paper that needs attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, the comment does not provide specific reasoning or examples to support this claim. It lacks detailed explanation or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the method, suggesting that it may not be scalable without a distributed version. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specificity and does not provide actionable guidance on how to address the scalability issue or what aspects of the method need to be revised to make it more scalable. While it points out a potential weakness, it does not offer detailed suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the eta_ri term is not clearly explained as a noncentral chisquared distribution. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to clarify this point. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"eta_ri term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the eta_ri term being a noncentral chisquared distribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the eta_ri term being a noncentral chisquared distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this term should be considered a noncentral chisquared distribution. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the eta_ri term being a noncentral chisquared distribution. This is a clear and actionable point that the authors can address to improve the understanding and clarity of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the implications of this clarification. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggests that the authors should provide more specific examples or references to support their claims. It also critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the authors should focus on generalization capabilities instead. While the comment provides some guidance on what needs to be clarified or revised, it does not offer explicit instructions on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (L15 and L1618), allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the discussion on certain RNNs working well for certain natural language reasoning tasks, suggesting that the reinforcement learning/agent analogy is out of place and that the examples later in the paper better illustrate generalization capabilities. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggests that the authors should provide more specific examples or references to support their claims. The reviewer also critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the examples later in the paper better illustrate generalization capabilities. While the comment identifies specific issues, it lacks detailed reasoning or references to substantiate the claims. The authors would need to make a significant effort to understand and address the critique, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and relevance of the discussion on certain RNNs working well for certain natural language reasoning tasks. It suggests that the discussion is vague and recommends providing more specific examples or references to support the claims. Additionally, it critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the examples later in the paper better illustrate generalization capabilities. While the comment identifies areas for improvement, it could be more helpful by offering specific examples or references to support the claims. Overall, the feedback is 3 as it provides actionable guidance but could be more comprehensive to fully address the issues."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more detailed analysis or justification for the proposed algorithm, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of difference in StableDiffusion with the proposed sensitivelayer selection against randomized selection and the absence of mathematical or theoretical justification for Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. The comment provides some logical reasoning by pointing out the lack of difference in StableDiffusion, but it lacks specific examples or references to support the claim about the absence of mathematical or theoretical justification. This makes the claim 3, as the authors would need to further explore the justification themselves to address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion. Additionally, it points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve their analysis. The feedback is 3 as it directs the authors to focus on these aspects, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. This is a clear and direct action for the authors to take, as it provides a specific guidance on how to improve the presentation of their data. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of triples as tuples instead of sets. This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuples instead of sets. This feedback is clear and directly addresses a potential issue with the presentation of the data, which could enhance the readability and understanding of the paper. By following this suggestion, the authors can improve the clarity and precision of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of speed analysis in the experiments, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. It suggests that the improvement on inference speed would be more interesting than reducing FLOPs. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include speed analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of speed analysis and the comparison of inference speed between the proposed network and prior work. It specifies the issue by pointing out the absence of such comparisons, which allows the authors to identify the part of the paper being addressed. The comment is also specific because it clearly articulates the need for comparisons of inference speed and why this would be more interesting than reducing FLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of speed analysis is a significant issue, as the experiments have compared GFLOPs of different segmentation networks but not the inference speed between the proposed network and prior work. The reviewer suggests that the improvement on inference speed would be more interesting than reducing FLOPs. This claim is 3 as it logically points out the importance of speed analysis, but it lacks specific examples or references to support the assertion that the improvement on inference speed is more significant. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of speed analysis in the experiments. It highlights the importance of comparing inference speed between the proposed network and prior work, suggesting that this would be more interesting than simply reducing FLOPs. This feedback is clear and actionable, as it directs the authors to include speed analysis in their experiments. However, it could be more helpful if it provided specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). The reviewer notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this scalability problem or suggest specific actions to improve the scalability of the quantization. The authors are left to infer that they need to address this issue, but without concrete steps, the comment remains 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of scalability in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the problem of quantization being a bottleneck for the method, which is crucial for the authors to understand and address. The comment is specific because it clearly outlines the issue with scalability and the impact on the method\"s purpose. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It also notes that even with clustering before, the cost of quantization is high in terms of both N (number of data) and M (dimension). The reviewer further explains that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. The claim is supported by logical reasoning and references to the paper, providing a clear understanding of the issue and its implications. Therefore, the comment is 5, aligning with a score of 5.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). This is a significant concern, as it affects the speed of VI (variable importance) and the method\"s purpose in big data/big model settings. The comment highlights the bottleneck created by quantization, which could hinder the method\"s effectiveness. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the scalability of the quantization. While it raises an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their methodology against existing methods, such as contrastive decoding, and to address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. The comment provides clear and concrete actions for the authors to take, including specific comparisons to make and issues to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"core methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is comparing the effectiveness of the method against existing methods like contrastive decoding and addressing issues mentioned above. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to existing methods or issues that need to be addressed. This makes the claim 3, as the authors would need to infer the specific methods and issues to be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. This feedback is specific and constructive, guiding the authors on how to enhance the rigor and relevance of their work. However, the comment could be more helpful if it provided examples of specific issues or comparisons to consider. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. It also points out that the validation experiments are not comprehensive and that the time complexity and efficiency of the computation are not clearly analyzed. Additionally, it suggests that the authors should further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what changes are needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment also lacks specificity in terms of what needs to be addressed regarding the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questioning how it would operate effectively when the dataset is not fully perceptible. It also critiques the validation experiments as not comprehensive and points out that the time complexity and efficiency of the computation are not clearly analyzed. The reviewer expects the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it lacks specific examples or references to support the claims, making it 3. The authors would need to make a significant effort to address the issues raised, but the feedback provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. It points out that the algorithm requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. Additionally, it critiques the validation experiments as not comprehensive and suggests that the time complexity and efficiency of the computation are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution rather than the form of the attack. While the feedback provides clear guidance on areas for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 3 as it highlights important areas for improvement, but it lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a statement in the paper that claims every kernel can be described by a feature space parameterized by a neural network, which is not true. The reviewer suggests that the limitation of representing infinitedimensional RKHSs with neural networks should be made more clear. While the comment identifies a specific issue with the claim, it does not provide explicit guidance on how to address it or what specific changes should be made to clarify the limitation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitation, but it lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of feature spaces and neural networks. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of representing infinitedimensional RKHSs with neural networks. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that every kernel can be described by a feature space parameterized by a neural network, pointing out a limitation with RBF kernels and their infinitedimensional representation. The reviewer provides a logical reasoning by referencing the fact that RKHS is famously infinitedimensional, making it impossible to represent with a neural network of finite width. This logical reasoning supports the claim, making it 4. However, the comment could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It points out a limitation with RBF kernels, which are famously infinitedimensional, making it impossible to represent them with a neural network of finite width. The reviewer suggests that the limitation should be made more clear, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a critical aspect of the paper that needs clarification, guiding the authors to enhance the accuracy and completeness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed method is not wellpositioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It suggests that the authors should conduct a thorough literature review to identify other works that use this property. While the comment explicitly states the need for a literature review, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of novelty in the proposed method and the need for a thorough literature review to identify other works that use the same property. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and scoreinterpolation, which have used this property. This provides a clear and robust justification for the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It provides specific examples from the literature, such as the original denoising score matching objective and scoreinterpolation, to illustrate the prevalence of this property. The comment also suggests that the authors conduct a thorough literature review to identify other works that use this property. This feedback is clear and actionable, as it guides the authors to conduct a literature review that could significantly enhance the novelty and impact of their work. However, it could be more helpful if it provided specific suggestions on how to conduct the literature review or what aspects to focus on. Overall, the comment is 4, as it effectively points out a potential weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or improve the handling of autoregressive decoding, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It mentions the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the handling of autoregressive decoding and the potential impact on inference benefits. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It suggests that the use of long token dimensions during training might limit the benefits of inference. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. This feedback is valuable as it prompts the authors to consider the limitations of their approach and how it might impact the inference phase. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how other approaches handle autoregressive decoding. Despite this, the comment still offers a clear direction for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a weakness in the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to substantiate this claim. This feedback is clear and concrete, as it specifies exactly what needs to be done to address the issue. The authors know exactly how to apply this suggestion to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the assumption that PCC is more relaxed than KL divergence due to its invariance to scale and shift. The comment provides a logical reasoning for why this assumption is not convincing and suggests a comparison between the gradients of KL and PCC to substantiate the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by comparing the gradient distribution of KL and PCC, suggesting that this comparison is necessary to substantiate the claim. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the gradient comparison themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key assumption in the paper regarding the relative relaxation of the Pearson correlation coefficient (PCC) compared to KL divergence. It challenges this assumption by pointing out that the constraint strength of a loss function is defined by its gradient distribution, and provides a logical reasoning for why this comparison is necessary. The comment suggests that the authors should provide a gradient comparison between KL and PCC to substantiate their claim. This feedback is clear and actionable, as it guides the authors on how to address a critical aspect of their argument. However, it could be more helpful if it included specific examples or references to similar comparisons in the literature. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should provide additional analysis or discussion, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether GPI with noise added can reproduce the data similarly well and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. Additionally, it mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. However, the comment lacks specific examples or references to support the claim that GPI cannot have a good fit with behavioral data. The suggestion to discuss the approach\"s suitability for pattern separation tasks is somewhat vague, as it does not provide detailed guidance on how to conduct this discussion. Therefore, the comment is 3, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises several pertinent questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also points out that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given direction to consider additional analysis or discussion, but the feedback could be more actionable with concrete steps or examples. Therefore, the comment is 3, as it provides insight into potential areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that if the authors have the resources, they should compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This is an explicit action that the authors can directly take, as it provides a clear direction for further exploration and comparison. The comment is specific in its request, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to compare the two, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be valuable or how it would contribute to the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, which could provide valuable insights into the performance of the proposed method. This feedback is actionable and offers a specific direction for further exploration and analysis, potentially enhancing the robustness and generalizability of the work. However, the comment lacks depth and does not explain why this comparison is important or how it might impact the paper\"s conclusions. To be more helpful, the comment could provide additional context or suggestions on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 3 as it identifies a potential area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. While the comment identifies an issue, it does not provide explicit guidance on how to address it or what specific experiments should be conducted. The authors are left to infer that they need to clarify this point, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the resolution of a debate left open in the paper. The comment questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the resolution of a debate left open in the paper, suggesting that the distribution cannot be considered a factor in the results. It also questions whether experiments disentangle changes in distribution from the removal of information. While the comment raises valid points, it lacks specific examples or references to support the claim that the distribution is a significant factor. The lack of detailed evidence or reasoning makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is 3 as it points out a potential issue in the paper that the authors may need to address. However, the comment lacks specific suggestions or guidance on how to resolve this issue or what experiments should be conducted. While it highlights an area for improvement, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same training method as the other methods. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that direct comparison with the other methods is unfair due to the different training methods. This provides clear guidance on what needs to be addressed to ensure fair comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that directly comparing methods using different training methods is unfair. It suggests that reproducing the results using the same training method as the other methods would be more appropriate. The comment provides a logical reasoning by pointing out the potential bias introduced by using different training methods. However, it lacks specific examples or references to support the claim that using cosine lr is unfair, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. This observation highlights a potential bias in the comparison, as the different training methods could affect the results. The comment suggests that reproducing the results using the same training method as the other methods would be more fair and appropriate. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the fairness and validity of their comparison. However, it could be more helpful if it included examples of how to reproduce the results or why using cosine lr is preferable. Overall, the comment is 4 as it guides the authors on how to address a critical aspect of their comparison."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects to focus on. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section or experiment where this combination is discussed. Without explicit references or clear indications, the authors cannot confidently determine which part of the paper should be addressed. Additionally, the comment lacks specificity regarding what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it identifies an area of interest, it lacks specificity and actionable guidance for the authors. It does not provide details on what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Without concrete suggestions or examples, the comment does not offer meaningful assistance to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the plots are terrible, providing specific issues with the plot quality. It mentions that the plots are too small, colors are hard to distinguish, axis labels are poorly labeled, and labels are visually similar. The reviewer also points out that these issues are the main presentation of the experimental results, which should be clearer. This feedback is clear and provides concrete actions for the authors to take, such as improving the plot size, color contrast, and label clarity. The comment is 5 as it directly instructs the authors on how to enhance the clarity and quality of their plots, ensuring that they are easily understandable and visually appealing.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plots\" and \"plots are terrible,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the plots, such as their small size, color contrast, and unclear labeling. This provides clear guidance on what needs to be addressed to improve the clarity and quality of the experimental results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the plots are terrible, with specific issues such as small size, poor color contrast, unclear axis labels, and visually similar labels. The reviewer provides a detailed description of these issues, which makes the claim 3. However, the comment lacks specific examples or references to support the claim, such as screenshots or detailed descriptions of the issues. This makes it 3, as the authors would need to make a significant effort to understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies several issues with the plots, including their small size, poor color contrast, unclear axis labels, and visually similar labels. The reviewer points out that these issues contribute to the overall clarity of the paper, which is rated as \"substandard.\" By highlighting these specific issues, the comment empowers the authors to make significant improvements to the clarity and quality of their plots, enhancing the overall presentation and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to address the issue of low performance gains. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance gains of the paper, specifically mentioning that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not specify which metrics or parts of the paper this analysis is based on, making it weakly grounded. The comment is specific in detailing the performance gains, but without explicit references to sections or metrics, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment highlights a specific issue with the performance gains of the paper, noting that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). This is a relevant observation that could impact the overall impact and significance of the work. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a series of questions about the impact of the information about incorrect and corrected phrases and the type of mistake on the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. While the questions imply that the authors should analyze and present this information, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis and present the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"information about incorrect phrase / corrected phrase and the information about the type of the mistake,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the impact of this information on the feedback network and the performance without and with each of these two types of information. Additionally, it asks about the performance with just natural language feedback. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point poses a question about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information. It does not make any claims or suggestions that require verification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information. It also inquires about the performance with just natural language feedback. This question prompts the authors to analyze and present data on the effectiveness of different types of information in their feedback network. While the comment does not provide specific suggestions or guidance on how to conduct this analysis, it does offer a clear direction for the authors to explore and potentially improve their work. Therefore, the comment is 3, as it encourages the authors to conduct a meaningful analysis and provides a direction for potential enhancements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with Table 1, noting that it does not show standard deviations. It suggests that this omission would make the submission stronger if the experiments were more extensive. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to include standard deviations. The action is implicit and somewhat vague, as the authors need to infer that they should include standard deviations in Table 1 and potentially expand the experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of standard deviations in Table 1 and the need for more extensive experiments. This provides clear guidance on what changes the authors should make to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations, which would make the submission stronger if the experiments were more extensive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this omission is significant or how it affects the overall strength of the submission. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not show standard deviations. This is a clear and actionable point that could significantly improve the paper by including this information. Additionally, the comment suggests that the experiments could be more extensive, which is a valuable suggestion for enhancing the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided additional guidance on how to expand the experiments or what specific aspects should be included. Overall, the feedback is 4 as it highlights a critical area for improvement and offers a direction for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. However, it does not provide explicit guidance or suggestions on how the authors should address this question or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific tables (1, 2, and 3) and the comparison with a different neural network in 14. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it raises a question about the performance boost due to additional parameters and suggests that a better Unary baseline might affect the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. The comment references a different work (14) for comparison, which provides some basis for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to conduct additional analysis or experiments to fully address the question raised. Therefore, the comment is 3, as it provides a starting point for further exploration but requires more detailed evidence or reasoning to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. It references a different work (14) for comparison and suggests that a better Unary baseline might affect the results. This feedback is 3 as it prompts the authors to consider the robustness of their results and the potential impact of different baselines. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the draft. To be more helpful, the comment could provide actionable steps or examples of how to conduct additional analyses or experiments to validate the results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improving the structure of the paper and highlights specific areas that require more attention, such as the IEM in Figure 3 and the visualization of Figure 7. It also suggests focusing on the IEM in Figure 3, which is considered the main figure in the paper. The comment is clear and provides concrete actions for the authors to take, such as reorganizing the structure of the paper and improving the visualization of specific figures. This level of detail and specificity makes the comment 5, as the authors know exactly what changes to make to improve the clarity and impact of their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the introduction, method, and experiments, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be improved, such as the structure of the paper and the focus on the IEM in Figure 3. Additionally, it provides specific suggestions for improvement, like improving the visualization of Figure 7 and focusing on the IEM in Figure 3. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests improvements to the structure, such as focusing on the IEM in Figure 3 and improving the visualization of Figure 7. While the comment provides some reasoning by mentioning the need for multiple readings and the importance of the IEM, it lacks specific examples or detailed justification for why the current structure is problematic or how the IEM should be improved. The suggestion to focus on the IEM is somewhat vague, as it does not provide detailed guidance on how to enhance the visualization or what specific aspects of the IEM are most important. Therefore, the claim is 3, as it provides some direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s structure, noting that it is hard to follow and requires multiple readings. It provides specific suggestions for improvement, such as reorganizing the structure to prioritize the IEM in Figure 3 and improving the visualization of Figure 7. These suggestions are actionable and can help the authors enhance the clarity and impact of their work. Additionally, the comment highlights the importance of the IEM in Figure 3, which is a crucial aspect of the paper. Overall, the feedback is 4 as it provides clear and constructive guidance for improving the paper\"s structure and presentation. However, it could be more helpful if it offered additional details or examples on how to implement these changes effectively. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback implies that the authors should expand their discussion of related work to include a comparison with their own work. While the action is implicit, it is clear that the authors need to provide a more comprehensive discussion of related work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this discussion should be included in, such as the introduction, literature review, or results section. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a more detailed discussion of related work, but without explicit references to sections or elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This claim is 3 as it provides a logical reasoning for expanding the discussion of related work. However, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors would need to infer the specific aspects of the related work that should be discussed and the differences to the presented work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically the inclusion of a more comprehensive discussion of related work. However, the comment lacks specific guidance on how to structure this discussion or what aspects of the related work should be highlighted. While it points out a potential weakness, it does not provide detailed suggestions on how to address it, making it 3 but not fully actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include attacks on other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which architectures or tasks to consider or how to implement these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper these experiments should be added to or which specific architectures or tasks should be considered. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment is not specific about what aspects of the experiments should be expanded or how they should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends expanding them to include attacks on other architectures and classification tasks. However, the comment does not provide any supporting evidence, examples, or references to justify why this expansion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it identifies a potential area for improvement in the paper, which could enhance its scope and relevance. However, the comment lacks specific guidance on which architectures or tasks to consider or how to implement these experiments. Without detailed suggestions or examples, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. It highlights the concern that the authors only tested four different learning rates and suggests that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. While the comment explicitly states what information is missing and why it is important, it does not provide specific guidance on how to address this issue or what additional testing might be needed. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"deep models\" and \"CIFAR10 and CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing\u2014the final used learning rates for the deep models\u2014and why it is important, as it could affect the results if the optimal learning rate for the baseline is outside the tested interval. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the need for information on the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. The reviewer suggests that if the optimal learning rate for the baseline is outside the tested interval, it could affect the results. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the importance of this information and the potential impact on the results, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by requesting information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is important because it could affect the results if the optimal learning rate for the baseline is outside the tested interval. The comment is clear and actionable, providing the authors with a direct and specific request for additional data or analysis. However, it could be more helpful if it offered suggestions on how to address this issue or what additional testing might be needed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or explain their choice. The comment lacks concrete steps or detailed advice on how to improve the draft, leaving the authors uncertain about what specific actions to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the transformer\"s lack of locality bias, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to substantiate the argument, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. It questions the authors\" explanation for why this choice is appropriate in their context. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this concern or provide a more compelling rationale for their choice. The feedback is 3 as it prompts the authors to consider the implications of their choice, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the output from the algorithm depends on the order in which the data is processed and suggests that this should be clarified. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to clarify this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the order of data processing. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the output from the algorithm depends on the order in which the data is processed and recommends clarifying this aspect. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of the algorithm\"s dependence on data order, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data is processed, suggesting that this should be clarified. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output, suggesting that it depends on the order in which the data is processed. This is a clear and actionable point that the authors should address to improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify this aspect or offered examples of how other studies have addressed similar issues. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the potential impact. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the potential impact of their mitigation strategies on performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies aimed at reducing memorization and questions their impact on the overall performance of the model. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\"s utility could deter adoption. However, the comment does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on performance, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. The comment highlights a potential issue with the adoption of these strategies if they significantly impair the model\"s utility. However, the comment lacks specific examples or references to support the claim that such a tradeoff exists or that the mitigation strategies might significantly impair the model. Without detailed evidence or examples, the claim is 3, as it provides a logical argument but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies aimed at reducing memorization, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It raises a concern about the impact of these strategies on the overall performance of the model, noting that if they significantly impair the model\"s utility, it could deter their adoption. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or mitigate the potential impact on performance. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the reason for using 6fold crossvalidation in the experiments. It points out that other papers in the field did not use crossvalidation, which raises questions about its necessity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the rationale behind the crossvalidation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear explanation for the use of crossvalidation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of 6fold crossvalidation and the comparison with other papers that did not use crossvalidation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of clarity regarding the reason for using 6fold crossvalidation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reason for using 6fold crossvalidation is unclear because other papers in the field did not use it. However, the comment does not provide any supporting evidence or references to substantiate this claim. Without specific examples or detailed reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the reason for using 6fold crossvalidation. It points out that other papers in the field did not use this validation method, which raises questions about its necessity. This feedback is 3 as it highlights an area where the authors need to provide more detailed explanation or justification for their methodology. However, the comment could be more helpful if it suggested ways to address this issue, such as providing a rationale for the use of crossvalidation or discussing its importance in the context of the problem being studied. Overall, the comment provides some insight but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide explicit instructions on how to do so. The action is clear but somewhat vague, as the authors know they need to conduct additional experiments but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three and there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This claim is 3 as it provides a logical reasoning for the need for additional experiments, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments themselves to fully understand the issue and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This feedback is clear and actionable, as it points out a critical weakness in the paper\"s results and provides a concrete direction for improvement. However, the comment could be more helpful if it offered specific suggestions on which experiments or analysis would be most beneficial. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the paper presents an effective engineering method for ReC but notes that the proposed framework incorporates combinatorial and heuristic aspects. It specifically points out the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information about the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the heuristic components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the impact of the heuristic components, such as the sophisticated filtering template. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents an effective engineering method for ReC but notes that the framework incorporates combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential area for clarification, it lacks specific examples or references to support the claim that these heuristic components are problematic or unclear. The reasoning is 3, as it points out a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed framework incorporates combinatorial and heuristic aspects, such as the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components, which is a valuable point for improving the paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify these aspects or what aspects of the heuristic components should be emphasized. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the feasibility of training the proposed method without using camera information, specifically mentioning Line 223 and the \"knowledge of CAD model correspondences.\" It raises concerns about how ray marching can be performed without knowing the viewpoint and the origin of the ray. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification regarding the use of camera information and ray marching. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of training the proposed method without using camera information, particularly regarding the \"knowledge of CAD model correspondences.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the feasibility of training the proposed method without using camera information, specifically mentioning \"Line 223\" and the \"knowledge of CAD model correspondences.\" The comment raises logical concerns about how ray marching can be performed without knowing the viewpoint and the origin of the ray. However, the comment lacks specific examples or references to support the claim that camera information is necessary for training. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the feasibility of training the proposed method without using camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. It highlights the importance of camera information for ray marching and understanding the origin of the ray. While the comment identifies a potential weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a potential problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically mentioning the need for a detailed comparison of time complexity and competitiveness with prior art. While the comment implies that the authors should include such a comparison, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of the comparison should be addressed. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a particular comparison to be made. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, the comment does not provide specific examples or references to prior work that should be compared, nor does it explain why this comparison is necessary or how it would enhance the paper. Without detailed guidance or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. This feedback is 3 as it identifies an area where the paper could be strengthened by providing a more comprehensive comparison with existing work. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper discusses ODA as a method for solving the MOIP problem but does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the method should be emphasized. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA\" and \"MOIP problem,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not clearly explain how the presented method improves performance and computation speed over ODA. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not clearly explain how the presented method improves performance and computation speed over ODA, which is a method for solving the MOIP problem. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without concrete evidence or detailed reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it does not clearly explain how the presented method improves performance and computation speed over ODA, which is a method for solving the MOIP problem. This feedback is 3 as it points out a gap in the paper\"s explanation, but it lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. While it highlights an area for improvement, the comment could be more helpful with additional guidance or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with some figures, particularly Figure 4, where the lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This feedback implies that the authors should provide additional explanations or labels to make the figures more selfexplanatory. However, the comment does not explicitly instruct the authors to add these explanations or labels, leaving the action somewhat implicit. While the authors can infer that they need to address this issue, the comment lacks concrete guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, specifically the lines \"No adapt\" and \"Finetune\" being covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 where lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. However, the comment does not provide specific examples or detailed reasoning to support why these figures are not selfexplanatory. Without additional context or explanation, the authors may find it challenging to understand the issue and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with some figures, particularly Figure 4, where lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it points out a specific area where the figures could be improved to enhance their selfexplanatory nature. By addressing this issue, the authors can enhance the clarity and accessibility of their figures, which is crucial for effectively communicating their research findings. However, the comment could be more helpful if it provided suggestions on how to improve the figures, such as adding labels or descriptions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their sampling method. The comment suggests that the sampling should be evaluated more thoroughly, but it does not specify which benchmarks should be used or how the evaluation should be conducted. The lack of concrete details makes it difficult for the authors to know exactly how to implement the suggested changes. Therefore, the comment is 3, as it identifies an area for improvement but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sampling performed to obtain different initializations x_0, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this sampling is important for convergence to the optimum but is not evaluated thoroughly on the proposed benchmarks, except for Table 1 in the supplementary. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sampling method used to obtain different initializations x_0 is important for convergence to the optimum, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the sampling is not evaluated thoroughly on the proposed benchmarks, except for Table 1 in the supplementary, where it is compared to sampling from a uniform distribution. However, without additional context or examples, the claim lacks sufficient support to be 5. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it points out that this sampling is not evaluated thoroughly on the proposed benchmarks, except for a comparison in Table 1 of the supplementary. While the comment highlights an area for improvement, it lacks specific guidance on how the authors should address this issue or what additional experiments could be conducted to evaluate the sampling method more thoroughly. The feedback is 3 as it directs the authors to consider evaluating the sampling method more comprehensively, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references 9 and 16. It questions why the authors compare the proposed method with 9 first and then 16, and why they only compare the computational cost with 9. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies areas that need clarification and potential issues, it does not provide explicit instructions or concrete suggestions on how to address these concerns. The authors are left to infer that they should provide a more detailed explanation or discussion of these aspects, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it highlights areas that need attention but does not offer detailed guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific papers, \"9\" and \"16,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the logic behind the comparisons, the computational cost, and its relevance in a practical scenario. The comment provides clear guidance on what needs to be addressed, namely the rationale behind the comparisons and the significance of the computational cost. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references 9 and 16. The reviewer questions why the authors compare the proposed method with 9 first and then 16, and why they only compare the computational cost with 9. The comment also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims. The authors are left to infer the basis of the reviewer\"s concerns, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several pertinent questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references 9 and 16. It questions why the authors compare the proposed method with 9 first and then 16, and why they only compare the computational cost with 9. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. These questions highlight areas that need clarification and potential issues in the paper, prompting the authors to reconsider their approach and provide a more detailed explanation or discussion of these aspects. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or improve the paper. Overall, the comment is 3 as it identifies areas that need attention but lacks detailed guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. While the comment explicitly states the need for additional experiments, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results, but this inference is not direct. The comment is specific in suggesting additional experiments and encouraging experiments on the full dataset, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why additional experiments are necessary or how they would improve the evaluation. The claim is based on a general suggestion, but without specific examples or detailed justification, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. This feedback is clear and actionable, as it directly instructs the authors to expand their experimental scope and improve the comprehensiveness of their evaluation. However, the comment could be more helpful if it provided specific suggestions on which datasets to include or how to conduct these experiments. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\" claims. It also mentions that the dataset transformation and experimental setup feel cumbersome and unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the tasks and experimental setup. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the proof of the authors\" claims and the clarity of the experimental setup. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task are unclear and that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without specific references or detailed explanations, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper regarding the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. It highlights that the authors\" claims are not clearly supported by the tasks and experimental setup, which could lead to confusion for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their work. While it points out areas for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. The comment is clear and concrete, as it specifies exactly what needs to be added and how it should be presented. This provides the authors with a direct and specific action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of jointly discovering, hallucinating, and adapting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of discussion on the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. This feedback is clear and actionable, as it points out a critical area that needs attention and suggests a specific improvement to enhance the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects to consider. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, it does not provide specific guidance on how the authors should address this issue or what kind of theoretical evidence would be appropriate. The comment implies that the authors should provide more detailed analysis or theoretical justification, but it does not offer concrete steps or examples of what this might entail. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of the correlation between dataset size and the Frobenius norm and singular values, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of theoretical evidence for the correlation and the need for more detailed analysis across different model architectures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is underwhelming and lacks theoretical evidence. It highlights the need for more detailed analysis and theoretical justification, which is crucial for strengthening the paper\"s contribution. However, the comment does not provide specific suggestions on how to address this issue or what kind of theoretical evidence would be appropriate. While it points out a significant weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leaking is likely due to its policy being obtained through supervised training on ImageNet. It also questions the authors\" conclusion in L114 about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific actions to take. The authors are left to infer that they should consider these points and potentially revise their work, but the feedback lacks concrete steps or suggestions for improvement. Therefore, the comment is 3, as it highlights areas for consideration but does not offer detailed guidance on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the use of AutoAugment as a stronger augmentation strategy and the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity. The comment further raises questions about the implications for SSL algorithms and suggests that combining two datasets might not necessarily lead to better representations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leaking is likely due to its policy being obtained through supervised training on ImageNet. The reviewer questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. The comment is 3 as it provides a logical reasoning for the concern about information leaking and raises questions about the implications for SSL algorithms. However, it lacks specific examples or references to support the claim about information leaking or the potential impact on SSL algorithms. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a number of important questions and concerns about the use of AutoAugment as a stronger augmentation strategy. It points out the potential for information leaking due to the policy being obtained through supervised training on ImageNet, which is a relevant and insightful observation. Additionally, the comment questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, suggesting that this could be a setback for SSL algorithms. The reviewer also raises the question of whether combining two datasets can lead to better representations. While the comment identifies potential weaknesses and areas for improvement, it could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues. Overall, the comment is 3 as it prompts the authors to consider these points, but it lacks detailed guidance or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting but not necessary to explore how the model works with tabular data, specifically by considering each attribute dimension as a modality. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore tabular data but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this could be discussed. The authors can infer that it relates to the model evaluation or methodology sections, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding as it does not explicitly mention where in the paper this should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality, would be interesting but not necessary. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exploration would be beneficial or necessary. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. This is a valuable suggestion as it could provide insights into the model\"s applicability to different forms of data. However, the comment lacks specific guidance on how to implement this exploration or what aspects of the model should be considered. While it identifies a potential area for improvement, the lack of detailed instructions or examples limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed guidance for the authors to fully address the suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include more analysis on the multilingual alignment of entity representations, specifically recommending visualizations or case studies for different types of languages. It also expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific visualizations or case studies should be included. The action is concrete but somewhat vague in terms of execution, as the authors need to determine the specific aspects of multilingual alignment to focus on and how to present the results. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the languageagnostic characters of entity representations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more analysis on the multilingual alignment of entity representations, including visualizations or case studies for different languages. The comment also expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis on the alignment of entity representations, particularly for multilingual alignment. It recommends adding more analysis, including visualizations or case studies, for different types of languages. The comment also expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. While the claim is based on logical reasoning and common knowledge about the importance of multilingual analysis, it lacks specific examples or references to support the suggestion for visualizations or case studies. This makes the claim 3, as it provides a clear direction but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the lack of analysis on the alignment of entity representations, particularly for multilingual alignment. It suggests that the authors should add more analysis, including visualizations or case studies, to address this gap. Additionally, it expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. This feedback is clear and actionable, providing the authors with specific areas to focus on to improve their draft. However, it could be more helpful if it included examples or detailed guidance on how to conduct the additional analysis or visualizations. Overall, the comment is 4 as it directs the authors to a critical area for improvement and offers a clear path for enhancing their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This provides a clear and explicit action for the authors to take, which is to include additional details on using attention in an appendix. The suggestion is concrete, as it specifies the exact location where the additional information should be included, making it 5.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, it does not specify which part of the paper discusses attention or where the additional details should be added. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting an appendix as a potential location for the additional details, but without full grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why additional details on attention are necessary or how they would benefit the paper. Without such justification, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including additional details on a particular aspect of their work. However, the comment could be more helpful if it provided specific examples or detailed guidance on what kind of information should be included in the appendix. Overall, the comment is 4 as it identifies a potential area for improvement and offers a concrete suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to check for duplicates and ensure the correct publication venues and years are included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the references list, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of duplicates and missing publication venues/years, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to verify and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the references list, noting that it contains duplicates and that the publication venues and/or publication years of many of the papers are missing. This feedback is clear and actionable, as it directs the authors to verify and correct their references list to ensure accuracy and completeness. However, the comment could be more helpful if it provided examples of specific duplicates or missing information, which would guide the authors in addressing these issues more effectively. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It suggests that the authors should analyze and compare their theoretical results to those of other comparable methods. This feedback provides a clear and concrete action for the authors to take, which is to clarify the error bound and compare their results with others in the field. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound in Theorem 1 and the need for analysis and comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. The comment suggests that the authors should analyze and compare their theoretical results with those of other comparable methods. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim about the clarity of the error bound or the need for comparison. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and that the authors need to analyze and compare their results with other comparable methods. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the authors clarify the error bound and compare their results. By addressing these points, the authors can enhance the clarity and rigor of their theoretical analysis, which is crucial for the credibility and impact of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out that the pseudocode of the proposed method is missing. It also references external works that may be relevant to understanding the performance difference. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue or what specific aspects of the pseudocode should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include the missing pseudocode and possibly explore the performance difference between explicit and implicit methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"locomotion tasks\" and the \"proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance difference between explicit and implicit methods and points out the missing pseudocode of the proposed method. Additionally, it references external works that could be relevant to understanding the performance difference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and mentions the missing pseudocode of the proposed method. It references external works by S\u00f8ren Asmussen and Peter W Glynn and P. Florence et al., which could provide some basis for the claim. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment is 3 as it requires more detailed explanation or examples to fully justify the claim.", "helpfulness_rationale": "The review comment raises a critical question about the performance of explicit methods compared to implicit methods on locomotion tasks, which is an important aspect of the paper. It also points out the missing pseudocode of the proposed method, which is a significant oversight. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the pseudocode should be included. While it identifies a significant gap in the paper, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not offer detailed guidance for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. It also mentions the method R3F and suggests that the authors should use it to maintain the generalization ability of the model. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the R3F method should be applied. The action is implicit and somewhat vague, as the authors need to infer that they should explore the R3F method to maintain generalization. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs to finetune the multilingual model and mentions the method R3F to maintain generalization ability. However, it does not specify which part of the paper this discussion pertains to, such as a specific section or experiment. The mention of \"lowresource language translations\" and \"R3F\" provides some context, but the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the insignificance of the improvement and suggests using R3F, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. The reviewer supports this claim by referencing the method R3F, which is used to maintain generalization ability. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a reference to a relevant work, the explanation is not comprehensive enough to fully support the claim. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs to finetune the multilingual model, suggesting that the improvement of 0.8 is insignificant in practical terms. It also mentions the method R3F as a potential solution to maintain generalization ability. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the R3F method should be applied. While it points out a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is 3, as it highlights an area for improvement but does not offer detailed guidance for implementation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific reason for the choice of Gaussian noise in the experiments. While it does not explicitly instruct the authors to address this issue, it implies that they should clarify the rationale behind their choice of noise types. The action is implicit but concrete, as the authors can infer that they need to provide a justification or explanation for their choice. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, which is the section where the authors discuss their model\"s ability to work well for a variety of image noise. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the choice of Gaussian noise in the experiments and asks for clarification on the rationale behind this choice. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of Gaussian noise in the experiments, suggesting that there might be a particular reason for this choice. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or justification to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of Gaussian noise in the experiments, which is an important aspect of the paper\"s methodology. It prompts the authors to clarify the rationale behind this choice, which could be crucial for understanding the model\"s applicability and robustness. While the comment identifies a potential area for improvement, it does not provide specific suggestions or guidance on how to address this issue. Therefore, it is 3 as it points out a relevant area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and direct action for the authors to take, as it provides a specific request for visualization that is crucial to the research motivation of the paper. The comment is specific and actionable, as it guides the authors on how to enhance their draft by including visualizations to support their claim. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the performance of existing PU learning methods as the dimensionality of the data increases. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, which is the visualization of this effect. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s claim about the performance of existing PU learning methods as the dimensionality of the data increases. It suggests that visualizing this effect would be beneficial for understanding the research motivation of the paper. This feedback is clear and actionable, as it directs the authors to provide visualizations that can help substantiate their claim and enhance the paper\"s clarity. By addressing this suggestion, the authors can significantly improve the comprehensiveness and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While the comment implies that the authors should consider moving this information to the supplementary materials, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider moving the information to the supplementary materials. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of recommending the placement of the empirical version in the supplementary materials, but without clear grounding, it is difficult for the authors to effectively address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not provide any supporting evidence, reasoning, or references to justify why this is the case. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While it provides a specific suggestion for organizing the information, it lacks depth and does not explain why this change would be beneficial or how it would impact the overall paper. The feedback is 3 as it points out a potential improvement, but it could be more actionable and detailed to fully assist the authors in making the necessary changes. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from 1 and references 2 to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. While the comment provides some guidance on what needs to be improved, it lacks explicit instructions on how to simplify the result descriptions or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from 1 and references 2 to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The suggestions are specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the result descriptions are needlessly convoluted and suggests that the authors consider a related idea from 1 and check for useful communication in light of 2. The reviewer provides references to external works, which adds some support to the claim by suggesting that the authors explore related ideas and consider the context of the references. However, the comment lacks detailed reasoning or specific examples of how the current descriptions are convoluted, making it 3. The authors would need to further analyze the feedback to understand the exact issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the complexity and clarity of the result descriptions, noting that some are needlessly convoluted. It provides a constructive suggestion by recommending the authors consider a related idea from 1 and referencing 2 to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. This feedback is 4 as it offers actionable steps for improving the clarity and simplicity of the results section. However, it could be more helpful if it provided more detailed guidance on how to simplify the descriptions or what specific changes should be made. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides some context for addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the approximation error should be mathematically characterized, which provides a clear and direct action for the authors to take. This guidance is specific and concrete, as it specifies the exact improvement needed to clarify the approximation error. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the approximation error, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a mathematical characterization of the approximation error. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not provide any supporting evidence or reasoning to justify why the current definition is unclear or how a mathematical characterization would improve clarity. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approximation error definition, noting that it is ambiguous without additional context. It suggests that providing a mathematical characterization would improve clarity. This feedback is clear and actionable, as it directs the authors to make a specific improvement to enhance the clarity and understanding of their work. However, the comment could be more helpful if it provided examples or guidance on how to mathematically characterize the approximation error. Overall, the comment is 4 as it effectively points out a potential area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific line in the paper (ln. 180182) and highlights a potential issue with the claim made in Corollary 10. It notes that the corollary only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors should clarify or rephrase their claim, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made in Corollary 10, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out that the corollary does not directly address the minimization of the expected convex surrogate. However, it lacks specific examples or references to support the claim, making it 3. The authors may need to further explore the implications of the corollary to fully understand and address the reviewer\"s point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim made in Corollary 10, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This is a clear and actionable point that the authors can address to improve the clarity and accuracy of their claims. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the claim to better align with the evidence presented. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. It also criticizes the evolution model for being simplistic, as it only changes edges associated with the 1 node changing cluster. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue. The authors can infer that they need to consider ways to increase the number of node changing clusters or explore more complex evolution models, but the comment lacks concrete suggestions or detailed instructions on how to achieve this. Therefore, the comment is 3, as it points out a problem but does not provide specific steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"evolution model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, and that the evolution model is simplistic in that it only changes edges associated with the 1 node changing cluster. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, which results in slow dynamics. The reviewer also criticizes the evolution model for being simplistic, as it only changes edges associated with the 1 node changing cluster. The comment provides logical reasoning by explaining the consequences of the reassignment probability and the simplicity of the evolution model. However, it lacks specific examples or references to support the claim that the model is too simplistic. Therefore, the comment is 3, as it provides a logical argument but could benefit from more detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. This observation highlights a limitation in the model\"s dynamics, as it results in slow changes. Additionally, the comment critiques the evolution model for being simplistic, as it only changes edges associated with the 1 node changing cluster. This feedback is valuable as it points out specific weaknesses in the model that the authors should address to improve its dynamics and complexity. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as exploring alternative models or methods for increasing the number of node changing clusters. Overall, the comment is 4 as it identifies important areas for improvement but lacks detailed guidance on how to achieve them."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there are missing details about the division to train and test sets, including numbers and the method used for division (random or other considerations). It clearly instructs the authors to add these details, providing a direct and concrete action for improvement. The comment is specific about what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division to train and test sets, including numbers and the method used for division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, such as details about the division method and numbers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division to train and test sets, including numbers and the method used for division. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the absence of details about the division to train and test sets, including numbers and the method used for division. It clearly instructs the authors to add these details, providing a direct and actionable suggestion for improvement. This feedback is valuable as it helps the authors clarify and strengthen their methodology section, ensuring that their experimental results are transparent and replicable. However, the comment could be more helpful if it offered additional guidance on how to present these details or what specific considerations should be taken into account. Overall, the comment is 4 as it effectively directs the authors to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for how to address the human labor issue or how to improve scalability. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of human labor in building text descriptions and the scalability of the framework with longtext inputs. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for human labor and the scalability issue, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that building text descriptions for each task still requires human labor and that the optimal textual format for policy learning varies from task to task and model to model. The reviewer also mentions the scalability issue with longtext inputs, referencing a previous question. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. It acknowledges the complexity of determining the optimal textual format for policy learning, which varies across tasks and models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the scalability of their framework. While it highlights important areas for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out potential weaknesses but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance improvement of the proposed methods is not significant, as evidenced by the figure 3, and recommends using tables to show the key improvements more intuitively and in detail. While the comment provides a clear action\u2014using tables to present the key improvements\u2014it does not specify which tables should be used or how to present them. The authors are left to infer the details of implementing this suggestion, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods is not significant, as evidenced by the figure, and suggests using tables to show the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, based on the figure 3. However, it does not provide specific details or data to support this claim, such as comparisons to other methods or baselines. The suggestion to use tables to present the key improvements is a logical suggestion, but without detailed evidence or examples, the claim remains 3. The authors would need to make a significant effort to verify the claim themselves, as the comment lacks the necessary evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the performance improvement of the proposed methods appears not to be significant, as evidenced by figure 3. It suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results. However, the comment could be more helpful if it included specific examples of how the tables should be structured or what aspects should be highlighted. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the experimental validation, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed information about the optimization strategy and consider related works, but the comment lacks specific instructions on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not offer concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental validation\" and \"shallow networks\" being considered, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental validation, such as the lack of description of the optimization strategy and the consideration of layer redundancy in the context of network pruning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, specifically mentioning the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, such as layer redundancy in the context of network pruning. The reviewer provides a reference to a specific paper that discusses this issue, which adds some level of verification to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation section, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how to address them. The reference to a specific paper on network pruning could be more helpful if it included suggestions on how to incorporate this work into the experimental validation. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the paper does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not provide any guidance on how the authors should address this issue or what specific theoretical results should be proven. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical results to substantiate their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not specify which part of the paper this issue pertains to, such as the theoretical results section or the methodology section. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. The comment is specific in identifying the lack of theoretical results but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the paper does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it lacks clarity and does not provide any suggestions or guidance on how the authors might address this issue or what theoretical results could be proven. Without actionable feedback or specific direction, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is ambiguous or atypical. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors have provided sufficient evidence to prove or disprove it. While the comment implies that the authors should provide more evidence to support or refute the hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to substantiate the hypothesis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is ambiguous or atypical. However, it does not specify which parts of the paper these hypotheses pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment also lacks specificity regarding what evidence would support or disprove the hypothesis, leaving the authors without clear guidance on how to address this suggestion. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is ambiguous or atypical. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors have provided sufficient evidence to prove or disprove it. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The authors are left to infer the need for more evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is ambiguous or atypical. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors have provided sufficient evidence to prove or disprove it. While the comment identifies a potential area for exploration, it lacks specific guidance or suggestions on how the authors might test or substantiate this hypothesis. The feedback is 3 as it points out a potential area for further investigation, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the model was only tested on a single supporting fact dataset for the bAbI task. It implies that the authors should consider testing the model on other tasks in the bAbI dataset. However, the comment does not provide explicit instructions or concrete guidance on how to address this issue, such as suggesting specific tasks to test or recommending additional datasets. The action is implicit and somewhat vague, as the authors can infer that they need to test the model on more tasks but may not be entirely sure which ones to prioritize. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the model was only tested on a single supporting fact dataset for Task 1. However, it does not provide specific guidance on what additional tasks should be tested or how to address this issue. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking for clarification about the model testing for the bAbI task. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the model testing for the bAbI task, specifically questioning whether the model was only tested on a single supporting fact dataset for Task 1. This is a valid point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what additional testing might be needed. While it identifies a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should improve Section 3.2 by providing more illustrations and examples. This feedback is clear and direct, giving the authors a specific action to take to enhance the clarity and comprehensiveness of their draft. The comment provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more illustrations and examples to improve the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 3.2 is difficult to follow and recommends providing more illustrations and examples to improve clarity. However, the comment does not provide specific examples or detailed reasoning to support why the section is challenging to understand or how additional illustrations and examples would enhance comprehension. Without these details, the authors may find it difficult to address the issue effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It suggests that the authors might improve the section by providing more illustrations and examples to enhance clarity. While the comment highlights a potential area for improvement, it lacks specific guidance on what types of illustrations or examples would be beneficial or how to effectively integrate them into the section. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed suggestions for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is limited, suggesting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could improve their technical contribution or what aspects of the typical model could be leveraged to enhance their work. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is limited and does not provide a specific part of the paper where this issue is addressed. It mentions the crossdomain recommendation setting, but without further context or detailed explanation, the authors may struggle to identify the exact section or aspect of the paper that needs improvement. The comment lacks specificity in detailing what is considered typical or how the technical contribution could be enhanced. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited and does not provide a significant extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is limited, specifically noting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could enhance their technical contribution or what aspects of the typical model could be leveraged to improve their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the comment implies that the authors should add these baselines, it does not provide explicit instructions on how to implement this suggestion or what specific baselines to include. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the addition of fullysupervised baselines but lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or how it would contribute to the understanding of the gap. Without such justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. This is a clear and actionable suggestion that could provide valuable insights into the performance of the models. However, the comment could be more helpful if it explained why this addition is necessary or how it would impact the understanding of the gap. Despite this, the suggestion is still valuable and provides a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically asking about the time required to calculate the hypervolume of different regions in each step of the LaMOO algorithm. It also mentions that the computation of hypervolume could be timeconsuming, especially for problems with many objectives. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to improve the algorithm\"s efficiency. The authors are left to infer that they should consider the time complexity and explore ways to optimize the algorithm, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it points out an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Time Complexity\" and the \"LaMOO algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the time complexity of the algorithm, particularly the calculation of hypervolume, which could be timeconsuming for problems with many objectives. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in the LaMOO algorithm could be timeconsuming, especially for problems with many objectives. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim that the time complexity is a problem. The authors are left to infer the potential impact on the algorithm\"s practicality, which may not be immediately clear. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in the LaMOO algorithm could be timeconsuming, especially for problems with many objectives. This is an important consideration for the practicality of the algorithm, as it could impact its applicability to realworld problems. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or optimize the algorithm for efficiency. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights an important area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment acknowledges that the dataset used in the experiments is small but suggests that results on larger datasets like ImageNet would be more convincing. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to include results on larger datasets. The action is implied, as the authors can infer that they should consider running experiments on larger datasets, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the dataset used in the experiments being small, suggesting that results on larger datasets like ImageNet would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to include results on larger datasets, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why larger datasets are necessary or how they would impact the paper\"s conclusions. Without specific examples or detailed explanations, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges the issue of using small datasets in the experiments and suggests that results on larger datasets like ImageNet would be more convincing. However, it does not provide specific guidance or suggestions on how to address this issue, such as recommending additional datasets or methods for scaling up the experiments. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, as well as the generic and vague title. It suggests being honest and direct in the critique and provides a specific example of what \"brittle convergence properties\" means. Additionally, it mentions that DeepRL methods are widely adopted and suggests considering the landscape 10 years ago. While the comment provides some guidance on what aspects to address, it lacks concrete details on how to implement these suggestions. The authors are given a general direction but may need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the limitations of evolutionary methods, the generic and vague title, and the need for more detailed discussion on leveraging state, reactiveness, and learning during an episode. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the title is too generic and vague and that the authors should be more precise in their critique. It also asks for clarification on the term \"brittle convergence properties\" and mentions the widespread adoption of DeepRL methods. Overall, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point makes several claims, including that the paper discusses limitations of evolutionary methods, the title is too generic and vague, and that DeepRL methods are widely adopted. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"brittle convergence properties\" is not explained, and the suggestion to be more precise in critiques is not accompanied by examples or detailed guidance. The comment also suggests considering the landscape 10 years ago, but this does not contribute to the verifiability of the claims. Overall, the comment lacks sufficient evidence or detailed reasoning to support its claims, making them 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, which could enhance the paper\"s depth and relevance. It also points out that the title is too generic and vague, suggesting that being more precise in the critique would be beneficial. Additionally, the reviewer questions the term \"brittle convergence properties\" and notes that DeepRL methods are widely adopted, suggesting that the authors should consider the landscape 10 years ago. While the comment provides some actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar works have tackled these topics. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image, and how the edges are handled in areas where depth discontinuities occur. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors know they need to provide more information about the synthesis process, but the comment lacks specific suggestions on how to improve the explanation or what details should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks about how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas with depth discontinuities. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, providing clear guidance on what aspects of the synthesis process are unclear. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. While the questions are valid, they do not provide specific examples or references to support the claim that the paper lacks clarity or explanation. The comment is 3, as it highlights areas that need further clarification, but it does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. These questions highlight areas where the paper could be improved by providing more detailed explanations or examples. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues, such as recommending additional experiments or clarifications. While it identifies important areas for improvement, the feedback lacks actionable steps for the authors to take. Therefore, the comment is 3, as it points out areas for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper claims a unique contribution regarding the number of points and apriori knowledge needed for its algorithm, but it suggests that empirical justification would be beneficial. While the comment implies that the authors should provide empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first claimed contribution\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper lacks empirical justification for the claim about the number of points and apriori knowledge needed for the algorithm. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is unique because it does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment suggests that empirical justification would be beneficial. While the claim is based on logical reasoning, it lacks specific examples or references to support the claim. The authors are left to infer the need for empirical evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks empirical justification, which is the claim about the algorithm\"s unique contribution regarding the number of points and apriori knowledge needed. It suggests that providing empirical evidence would strengthen the paper\"s argument. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct the empirical analysis or what specific data or experiments should be included. This limits the comment\"s helpfulness, as it provides a direction for improvement but lacks detailed guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. While the comment identifies issues with novelty and similarity, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should improve the novelty and differentiate their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"specific components of the approach,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with novelty and similarity, such as the use of MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before, and the similarity in sampling strategy to epsilongreedy and BRPNAS. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. The reviewer also notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, the reviewer states that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. The comment provides specific references to external works, such as 2,3,7 and 5, which supports the claim by citing examples of previous work. This makes the claim 4, as it provides a solid foundation for the authors to understand and address the issue of novelty and similarity. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty and originality of the approach, noting that the specific components are not novel as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also points out that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, the comment highlights that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. This feedback is 3 as it provides clear and actionable information about areas where the paper could be improved by differentiating the approach or presenting new insights. However, it could be more helpful if it offered suggestions on how to address these issues or improve the novelty of the approach. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015) and suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and provides a concrete action for the authors to take, which is to include a detailed discussion on the comparison with RMED. The comment is specific in identifying the issue and provides a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed S1DBED algorithm\" and \"RMED (Komiyama et al. 2015),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion on the comparison with RMED. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the novelty of the proposed S1DBED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED to justify its novelty. This feedback is clear and actionable, as it directs the authors to include a detailed discussion on the comparison with RMED to enhance the novelty of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the previous work should be discussed or how the authors should incorporate this discussion into their paper. The comment lacks explicit guidance or concrete suggestions on how to address this issue, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the discussion should be included. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. The comment is specific in identifying the need for a comprehensive discussion of previous work, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which previous works are missing or how they should be integrated into the paper. Without specific references or examples, the claim lacks verifiability, as it does not provide a clear basis for the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical observation that could significantly impact the paper\"s credibility and depth. However, the comment lacks specific guidance on which previous works should be discussed or how the authors might integrate this discussion into their paper. Without actionable suggestions or examples, the authors are left with a general direction but no clear path to follow. Therefore, the comment is 3, as it points out an area for improvement but does not provide detailed guidance for implementation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises questions about the OT sample selection process, specifically whether it runs once or iteratively, and whether the EP module is updated during the training steps. It suggests that more details and a flow chart would be helpful to clarify the process. Additionally, it asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment implies that the authors should provide more details and a flow chart, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and a flow chart. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. The comment also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful to clarify the process. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that these details are necessary or how they would enhance the clarity of the paper. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the OT sample selection process, suggesting that more details and a flow chart would be beneficial for clarity. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and comprehensibility of their work. By addressing these questions, the authors can improve the transparency and accessibility of their methodology, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix, asking why these methods are not included in the experiments and how they compare to ConBO. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include experiments with continuous tasks and consider including entropy methods in the experiments. The action is concrete but somewhat vague, as it lacks detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on how KG handles the continuous task setting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of experiments with continuous tasks and questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix. The comment further asks how these methods compare to ConBO. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. While the comment identifies a potential gap in the experimental setup, it lacks specific examples or references to support the claim that these methods should be included in the experiments. The reasoning is 3, as it highlights a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. This feedback is clear and actionable, as it prompts the authors to address the omission of continuous tasks in their experiments and to consider including entropy methods for conditional optimization in the main text. By providing specific questions and suggestions, the comment empowers the authors to enhance the comprehensiveness and rigor of their experimental evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a comparison of GCG with other LLMs could be included, as it demonstrated the transferability of its approach. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs. While the comment implies that the authors should include this comparison and address the jailbreaking issue, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG\" and \"their approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with other LLMs and the issue of low jailbreaking percentages for certain LLMs. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison with other LLMs could be included, as it demonstrated the transferability of GCG\"s approach. However, the comment does not provide specific examples or references to support this claim, nor does it explain why such a comparison is necessary or how it would benefit the paper. The mention of a low jailbreaking percentage for certain LLMs is also not further elaborated. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the inclusion of a comparison with other LLMs, which could enhance the paper\"s contribution. It also points out a minor issue with the jailbreaking percentage for certain LLMs. While the comment identifies areas for improvement, it lacks detailed guidance on how to conduct the comparison or address the jailbreaking issue. This limits the comment\"s helpfulness, as it provides some direction but not enough depth to fully support the authors in making these improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the authors\" explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it acknowledges the novelty of the approach, it explicitly requests a more detailed explanation to better understand the difference. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of unsupervised feature selection from a diffusion perspective, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of the difference between similarity and exit times in nature. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer acknowledges the novelty of the approach but expresses difficulty in understanding the distinction. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the explanation is unclear. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to better understand the distinction. This feedback is 3 as it points out a potential gap in the paper\"s explanation, prompting the authors to provide a clearer explanation. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of how the distinction might be clarified. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. While it implies that the authors should address this limitation, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations of the framework, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the framework is limited in this way. Without such information, the authors may find it challenging to address the question or understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. This is a relevant point that could help the authors identify potential areas for improvement or expansion in their work. However, the comment lacks specific guidance or suggestions on how to address these limitations, such as suggesting specific experiments or analyses that could be conducted. While it points out an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the calculation of precision/recall/F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these metrics and AUC results. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the calculation of precision/recall/F1score for a 4class classification of breast density and the reporting of AUC results for breast cancer detection. It also specifies the need for sensitivity and specificity at different operating points for model performance comparisons. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual questions about the calculation of precision/recall/F1score and the reporting of AUC results. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the calculation and reporting of metrics for a 4class classification of breast density and breast cancer detection. It suggests that providing AUC results with sensitivity and specificity at different operating points could be more informative for comparisons. This feedback is clear and actionable, as it directs the authors to include specific metrics that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it provided examples of how these metrics are typically reported or suggested specific operating points to consider. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is wellstudied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\" dataset can be considered extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use the Kialo dataset rather than being directly told to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters, and that it is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in suggesting that the Kialo dataset could be used as an alternative, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community. The reviewer claims that the Kialo dataset provides pairs of short claims and their counters and is cleaner than the dataset created by the authors. However, the comment lacks specific examples or references to support the claim that the Kialo dataset is cleaner or that it provides exactly what the authors need. While the suggestion to use the Kialo dataset is logical, the lack of detailed evidence or comparisons makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community and provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner than the one created by the authors and suggests that the authors\" dataset can be considered extra data to learn from. While the comment identifies a potential alternative dataset, it lacks detailed guidance on how the authors might incorporate this suggestion into their work or why the Kialo dataset is preferable. The feedback is 3 as it points out a potential source of data, but it could be more beneficial with additional explanation or suggestions for incorporating the Kialo dataset. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Transformer in the paper, noting that it is no longer novel in the field and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement in the ablation study, suggesting that it is limited (<1%). However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific modifications should be made to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the novelty and impact of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Transformer\" and \"crosslayer,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the modification does not bring much insight and that the selfcross attention improvement is limited. Additionally, it provides specific examples from the ablation study (table 4 and 5) to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of Transformer in the paper is not novel and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer supports this claim by referencing the widespread adoption of Transformer in NLP and vision tasks, which suggests that the modification is not innovative. Additionally, the reviewer points out that the selfcross attention improvement is limited (<1%), further supporting the claim that the modification does not bring significant improvements. The comment is 4 as it provides logical reasoning and specific examples from the ablation study to substantiate the claim. However, it could be strengthened by referencing specific studies or literature that support the claim about the widespread adoption of Transformer. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a critical analysis of the paper\"s use of Transformer, noting that it is no longer novel in the field and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement, suggesting that it is limited (<1%). This feedback is 3 as it points out a potential weakness in the paper\"s contribution, but it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. While it identifies areas for improvement, the comment could be more helpful by providing actionable advice or examples of how the authors might enhance their work. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses a concern about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. However, it does not provide specific guidance on how to implement these changes or what aspects of the experiments should be improved. The comment implies that the authors should address the weaknesses mentioned, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the limited number of tasks and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. The comment also asks the authors to address the weaknesses mentioned above, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the number of tasks in the experiments is limited and recommends including at least 10 tasks and sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning or evidence to support why the current number of tasks is insufficient or how adding more tasks would improve the experiments. The suggestion is based on a general expectation, but without detailed justification or examples, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically the number of tasks, which is considered too limited. It suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, as it provides a specific direction for improvement. However, the comment could be more helpful if it explained why the current number of tasks is insufficient or how adding more tasks would enhance the experiments. Despite this, the feedback is 4 as it guides the authors on how to strengthen their experimental design."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional tasks they should include in their experiments. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, specifically mentioning \"sentence similarity tasks and open domain QA tasks.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited and suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out that these tasks are common in the NLP field and could enhance the scope of the experiments. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the experiments. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the scope of their work. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include the prompt in the appendix or supplement, providing a clear action for the authors to take. Additionally, it suggests that the abstract might be difficult to understand and recommends rephrasing it. However, the comment does not provide specific guidance on how to rephrase the abstract or what changes to make to the Figure 2. While the action is clear, the lack of detailed instructions on how to implement the rephrasing or label the yaxes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the prompt and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as including the prompt in the appendix or supplement and clarifying the purpose of Figure 2. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, providing a clear and actionable suggestion for improvement. However, the comment does not provide any supporting evidence or reasoning to justify why the prompt should be included or how it would enhance the paper. The mention of the abstract and Figure 2 is more of a request for clarification than a claim, as it does not challenge or question the existing content. Therefore, the comment is classified as \"No\" because it lacks verifiable evidence or reasoning to support the claim.", "helpfulness_rationale": "The review comment provides two main pieces of feedback. First, it suggests that the prompt should be included in the appendix or supplement, which is a clear and actionable suggestion for improving the paper. This feedback is specific and can help the authors ensure that their work is accessible and understandable. Second, it points out that the abstract is difficult to understand and recommends rephrasing it, which is also a helpful suggestion for clarity. Additionally, the comment notes that Figure 2 is unclear and lacks labeled yaxes, providing specific areas for improvement. Overall, the comment is 4 as it identifies areas for clarity and improvement, offering actionable guidance for the authors to enhance their draft. However, it could be more helpful if it provided additional details or examples on how to rephrase the abstract or improve Figure 2. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity might not appear in earlier layers. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to clarify the motivation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity might not appear in earlier layers. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in questioning the motivation but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity might not appear in earlier layers. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity might not appear in earlier layers. This is a valid point that could lead to a deeper understanding of the model\"s behavior and potential limitations. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or what alternative analyses could be considered. Without detailed suggestions or examples, the feedback is 3 as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the parameter S remains a problem, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps the authors should consider to improve the parameter setting. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the issue of setting the parameter S, but it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the parameter S setting is problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment states that \"How to set the parameter S remains a problem,\" but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the parameter S, indicating that it remains a problem. However, it does not provide any guidance or suggestions on how to address this issue or improve the parameter setting. Without actionable feedback or detailed insights, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider conducting a human evaluation, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The authors are left to infer that they should consider conducting a human evaluation, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper discusses the evaluation metrics or the caption generation process, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include human evaluation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback highlights a potential weakness in the paper\"s evaluation methodology and provides a clear direction for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the caption generation process should be evaluated by humans. While it identifies an area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that while the introduction claims that shape constraints do not require tuning a free parameter, the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be considered a hyperparameter that needs to be chosen or tuned. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that shape constraints do not require tuning a free parameter. The comment points out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction statement about shape constraints not requiring tuning is technically true but misleading. The reviewer provides a logical reasoning by pointing out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This reasoning is based on a logical distinction between constraints and hyperparameters, which is a common understanding in the field. However, the comment could be strengthened by providing specific examples or references to support the claim that these choices should be considered hyperparameters. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential misconception in the introduction regarding the claim that shape constraints do not require tuning a free parameter. It points out that the choice of convex or concave constraints, and increasing or decreasing constraints, can be considered hyperparameters that need to be chosen or tuned. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By clarifying the distinction between constraints and hyperparameters, the comment offers a constructive suggestion that can help the authors improve the clarity and accuracy of their introduction. However, the comment could be more helpful if it provided additional guidance on how to present this information or suggested specific language to use in the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It highlights a specific assumption, Assumption 4.1, which indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be adapted from previous theorems with straightforward modifications, as outlined in Modification 1 in Appendix C. This provides a clear and concrete action for the authors to take, which is to review and potentially revise the convergence proof to enhance its novelty and rigor. The comment is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical proof for convergence, noting that it lacks novelty and rigor due to the trivial adaptation from previous theorems. The comment provides a clear rationale for why the proof is not substantial, which helps the authors understand the need for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial and lacks novelty and rigor. It supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted from previous theorems with straightforward modifications, as outlined in Modification 1 in Appendix C. This reasoning is based on logical deduction from the assumptions and the provided modifications, making the claim 4. However, the comment could be strengthened by referencing specific theorems or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It points out that the assumption of $X$ being i.i.d. leads to a clear covariance matrix for $Z$, which can be trivially adapted from previous theorems with straightforward modifications. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By highlighting the lack of novelty and rigor in the proof, the comment offers a direct path for improvement. However, it could be more helpful if it provided suggestions on how to enhance the rigor or novelty of the proof. Overall, the comment is 4 as it guides the authors toward a meaningful revision of their theoretical work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental setup borrowed from 2 is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This provides a clear and direct action for the authors to take, which is to mention this fact clearly in their paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental setup borrowed from 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, namely that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup borrowed from 2 is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This claim is 3 as it provides a logical reasoning for the classification, based on the description of the experimental setup. However, the comment lacks specific examples or references to 2 to fully substantiate the claim. Providing more detailed evidence or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This is a clear and actionable point that the authors should address to ensure the validity and credibility of their results. By mentioning this issue, the comment provides the authors with a concrete area for improvement, which can help them enhance the transparency and reliability of their experimental setup. However, the comment could be more helpful if it suggested how to clarify this point in the paper or provided examples of how other studies have addressed similar issues. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues: the limited scope of datasets and models used in the study and the lack of assessment of other important biases and datasets. It also points out the absence of assessments on stateoftheart generative models like GPT. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand their dataset and model selection and include assessments on additional biases and models like GPT. However, the comment lacks concrete suggestions on how to implement these changes or what specific biases and models should be included. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the limitations of the datasets and models used in the study, specifically mentioning the bias benchmarks and the absence of assessments on stateoftheart generative models like GPT. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the dataset and model selection and the need for additional assessments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the datasets and models used in the study are limited and that the bias benchmarks only assess gender, race, and religion. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies specific limitations, it lacks detailed justification or examples to fully substantiate the claim. The authors would need to infer the importance of these assessments and the potential impact on the study\"s conclusions. Therefore, the comment is 3, as it provides some basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant limitation in the study, noting that the datasets and models used are limited and that the bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. This feedback is valuable as it highlights areas where the study could be expanded to include a broader range of biases and models, which would enhance its scope and relevance. However, the comment could be more helpful if it provided specific suggestions on how to address these limitations, such as recommending additional datasets or models to consider. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it lacks detailed guidance on execution."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential contradiction in the paper, noting that the multienv model is stated to have an inevitable performance loss but also outperforms the singleenv model due to knowledge sharing. The reviewer requests clarification on this contradiction, implying that the authors should address this issue to ensure consistency in their claims. While the action is implicit, it is clear that the authors need to clarify the contradiction, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about the multienv model having an inevitable performance loss and the statement about knowledge sharing leading to outperformance. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of contradiction between these two statements and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contradiction between the claims that the multienv model has an inevitable performance loss and that it outperforms the singleenv model due to knowledge sharing. The reviewer does not provide specific evidence or reasoning to support the claim of contradiction, making it difficult for the authors to understand the basis of the issue. The lack of detailed explanation or references makes the claim 2, as it requires further clarification from the authors to fully understand the issue. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the performance of the multienv model. It points out that the model is stated to have an inevitable performance loss but also outperforms the singleenv model due to knowledge sharing. This feedback is valuable as it prompts the authors to clarify this contradiction, which could be a source of confusion or misinterpretation in their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to reconcile these conflicting statements. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or a citation to the metrics. This feedback is explicit, as it clearly states what the authors need to do to improve their draft: either provide an explanation or a citation to the metrics used. The action is concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of the metrics,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation or a citation to the metrics used in the paper. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the metrics is limited and suggests that an explanation or citation to the metrics would be beneficial. However, the comment does not provide specific examples or detailed reasoning to support why the current description is insufficient or how an explanation or citation would improve the paper. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the lack of an explanation or citation for the metrics used. This is a critical feedback as it highlights an area where the authors could enhance the clarity and transparency of their work. By suggesting that an explanation or citation would be beneficial, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific examples of how the metrics are used or why they are important, which would guide the authors in addressing the issue more effectively. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies issues with Figure 3, including the unclear workflow and captions, as well as the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be improved, namely the clarity and comprehensibility of the figure. The comment offers concrete suggestions for improvement, making it 5. Authors know exactly what needs to be addressed to improve the figure, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as the representation of communication modes on the left side. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks specific references or examples to clarify the issues, making it difficult for the authors to address the feedback effectively. Therefore, the claim is considered 2, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as the confusing representation of communication modes on the left side. This feedback is clear and actionable, as it points out specific areas that need improvement to enhance the clarity and comprehensibility of the figure. By addressing these issues, the authors can significantly improve the figure and make it more accessible to readers. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered examples of how similar figures have been effectively presented. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"learned MASK embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this term or what specific actions they should take to address this issue. The comment lacks actionable details, such as recommending a definition or clarification of the term, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SSL pretraining stage\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"learned MASK embedding,\" which is unclear in the context of SSL pretraining. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"learned MASK embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to explain why this term is unclear or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. This is a clear and actionable point that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the term or offered examples of how it might be defined or explained. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented in the literature for standard networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the originality of the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in identifying the issue of derivative results, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the originality of the reported results, suggesting that they are partially derivative as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the originality of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It suggests that the authors should spend more time motivating the problem and its relevance. While the comment implies that the authors should provide more context or examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more motivation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the objective of the paper, which is to design fast label aggregation algorithms for a streaming setting. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the lack of motivation for the problem and the use of static datasets in the empirical analysis. It suggests that the paper should better motivate the problem and its relevance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It suggests that the problem should be better motivated, as the datasets used are static. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors may find it challenging to understand the exact nature of the motivation needed or how to address the issue without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which is a critical observation that could impact the paper\"s usefulness. The comment suggests that the problem should be better motivated to make the paper more relevant and valuable. While it highlights an important area for improvement, it does not provide specific suggestions or examples of how the authors might address this issue. The feedback is 3 as it directs the authors\" attention to a critical aspect of their work, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for incontext learning of large language models should be included in Tables 2 and 3. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to add these baselines or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3\" and \"Question A,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional relevant CoT baselines for incontext learning of large language models. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach to smallscale language models. The reviewer provides a specific observation that additional relevant CoT baselines for incontext learning of large language models (such as text003 and ChatGPT) are missing in Tables 2 and 3. This claim is 3 as it provides a logical reasoning for the need to include these baselines, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for incontext learning of large language models (such as text003 and ChatGPT) should be included in Tables 2 and 3. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the scope and comprehensiveness of their study. By addressing this point, the authors can ensure that their work is more comprehensive and relevant to the field. However, the comment could be more helpful if it included specific examples or references to relevant CoT baselines. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their study."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Figure 3 is difficult to read, providing a clear action for the authors to take. However, it does not specify what aspects of the figure are challenging to read or how the authors might improve the figure to make it more readable. While the action is explicit, the lack of concrete details on how to address the issue makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not provide specific details on what makes the figure difficult to read or what aspects need improvement. Without these details, the authors may struggle to understand exactly what changes are needed to enhance the figure\"s readability. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with Figure 3, noting that it is difficult to read anything on the figure. While this feedback identifies a clear problem, it lacks depth and does not provide suggestions on how to improve the figure\"s readability or what specific elements might be causing the issue. Without additional guidance or context, the authors may struggle to address the problem effectively. Therefore, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the connection should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential area for further exploration or discussion, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. The comment lacks depth and specificity, leaving the authors without clear guidance on how to proceed. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the training of the GAT model and suggests that the text needs to be reviewed by an English native speaker to improve clarity. While the comment implies that the authors should review the text and potentially rewrite some sentences, it does not provide specific guidance on how to achieve these improvements. The action is implicit and somewhat vague, as the authors need to infer that they should review and rewrite the text to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the training of the GAT model and suggests that the text needs to be reviewed by an English native speaker to improve clarity. However, it does not specify which part of the paper this pertains to, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting that the text needs to be reviewed and rewritten for clarity, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training of the GAT model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the training of the GAT model and suggests that the text needs to be reviewed by an English native speaker to improve clarity. While this feedback identifies a potential issue with the clarity of the text, it lacks specific guidance on how to address the problem or what specific sentences need to be rewritten. The comment is 3 as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and questions the justification behind using an SGD learning rate of ~0.1. While the comment provides a specific action to take regarding the parameter `lambda`, it does not offer guidance on how to address the issue with the SGD learning rate or what the justification should be. The action is explicit but lacks concrete details on how to implement the change or justify the choice of `lambda`. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes two claims: first, that replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` is problematic, and second, that the use of an SGD learning rate of ~0.1 is unclear and lacks justification. The first claim is 3 as it points out a potential issue with the parameter choice, but it does not provide specific reasoning or examples to support the claim. The second claim is also 3, as it questions the justification behind the learning rate choice but lacks detailed explanation or references to support the claim. Overall, the comment is 3, as it highlights areas for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1 without a clear justification. It provides actionable feedback by suggesting that the authors should justify the use of `lambda` and clarify the rationale behind the learning rate choice. This feedback is clear and constructive, as it guides the authors on how to improve the clarity and justification of their work. However, the comment could be more helpful if it offered additional suggestions or examples of how to justify these choices. Overall, the comment is 4, as it provides clear and actionable feedback that can help the authors enhance the clarity and rigor of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This guidance is clear and specific, giving the authors a direct action to take. The comment also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the importance of error analysis and its role in evaluating model performance and identifying potential issues. It also encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it details the importance of error analysis and its role in guiding subsequent improvements and expansions of the ERC research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This claim is 3 as it logically supports the importance of error analysis in the context of model evaluation and improvement. However, the comment lacks specific examples or references to substantiate the claim fully. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of error analysis in evaluating model performance and identifying potential issues, and encourages the authors to conduct such analysis and provide detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by incorporating error analysis, which can aid in guiding subsequent improvements and expansions of the ERC research. However, the comment could be more helpful if it included specific examples or suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to perform these tasks or offer specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should include these discussions, making it weakly grounded. The suggestion to analyze the domain gap and discuss the gap between datasets is specific, as it provides clear guidance on what aspects to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a logical basis for the suggestion to analyze the domain gap, it lacks specific examples or references to support the claim about the gap between datasets or the value of finetuning on synthetic data. This makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to analyze the domain gap and discuss the gap between datasets. It highlights the importance of understanding the impact of domain differences on the adaptation process and the potential value of the approach if it can finetune a pretrained model on synthetic data. This feedback is valuable as it directs the authors to consider these aspects in their analysis and discussion, which could enhance the clarity and depth of their work. However, the comment could be more helpful if it included specific examples or references to support the claim about the gap between datasets or the value of finetuning on synthetic data. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the scalability of the model, specifically noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment implies that the authors should consider this issue, it does not provide explicit instructions or concrete steps on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider scalability and performance tradeoffs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and the issue of scalability, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the performance degradation as the maximum number of identities grows, and suggests that the capacity should be set to a small number, like 10. The comment further questions whether the authors have considered how to scale up without compromising performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the model degrades as the maximum number of identities grows, suggesting that the capacity should be set to a small number, like 10. The reviewer provides a specific example from Table 3 (a) to support this claim. However, the comment lacks detailed reasoning or references to explain why this specific capacity threshold is necessary or how it affects performance. While the claim is based on a specific observation, it could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides some support but lacks full clarity and depth.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the model, noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, to address this issue. The comment also raises a valid question about how to scale up without compromising performance, which is an important consideration for realworld applications. While the comment provides a clear and actionable suggestion, it could be more helpful if it offered additional insights or examples on how to achieve this scalability without sacrificing performance. Overall, the comment is 4 as it directs the authors to consider a critical aspect of their model\"s scalability and performance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the authors claim their work as preliminary but question the NLPspecific aspects of their approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be revised to better align with an NLPspecific focus. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim made by the authors regarding their work being preliminary and discusses the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspect of the approach is lacking in being NLPspecific. Without clear guidance on where the issue is located or what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors claim their work as preliminary but question the NLPspecific aspects of their approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a discrepancy between the authors\" claim of their work as preliminary and the lack of NLPspecific aspects in their approach. However, it does not provide any constructive feedback or suggestions on how the authors might address this issue or improve their work. Without actionable guidance or specific examples, the comment does not assist the authors in enhancing their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that at least one NCEbased method should be included for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, as it specifies the exact action the authors need to take by including a specific method for comparison. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific study 1 that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper should include this comparison or which section would benefit from it. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention the sections. The suggestion is specific, as it clearly identifies the need for a comparison with NCEbased methods. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison. It references a specific study 1 that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This reference provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how NCEbased methods could enhance the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison. It references a specific study 1 that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is 3 as it provides a clear direction for the authors to consider adding a relevant comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the paper\"s contribution. While it identifies a potential area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a clear direction for improvement, it does not specify which specific tests should be conducted or how to conduct them. Additionally, it does not mention which recent LLMs should be compared. While the action is explicit, the lack of concrete details on how to implement the suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the experiment section, specifically recommending the use of significance tests on human evaluation results and comparing the proposed method with recent LLMs. However, it does not specify which part of the experiment section needs improvement or which specific LLMs should be compared. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting improvements, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these changes would significantly enhance the experiment section. The absence of detailed justification or evidence makes the claim 3, as the authors would need to make a significant effort to understand and implement the suggested improvements.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment section, specifically suggesting the use of significance tests on human evaluation results and comparing the proposed method with recent LLMs. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experiment section. However, the comment could be more helpful if it included examples of which tests should be conducted or which LLMs should be compared. Despite this, the feedback is 4 as it directs the authors to specific areas for improvement, which can significantly enhance the quality of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to discuss a previous work on joint error for UDA, specifically mentioning \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. It also suggests that the authors should illustrate the relationship between this work and their proposed method, and explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of joint error for UDA, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to discuss a previous work on joint error and how it relates to the proposed method. The comment provides a clear direction for improvement by suggesting the authors discuss the relationship between the previous work and their method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about the lack of research on joint error for UDA is incorrect, as it has already been studied in previous works like \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. The reviewer suggests that the authors should discuss this work and its relationship to their proposed method. This claim is 3 as it references a specific work, providing some evidence for the existence of prior research on joint error. However, the comment could be strengthened by providing more detailed analysis or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the lack of research on joint error for UDA. It points out that this issue has already been studied in previous works, specifically mentioning \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. The comment suggests that the authors should discuss this work and its relationship to their proposed method, as well as explain why their method is better. This feedback is clear and actionable, providing the authors with a specific direction for improvement by suggesting they address the existing literature and justify their approach. By addressing these points, the authors can enhance the novelty and relevance of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the largerscale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors can infer that they should consider the impact of dataset size on performance and potentially adjust the comparison with SOTA methods. However, the comment lacks concrete steps or suggestions on how to conduct this adjustment or what specific aspects of the comparison should be revised. Therefore, the comment is 3, as it highlights an area for consideration but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with stateoftheart (SOTA) methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison with SOTA methods. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the difference in dataset sizes. The reviewer provides a logical reasoning by pointing out that the superiority of the proposed method may be attributed to the largerscale datasets. However, the comment lacks specific examples or references to support the claim that the dataset size significantly impacts the accuracy. While the reasoning is sound, the absence of detailed evidence or references makes the claim 3. The authors would need to further explore the impact of dataset size on performance to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the proposed method with stateoftheart (SOTA) methods. It points out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential bias in the comparison, as the larger dataset may contribute to the superiority of the proposed method. The comment suggests that the superiority may be due to the largerscale datasets, which is a valuable insight for the authors to consider. However, the comment could be more helpful by providing specific suggestions on how to address this issue, such as adjusting the comparison or discussing the implications of dataset size on performance. Overall, the comment is 3 as it identifies a relevant concern but lacks detailed guidance on how to resolve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It also notes the absence of a discussion on the research gap, such as why existing methods cannot be applied. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the research gap should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification for the need of a new curriculum learning method and address the research gap, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, as existing methods cannot be applied. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It points out the absence of a discussion on the research gap, such as why existing methods cannot be applied. This feedback is 3 as it highlights a potential gap in the paper that the authors should address to strengthen their argument. However, the comment could be more helpful if it provided suggestions on how to address this gap or what specific aspects of the research gap should be discussed. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a specific suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest ngram features. This is an explicit and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done and how it can be done, making it 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach to address the domain adaptation problem, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. This claim is 3 as it provides a logical reasoning for the suggestion, based on the common use of these models in domain adaptation tasks in the NLP field. However, the comment lacks specific examples or references to support the claim fully, such as studies or experiments that demonstrate the effectiveness of these models in domain adaptation. This makes the claim 3, as it provides a reasonable basis but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. This feedback is clear and offers a concrete way for the authors to enhance their methodology and improve the robustness of their results. By following this advice, the authors can potentially overcome domainshift issues and provide a more robust evaluation of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or if it is merely due to having more parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed analysis or clarification in their ablation study. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or if it is merely due to having more parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology and results sections where the method and its performance are discussed. The comment is specific in detailing what needs to be addressed, namely the need for more detailed analysis or clarification in the ablation study. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions whether the main performance gain of the proposed method is due to a specific module or if it is merely due to having more parameters. It suggests that the current version of the ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the need for more detailed analysis or clarification in the ablation study to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or if it is merely due to having more parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of explanation in the paper regarding the two quantities mentioned in lines 196197. It explicitly asks for more clarification on why the two quantities are different and how they capture the difference in learning settings. This feedback provides a clear and direct action for the authors to take, which is to provide additional explanation in these lines. The comment is specific and concrete, giving the authors a clear idea of what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l 1967,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation regarding the two quantities and their relationship to learning settings. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the explanation provided in lines 196197, asking for more clarification on why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is necessary or how it would impact the paper\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where more explanation is needed, specifically regarding the two quantities mentioned in lines 196197. It asks for clarification on why the two quantities are different and how they capture the difference in learning settings. While the comment highlights an important area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The authors are given a clear direction to provide more explanation, but the comment could be more helpful with additional context or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and direct request, providing the authors with a specific action to take. The comment is specific in detailing what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the sensitivity of fixed tuning parameters in the model, providing a clear reference point for the authors to address. It is also specific because it asks for a discussion on both strengths and weaknesses, giving the authors a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This feedback is clear and actionable, as it directs the authors to provide a detailed analysis of the model\"s sensitivity to fixed parameters. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment provides a valuable direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed framework should be tested with different policy gradient approaches and provides a specific question about the number of random seeds used for learning the policies (DDPO and IPPG). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment results. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its request for information about the random seeds used, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not provide any supporting evidence, reasoning, or references to justify why these changes would be beneficial or necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional experiments. However, the comment lacks depth and does not provide specific guidance on how to implement these changes or what specific aspects of the framework would benefit from testing with different policy gradient approaches. While it points out a potential area for enhancement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. While it implies that the authors should expand their analysis, it does not provide specific guidance on which datasets or tasks to include or how to conduct the additional evaluations. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to enhance their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting the need for additional datasets and tasks, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. However, it does not provide any specific reasoning or evidence to support why this would be beneficial or how it would impact the paper\"s conclusions. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s evaluation, noting that it is based on only one dataset and one task. It suggests that expanding the analysis to more datasets and tasks would strengthen the results and conclusions. This feedback is 3 as it points out an area for improvement, but it lacks specific guidance on which datasets or tasks to consider or how to conduct the additional evaluations. While it highlights a potential weakness, the comment does not provide actionable steps for the authors to address it. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific areas where the writing could be improved, such as the definition of \"relevant\" auxiliary model weights in 2.1. It provides explicit guidance on what needs to be clarified, namely the interpretation of the current definition. This feedback is clear and concrete, as it directly instructs the authors on what part of the writing needs improvement and how to clarify it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the interpretation of the \"relevant\" auxiliary model weights in the definition. This provides clear guidance on what aspect of the writing needs clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the writing in specific sections, such as definition 2.1. It suggests that the definition is difficult to interpret and provides examples of areas that could be improved. However, the comment does not provide specific reasoning or examples to support why the writing is unclear or how it could be clarified. Without additional context or detailed explanation, the claim remains 3, as it lacks the necessary evidence or justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the writing could be improved, providing clear and actionable feedback. It points out that the definitions in the paper, such as \"relevant\" auxiliary model weights in definition 2.1, are difficult to interpret. By highlighting these areas, the comment offers a concrete way for the authors to enhance the clarity and accessibility of their writing. However, the comment could be more helpful if it provided suggestions on how to clarify these definitions or examples to improve understanding. Overall, the feedback is 4 as it directs the authors to specific areas needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It suggests that the use of ULiRA 1 is recommended. However, the comment does not provide explicit instructions on how to address this concern or implement the suggested use of ULiRA. While the authors can infer that they should consider using ULiRA, the comment lacks concrete guidance on how to integrate it into their work. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and raises concerns about the robustness of MIA testing for privacy guarantees. It also suggests using ULiRA 1 as a recommendation. However, the comment does not specify which part of the paper discusses the use of MIA testing or where the recommendation for ULiRA should be integrated. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue with MIA testing and the recommendation for ULiRA, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It suggests that the use of ULiRA 1 is recommended. The comment provides a logical reasoning by pointing out the potential limitations of MIA testing and the need for a more robust approach. However, it lacks specific examples or references to support the claim about the robustness of MIA testing or the effectiveness of ULiRA. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It points out that the robustness of MIA testing itself is questionable for privacy guarantees. The comment suggests using ULiRA 1 as a more robust alternative. While the comment highlights an important issue, it lacks specific guidance on how to address the concern or integrate ULiRA into the paper. The authors are given a direction to consider, but the feedback could be more actionable with detailed suggestions on how to implement the suggested change. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks depth and actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that it could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they should consider presenting this information, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting it in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion to present the information in the language of kernel interpolation/smoothing, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that the information could be presented in the \"language of kernel interpolation/smoothing.\" However, the comment lacks any supporting evidence, reasoning, or references to justify why this is relevant or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it does not provide sufficient justification for the authors to address the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression, suggesting that it could be presented in the \"language of kernel interpolation/smoothing.\" While it identifies a potential area for improvement, the comment lacks specific guidance or suggestions on how to address this issue or what aspects of kernel (ridge) regression should be included. The feedback is 3 as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. It explicitly asks if it is possible to conduct such a comparison. The comment provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. This guidance is explicit and concrete, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and suggesting a comparison with final outputs. The comment further questions whether a quantitative comparison on the final outputs is possible, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. The comment provides a logical reasoning by pointing out that the current evaluation does not fully demonstrate ModelAngelo\"s superiority to competitors. However, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing in demonstrating ModelAngelo\"s superiority to competitors. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it offered additional guidance on how to conduct such a comparison or provided examples of how it might be done. Overall, the comment is 4 as it points out a critical area for improvement and provides a clear direction for the authors to enhance their evaluation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, it recommends including error bars and/or pvalues when statistical inferences are made. While the comment provides specific actions to take, such as adding more details and including error bars, it does not explicitly instruct the authors on how to implement these changes. The action is concrete but somewhat vague in terms of execution, as the authors need to determine which specific details to include and how to present them. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"simulation or experimentbased evidence\" and \"fig. 2,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues with the explanations, the lack of detailed procedures, and the confusion regarding \"sample count\" in fig. 2. Additionally, it provides specific suggestions for improvement, such as adding more details to the paper and including error bars or pvalues when statistical inferences are made. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations in the paper are qualitative and that the procedures are described minimally or not at all, with some figures being confusing. The reviewer suggests that adding more details and supplementary information would be beneficial. Additionally, the comment recommends including error bars and/or pvalues when statistical inferences are made. While the comment identifies specific issues with the paper, it lacks detailed examples or references to support the claim about the qualitative nature of the explanations or the confusion in the figures. The suggestion to include error bars and pvalues is logical, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, it recommends including error bars and/or pvalues when statistical inferences are made. While the comment provides clear and actionable feedback on areas for improvement, it could be more helpful if it offered specific suggestions on how to enhance the explanations and figures. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add supportive references for claims that may be inspired by existing studies. It provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment is clear and concrete, as it specifies which parts of the paper need references and provides a specific example of where these references should be added. This gives the authors a direct action to take to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to add supportive references for claims inspired by existing studies. The comment provides a detailed example of the factors that need references, such as order sensitivity, complexity, diversity, and style sensitivity. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims may be inspired by existing studies and suggests that it is critical to add supportive references. The reviewer provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. However, the comment lacks detailed reasoning or specific references to existing studies that support the claims. While it highlights a potential issue, the lack of detailed evidence or examples makes the claim 3. The authors would need to further investigate and provide references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references are necessary. It provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. This feedback is clear and actionable, as it directs the authors to include references to support their claims. However, the comment could be more helpful if it suggested specific references or ways to integrate these references into the paper. Overall, the comment is 4 as it highlights a significant area for improvement and provides a clear direction for the authors to enhance the credibility and robustness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. This feedback implies that the authors should include this information in their paper to enhance its clarity and usefulness to the community. However, the comment does not provide specific guidance on how to present these settings or what aspects should be included. While the action is implied, it is not as concrete as it could be, as the authors are left to infer the exact details of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include these settings, but without explicit references to sections or elements of the paper, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. However, the comment lacks specific examples or references to these works, making it difficult for the authors to understand the exact nature of the suggestion. Without detailed justification or examples, the claim is not 5, as it relies on general knowledge of the field rather than specific evidence or reasoning. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. This feedback is 3 as it identifies a specific area for improvement, which could enhance the clarity and usefulness of the paper for the community. However, the comment lacks detailed guidance on how to implement this suggestion or what specific settings should be included. While it points out a potential improvement, it does not provide actionable steps for the authors to follow, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts, noting that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. However, the comment does not explicitly instruct the authors on how to address this issue or what specific information should be included to clarify the generalizability of these examples. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or examples to address the concern, but the comment lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of the examples of biases and prediction shifts presented in these sections. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases and prediction shifts but lacks clarity on their generalizability. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the presentation of examples of biases and prediction shifts in the paper. It points out that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. This feedback is clear and actionable, as it directs the authors to clarify the generalizability of these examples to enhance the understanding and applicability of their work. However, the comment could be more helpful if it suggested specific ways to address this issue, such as providing additional context or examples to illustrate the generalizability. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that adding a few more datasets would be beneficial, particularly in terms of crosstask transferability. While the comment implies that the authors should consider adding more datasets, it does not provide specific guidance on which datasets to include or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should add more datasets but are not given concrete details on which datasets to include or how to integrate them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on crosstask transferability. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need to be revised. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would enhance the analysis. Without specific details or references, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they would enhance the analysis. The feedback is 3 as it points out a potential area for improvement, but it does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks are somewhat standard and implies that the authors could have included more unique tasks to showcase the diversity of images/plots. It provides an example of interleaved imagetext tasks, such as question answering from images, as a potential area for improvement. While the comment implies that the authors should consider these tasks, it does not explicitly instruct them to do so or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should consider these tasks but may not be entirely sure how to integrate them into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also mentions the potential for unique tasks that could showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. However, the comment does not specify which part of the paper these tasks should be added to or how they would be integrated. While the authors might have an idea of where these tasks could fit, the comment lacks explicit grounding. It is specific about the need for unique tasks but does not provide detailed guidance on how to implement them. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also implies that the tasks could be more unique and diverse, such as interleaved imagetext tasks like question answering from images. The comment provides a logical reasoning for why the tasks could be more diverse and suggests specific examples of tasks that could be considered. However, it lacks specific examples or references to support the claim that these tasks would be beneficial or how they would enhance the paper. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the tasks being somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It suggests that the authors could create more unique tasks to showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. This feedback is 3 as it points out a potential area for improvement and provides an example of a more diverse task that could be considered. However, the comment could be more helpful if it offered specific guidance on how to implement these tasks or provided examples of how they could be integrated into the paper. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether there is any additional novel effort in the 3D Gaussians generation section, which is currently following the previous work, Luciddreamer. This is a clear and direct request for the authors to provide additional information or context to differentiate their work from the existing literature. The action is explicit and concrete, as it specifies what the authors need to address to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether there is any additional novel effort in this section. This provides clear guidance on what the authors need to clarify or improve in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussians generation is merely following previous work, specifically Luciddreamer. However, it does not provide any evidence, reasoning, or examples to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper, Sec. 3.1, where the authors appear to be following previous work, Luciddreamer, without adding any additional novel effort. This feedback is 3 as it points out a potential issue in the paper\"s originality and suggests that the authors clarify whether there is any additional effort or innovation in this section. However, the comment could be more helpful if it provided suggestions on how to differentiate the work or what specific aspects could be improved. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the tractability of MMD DRO compared to other methods like phidivergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude and that the nonnegative constraint on the distribution is dropped, requiring further approximation. Additionally, it questions the assumption that the loss function belongs to the RKHS. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the tractability and assumptions of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the upper bound provided in Theorem 3.1, noting that it drops the nonnegative constraint on the distribution and requires further approximation. Additionally, it questions the assumption that the loss function belongs to the RKHS, providing specific concerns about the method. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that MMD DRO does not enjoy a tractable exact equivalent reformulation, which is a severe drawback. The reviewer supports this claim by pointing out that the upper bound provided in Theorem 3.1 is crude because it drops the nonnegative constraint on the distribution and requires further approximation. Additionally, the reviewer questions the assumption that the loss function belongs to the RKHS, which is already pointed out by the authors. The comment provides logical reasoning and specific examples to support the claim, making it 4. However, it could be strengthened by providing more detailed explanations or references to similar works that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the tractability of MMD DRO compared to other methods like phidivergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude because it drops the nonnegative constraint on the distribution, requiring further approximation. Additionally, it questions the assumption that the loss function belongs to the RKHS, which is already pointed out by the authors. The comment provides specific and actionable feedback by suggesting that the authors should reconsider the tractability and assumptions of their method. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of alternative approaches. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics like covariance to design better defenses in binary classification. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues or what specific actions to take. The authors are left to infer that they need to provide more information or analysis to address these points, but the comment lacks detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it specifically references the section on binary classification. However, it does not explicitly mention which part of the paper discusses these topics, making it weakly grounded. The comment is specific in its inquiry about the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints, as well as the potential use of statistics like covariance to design better defenses. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. The reviewer also asks about the potential use of statistics like covariance to design better defenses in binary classification. While the questions are logical and relevant, they do not provide specific examples or references to support the claims. The authors would need to make a significant effort to address these questions, which makes the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics like covariance to design better defenses in binary classification. While the questions themselves are insightful and could lead to valuable discussions, the comment lacks specific guidance or suggestions on how the authors might address these issues or what specific analyses or experiments could be conducted. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more beneficial with additional direction or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would impact the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This is a clear and actionable suggestion that could potentially improve the paper by providing additional insights into the performance of the baselines. However, the comment lacks depth and does not explain why this approach might be beneficial or how it could be implemented effectively. While it provides a valuable direction for the authors to explore, it could be more helpful with additional guidance or rationale. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance. While the comment provides a clear list of specific questions that need to be addressed, it does not offer explicit guidance on how to implement these improvements. The authors are left with a clear understanding of what needs to be added but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the techniques and the reproducibility of the results. It provides detailed questions about the sparsification process, landmark generation, and number of landmarks used, as well as how to achieve shape invariance. This level of specificity allows the authors to accurately identify the parts of the paper that need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of detail in the paper regarding the techniques used and the reproducibility of the results. It highlights specific areas that are unclear, such as the sparsification process, landmark generation, and number of landmarks used. The reviewer also questions how to achieve shape invariance. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support the claims. This makes the comment 3, as it highlights areas that need clarification but lacks the depth and evidence needed for full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks detail and clarity, particularly regarding the techniques used and the reproducibility of the results. It highlights specific questions that need to be addressed, such as the sparsification process, landmark generation, and number of landmarks used. The comment also questions how to achieve shape invariance and provides a clear list of issues that need clarification. This feedback is actionable and offers a detailed roadmap for the authors to improve the clarity and comprehensiveness of their paper. However, it could be more helpful if it provided suggestions on how to address these issues or examples of how similar techniques have been implemented in other works. Overall, the comment is 4 as it guides the authors toward improving the clarity and reproducibility of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to reorganize the Appendix H section, which is difficult to follow. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific about the issue of difficulty in following the section, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Appendix H section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is that it is difficult to follow. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Appendix H section is difficult to follow. However, it does not provide any specific examples or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. This feedback is clear and actionable, as it directs the authors to reorganize the section to improve its clarity and accessibility. However, the comment could be more helpful if it provided suggestions on how to reorganize the section or what specific changes might improve its readability. Overall, the comment is 3 as it points out a clear area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer suggests that more technical details, such as the number of units in the RNN implementation, are missing. This feedback implies that the authors should include more detailed descriptions of the technical aspects of their work to improve reproducibility. However, the comment does not explicitly instruct the authors to add these details, leaving it somewhat vague. While the action is implied, the authors can infer that they need to provide more technical information, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with reproducibility, such as the lack of technical details like the number of units in the RNN implementation. This provides clear guidance on what needs to be addressed to improve reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, as it lacks technical details necessary for reproduction. The reviewer provides a specific example of the lack of details about the RNN implementation, such as the number of units. This claim is 3 as it highlights a gap in the paper\"s reproducibility, but it could be strengthened by providing more detailed examples or references to similar works that require such technical details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer highlights specific areas that are missing, such as technical details about the RNN implementation, which are necessary for reproducing the work. This feedback is clear and actionable, as it points out specific gaps in the paper that need to be addressed to improve its reproducibility. However, the comment could be more helpful if it suggested ways to address these gaps or provided examples of how similar details have been presented in other works. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars or more random trials to potentially reduce random fluctuations in the results. While the comment implies that the authors should consider adding these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars or more trials to improve the figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger with the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. However, the comment does not provide any specific reasoning or evidence to support why error bars or more trials would be beneficial. It lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in Figure 1, suggesting that the inclusion of error bars or more random trials could strengthen the figure by potentially reducing random fluctuations in the results. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the figure\"s robustness and clarity. However, the comment could be more helpful if it explained why error bars or additional trials are beneficial or how they might impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. It also references external works that discuss contextaware robust finetuning, finetuning impact on foundation models, and robust finetuning of zeroshot models. While the comment provides explicit actions, it does not specify how to implement these suggestions or what specific details should be included in the introduction or Figure 1. The authors are given clear guidance on what needs to be added but lack detailed instructions on how to execute these actions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"related work section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a brief introduction to energy models in the related work section and the lack of clarity regarding the correspondence between different learning rates and steps in Figure 1. The comment also provides references to external works that could be relevant to the contextaware robust finetuning discussed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. The reviewer references external works to support their claim, such as \"Contextaware robust finetuning,\" \"Finetuning can cripple your foundation model; preserving features may be the solution,\" and \"Robust finetuning of zeroshot models.\" These references provide a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how these references relate to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section. It also points out that the correspondence between different learning rates and steps in Figure 1 is not clearly explained, which is a critical aspect of the paper. Additionally, the comment references external works that could be relevant to the contextaware robust finetuning discussed in the paper. This feedback is clear and provides the authors with a concrete direction for improving their draft, making it 4. However, it could be more comprehensive by offering suggestions on how to integrate the energy models into the related work section or how to clarify the correspondence in Figure 1. Overall, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of premature evictions. The comment lacks concrete details or suggestions on how to improve the approach or validate its effectiveness. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach used in FIITED, specifically the potential for biases due to temporary high utility scores for recent chunks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue of premature evictions due to temporary high utility scores. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the risk of premature evictions due to temporary high utility scores for recent chunks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the bias or how it might manifest in their work. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. This is a valuable observation that could lead to premature evictions of other valuable chunks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the risk of biases. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the focus on DNNs is not relevant to the paper\"s core focus on detecting drift types and magnitude. The comment implies that the authors should reconsider the content and relevance of this paragraph, but it does not provide specific guidance on how to revise it or what alternative content could be included. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper\"s focus. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is 3 as it logically argues that the introduction of DNNs is not relevant to the paper\"s core focus on detecting drift types and magnitude. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide detailed guidance on how to improve the draft. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the paper\"s core focus. This feedback is clear and actionable, as it suggests that the authors should reconsider the relevance and content of this paragraph to ensure it aligns with the paper\"s central theme. By addressing this issue, the authors can improve the clarity and focus of their introduction, making the paper more effective for its intended audience. However, the comment could be more helpful if it provided suggestions on how to better integrate the DNN introduction with the paper\"s core focus. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the paper lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include quantitative experiments and comparisons, as well as detailed explanations of the algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not offer specific steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the methodology and the experimental section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of quantitative experiments and comparisons with other algorithms, as well as the need for more detailed explanations of the presented ones. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the lack of quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones, makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. The comment provides a logical reasoning for the need for more detailed information, but it does not cite specific examples or references to support the claim. This makes the claim 3, as it provides a reasonable basis but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. This feedback is valuable as it highlights a critical area for improvement in the paper, namely the need for more comprehensive and detailed experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps, such as which experiments to conduct or how to present the results more effectively. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the clarity of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its concern about the model\"s ability to generate novel knowledge or testable hypotheses, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. While the comment implies that the authors should create a simplified version, it does not provide specific guidance on how to achieve this or what aspects of Theorem 2 should be simplified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests presenting a simplified version of Theorem 2, similar to Theorem 1, to make it more accessible to the general audience. However, it does not specify which part of the paper contains Theorem 2 or where the simplified version should be placed. The authors can infer that it relates to the section containing the theorem, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. However, the comment does not provide any reasoning, examples, or references to support why this simplification is necessary or how it would benefit the paper. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. This feedback is 3 as it identifies a potential issue with the presentation of the theorem, which could improve the clarity and comprehensibility of the paper. However, the comment lacks specific guidance on how to achieve this simplification or what aspects of Theorem 2 should be simplified. While it points out a potential area for improvement, the authors are left with a general suggestion without detailed instructions on how to implement it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider conducting experiments using a larger image resolution, such as 224*224, to explore the performance of their model. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to implement this suggestion or what specific aspects of the model should be tested at the larger resolution. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by testing the model at a larger resolution, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. This is a valuable suggestion that could provide insights into how the model would perform with different image resolutions. However, the comment lacks depth and does not explain why this change would be beneficial or how it might impact the results. Additionally, it does not offer specific guidance on how to implement this suggestion or what aspects of the model should be tested at the larger resolution. While the suggestion is 3, it could be more actionable and comprehensive with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the \"keypoint mask averaged feature vector\" in the \"KeyQN\" section, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the calculation of the \"keypoint mask averaged feature vector\" and suggests a possible explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the calculation of the \"keypoint mask averaged feature vector\" in the \"KeyQN\" section. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the calculation of the \"keypoint mask averaged feature vector\" in the \"KeyQN\" section, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While this question may be relevant to the authors, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address the issue or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use styles or add color to make it easier to distinguish between the different curves in Figure 2. While the suggestion is clear and provides a specific action to take, it lacks detailed guidance on which styles or colors to use. The authors are left to infer the specifics of how to implement this suggestion, which makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the difficulty in distinguishing between the different curves. The comment provides a clear suggestion to use styles or add color to improve the figure, offering a concrete action for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the curves in Figure 2 are difficult to distinguish, and it provides a specific suggestion to use styles or add color to improve the figure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current figure is difficult to distinguish or how the suggested changes would improve clarity. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand the basis of the suggestion without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on Figure 2, noting that the different curves are difficult to distinguish. It suggests using styles or adding color to improve clarity. While the comment identifies a specific issue with the figure, it lacks depth and does not provide detailed guidance on how to implement the suggested changes or which styles or colors might be most effective. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors tone down the introduction and not refer to the task as \"language learning.\" It suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is 5 as it gives a direct and specific direction for improvement, ensuring that the authors know exactly how to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"claims made in the introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the overstatement of the task as \"language learning\" and the evaluation on question answering, suggesting that it is more accurately described as a feedbackdriven QA in the form of a dialog. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are far from what has been achieved by the tasks and models, and suggests that the authors should tone down the introduction and not refer to it as \"language learning.\" The reviewer provides a logical reasoning by pointing out that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment lacks specific examples or references to support the claim that the task is significantly different from language learning. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are far from what has been achieved by the tasks and models. It suggests that the authors should tone down the introduction and not refer to it as \"language learning,\" as it is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the clarity and accuracy of their introduction. By addressing this point, the authors can enhance the credibility and coherence of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or provide a convincing analytical or empirical argument. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of the analytical or empirical evidence are lacking, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the central contribution of the paper, which is based on modeling weight evolution using ODEs, is not convincing due to the issue of neural ODEs exhibiting inaccuracy while recomputing activations. The reviewer questions whether this problem has been previously reported and suggests that the current paper lacks a convincing analytical or empirical argument to support the claim. However, the comment does not provide specific references or examples to substantiate the claim, making it difficult for the authors to understand the basis of the reviewer\"s skepticism. This lack of supporting evidence or detailed reasoning makes the claim 2, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s central contribution, which is based on modeling weight evolution using ODEs. It questions the accuracy of neural ODEs while recomputing activations, suggesting that this issue has been previously reported. The comment highlights a gap in the paper\"s analytical or empirical evidence to support the claim, indicating that the authors need to provide a more convincing argument or evidence to address this concern. However, the comment does not offer specific suggestions or guidance on how the authors might improve their analysis or evidence to address this issue. While it points out a potential weakness, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While the comment implies that the authors should add this information, it does not explicitly instruct them to do so or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include this detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section, figure, or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting what needs to be mentioned, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While it identifies a potential area for clarification, it lacks specificity and does not provide guidance on how to address this issue or why it is important. The comment is 3 as it points out a potential gap in the explanation, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment implies that the authors should focus on proving lower bounds for collaborative ranking, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or analysis section where lower bounds are discussed. The comment is specific in detailing what is problematic\u2014the ease of obtaining lower bounds due to the reduction from collaborative ranking\u2014but it does not provide specific guidance on how to address this issue. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. The comment provides a logical reasoning for why the lower bound results are not as challenging as initially assumed, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to further explore the reduction from collaborative ranking to understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. This feedback highlights a potential weakness in the paper\"s originality and contribution, as it suggests that the results are not as novel as initially presented. While the comment provides some insight into the potential limitations of the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. While the comment implies that the authors should consider using more advanced prompting techniques, it does not provide specific guidance on how to implement this suggestion or what specific prompts might be effective. The action is implicit and somewhat vague, as the authors need to infer the need for more advanced prompting techniques and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use carefully curated prompts is specific, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment provides a logical argument for the need to improve the prompting technique, it lacks specific examples or references to support the claim that carefully curated prompts would lead to better results. This makes the claim 3, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the study, specifically the prompting technique used, which is described as basic and failing to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an area for improvement, it lacks specific guidance or examples on how to implement this suggestion. The authors are given a general direction but are not provided with detailed steps or examples to follow. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the authors addressed concerns about maintaining probabilities at large batch sizes. However, the comment does not explicitly instruct the authors to conduct these additional experiments or provide guidance on how to manage compute issues. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on larger datasets, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup, but the comment lacks full grounding as it does not explicitly mention the section. The comment is specific in suggesting additional experiments but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger datasets, which is a suggestion for improvement. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. The comment does not provide specific reasoning or evidence to support why maintaining probabilities might be an issue or how it could be addressed. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the potential issue and address it themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, which is a constructive suggestion for improving the paper. It acknowledges the potential issue of compute but notes that maintaining probabilities might become an issue at large batch sizes. The comment appreciates the authors\" response and provides a positive assessment of how well the authors addressed concerns about maintaining probabilities. However, it could be more helpful if it offered specific guidance on how to manage compute issues or how to address concerns about maintaining probabilities at large batch sizes. Overall, the comment provides actionable feedback but could be more comprehensive with additional details, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the performance of the model on REC and RES is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance or suggestions for potential improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the performance of the model on REC and RES being behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by references to external works, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or specific metrics to support the claim further. As it stands, the claim is 4 due to the inclusion of references, but it could be more robust with additional evidence or explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a significant issue with the performance of the model on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This feedback is valuable as it identifies a clear area for improvement, allowing the authors to address the issue and potentially improve their results. However, the comment could be more helpful if it provided suggestions on how to improve the performance or offered guidance on potential strategies for catching up with more recent models. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the term \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This implies that the authors should revise the language in the paper to be more precise and accurate. However, the comment does not provide specific guidance on how to rephrase the term or what alternative wording would be more appropriate. The action is implicit and somewhat vague, as the authors need to infer the exact changes needed to make the comment more actionable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific figure, \"Fig. 5,\" which provides evidence that some information is learned before the model can use the concepts. However, it does not specify which part of the figure or the paper this evidence is presented in, making it weakly grounded. The comment is specific in suggesting that the term \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This provides clear guidance on what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the term \"evidence\" might be too strong in describing the figure, recommending a more appropriate wording like \"Fig.\" This is a suggestion for clarification rather than a claim or opinion that requires verification. It does not present an argument or evidence to support the claim that \"evidence\" is inappropriate, making it a factual observation rather than a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific figure, \"Fig. 5,\" and points out that the term \"evidence\" might be too strong for the figure. It suggests a more appropriate wording, such as \"Fig.\" This feedback is 3 as it provides a clear suggestion for improving the language used in the paper. However, it could be more helpful if it explained why \"evidence\" might be inappropriate or provided additional context on how the figure is presented or what it shows. Overall, the comment offers a specific and actionable suggestion, but it could be more comprehensive to fully assist the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation instead of crossattention. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue or improve the novelty of their approach. The action is implicit and somewhat vague, as the authors can infer that they need to explore ways to enhance the innovation of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed video storyboarding approach\" and \"framewise SDSA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty in the approach, noting that it relies heavily on framewise SDSA and that the only notable difference is the mask source. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation rather than crossattention. This claim is 3 as it provides a specific comparison to ConsiStory, which is a wellknown approach, and highlights the difference in the mask source. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer highlights the only notable difference as the mask source, which uses CLIPseg and OTSU segmentation rather than crossattention. This feedback is 3 as it points out a specific area where the paper could be improved by exploring more innovative approaches or techniques. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. To be more helpful, the comment could provide specific suggestions or examples of alternative methods that could be considered. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method being discussed is more relevant for addressing issues in images with multiple objects or cluttered scenes. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. While the comment implies that the authors should consider conducting such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison, but it is not as concrete as it could be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method being discussed is more relevant for addressing issues in images with multiple objects or cluttered scenes. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a comparison with previous approaches. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the method being discussed is more relevant for addressing issues in images with multiple objects or cluttered scenes. However, it does not provide any supporting evidence or references to substantiate this claim. The comment lacks specific examples or detailed reasoning to justify why this method would be more effective in such scenarios. As a result, the claim is not verifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the method being discussed is more relevant for addressing issues in images with multiple objects or cluttered scenes. It proposes an interesting comparison with previous approaches on fewshot classification in such datasets. This feedback is 3 as it provides a direction for the authors to consider in terms of applicability and potential improvements. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the feedback provides a valuable direction for the authors to explore, but it could be more actionable with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or specify how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation of the bounds. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be added. This makes it difficult for the authors to pinpoint the exact section that needs improvement. While the authors might have an idea of where the bounds are discussed, the comment lacks specificity in identifying the exact part of the paper that needs more explanation. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this additional explanation is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to effectively present this additional explanation or what specific aspects of the bounds need clarification. The comment is 3 as it points out a potential weakness, but it does not offer actionable steps for the authors to address it. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not provide any guidance on how the authors should revise or adjust their explanation. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this explanation is provided in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the explanation are considered unnecessary or how the authors might improve it. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not provide any specific guidance or suggestions on how the authors might revise or improve their explanation. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability. The reviewer also points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the transferability and complexity of the tasks but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the zeroshot nature of the work and the transferability of the policy, suggesting that the difficulty of the source and target tasks might limit the transferability. It also provides specific examples of the manipulation scenario, such as the 3prong task with clockwise/counterclockwise rotations and the 4prong task, which could be used to clarify the target task. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the transferability and the need for clarification, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the difficulty of the tasks or the transferability of the policy. While it provides some context and examples, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to illustrate this point. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or clarify the transferability in the paper. While it identifies potential weaknesses and areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide specific guidance on how the authors should address this concern or what steps they should take to improve the results on larger backbones like SwinB or SwinL. The action is implicit and somewhat vague, as the authors can infer that they need to test the method on larger backbones but are not given concrete steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. It also suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the relative gains and the potential impact of the global pooling structure on the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment lacks specific examples or references to support the claim about the relative gains or the potential impact of the global pooling structure on the results. Without detailed evidence or comparisons, the claim is 3, as it provides a logical reasoning but lacks sufficient justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that the relative gains are not very strong, even on smaller backbone models like ResNet50. It suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the results on larger backbones like SwinB or SwinL. While it points out a potential limitation, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial with the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take to address this critique. It lacks guidance on how the authors might improve their analysis or what specific aspects of the neural network analysis need attention. As a result, the comment is 1, as it does not offer any direction for the authors to follow.", "grounding_specificity_rationale": "The comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial with the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. However, the comment does not specify which sections of the paper these critiques pertain to, making it weakly grounded. The comment is specific in detailing the issue with the analysis of neural networks, but without explicit references to sections, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of neural networks is less significant due to the existing NTK theorem, which makes the extension from linear models to wide fullyconnected neural networks trivial. The reviewer supports this claim by pointing out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. However, the comment lacks specific examples or references to the literature that substantiate the claim about the triviality of the extension. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3, as it requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial with the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. This feedback highlights a potential weakness in the paper\"s analysis and suggests that the authors should address this issue by providing a more comprehensive analysis of neural networks. However, the comment does not offer specific suggestions or guidance on how the authors might improve their analysis or what aspects of the neural network analysis need attention. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a specific suggestion to consider using more datasets to ensure rigor. However, the comment does not provide explicit guidance on how to select or acquire additional datasets, nor does it offer specific examples of datasets that could be used. While the action is implicit, it is clear that the authors need to consider expanding their dataset selection, but the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment is fully grounded as it explicitly mentions the number of datasets for each task, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it details the concern about the rigor of the evaluation and suggests that more datasets might be needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a logical reasoning by pointing out that having a limited number of datasets could impact the evaluation\"s thoroughness. However, the comment lacks specific examples or references to support the claim that some datasets are too large for all algorithms. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment provides a logical reasoning for the need to consider additional datasets to ensure thorough evaluation. However, it lacks specific suggestions on how to address this issue or which datasets could be considered. While it identifies a potential weakness, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of results with larger models like ResNet101/152, which is a specific action for the authors to take. However, it does not provide guidance on how to conduct these experiments or what specific aspects to focus on. The comment implies that the authors should include results with larger models, but it lacks concrete details on how to implement this action. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the performance of ResNet models on imageNet classification, specifically mentioning ResNet50/34/18 and noting the absence of results with larger models like ResNet101/152. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in identifying the issue of not including results with larger models, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no results with larger models like ResNet101/152, but it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to previous studies or benchmarks, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of results with larger models like ResNet101/152. This feedback highlights a potential gap in the paper\"s evaluation, which could be addressed by including results with these models. However, the comment lacks depth and does not provide suggestions on how to conduct these experiments or what specific aspects to focus on. While it identifies a potential weakness, it does not offer actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential confusion in the paper regarding the use of terms like \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific changes should be made to clarify the terms. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, specifically mentioning a reference to Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al., 2017). This provides full grounding as it clearly identifies the part of the paper being addressed. The comment also specifies the issue of confusion regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" and \"expensive to evaluate\" are confusing, as they appear in different parts of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these terms are confusing or how they could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" used in different parts of the document. This is a clear and actionable observation that can help the authors clarify their language and improve the coherence of their writing. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific changes or clarifications to be made in the text. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the method addresses sparse reward problems and questions whether it can solve sparsereward tasks as well as other methods (Qmix). However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, or suggesting ways to improve the method\"s performance in sparsereward scenarios. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the method and the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the method addresses sparse reward problems and whether it can solve sparsereward tasks as well as other methods (Qmix). The comment provides a clear direction for improvement by asking for clarification on the method\"s performance in sparsereward scenarios. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the method\"s ability to address sparse reward problems and suggests that the experiments do not support this claim. The reviewer provides a logical reasoning by comparing the proposed method to dense reward signals and subtaskspecific rewards, which are similar to dense reward signals. However, the comment lacks specific examples or references to support the claim that the method does not address sparse reward problems effectively. While the reasoning is somewhat logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems effectively, based on the experiments. It suggests that the proposed method requires subtaskspecific rewards, which is similar to dense reward signals, and questions whether it can solve sparsereward tasks as well as other methods (Qmix). The comment also provides minor comments that could be addressed to improve the draft. However, the feedback lacks specific suggestions or actionable steps for the authors to take in response to the critique. While it identifies areas for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"curated AH36M dataset\" and the need for clarification on whether it is used for training. It also raises questions about whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of the curated AH36M dataset for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This is an important consideration for ensuring the fairness and validity of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to clarify the use of the dataset. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment identifies two main issues: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or discussion are confusing. It lacks concrete details on how to improve the clarity or depth of the paper. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies specific issues with the proof of the main results, suggesting that there are confusing mistakes. However, it does not specify which part of the proof is confusing or where the mistakes are located. Additionally, it mentions the lack of a detailed discussion and comparison with previous work, but it does not specify which parts of the paper are missing this discussion. The comment also suggests that the paper lacks new insights, but it does not provide specific examples or details to support this claim. Overall, the comment is 1 and lacks specificity, making it difficult for the authors to understand and address the issues. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. Additionally, it suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of specific examples or references makes the claim 1, as it does not provide sufficient evidence or justification to support the claims. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed guidance on how to address these issues or what aspects of the proof or discussion are confusing. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses several issues related to the motivation, experimental results, and comparison of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment does provide some specificity by mentioning the addition of CAT and GAN, which could be used to guide the authors in identifying the relevant sections. Overall, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in detailing the issues. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the motivation for using an adversarial network is unclear and that the experimental results are unfair. It also suggests that the proposed model is equipped with a larger CAT and GAN, which could be considered an unfair comparison. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. While it highlights these areas for improvement, the comment does not provide specific suggestions or guidance on how the authors might address these issues. It lacks actionable advice or detailed feedback that would help the authors improve their draft. As a result, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to compare their captioning experiment results to the official COOC leader board on the blind test set, which is a clear and concrete action. It also suggests that the paper should compare to other approaches that have been evaluated on the blind challenge set, providing a specific example of 5,17 and mentioning that several other approaches have been proposed since then. This feedback is detailed and provides specific guidance on how to improve the paper by including comparisons to official test sets and other relevant works. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the captioning experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of results to the official COOC leader board on the blind test set and the inclusion of comparisons to other approaches that have been evaluated on the blind challenge set. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the captioning experiment should be compared to the official COOC leader board on the blind test set, which is a specific suggestion for improvement. The reviewer provides a reference to the COOC leaderboard and examples of approaches that have been evaluated on it, such as 5,17. This provides a clear and concrete basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on how the authors can improve their captioning experiment. It points out that the paper currently compares to related work only on some not official test set or dev set, which is not ideal for demonstrating the final results. The reviewer suggests that the paper should compare to the official COOC leader board on the blind test set, which is a widely recognized benchmark in the field. Additionally, the comment suggests that the paper should include comparisons to other approaches that have been evaluated on the blind challenge set, such as 5,17, and mentions that several other approaches have been proposed since then. This feedback is clear and provides a concrete direction for the authors to enhance the rigor and credibility of their results. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the reliability of the results or what specific steps to take to validate them. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the MSE being significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results and highlights a potential weakness in the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the reliability of their experimental results. Without specific recommendations or examples, the feedback lacks depth and does not fully support the authors in improving their draft. Therefore, the comment is rated as 2, as it points out a problem but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as recommending ways to differentiate the methodology or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique is based on, such as specific sections or methods where the extension is evident. Without explicit references to sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or references to existing methods to substantiate this claim. Without detailed comparisons or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might differentiate their work or enhance its originality. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific techniques or approaches to incorporate adversarial loss or explaining why it is necessary. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where this is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the adversarial loss are missing or how it could be incorporated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is no adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting the absence of adversarial loss to ensure that perturbed data is similar to authentic data. This is a relevant point that could impact the validity and reliability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate adversarial loss. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific line (L248) where the term \"wrong\" is used and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5 as it offers a direct and specific suggestion for clarification, making it easy for the authors to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"wrong\" and the use of terms like \"good\" and \"bad\" explanations. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the term \"wrong\" in a specific context and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This is a request for clarification rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the term \"wrong\" in the paper and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and actionable, as it points out a potential confusion in the paper that could be resolved by providing additional context or clarification. By addressing this issue, the authors can improve the clarity and coherence of their argument. However, the comment could be more helpful if it provided suggestions on how to clarify the terms or offered examples of how they might be used more effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The reviewer is open to changing their rating based on feedback from the authors and comments from other reviewers. While the comment implies that the authors should provide additional analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as it lacks specific guidance on what kind of analysis should be provided. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance comparison and the need for analysis to address the issue of inferior results. It also specifies the need for analysis to be provided, which adds clarity to the comment. However, it does not provide specific examples of what kind of analysis should be conducted or how it should be presented, leaving some room for interpretation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The comment provides a logical reasoning by pointing out the limited comparison and the need for analysis to explain the results. However, it lacks specific examples or references to support the claim that the results violate the motivation. This makes the claim 3, as the authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The reviewer acknowledges the possibility of changing their rating based on feedback from the authors and comments from other reviewers. This feedback is clear and actionable, as it points out a specific area for improvement and encourages the authors to address it. However, it could be more helpful if it provided specific guidance on what kind of analysis should be conducted or how it should be presented. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the current experimental comparison only compares ELF (the author\"s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. This feedback provides a clear and concrete action for the authors to take, which is to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. The comment is 5 as it directly instructs the authors on how to enhance their experimental section to better support their claims.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental demonstration of the contribution points\" and the \"experimental comparison between ELF (the author\"s method) and the baseline without Mid Vision Feedback (MVF),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a comparison with the image classification result of Mid Vision Feedback (MVF) to prove the superiority of the schema searched by ELF. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment highlights a gap in the experimental section, noting that the current comparison only compares ELF (the author\"s method) with the baseline without MVF. This critique is 3 as it points out a specific issue with the experimental setup, but it could be strengthened by providing more detailed reasoning or examples of how the comparison with MVF could enhance the demonstration of the contribution points. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it points out a critical area where the paper lacks evidence to support its claims. By suggesting a comparison with MVF, the reviewer provides a concrete suggestion for the authors to enhance their experimental section and demonstrate the superiority of their method. However, the comment could be more helpful if it offered specific guidance on how to conduct this comparison or what specific metrics to use. Overall, the comment is 4 as it effectively highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should add more content on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors can infer that it relates to the dataset analysis or discussion, but the comment lacks full grounding. It is specific in suggesting what needs to be addressed, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they could be addressed. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it points out a gap in the paper that could enhance its depth and relevance. However, the comment could be more helpful if it provided examples or detailed suggestions on how to address this issue, such as which types of activities should be covered or how they could be integrated into the existing analysis. Overall, the comment is 4 as it directs the authors to a meaningful area for expansion and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should use different notation to avoid confusion between the dimensionality of points and the dilation factor. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the clarity of their paper. The comment is concrete, as it specifies the need for different notation, and it is also somewhat vague as it does not provide detailed guidance on what specific notation should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"D\" to represent both dimensionality and dilation factor, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of different notation to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using \"D\" to represent both dimensionality and dilation factor can cause confusion. However, it does not provide any supporting evidence or examples to substantiate this claim. The comment lacks specific reasoning or references to justify why using different notation would be beneficial, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of \"D\" to represent both dimensionality and dilation factor, suggesting that different notation should be used to avoid confusion. This is a clear and actionable suggestion that can help improve the clarity and readability of the paper. However, the comment could be more helpful if it provided examples of alternative notations or explained why the current notation is confusing. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can enhance the clarity and accessibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions\" in a specific context. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more elaboration on the concept of state, but the comment lacks concrete suggestions on what specific aspects should be clarified or how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the equivalence of \"elements\" to \"states\" or \"actions\" and requests more elaboration on the concept of state. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" and seeks further elaboration on the equivalence of \"elements\" to \"states\" or \"actions.\" While the comment identifies a potential area of confusion, it does not provide specific examples or references to support the claim that the concept of state is unclear. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions.\" It points out that the authors need to provide more elaboration on this concept to enhance the clarity of their work. While the comment highlights an important area for improvement, it does not offer specific suggestions or guidance on how to address the issue of clarity. The authors are left to infer that they need to provide more detailed explanations, but without concrete advice, the feedback is 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the use of a Jaccard index. This provides a clear and explicit action for the authors to take, as it specifies a specific method for evaluating the support of their solution. The suggestion is concrete, as it directly instructs the authors on how to conduct the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the use of a Jaccard index. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table where the results are presented. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a comparison using a Jaccard index. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the use of a Jaccard index. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the use of a Jaccard index. This is a clear and actionable suggestion that could provide valuable insights into the effectiveness of the proposed solution. By including this comparison, the authors could demonstrate the strengths and limitations of their approach relative to existing methods. However, the comment could be more helpful if it explained why the Jaccard index is an appropriate metric for this comparison or how it would enhance the paper\"s contribution. Overall, the comment is 4 as it provides a specific direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific observation regarding the behavior of a generator equipped with a standard RGCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. While it implies that the authors should investigate and explain the reason behind the difference, it lacks detailed guidance on how to do so. Therefore, the comment is 3, as it identifies an area for further exploration but does not offer specific steps for implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the tendency of a generator equipped with a standard RGCN as a discriminator to collapse after several iterations, while the proposed module does not. The comment suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, it does not provide specific suggestions on how to address this issue or what aspects of the proposed module should be explored. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a generator equipped with a standard RGCN as a discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or examples to substantiate the claim, making it 3. The authors would need to make a significant effort to verify the claim themselves, as the comment does not offer enough guidance or evidence to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific observation regarding the behavior of a generator equipped with a standard RGCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. This observation is important as it highlights a potential difference between the proposed method and previous ones, which could be a key aspect of the paper\"s contribution. However, the comment acknowledges that this part is missing from the current version of the submission. While it points out the importance of understanding the reason behind this difference, it does not provide specific suggestions or guidance on how the authors might address this issue or explore the mechanism behind the proposed module\"s effectiveness. The feedback is 3 as it directs the authors\" attention to a critical area for improvement, but it lacks detailed guidance on how to proceed. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the originality of the paper, noting similarities to a previous study. It implies that the authors should address this issue by either explaining how their work differs from the previous study or demonstrating novel contributions. However, the comment does not provide specific guidance on how to do this, such as suggesting ways to differentiate the work or highlighting areas where novelty is present. The action is implicit and somewhat vague, as the authors need to infer that they should address the originality concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the paper, specifically mentioning a previous study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning.\" This provides some grounding by referencing a specific work, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what aspects of the paper are similar to the previous study or how the authors can address the originality concerns. The lack of specificity regarding the issues or suggestions for improvement makes it 2. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s originality is questionable due to similarities with a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The mention of the previous study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning,\" serves as a reference but does not offer sufficient evidence or analysis to support the claim. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to further explore the similarities themselves to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the paper, noting similarities to a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address the originality concerns. It does not provide actionable feedback or detailed advice on how to differentiate the work or demonstrate novelty. As a result, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit suggestions on how the authors should clarify these comparisons or what specific aspects need to be addressed. There is no guidance on whether additional explanations or examples are needed, nor is there a recommendation for how to present the comparisons more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical comparisons to adaptive learning of GPRGNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the theoretical comparisons to adaptive learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN. It points out that the comparisons are not clear, which is a critical issue for understanding the paper\"s contributions and implications. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these comparisons or what aspects need to be addressed. While it highlights an important area for improvement, the feedback is incomplete and does not fully support the authors in making the necessary changes. Therefore, the comment is 3, as it provides a direction for improvement but lacks actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination. It highlights that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when performing other tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the measurement. The action is implicit and somewhat vague, as the authors can infer that they need to consider alternative methods for measuring object hallucination, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is used. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination, suggesting that a simple yes response does not necessarily indicate comprehension of the object in the image. The reviewer provides a logical reasoning by explaining that the model may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support the claim that a simple yes/no response is insufficient. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. It points out that the model may still produce incorrect objects when undertaking other tasks. This feedback is 3 as it identifies a potential limitation in the methodology and encourages the authors to consider alternative methods for measuring object hallucination. However, the comment could be more helpful if it provided specific suggestions or examples of alternative methods that could be used. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and that the discussion requires improvement. It explicitly recommends conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and adjusting the model training to improve the context of their results. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment addresses the issue of the verylongterm forecasting task being of limited practical significance and suggests that the discussion requires improvement. However, it does not specify which part of the paper discusses this task or the specific aspects that need improvement. The authors can infer that it relates to the discussion section, but the comment lacks full grounding as it does not explicitly mention the section. The suggestion to conduct experiments on more datasets and train the baseline models with the \"correct\" forecast horizon is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion requires improvement. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the limited practical significance of the verylongterm forecasting task. It suggests that the discussion requires improvement by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is clear and actionable, providing the authors with specific steps to enhance the relevance and practical significance of their work. However, the comment could be more helpful if it explained why the current discussion is insufficient or how the suggested improvements would impact the paper\"s contribution. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. It suggests that this is a key difference between the work and VideoChatGPT and other works. The reviewer implies that the authors should include experiments and explanation to address this gap. While the comment does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to conduct them, it clearly points out the missing components and suggests a direction for improvement. The action is implicit but concrete, as the authors can infer the need to include these experiments and explanations. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experiments  Ablation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the inclusion of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. The reviewer suggests that this is a key difference between the work and VideoChatGPT and other works. However, the comment lacks specific examples or references to support the claim that these queries are crucial or how they would impact the results. Without detailed justification or evidence, the claim remains 3, as it provides a logical suggestion but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of experiments and explanation regarding the different queries used in spatiotemporal representation. It highlights the importance of these queries, as they are a key difference between the work and VideoChatGPT and other works. The comment suggests that the authors should include experiments and explanation to address this gap, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific examples of queries or detailed guidance on how to conduct these experiments. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer concrete steps or examples of what these details should include. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not specify which part of the paper discusses the FRM, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for more details on the innovative aspects of the FRM, but it is 1 as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation. It suggests that the innovative aspects should be detailed, but it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. While the comment highlights a potential weakness, it lacks actionable advice or examples that would help the authors improve their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider the potential negative social impacts of their work, such as increased automation or dual use risks. While the comment does not explicitly instruct the authors to include these aspects in their paper, it provides a clear direction for improvement by highlighting areas that could be explored. The action is implicit but concrete, as it specifies the potential negative impacts that should be addressed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential negative social impacts of the work, such as increased automation or dual use risks. The comment provides a clear direction for improvement by suggesting that the authors should consider these aspects in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not consider the potential negative social impacts of their work, such as increased automation or dual use risks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without concrete evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the lack of consideration of negative social impacts, such as increased automation or dual use risks. While it acknowledges that the authors may not have intended to address these aspects, it suggests that they could consider doing so. The comment provides a clear direction for improvement by highlighting areas that could be explored, which is helpful for the authors. However, it could be more helpful if it offered specific examples or guidance on how to address these potential impacts. Overall, the comment is 4 as it points out a relevant area for consideration, but it could be more actionable with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific reorganization of the sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides a clear and concrete action for the authors to take, as it offers a specific way to restructure the sections to improve clarity and coherence. The comment is explicit in its suggestion and provides a concrete implementation, making it 5.", "grounding_specificity_rationale": "The comment suggests reorganizing sections 3 and 4 to improve clarity and coherence. It explicitly mentions \"Section 3 and Section 4,\" providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific because it suggests a specific reorganization, such as moving the first paragraph of Section 4 to Section 3 and placing the remainder before Section 3. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that sections 3 and 4 are redundant and proposes a specific reorganization to improve clarity and coherence. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the sections are redundant or how the suggested reorganization would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential redundancy in Sections 3 and 4, suggesting that reorganizing these sections could improve clarity and coherence. It provides a specific and actionable suggestion by proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This feedback is clear and offers a concrete way for the authors to enhance the structure and organization of their paper, which could improve the overall readability and comprehensibility. However, the comment could be more helpful if it explained why the current organization is redundant or how the suggested reorganization would benefit the paper. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should provide more details to establish a connection between these concepts. However, the comment does not specify what kind of details are needed or how the authors should present them. While the action is implicit, it is vague because it lacks concrete guidance on how to address the issue of clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the connection between these concepts and the zeroshot learning effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might clarify these concepts or improve the clarity of their writing. While it highlights an area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these analyses to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"strong empirical results\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the potential contribution of finding out the reasons behind the empirical results through theoretical analyses or extensive experiments. However, the comment lacks specificity regarding what kind of theoretical analyses or experiments would be needed to address the questions raised. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment raises valid questions about the empirical results, it lacks specific examples or references to support the claim that these analyses are missing from the paper. The suggestion is logical and relevant, but the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is clear and actionable, as it points out a specific area where the authors could enhance their work by conducting additional analyses or experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these analyses or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for a citation regarding the kmax problem, which is a clear and direct action for the authors to take. The comment provides a specific request for additional information, ensuring that the authors know exactly what is expected of them. The action is concrete, as it specifies the need for a citation, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for a citation regarding the kmax problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a citation regarding the kmax problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for a citation regarding the kmax problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where additional information or clarification is needed. By asking for a citation regarding the kmax problem, the reviewer prompts the authors to provide more context or references to support their claims. This feedback is actionable and can help the authors enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address the kmax problem or integrate the cited work into the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback implies that the authors should provide more detailed information about the estimation process and the model\"s reliability. However, the comment does not explicitly instruct the authors to include this information, nor does it provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This provides clear guidance on what the authors need to include in their paper to improve it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the applicability or what specific changes could be made to mitigate the assumptions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the assumptions made and their impact on applicability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods, specifically noting that strong assumptions are made about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. This feedback highlights a potential weakness in the paper that could impact its relevance and practicality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. While it points out a relevant concern, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with the word \"thousands\" in the main text, suggesting that it might be more accurate to say \"on the subword level.\" This provides a clear and concrete action for the authors to take, as they are directly instructed to make a specific change to the text. The comment is explicit and provides concrete guidance on how to implement the suggested correction, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inaccuracy of the word \"thousands\" and suggests a possible correction to \"on the subword level.\" This provides clear guidance on what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the word \"thousands\" is not accurate in the main text, suggesting that it might be more accurate to say \"on the subword level.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the word \"thousands\" in the main text, suggesting that it might be more accurate to say \"on the subword level.\" This feedback is clear and actionable, as it provides a concrete suggestion for improving the accuracy of the text. However, the comment could be more helpful if it explained why this change is necessary or how it would enhance the clarity of the text. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can help them refine their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It notes that several hyperparameters, such as regularization, are not explicitly mentioned and asks for clarification on why the y value in the latent path figures is always 0 at x=0. The reviewer also expresses interest in seeing further analysis on the model, specifically mentioning interpolations. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are somewhat vague, as they do not specify how to address the issues or what specific analyses should be conducted. Therefore, the comment is 3, as it points out areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig 3\" and \"regularization,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues by questioning why the y value in the latent path figures is always 0 at x=0 and asking for clarification on the normalization. Additionally, it suggests further analysis on the model using interpolations. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the absence of certain hyperparameters, such as regularization, and the constant value of y at x=0 in the latent path figures. It also suggests that further analysis on the model could be beneficial. While the comment identifies areas for clarification and potential improvements, it lacks specific examples or references to support the claims. The authors would need to make a significant effort to understand and address the issues raised, as the comment does not provide detailed reasoning or evidence. Therefore, the comment is 3, as it points out potential areas for improvement but lacks the necessary justification to be 5.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the absence of certain hyperparameters, such as regularization, and the constant value of y at x=0 in the latent path figures. It also suggests that further analysis on the model could be beneficial, specifically mentioning interpolations. While the comment raises important questions and points out potential weaknesses, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general sense of what needs to be improved but are not provided with actionable steps or detailed advice on how to implement these improvements. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It specifically points out examples like Figure 1 and the deeprag algorithm, which are mentioned in the appendix but not in the main sections. The comment suggests that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions should be included in the main sections. While the comment provides a clear action to take, it lacks specific guidance on how to address the issue, such as suggesting a particular section or paragraph where the contributions should be explained. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, such as Figure 1 and the deeprag algorithm, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clear explanation of the contributions in the Introduction and the placement of supporting material in the appendix. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. The reviewer provides specific examples, such as Figure 1 and the deeprag algorithm, which are mentioned in the appendix but not in the main sections. This provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the use of forward referencing where material is introduced without proper explanation and is later explained in later sections. It provides specific examples, such as Figure 1 and the deeprag algorithm, which are mentioned in the appendix but not in the main sections. The comment suggests that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions should be included in the main sections. This feedback is clear and actionable, as it directs the authors to improve the clarity and organization of their paper. However, it could be more helpful if it provided suggestions on how to structure the paper or what specific information should be included in the main sections. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the effect of rounding core tensors on the full tensor error and seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should provide more information on the theoretical aspects of the approximation error, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the rounding of core tensors to smaller ranks with a given accuracy by clustering values or imposing some error decision epsilon. This allows the authors to accurately identify the relevant section. The comment is also specific because it asks for clarification on the effect of rounding on the full tensor error and seeks information on any error bound in terms of epsilon. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical aspects of rounding core tensors and the effect on the full tensor error. It seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The authors are left to infer the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors need to provide more clarification on the theoretical aspects of rounding core tensors and its effect on the full tensor error. It raises a question about the error bound in terms of epsilon and suggests that the authors should address this issue to improve the comprehensiveness of their work. While the comment highlights an important area for clarification, it does not offer specific suggestions or guidance on how to present this information. The authors are left to infer that they need to provide more details, which limits the comment\"s helpfulness. Therefore, the comment is 3, as it points out a potential weakness but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. While the comment implies that the authors should add results on the generative setting, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"visual dialog,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on the generative setting in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. The reviewer suggests that the authors should include results on the generative setting as well. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. This feedback is clear and actionable, as it directs the authors to address a gap in their experimental evaluation. However, the comment could be more helpful if it provided additional context or examples on how to conduct the analysis on the generative setting. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what kind of evidence or examples would be sufficient or how the authors should present them. The comment lacks explicit guidance on how to implement this suggestion, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or example that needs improvement. The comment is 1, as it does not specify where in the paper this issue is addressed. Additionally, it lacks specificity as it does not provide details on what kind of evidence or examples would be sufficient to convince the reader. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. While it identifies a potential weakness in the paper, it lacks specificity and does not provide guidance on what kind of evidence or examples would be sufficient to address this concern. The comment is 3 as it points out an area for improvement, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive and detailed."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to explore the effectiveness of the approach for other language families. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the effectiveness of the proposed approach for other language families, which is a clear and specific point. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of unknown effectiveness, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the effectiveness of the proposed approach for other language families. It highlights a gap in the paper that needs to be addressed, which is important for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how to explore or demonstrate the effectiveness of the approach for other language families. While it points out a relevant issue, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or methods to ensure privacy protection. As a result, the authors are left without a clear understanding of what steps to take to improve their draft in this area. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of analysis on the security (protection of privacy) of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the analysis should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of security analysis, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. This is a critical oversight that could impact the overall robustness and trustworthiness of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending particular analyses or methods to ensure privacy protection. Without actionable advice, the authors are left with a clear understanding of the problem but without direction on how to resolve it. Therefore, the comment is 3, as it points out a significant area for improvement but does not provide detailed guidance for addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. This provides a clear and direct action for the authors to take, which is to explicitly mention the form of p in their draft. The comment also references the reviewer\"s previous comment, which adds context and clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the form of p is not explicitly stated and assumes it to be a Gaussian distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or necessary. Without additional context or explanation, the claim remains 1, as it lacks the necessary justification for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the form of p is not explicitly stated near line 135, despite being assumed to be a Gaussian distribution. This feedback is clear and actionable, as it directs the authors to explicitly mention the form of p in their draft. By addressing this point, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it guides the authors toward a specific improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. While it implies that the authors should expand on these differences, it does not explicitly instruct them to do so or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed descriptions of the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not specify which parts of the related work section are lacking in detail or which works are not described adequately. Without explicit references to specific sections or works, the authors cannot confidently determine which parts need attention. The comment is 1 as it does not specify where in the paper the related work section is located, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not provide specific examples or references to the works that are lacking in detail, making it difficult for the authors to understand which aspects need improvement. The claim is based on a general observation without specific examples or evidence, making it challenging for the authors to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the related work section, specifically the lack of detailed descriptions of the differences between the works mentioned. This feedback is 3 as it points out an area where the paper could be improved, but it does not provide specific guidance on how to address this issue or what aspects of the related work should be expanded upon. The comment highlights a potential gap in the paper, but without actionable advice or examples, it limits the authors\" ability to make significant improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to explain what type of understanding is gained by looking at the PPP maps. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is concrete because it specifies the exact information that needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors state the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for an explanation of what type of understanding is gained by looking at the PPP maps, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the authors\" explanation regarding the understanding gained from looking at PPP maps. It suggests that while the importance of reliable PPP metrics is mentioned, the article lacks explicit explanation or understanding of this concept. The comment is 3 as it logically points out a gap in the explanation but does not provide specific examples or references to support the claim. The authors may need to provide more detailed explanations to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the understanding gained from looking at PPP maps. It points out that while the authors mention the importance of reliable PPP metrics, they do not provide an explicit explanation or understanding of this concept. The comment is 3 as it highlights a specific area for improvement, namely the need for a more detailed explanation of the concept. However, it lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This implies that the authors should include such comparisons to enhance the credibility of their work. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other stateoftheart methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which affects the credibility of their work. However, the comment does not provide specific examples or references to these stateoftheart methods or explain how the absence of such comparisons impacts the credibility of the work. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of the comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided sufficient evidence for the credibility of their work. It points out the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT, which is a relevant benchmark for evaluating the effectiveness of the proposed methods. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the credibility of their work. However, the comment could be more helpful if it provided examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. It also mentions that the connection between the text and the figure, as well as the equations, is difficult to understand. This provides clear and concrete actions for the authors to take, such as redrawing the figure and improving the explanations in the text. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forwardprediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the lack of a clear schematic representation in Figure 2(b) and the difficulty in connecting the text and equations with the figure. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. The reviewer provides a specific example of the figure not showing the schematic representation and notes the difficulty in connecting the text and equations with the figure. This provides a clear and concrete basis for the claim, making it 4. However, the comment could be strengthened by providing additional details or references to similar issues in other works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clear explanation and representation of the forwardprediction model in Figure 2(b). It points out that the figure does not provide a schematic representation of the model, making it difficult for readers to understand the concept. The comment suggests that the figure should be redrawn to better illustrate the model. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can help the authors enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance on how to improve the explanation or suggested alternative ways to present the model. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The reviewer also questions the authors\" choice of baseline and suggests they should provide a stronger baseline to prove the usefulness of FP. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger baseline and consider the impact of rewardless actions on RBI. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RBI\" and \"Task 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that RBI only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone and questions the choice of baseline. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the significance of the issue and the potential impact on the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This is a significant observation that could impact the performance and effectiveness of the model. The comment suggests that this could be a factor contributing to the superiority of FP + RBI over RBI alone. Additionally, it questions the choice of baseline and suggests that the authors should provide a stronger baseline to prove the usefulness of FP. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. Therefore, it is 3, as it points out potential weaknesses but does not provide detailed guidance on how to resolve them."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer suggests that the only benefit is the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the statement, it does not provide explicit guidance on how the authors should address this misleading aspect. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the time scales involved and possibly revise the statement to be more accurate. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiscale statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, explaining that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The comment further suggests that the only benefit is the reduction of gradient path by the slow RNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer supports this claim by explaining the distinction between physical and logical time scales and the potential benefit of reducing gradient path by the slow RNN. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. As it stands, the comment is 4, as it provides a logical explanation but lacks specific references or detailed evidence to fully support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential misleading aspect in the paper regarding the multiscale statement. It points out that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and understanding of the work. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this aspect or rephrase the statement to be more accurate. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestion to discuss the similarity and difference with reinforcement learning is a vague direction, and the comment lacks specific guidance on how to address these issues. The authors are left to infer that they need to provide more detailed analysis and discussion, but without clear steps or examples, the action remains implicit. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment also suggests a direction for the conclusion, but this does not provide specific guidance on how to implement it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and that there is no discussion of limitations. It also suggests a direction for the conclusion, which is to discuss the similarity and difference with reinforcement learning and the generalizability of the results. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The suggestion for the conclusion is somewhat vague, leaving the authors to infer the need for more detailed analysis and discussion. Therefore, the comment is 3, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several weaknesses in the paper, including the lack of discussion on limitations and the weakness of the baseline methods. It also suggests a direction for the conclusion by proposing a discussion on the similarity and difference with reinforcement learning, and the generalizability of the results. While the comment highlights areas for improvement, it lacks specific guidance or examples on how to address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with more detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the distinction between the expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. While the comment implies that the authors should make this distinction clearer upfront, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction, but it is concrete in that it provides a clear direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. The comment provides a clear direction for improvement by suggesting that the distinction should be made clearer upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). The reviewer suggests that in the current paper, the decisionmaker does care about the noise, and the objective function of interest is the stochastic noisy function. The comment provides a logical reasoning for the distinction between the two scenarios, but it lacks specific examples or references to support the claim that the current paper\"s approach is misleading. Therefore, the claim is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s approach to evaluation, noting that the expected performance under observation noise is typically used because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. However, in the current paper, the decisionmaker is interested in the stochastic noisy function, which is a different objective. The comment suggests that the distinction between these two should be clarified upfront to avoid misleading the reader. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to clarify this distinction or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it highlights an important distinction that the authors should consider, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This implies that the authors should experiment with VGAE with a vamp prior to compare its performance to the current model. Additionally, the comment recommends keeping the generative model fixed and optimizing only the inference part, parameterizing it as either SIGVAE or VGAE to compare the representations. While the suggestion to run VGAE with a vamp prior is explicit, the action is somewhat vague as it does not provide detailed guidance on how to implement this change or what specific aspects to focus on. The second part about optimizing the inference part is also somewhat vague, as it lacks specific instructions on how to parameterize the models or what aspects to compare. Overall, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VGAE with a vamp prior\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely running VGAE with a vamp prior to better match the doubly stochastic construction and optimizing the inference part of the model by parameterizing it as either SIGVAE or VGAE to compare the representations. This provides clear guidance on what changes need to be made to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This claim is 3 as it provides a logical reasoning for the suggestion, which is to test whether the benefits are coming from a better generative model or better inference due to doublysemi implicit variational inference. However, the comment lacks specific examples or references to support the claim, such as studies or experiments that have demonstrated the effectiveness of this approach. Additionally, the minor point about optimizing the inference part of the model is also 3, as it suggests a potential method for comparison but lacks detailed guidance on implementation or analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help inform whether the benefits are coming from a better generative model or better inference due to doublysemi implicit variational inference. This is a clear and actionable suggestion that could significantly impact the authors\" understanding of their model\"s performance. Second, it recommends keeping the generative model fixed and optimizing only the inference part, parameterizing it as either SIGVAE or VGAE to compare the representations. This suggestion is also 3 as it offers a potential method for comparison, but it lacks specific guidance on how to implement this change or what aspects to focus on. Overall, the comment provides valuable insights and actionable suggestions, making it 4. However, it could be more comprehensive with additional details or examples. Therefore, it is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to enhance the novelty or contribution of their work. The action is implicit and vague, as the authors are left to infer that they need to improve the novelty or contribution of their work, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method, specifically mentioning Table 2, and acknowledges the novelty and contribution of the work. However, it does not specify which part of the paper discusses the novelty or contribution, making it weakly grounded. The comment does specify that the main contribution is a new network design inspired by prior work for sound source localization, which provides some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method\"s performance is good, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment lacks specific examples or references to support the claim that the method is incremental or lacks novelty. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. While the comment identifies a potential issue with the novelty and contribution of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening, but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the importance of longrange dependencies in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the importance of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment lacks specific examples or references to support the claim that learning longrange dependencies is not always necessary. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This feedback is 3 as it prompts the authors to consider the importance of longrange dependencies in their work and to address the potential ambiguity in their claims. However, the comment could be more helpful if it provided specific suggestions on how to frame this discussion or what aspects of the topic should be explored. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definition of $e_l$ and consider the impact of $M$ on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3 and Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the exponential dependence on the diameter $M$ of the domain of data and how this affects the constant factor of the required feature size. The comment provides a clear observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment lacks specific examples or references to support the claim about the exponential dependence on $M$ or the observation about Figure 1. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the definition of $e_l$ in Equation (3). It also points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data, which affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or clarify the definition of $e_l$. Despite this, the feedback is 3 as it highlights a critical area for improvement and provides a specific observation that the authors can consider. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, another phenomenon observed in the context of very deep graph networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to improve the modeling ability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs, specifically mentioning oversquashing and vanishing/exploding gradients as potential causes. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment does provide some specificity by mentioning oversmoothing as another phenomenon observed in the context of very deep graph networks, which could also contribute to the poor performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modeling ability of DGNs is due to oversquashing and vanishing/exploding gradients, but also suggests that oversmoothing could be a contributing factor. The reviewer supports this claim by referencing a paper that discusses oversmoothing in the context of very deep graph networks. However, the comment does not provide specific examples or detailed explanations of how oversmoothing affects the modeling ability, which would strengthen the verifiability. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue or what specific aspects of the model might be contributing to the problem. The reference to a related paper provides some context but does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there is a demonstration or result related to the model collapsing less than other methods. It also asks about the specific observation of gradients becoming 0 and collapsing, mentioning line 159. While the comment implies that the authors should provide evidence or examples to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a demonstration or result related to the model collapsing less than other methods, and it raises questions about the common occurrence of gradients becoming 0 and collapsing. This provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the demonstration or results related to the model collapsing less than other methods. It specifically mentions line 159, where the authors mention gradients becoming 0 and collapsing. This feedback is 3 as it prompts the authors to provide evidence or examples to support their claim, which could strengthen the paper\"s argument. However, the comment lacks depth and does not offer specific suggestions on how to address the issue or what kind of evidence would be beneficial. While it points out a potential area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these issues are found in. The authors cannot confidently determine which sections or examples are being addressed, making it weakly grounded. The comment is specific in identifying the issue of unclear problem formulation, but without explicit references to sections or examples, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without specific examples or references, the claim lacks verifiability, making it challenging for the authors to understand and improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it does not provide specific examples or guidance on how to improve the clarity or what aspects of the formulation are unclear. Without actionable feedback or detailed suggestions, the authors are left without a clear path to address the issue. Therefore, the comment is 1, as it lacks the necessary information to support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear and concrete action for the authors to take, as it specifies the exact models to include in the experiments and the purpose of doing so. The comment is specific and directs the authors on how to enhance their draft, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear direction for the authors to expand their experimental scope. However, it does not specify which part of the paper should include these experiments, such as the results or methodology sections. While the authors can infer that it relates to the experimental section, the comment lacks full grounding as it does not explicitly mention the section. The suggestion is specific, as it details what additional experiments are needed, but it is weakly grounded because it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical reasoning for expanding the experimental scope, which could enhance the applicability and generalizability of the method across various LLM families. However, the comment lacks specific examples or references to support the claim, such as explaining why these particular models are relevant or how they would impact the results. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directs the authors to expand their experimental scope and includes specific models to consider. By addressing this suggestion, the authors can enhance the robustness and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or rationale for why these specific models are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method seems to only work for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper this observation pertains to, making it weakly grounded. The comment is specific in its critique of the method\"s applicability, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the method, noting that it only works for generative models that can be finetuned as an in/outpainting model. This is a relevant observation that could impact the applicability and scope of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or expand the method\"s applicability. While it identifies an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\"s imagined process. However, the comment does not provide explicit guidance on how to address this issue or improve the connections. It mentions that the process could work but is computationally demanding, but this is not enough to direct the authors on how to improve their draft. The action is implicit and vague, leaving the authors uncertain about how to apply the feedback to enhance their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first part and the second part, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the perceived weakness in the connections between the curve finding and FGE, and it provides a rationale for this observation. The comment suggests that the process described in the first part does not match the title or the author\"s imagined process, and it mentions that this could work but is computationally demanding. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the connections between the curve finding and FGE are weak, suggesting that the process described in the first part does not match the title or the author\"s imagined process. The reviewer provides a rationale by explaining that the process could work but is computationally demanding. This reasoning is 3 as it highlights a potential issue with the paper\"s structure and suggests a potential solution. However, the comment lacks specific examples or detailed explanations to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\"s imagined process. It highlights a discrepancy between the imagined process and the actual content, which could lead to confusion for readers. The comment also mentions that the process could work but is computationally demanding, providing some insight into the potential challenges. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the connections between the two parts. While it points out a potential problem, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results for linear scalarization + Concorde, which is a known SOTA heuristicbased solver, to provide a better comparison with the learningbased solvers. This feedback is explicit and provides a clear action for the authors to take, as it specifies the need for including these results in the paper. The comment is concrete, as it directly instructs the authors on what to add to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"Pareto front\" from Figure 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results for linear scalarization + Concorde to provide a better comparison with the learningbased solvers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, but it suggests that for the single objective TSP, the SOTA heuristicsolver (e.g., Concorde) usually has the best performance. The reviewer provides a rationale by mentioning that the obtained Pareto front is not highly nonconvex, which affects the comparison. However, the comment lacks specific examples or references to support the claim about the superiority of learningbased solvers. While the suggestion to include results for linear scalarization + Concorde is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the learningbased solvers are better than the heuristicbased solvers but that for the single objective TSP, the SOTA heuristicsolver (e.g., Concorde) usually has the best performance. The comment suggests that the authors should include results for linear scalarization + Concorde to provide a better comparison. This feedback is clear and actionable, as it directs the authors to include additional results that could enhance the comprehensiveness and relevance of their experimental analysis. However, the comment could be more helpful if it provided more detailed guidance on how to interpret and present these results. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use generalized Voronoi graphs, semantic maps, or pose graphs for exploration. While the comment implies that the authors should provide a comparison or discussion of their method with these existing methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific aspects of the comparison that should be made. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"generalized Voronoi graph or semantic maps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, a discussion of the proposed method in relation to existing methods that use similar concepts for exploration. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer supports this claim by referencing existing methods, such as graphbased SLAM, where loop closure is applied. This provides a clear and specific comparison, making the claim 4. However, the comment could be strengthened by providing more detailed examples or references to specific methods or studies where these ideas are discussed. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas presented are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. It suggests that the paper should discuss the proposed method in relation to these existing methods, which could enhance its originality and contribution. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific examples or references to these existing methods, which would guide the authors in their comparison and discussion. Overall, the comment is 4 as it highlights an area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some experimental details and tasks back into the main text and moving background information from Section 2 to the appendix. While the suggestion is clear, it does not provide specific guidance on which details should be moved or how to structure them. The authors are left to infer which details are crucial to include in the main text and which can be moved to the appendix. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, tasks, and other details being moved to the appendix, making it difficult to interpret the paper. It suggests moving some of these details back into the main text and moving background information from Section 2 to the appendix. However, the comment does not specify which details should be moved or where they should be placed, leaving the authors to infer the exact changes needed. While the authors can infer the general areas being addressed, the comment lacks specificity in terms of what needs to be addressed or how to implement the suggested changes. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the experimental setup, tasks, and other details are moved to the appendix, making it difficult to interpret the paper. The reviewer proposes moving some of these details back into the main text and suggests moving background information from Section 2 to the appendix. However, the comment lacks specific examples or detailed reasoning to support why these changes would improve the clarity or interpretability of the paper. Without specific examples or references, the claim is 3, as it provides a general direction but lacks the necessary detail to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and presentation of the experimental setup, tasks, and other details, which are currently placed in the appendix. This makes it difficult for readers to interpret the paper effectively. The comment suggests a solution by recommending moving some of these details back into the main text and moving background information from Section 2 to the appendix. This feedback is clear and actionable, providing the authors with a concrete direction to improve the clarity and accessibility of their paper. However, it could be more helpful if it included specific examples of which details should be moved or how to structure them. Overall, the comment is 4 as it guides the authors toward a more organized and userfriendly presentation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that providing glosses in Figure 2 would be helpful. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the figure. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests providing glosses in Figure 2, which implies that it is referring to a specific figure in the paper. However, it does not explicitly mention the figure, making it weakly grounded. The comment is specific in suggesting what needs to be added, which is the provision of glosses. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests providing glosses in Figure 2, which is a request for clarification or additional information. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment suggests that providing glosses in Figure 2 would be helpful. This feedback is specific and actionable, as it directly addresses a potential issue with the clarity of the figure. By suggesting the inclusion of glosses, the reviewer provides a clear and concrete suggestion for improvement. However, the comment could be more helpful if it explained why glosses are necessary or how they would enhance the figure\"s clarity. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear action for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. This implies that the authors should include a reference to the work or methodology that \"Memb\" refers to. However, the comment does not specify which work or methodology should be referenced, leaving the authors with a vague action to take. The action is explicit in identifying the need for a reference, but it lacks concrete guidance on which specific work or methodology should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment mentions \"Memb\" as the previous stateoftheart, but it does not specify which part of the paper this reference is made in. This makes it difficult for the authors to pinpoint the exact section that needs attention. However, the comment does specify the issue of not providing a reference, which is clear and specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the term \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. This is a clear and actionable point, as it highlights a potential gap in the paper\"s literature review or citation. By addressing this issue, the authors can ensure that their work is properly contextualized and supported by relevant references. However, the comment could be more helpful if it provided suggestions on how to include the missing reference or what specific works should be cited. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or improve their draft. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this choice is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the quantization choice are being questioned or how it could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be preferable. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. While it identifies a potential area for improvement, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or why finer grouping might be beneficial. The comment is 3 as it prompts the authors to consider a different approach, but it could be more beneficial with additional context or suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It explicitly recommends conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact aspect to investigate and offers a specific direction for further analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this analysis could be conducted. The authors can infer that it relates to the model evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular aspect to investigate, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the study. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests studying the impact of the ratio of unseen classes on the performance of the model. It provides a specific direction for further analysis by recommending experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback is actionable and constructive, as it offers a clear and concrete suggestion for the authors to enhance their study. However, the comment could be more helpful if it provided additional context or examples of how this analysis could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. While the comment implies that the authors should provide an explanation or rationale for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address this question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these architectures are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of using GRU for the Pyramid and LSTM for the sequential part, questioning whether the combination of these architectures is a reason for the improvements. This is a valuable point as it prompts the authors to consider the rationale behind their choice and whether it is justified. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it could be more helpful with additional context or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in a specific line of the paper. While it identifies a potential issue with the clarity of the definition, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the definition, but it lacks concrete instructions or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices\" and seeks clarification on how it is defined in this context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the definition of \"active vertices\" in a specific line of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in a specific line of the paper, which is a clear and actionable point. By asking for clarification on the definition, the reviewer prompts the authors to provide more detailed explanations or definitions to ensure that their work is clear and understandable. This feedback is valuable as it helps the authors improve the clarity and comprehensibility of their draft, which is an important aspect of scientific communication. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy between the paper\"s claims and the limitations it discusses. It points out that the theory is not mentioned as a limitation in the main text, despite being applicable to the used model. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text. Additionally, the comment notes that the vagueness of structural assumptions in the appendix makes it difficult to find the theoretical limitation. The reviewer also suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general, which could be a valuable addition to the paper. The feedback is explicit and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fact that their theory does not seem to be applicable to the used model\" and the \"vagueness of unspecified 'structural assumptions,\" that are only given in the appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of the theoretical limitation not being mentioned in the main text and suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the theoretical limitation of its theory being applicable to the used model, despite the vagueness of structural assumptions in the appendix. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and should elaborate on the potential negative societal impact of these networks. The comment provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about the current use of graph neural networks in industry. Additionally, the suggestion to elaborate on the negative societal impact is somewhat vague, as it does not provide detailed guidance on what aspects should be addressed. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks specific evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the theoretical limitation of the theory being applicable to the used model is not mentioned in the main text. This is a critical oversight, as it affects the validity and applicability of the paper\"s claims. The reviewer suggests that the authors should address this limitation by explicitly mentioning it in the main text, which would enhance the transparency and credibility of the work. Additionally, the comment points out the vagueness of structural assumptions in the appendix, making it difficult for readers to find the theoretical limitation. This feedback is valuable as it highlights a critical area for improvement in the paper. However, the comment could be more helpful if it provided specific guidance on how to address the vagueness of structural assumptions or how to elaborate on the potential negative societal impact of graph neural networks. Overall, the comment is 4 as it identifies a significant issue and offers actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, and it specifically mentions the paper and supplement as references. It also highlights a weakness in the proposed FSR metric. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or suggestions for improvement. Without actionable advice or specific steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, and it specifically mentions the paper and supplement as references. However, it does not specify which part of the paper or supplement is being referred to, making it weakly grounded. The comment also lacks specificity regarding what aspects of the loss principles are unclear or how they could be improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, and it mentions the paper and supplement as references. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification and does not present an argument or claim that needs justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, referencing the paper and supplement. It also highlights a specific weakness in the proposed FSR metric. However, the comment lacks actionable feedback or suggestions for improvement, such as providing examples or guidance on how to address the identified weaknesses. Without concrete advice or direction, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"epsilongreedy\" in the context of training, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"epsilongreedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. This question highlights a potential area of confusion or misunderstanding in the paper, which could be clarified to enhance the readers\" comprehension. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but not comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or what specific aspects need attention. The authors are left without any direction on how to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this combination is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the combination are lacking or how the authors could improve it. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might improve their work or address the critique. The comment identifies a potential issue with the method\"s novelty but does not offer actionable advice or insights into how to enhance the paper. As a result, the feedback is not helpful, as it does not assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to ensure that both heads are affected. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the affected layers, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). This is a clear observation that could be relevant for the authors to address, as it highlights a potential imbalance in the paper\"s focus. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific changes could be made to ensure a more balanced presentation. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide explicit guidance on what specific part of the framework is vital or how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the importance of the framework in the context of weakly supervised learning. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of the framework are vital or how the discussion could be improved. Without clear guidance, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not provide any supporting evidence, reasoning, or references to justify why this part is crucial or how it distinguishes the paper from other related work. Without such information, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the discussion. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is not strong. It also highlights the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment identifies areas for improvement, it does not provide explicit guidance on how to strengthen the analogy or clarify the connection between the decomposition/integration steps and Fourier analysis. The authors are left to infer that they need to address these issues, but the lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment critiques the analogy between HOI analysis and Harmonic analysis, noting that the link is weak. It also points out the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. However, the comment does not specify which part of the paper discusses the analogy or the basis for HOI analysis, making it weakly grounded. The comment is specific in detailing the issues with the analogy and the connection to Fourier analysis, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, and that the connection between the decomposition/integration steps and Fourier analysis is not close. The reviewer provides logical reasoning by pointing out the limited basis for HOI analysis, with only two elements (human and object), and the lack of a direct connection between the decomposition/integration steps and Fourier analysis. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the basis of the analogy and the connection to Fourier analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is not strong. It also highlights the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment points out areas for improvement, it lacks specific suggestions or guidance on how to strengthen the analogy or clarify the connection between the decomposition/integration steps and Fourier analysis. The feedback is 3 as it provides insight into potential weaknesses, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. However, it also acknowledges that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore its implications further. The action is implicit and somewhat vague, as the authors can infer that they might need to consider the impact of this limitation on the applicability of their methodology. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the potential limitation of the proposed methodology, specifically regarding the performance gains of dynamic precision control during training on bitserial accelerators. It also mentions the use of bitparallel fixedpoint numbers by most existing ML accelerators, which could restrict the implications of the proposed methodology. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the applicability of the methodology to existing accelerators. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which is a specific observation about the applicability of the proposed methodology. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. It also acknowledges that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or explore its implications further. The feedback is 3 as it points out a potential issue but does not provide actionable steps for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer asks whether the focus distance extends beyond these examples and if it generalizes well. While the comment implies that the authors should consider including additional focus distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the focus distance range. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the focus distance shown in the figure, suggesting that it should include other distances beyond those present in the training data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer suggests that the focus distance should be expanded to include other distances, implying that it may not generalize well. However, the comment lacks specific examples or references to support the claim that other distances are necessary or how they would impact the generalizability. This makes the claim 3, as it provides a logical suggestion but lacks detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 8, noting that it only shows focus distances of 1m and 5m, which are both present in the training data. It raises a valid question about whether the focus distance extends beyond these examples and whether it generalizes well. This feedback is 3 as it prompts the authors to consider whether their results are robust across a broader range of focus distances. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional focus distances to test or discussing the implications of this limitation. Overall, the comment is 3 as it points out a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a clear direction for the authors to consider broadening their definition of content and style, it does not offer specific guidance on how to implement this suggestion. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" neural application and provides a specific example from Gabbay & Hosehn (2018) to illustrate the broader definition of content and style. It also raises a question about the authors\" understanding of the term \"style\" in their model, which adds specificity to the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, providing an example from Gabbay & Hosehn (2018) where style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a logical reasoning for broadening the definition of content and style, it lacks specific examples or references to support the claim that the authors\" understanding is incorrect. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider broadening their definition of content and style, particularly in the context of their neural application. It offers an example from Gabbay & Hosehn (2018) to illustrate how style can be defined more broadly and how content can be understood as information that can be transferred among groups. Additionally, the comment raises a pertinent question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. This feedback is valuable as it prompts the authors to reconsider their terminology and potentially enhance the clarity and applicability of their work. However, the comment could be more helpful if it provided specific guidance on how to address the question about the temporal dynamic structure. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. It provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. While the comment identifies areas that need further explanation, it does not explicitly instruct the authors on how to improve the analysis or provide specific guidance on how to address the issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the analysis could be explained in depth, particularly regarding the information distortion and the quantization of MHSA. The comment provides specific examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. The reviewer provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This provides a logical and detailed explanation of the issue, making the claim 4. However, the comment could be strengthened by referencing specific studies or literature that support the claims about information distortion and quantization. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the information distortion and the quantization of MHSA. It highlights the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This feedback is 5 as it identifies specific areas where the authors need to provide more depth and clarity in their analysis. By pointing out the limitations of the proposed approach and referencing existing work, the comment offers actionable guidance for the authors to improve their draft. However, it could be further enhanced by suggesting specific ways to address the issues or providing additional references to support the claims. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a main weakness of the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN, and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to include comparisons to STN and provide more detailed explanations of the novelty of their approach. However, the comment lacks concrete suggestions on how to conduct these comparisons or what specific aspects to focus on. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses a specific issue with the paper, namely the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It mentions the proposed Xtransformation and its similarity to STN, as well as the use of STN in PointNet. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these topics are discussed. The comment is specific in detailing what needs to be addressed, such as the need for comparisons to STN and the need for more detailed explanations of the novelty of the proposed approach. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to spatial transformer networks (STN) and the absence of comparisons to STN. The reviewer provides logical reasoning by pointing out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, the reviewer notes the absence of empirical or conceptual comparisons to STN in the paper, which is important. However, the comment lacks specific examples or references to support the claim that the technical novelty is limited. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper, which is important. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it identifies areas for improvement, but it lacks actionable advice or detailed guidance on how to enhance the paper. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a confusion regarding the reward in Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. It provides references to external works that might help clarify the issue, such as 1 and 2, which are articles on the topic. However, the comment does not explicitly instruct the authors to include equations or provide guidance on how to address the confusion. While the references offer potential sources of clarification, the action is implicit and lacks concrete steps for the authors to take. Therefore, the comment is 3, as it provides a direction but not detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of confusion regarding the reward and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. The references provided, such as 1 and 2, offer additional context and examples for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Eq. 12, specifically questioning where the reward comes from and whether one of the r_i is taken from Eq. 11. The reviewer suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment identifies a potential issue with the clarity of the equations, it does not provide specific examples or detailed reasoning to support the claim that the equations are confusing. The references to external works, 1 and 2, could be used to support the claim, but the comment itself lacks sufficient evidence or detailed explanation. Therefore, the claim is 3, as it points out a potential issue but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Eq. 12, noting that the reward source is not clearly explained and suggesting that the network model in Sec. 4.2 could be improved with equations. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity of their work. Additionally, the references to external works, such as 1 and 2, offer potential sources of guidance and examples for the authors to consider. However, the comment could be more helpful if it included specific suggestions on how to present the equations or what aspects of the network model should be explained. Overall, the comment is 4 as it effectively points out a specific area for improvement and provides a starting point for the authors to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It explicitly instructs them to correct the labeling of \"Fig.7\" to \"Fig.12\" in Supp. Page 31 and to attach each theorem and corollary to its corresponding proof link. Additionally, it highlights the primary concerns of motivation, methodology soundness, and experiment persuasion, which the authors should address to improve the paper. The comment is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of incorrect labeling of \"Fig.7\" as \"Fig.12\" and suggests attaching each theorem and corollary to its corresponding proof link. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the labeling of \"Fig.7\" as \"Fig.12\" in Supp. Page 31 and suggests attaching each theorem and corollary to its corresponding proof link. The reviewer provides a logical reasoning by explaining that this would make it easier for readers to follow the paper. However, the comment lacks specific examples or references to support the claim about the importance of attaching theorems and corollaries to their proofs. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions to improve the clarity and accessibility of the paper. It points out a specific error in the labeling of \"Fig.7\" as \"Fig.12\" in Supp. Page 31 and suggests attaching each theorem and corollary to its corresponding proof link. This feedback is clear and direct, offering a concrete way for the authors to enhance the readability and comprehensibility of their work. Additionally, the comment acknowledges the paper\"s strengths, such as its novelty, clear theoretical guarantees, and convincing empirical results. However, it also highlights areas for improvement, such as addressing concerns about motivation, methodology soundness, and experiment persuasion. Overall, the comment is 4 as it provides actionable guidance and constructive feedback, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the definition and implementation of certain concepts in the paper. It specifically asks about the determiner missing in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. While the questions are clear and specific, they do not provide explicit guidance on how the authors should address these issues. The authors can infer that they need to clarify the missing determiner, explain the action verbs, and provide more information on \"action frames,\" but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking about the determiner missing in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the definition and implementation of certain concepts in the paper, such as the missing determiner in Section 3 and the action verbs used. It also asks about the \"action frames\" mentioned later in the paper and how they are chosen. While the questions are clear and provide a direction for improvement, the comment lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need clarification, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a minor issue with the spelling of \"Empiically\" on line 32 of page 1, suggesting it should be corrected to \"Empirically.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the spelling of \"Empiically\" on line 32, which should be changed to \"Empirically.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, noting a misspelling in the text. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a minor but important issue with the spelling of \"Empiically\" on line 32 of page 1, suggesting it should be corrected to \"Empirically.\" This is a clear and actionable suggestion that can help improve the accuracy and professionalism of the paper. By addressing this issue, the authors can enhance the clarity and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the feature selection in Section 4.2 could be improved by considering representation learning, which is discussed in the appendix. While the comment implies that the authors should consider incorporating representation learning into their feature selection process, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should integrate representation learning into their feature selection process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out that the proposed invariant learning module focuses on mask selection and rawlevel features, while the framework discussed in the appendix is not limited to rawlevel selection. The comment suggests that the feature selection in Section 4.2 could be improved by considering representation learning, which is discussed in the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed invariant learning module focuses on mask selection and rawlevel features, while the framework discussed in the appendix is not limited to rawlevel selection. The reviewer suggests that the feature selection in Section 4.2 could be improved by considering representation learning, which is discussed in the appendix. However, the comment lacks specific examples or references to support the claim that the current feature selection is limited or inadequate. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors could improve their work. It points out that the proposed invariant learning module focuses on mask selection and rawlevel features, while the framework discussed in the appendix is not limited to rawlevel selection. The reviewer suggests that the feature selection in Section 4.2 could be improved by considering representation learning, which is discussed in the appendix. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by integrating representation learning into the feature selection process. However, the comment could be more helpful if it included specific examples or references to support the claim about the appendix framework. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the paper, namely that some details are missing, such as how to design the rewards. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific steps to clarify the reward design or suggesting ways to improve the explanation. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely that some details are missing, such as how to design the rewards. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the missing details regarding reward design, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the lack of clarity in the reward design. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the exact details that are missing or how to address them. Without additional context or examples, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely that some details are missing, such as the design of rewards. This is a clear and actionable point that the authors can address to improve the clarity and comprehensiveness of their work. However, the comment lacks depth and does not provide specific suggestions or examples on how to improve the clarity of the reward design. While it highlights an important area for improvement, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the generalizability of a model to different numbers of entities, specifically mentioning Figure 3 of INs as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the generalizability of the model. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes or improvements are needed to enhance the generalizability of their model. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3 of INs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity on how to generalize a model to different numbers of entities, as shown in Figure 3 of INs. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the number of entities is fixed and that it is unclear how to generalize a model to different numbers of entities, citing Figure 3 of INs as an example. However, the comment lacks specific reasoning or evidence to support this claim, such as explaining why the number of entities is fixed or how it affects the generalizability of the model. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the number of entities is fixed and questioning how the model can be generalized to different numbers of entities. It references Figure 3 of INs as an example, which provides some context for the reviewer. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue or improve the generalizability of their model. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required. It also mentions that the experimental design is good. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest improvements, offer guidance on how to address the weakness, or provide specific feedback on the execution effort or experimental design. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"double edge point,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, backed by good experimental design. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. However, it also points out that the approach lacks novelty and that the execution effort may outweigh the novelty. The comment suggests that the lack of code release after the revision process could be a weakness, but it does not provide specific examples or detailed reasoning to support this claim. While the comment provides some insight into the potential weaknesses, it lacks the necessary evidence or detailed reasoning to be 5. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. It also points out the lack of novelty in the approach and suggests that the execution effort may outweigh the novelty. However, the comment does not provide specific suggestions or guidance on how the authors might address this weakness or improve the novelty of their approach. While it identifies a potential issue, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count and computational cheapness. This provides a clear and direct action for the authors to take, as they are instructed to include this information in their draft. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Prithvi WxC\" emulator, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the runtime of Prithvi WxC in relation to its large parameter count. This provides clear guidance on what aspect of the emulator needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count and computational cheapness. However, the comment does not provide any supporting evidence or reasoning to justify why this runtime is important or how it affects the emulator\"s applications. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the runtime of Prithvi WxC should be discussed, given its large parameter count and computational cheapness. This is a clear and actionable suggestion that could enhance the paper by providing additional context and insights into the emulator\"s performance. However, the comment could be more helpful if it included specific examples or references to similar studies that have discussed runtime limitations in similar contexts. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or complexity of the idea, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the novelty or straightforwardness are problematic, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions for how the authors might enhance the novelty or complexity of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of what improvements could be made to address the critique. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making it difficult for the authors to know how to implement the suggested improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the framing contribute to overselling the method, making it difficult for the authors to understand and address the concern. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific references or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1 due to the lack of supporting evidence or justification.", "helpfulness_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed feedback on how the framing of the paper contributes to this overselling. Without concrete guidance or suggestions for improvement, the authors are left without actionable steps to address the issue. The comment identifies a potential weakness but lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. While the comment provides a clear direction for improvement, it does not specify which steps should be taken or how to implement the changes. The authors are given a general idea of what needs to be improved but are left to determine the exact actions to take. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the model description is discussed. The authors can infer that it relates to the model description or methodology sections, but this inference is not direct. The comment is specific in suggesting improvements but lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the understanding of the model. The suggestion is based on a general observation, but without further explanation or evidence, it lacks verifiability. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be presented in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table, which could enhance the clarity of the description. While the comment provides actionable suggestions, it could be more helpful if it offered specific examples or detailed guidance on how to implement these improvements. Overall, the feedback is 3 as it points out areas for improvement but lacks comprehensive guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the quality of paraphrases generated for training data, specifically noting that the paraphrases need to be sufficiently different from the original sentences to ensure the model\"s reliance on them. However, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve the quality of the paraphrases. The comment lacks concrete details on how to implement the suggested improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the process of generating paraphrases for training data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paraphrases, noting that they need to be sufficiently different from the original sentences to ensure the quality of the final training data. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paraphrases generated for training data are unclear in their difference from the original sentences, which impacts the quality of the final training data. The comment provides a logical reasoning by explaining the importance of the paraphrases and how their quality affects the model\"s reliance on them. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide detailed guidance on how to improve the paraphrases. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the quality of paraphrases generated for training data, noting that the paraphrases need to be sufficiently different from the original sentences to ensure the model\"s reliance on them. This is a crucial point that could significantly impact the quality of the final training data and the overall success of the model. The comment provides a clear and actionable suggestion for improvement, suggesting that the authors should focus on ensuring the paraphrases are sufficiently distinct from the original sentences. However, the comment could be more helpful if it offered specific guidance on how to achieve this goal, such as suggesting metrics or methods for evaluating the paraphrases\" distinctiveness. Overall, the comment is 4 as it highlights a critical issue and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggests that another color or a larger font might help in highlighting the humanidentified rationales better. While the comment provides a clear and concrete suggestion for improvement, it does not explicitly instruct the authors on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider changing the font or color of the text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that identifying rationales for more complicated NLP tasks like machine translation is not a simple problem, and that the paper is wellorganized and easy to follow. The comment suggests that Figure 2 is cluttered and that the \"bold\" text is hard to see, proposing a solution of using another color or a larger font to improve clarity. While the comment provides a logical reasoning for the issue with Figure 2, it lacks specific examples or references to support the claim about the complexity of identifying rationales for NLP tasks. The suggestion to improve the figure is 3, as it provides a clear rationale but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This feedback is clear and actionable, as it provides a concrete suggestion for improving the figure\"s readability and usability. However, the comment could be more helpful if it explained why the current font or color is problematic or how the suggested changes would enhance the figure\"s purpose. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should verify the effectiveness and universality of the FlippedQA framework beyond LLMbased models, specifically mentioning HiTeA and InternVideo as examples. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct additional experiments to verify the framework\"s effectiveness and universality, but the comment lacks concrete details on how to implement this action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the FlippedQA framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to verify the effectiveness and universality of the framework beyond LLMbased models. The comment provides a clear direction for the authors to expand their experimental evaluation to include nonLLMbased models like HiTeA and InternVideo. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FlippedQA framework is a general framework for various generative VideoQA models but is only applied to LLMbased models. The reviewer suggests that verifying its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo would be beneficial. While the comment provides a logical reasoning for the need to expand the application of the framework, it lacks specific examples or references to support the claim that other models are not effectively utilizing the framework. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, specifically the narrow application of the FlippedQA framework to LLMbased models. It suggests that verifying the effectiveness and universality of the framework to nonLLMbased models like HiTeA and InternVideo would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental evaluation and demonstrate the generalizability of their framework. By addressing this suggestion, the authors can enhance the robustness and applicability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific guidance or suggestions on how to improve the writing. The authors are left without any concrete steps or examples to follow in order to enhance their draft. As a result, the comment lacks actionability, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly challenging to understand or where the writing could be improved. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point suggests that the writing could be improved, indicating that it was difficult to understand the main idea and theoretical analysis of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to identify the exact areas that need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing could be improved, indicating that it was difficult to understand the main idea and theoretical analysis of the paper. However, it does not provide specific examples or guidance on how to improve the writing, such as suggesting clearer explanations or more accessible language. Without actionable feedback or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but lacks depth and specificity in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address these concerns to improve the paper. However, it does not provide specific guidance on how to address these concerns or what aspects of the method should be improved. The mention of existing methods and references to ClopperPearson intervals and Gaussian elimination suggest that the authors should provide more detailed explanations or comparisons with these methods. However, the comment lacks concrete steps or suggestions on how to enhance the theoretical novelty or address the concerns. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the methodology and its theoretical novelty, specifically mentioning the use of existing methods like ClopperPearson intervals and Gaussian elimination. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the lack of theoretical novelty and the need for addressing these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer acknowledges a willingness to improve their score if the authors address these concerns. However, the comment does not provide specific examples or detailed reasoning to support the claim about the lack of novelty. The references to ClopperPearson intervals and Gaussian elimination suggest that the reviewer is familiar with these methods, but this alone does not fully substantiate the claim. The comment could be strengthened by providing more detailed reasoning or examples to support the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant concern about the novelty of the proposed method, noting that it primarily builds upon existing methods like ClopperPearson intervals and Gaussian elimination. While it acknowledges the authors\" willingness to improve the score, it does not provide specific guidance or suggestions on how to address this concern or enhance the theoretical novelty of the method. The references to existing methods and the lack of novelty are mentioned, but without further elaboration or actionable advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a critical issue but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks explicit or implicit actions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or background information that would help the authors identify the relevant section. Without explicit references or context, the authors cannot confidently determine which part of the paper needs attention. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the concatenation of text input by the four text elements of an object. While it highlights a potential area of interest, it lacks any guidance or suggestions on how the authors might address this question or what implications it might have for their work. Without actionable feedback or context, the comment does not provide the authors with a clear path forward in improving their draft. Therefore, it is 1."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper should provide a stronger motivation for why the topic is important. However, it does not specify what kind of motivation is needed or how it should be presented. The authors are left to infer that they need to include a motivation section, but without concrete guidance on what aspects to focus on or how to structure it, the action remains vague. Therefore, this comment is 3, as it identifies a potential area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not specify which part of the paper this issue pertains to, such as the introduction or the sections where the topic is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what kind of motivation is needed or how it should be presented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this motivation or what aspects of the paper need to be revised. Without actionable advice or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it points out an area for improvement but does not offer sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made to the sentence. The action is implicit and vague, as the authors are left to infer that they need to revise the sentence but without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence in lines 1217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the cumbersomeness of the sentence and the need for clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any specific reasoning or examples to support this claim. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the abstract, specifically the sentence in lines 1217. It points out that the sentence is cumbersome and could be made clearer, providing a clear direction for improvement. However, the comment lacks depth and does not offer specific suggestions or examples on how to improve the clarity of the sentence. While it highlights an area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a starting point for the authors but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative comparisons that might be more fair. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their comparisons, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the comparisons to zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model and zeroshot singleimage 3D reconstruction models are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This feedback is 3 as it points out a potential bias in the experimental setup, which could impact the validity of the results. However, the comment lacks specific suggestions on how to address this issue or alternative comparisons that might be more fair. While it highlights an important consideration, the lack of actionable guidance limits its usefulness for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance. It also points out that Table 5 shows a tradeoff between head and tail categories but notes that similar tradeoffs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. Additionally, the reviewer encourages the authors to continue this line of work for future submissions. While the comment provides explicit actions to take, such as investigating the tradeoffs and improving the baselines, it lacks specific guidance on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple Kang et al.,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple Kang et al. and suggests exploring the tradeoff between head and tail categories for the baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance, and it provides a specific example of this by referencing Table 5. Additionally, it suggests that similar tradeoffs have not been fully investigated for the baselines, specifically by changing hyperparameters in Decouple Kang et al.. This claim is 3 as it provides a specific example of the tradeoff between head and tail categories and suggests that further investigation is needed. However, the comment lacks detailed evidence or references to support the claim that the proposed approach is worse than Decouple Kang et al. or that similar tradeoffs have not been fully explored. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several pieces of constructive feedback that can help the authors improve their draft. First, it points out that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance, which is a significant concern. It also highlights the tradeoff between head and tail categories shown in Table 5 and suggests that similar tradeoffs have not been fully explored for the baselines. The reviewer encourages the authors to continue this line of work for future submissions, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to investigate these tradeoffs or improve the baselines. Overall, the comment is 4 as it identifies areas for improvement and offers a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. While the suggestion is clear, it lacks specific guidance on how to conduct these experiments or what specific aspects of the C2D method should be tested on these datasets. The authors are left to infer that they should conduct these experiments, but without detailed instructions on how to implement them, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting the need for additional experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the method. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This is a clear and actionable suggestion that could enhance the robustness and generalizability of the method. However, the comment lacks specific guidance on which aspects of the C2D method should be tested or how these experiments should be designed. While it points to a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully beneficial."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the evaluation, specifically the reliance on only four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for more datasets, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" and \"4 OCR QA datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation, suggesting that it is limited and relies too heavily on these datasets. The comment further recommends including more scenarios like the LLaVA benchmark, particularly in ablation studies. This provides clear guidance on what needs to be addressed to improve the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited and relies too heavily on four OCR QA datasets, which may be unreliable. The reviewer supports this claim by referencing the authors\" admission in Fig 4(5) and suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. This provides a logical basis for the claim, as it highlights a potential limitation in the evaluation methodology and suggests a way to enhance it. However, the comment could be strengthened by providing specific examples or references to studies that have used the LLaVA benchmark, which would further substantiate the claim. Overall, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, specifically the reliance on only four OCR QA datasets. It suggests that the evaluation may be unreliable and recommends including more scenarios like the LLaVA benchmark, particularly in ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation section by expanding the dataset selection. However, the comment could be more helpful if it explained why the LLaVA benchmark is particularly relevant or how it might enhance the evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the necessity of the current formulation and suggests that simpler visual reasoning tasks might be sufficient. However, the comment does not provide explicit guidance on how to address these concerns or improve the tasks. It lacks specific suggestions or actionable steps for the authors to take, such as recommending alternative tasks or methods to simplify the current ones. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment addresses specific concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the necessity of the current formulation and suggests that simpler visual reasoning tasks might be sufficient. However, the comment does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the tasks and the need for simpler alternatives, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. The reviewer also questions the necessity of the current formulation and suggests that simpler visual reasoning tasks might be sufficient. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or evidence makes the claim 2, as it provides some insight but not enough to fully substantiate the critique. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the necessity of the current formulation and suggests that simpler visual reasoning tasks might be sufficient. While the comment identifies a potential issue with the paper\"s approach, it lacks specific suggestions or actionable steps for the authors to address these concerns. It does not provide guidance on how to simplify the tasks or what alternative tasks might be more effective. As a result, the comment is 3 as it points out a potential weakness but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the evaluation of weak supervision could be improved by addressing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, specifically mentioning that the authors\" embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the evaluation. The authors are left to infer that they need to consider the realism of the tweets and the authors\" generation, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the authors\" generation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the realism of the evaluated tweets and the authors\" generation, suggesting that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. The reviewer also questions the realism of the authors\" generation, specifically mentioning that the authors\" embeddings are initialized by averaging artificial tweets. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the evaluation is unrealistic. The reasoning is 3, as it highlights potential weaknesses but does not provide detailed evidence or references to substantiate the claims fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the authors\" generation. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, noting that the authors\" embeddings are initialized by averaging artificial tweets. This feedback is 3 as it highlights areas where the evaluation could be improved, but it lacks specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to consider the realism of the tweets and the authors\" generation, but the comment does not provide actionable steps for improvement. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of essential visualization of intermediate processes and comparisons, which is a clear actionable point. However, it does not provide specific guidance on what visualizations or comparisons are missing or how they should be presented. The authors are left to infer that they need to include visualizations and comparisons, but without concrete suggestions on what to include or how to present them, the comment remains vague. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualization of intermediate processes and comparisons, but it does not specify which parts of the paper should include these visualizations or comparisons. Without explicit references to sections, figures, or tables, the authors cannot confidently determine which parts need attention. The comment is specific in identifying the need for visualization and comparison, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the paper\"s current visualization or comparison sections, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, specifically the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it points out an area where the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on what types of visualizations or comparisons would be beneficial or how they could be integrated into the paper. Despite this, the feedback is valuable as it directs the authors\" attention to an important aspect of their draft that needs improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. However, it does not provide any guidance on how the authors should address this issue or what specific changes need to be made to ensure compliance with the stated condition. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Definition 1\" and \"expected counterfactual,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This is a clear and actionable point that the authors can address to improve the accuracy and validity of their work. However, the comment lacks depth and does not provide suggestions on how to resolve the issue or what specific changes need to be made. While it highlights a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The authors are left to infer that they might need to reconsider the importance of their result in light of the external work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the iteration complexity in Theorem 3 is no longer dimensionfree, which is a clear concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. However, the comment does not provide specific examples or detailed reasoning from the external work to support the claim that the result is not surprising or significant. While the reference to 15 provides some context, the comment lacks sufficient evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is 3, as it provides some basis but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. While the comment identifies potential weaknesses in the paper, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the paper. The feedback is 3 as it highlights areas for improvement, but it could be more beneficial with additional actionable advice or insights. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action, providing the authors with a specific step to take in order to improve their draft. The comment is specific and concrete, as it specifies the exact location where the results should be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the experiments section, namely the keypoint detection results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is clear and actionable, as it directly instructs the authors to include keypoint detection results in the experiments section. This feedback is specific and provides a concrete step for the authors to improve their draft, ensuring that the results are presented in a more comprehensive manner. However, the comment could be more helpful if it explained why keypoint detection results are important or how they might impact the overall understanding of the experiments. Despite this, the comment still offers valuable guidance that can help the authors enhance their work. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This explicit action provides a clear direction for the authors to take, as it specifies a specific comparison to be made. The comment is concrete, as it directly instructs the authors on what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with existing models, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific comparison that could enhance the paper by comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is actionable and provides a clear direction for the authors to improve their draft by including a comparison that could strengthen the paper\"s contribution. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. It also mentions minor problems, but does not provide further details or suggestions for improvement. The comment implies that the authors should clarify this aspect of their methodology, but it lacks explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the grid search process but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grid search of learning rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking whether the grid search is performed on the validation set, providing clear guidance on what needs to be clarified. However, the comment does not provide specific suggestions or examples on how to improve the clarity or execution of this aspect. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking about the grid search for learning rate, specifically whether it is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. This is a relevant point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" is being used inappropriately. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or adjust their terminology. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This is a relevant point that could prompt the authors to reconsider their terminology and potentially clarify their findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a potential area for clarification, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. It is a factual statement seeking additional information, making \"No\" the appropriate label.", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This is a relevant and insightful point that could prompt the authors to consider the broader implications of their findings and ensure that their work is inclusive and applicable to diverse populations. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional analyses or discussions. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment does not provide specific guidance on how to improve the output quality or what aspects need attention. It lacks concrete actions or suggestions for the authors to take, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is still room for improvement. However, it does not specify which part of the paper discusses the output quality, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the output quality but lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. The reviewer suggests that there is still room for improvement in result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment lacks specific examples or references to recent GAN works that demonstrate the improvement in quality, making it 3. The authors would need to infer the specific examples or references themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the output quality of the paper, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment does not provide specific suggestions or guidance on how the authors might improve the output quality or what aspects need attention. While it highlights an area for potential improvement, the lack of actionable feedback limits its usefulness for the authors. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their work. It lacks concrete details on what specific changes or improvements are needed, leaving the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies areas of concern but does not offer detailed instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"soft labels is essentially on top of CRM and Cross entropy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the use of subpar hyperparameters and the results being impressive but potentially misleading due to the use of subpar hyperparameters. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the concerns or how to address them. The lack of detailed justification or evidence makes the claim 2, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters, suggesting that the authors may be using suboptimal parameters. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it points out areas of concern, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the simple/traditional experiment for unseen characters is a good idea but is presented as an afterthought. It implies that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to add translations or specify how to present the evaluation results. The action is concrete but somewhat vague in terms of execution, as the authors need to determine the specific translations and how to present the evaluation results. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more evaluation on classifying unseen words and the addition of translations to Figure 6 for nonChinese speakers. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is presented as an afterthought and that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment identifies a potential issue with the presentation of the experiment, it lacks specific examples or references to support the claim that the current presentation is inadequate. The suggestion to add translations is somewhat vague, as it does not specify which translations should be included or how they would enhance the figure. Therefore, the claim is 3, as it provides a logical basis but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the simple/traditional experiment for unseen characters, suggesting that it is presented as an afterthought. It also suggests that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer provides a specific suggestion to add translations to Figure 6 for nonChinese speakers, which could enhance the clarity and accessibility of the paper. However, the comment could be more helpful if it provided more detailed guidance on how to implement these suggestions or offered examples of how translations could be incorporated. Overall, the comment is 3 as it points out a potential area for improvement but lacks depth and specificity in its suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the number of images provided in the VioT dataset is small, which may impact the validity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the number of images, provide additional data, or justify the current number of images. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the VioT dataset, specifically mentioning the number of images provided in each of the four categories. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspect of the dataset or the approach is problematic. It suggests that the number of images is small, but without further explanation or suggestions, the authors may struggle to understand how to address this issue. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is small, which may impact the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of images is insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the VioT dataset, noting that the number of images provided is small. This observation highlights a potential limitation in the study, as the number of images may impact the validity of the approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional data collection or justifying the current number of images. While it points out a relevant concern, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance, which could be interesting. However, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The authors are left to infer that they should consider conducting such a study, but without specific details on how to structure it or what aspects to focus on, the action remains vague. Therefore, the comment is 3, as it implies an action but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study of the number of layers versus performance, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where this analysis could be conducted. Without explicit references to sections or experiments, the authors cannot confidently determine the exact part of the paper that needs revision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests conducting an ablation study of the number of layers versus performance, which is a suggestion for improvement. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this study would be beneficial or how it would contribute to the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance, which could provide insight into the impact of layer count on model performance. This is a valuable suggestion that could enhance the paper\"s contribution by offering a more detailed analysis of the model\"s architecture. However, the comment lacks specific guidance on how to conduct the study or what aspects to focus on, such as which performance metrics to use or how to interpret the results. While it provides a clear direction for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed, and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and that they had to read the text multiple times. While the comment provides some guidance on what needs to be improved, it lacks concrete details on how to implement these changes. The authors are given a general idea of what needs to be addressed, but the specific steps for improvement are not fully articulated. Therefore, the comment is 3, as it provides a direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig. 1 and 2\" and \"figure captions,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the paper, such as the difficulty in following the mathematical derivations and the lack of explanations in the figure captions. The comment provides clear guidance on what needs to be addressed, such as the need for more intuitive explanations and additional legends. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also mentions that figure captions are lacking and require additional explanations and legends. The reviewer provides specific examples, such as the need to explain the colors in Fig. 2, which adds some level of verifiability to the claim. However, the comment lacks detailed reasoning or references to support the claim that the paper is hard to follow or the need for more intuitive explanations. While the examples provide some evidence, the overall claim could be strengthened with more detailed justification or references to similar works. Therefore, the comment is 3, as it provides some support but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It provides examples of what could be improved, such as the need for more intuitive explanations and additional legends. The comment also mentions that Fig. 1 and 2 did not contribute much to the understanding, and that the authors had to read the text multiple times. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and accessibility of their paper. However, it could be more helpful if it offered suggestions on how to improve the mathematical derivations or provided examples of how to make the figures more intuitive. Overall, the comment is 4 as it provides valuable insights and direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. It explicitly states that resolving this issue would influence the reviewer\"s rating. While the comment does not provide specific guidance on how to address this issue, it implies that the authors should investigate the robustness of their results to different hyperparameter settings. The action is implicit but concrete, as the authors can infer that they need to assess the sensitivity of their results and consider different hyperparameter choices. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"empirical results\" and the \"hyperparameter choices,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of sensitivity to hyperparameter choices and the potential impact on the method\"s effectiveness. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. This claim is 3 as it highlights a potential issue with the robustness of the results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer suggests that resolving this issue would influence their rating, indicating a need for more detailed analysis or evidence to support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the robustness of the empirical results, specifically the sensitivity to hyperparameter choices. It highlights the potential impact of incorrect choices on the effectiveness of the method, which is a crucial consideration for the authors. The comment explicitly states that resolving this issue would influence the reviewer\"s rating, providing a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it offered specific guidance on how to assess the sensitivity or how to make more robust choices for hyperparameters. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation of their method\"s novelty and contribution, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they need to provide a more detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the novelty and contribution, as it points out that the method is similar to existing approaches. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is similar to existing attack methods on a surrogate model, suggesting that the novelty and contribution of the proposed method are not adequately addressed. However, the comment does not provide specific examples or references to existing methods, making it difficult for the authors to understand the exact nature of the similarity. Without detailed comparisons or references, the claim lacks sufficient evidence to be 5. Therefore, the comment is categorized as 2, as it provides some support but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the proposed method is similar to existing attack methods on a surrogate model. It suggests that the authors need to further claim the novelty and contribution of their method to differentiate it from existing work. While the comment highlights an important area for improvement, it lacks specific guidance on how the authors might effectively demonstrate the novelty and contribution of their method. The feedback is 3 as it points out a potential weakness but does not provide detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. It also provides specific references to external works that could be used to improve the clarity of the text. While the comment identifies the issues, it does not offer explicit guidance on how to address them, such as suggesting font size changes or providing examples of how to improve readability. The references are helpful but do not fully replace the need for explicit instructions. Therefore, the comment is 3, as it provides some direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the text in table 1 being too small and hard to read, and the missing gradient symbol in Algorithm 1. Additionally, it provides specific references to external works that could be used to improve the clarity of the text. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point makes two claims: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. The reviewer supports these claims by providing specific references to external works that could be used to improve the clarity of the text. However, the comment does not provide detailed reasoning or examples of how these references could address the issues. While the references offer a starting point, the comment lacks the depth and specificity needed to fully substantiate the claims. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. It also provides references to external works that could be used to improve the clarity of the text. While the comment highlights these issues, it does not offer detailed guidance or suggestions on how to address them. The references are helpful but do not fully replace the need for explicit instructions. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice for the authors to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed discussion on computational aspects and address the practical limitations of their methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It specifically mentions the appendix and the algorithm\"s requirement to solve several LPs in high dimensions, which is not easily calculable. The comment also points out that the experiments are performed on small datasets. However, it does not explicitly mention which part of the paper discusses computational aspects or where the appendix is located, making it weakly grounded. The comment is specific in detailing the issues with the computational aspects and the experiments, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods for high dimensions. The reviewer supports this claim by pointing out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific examples or studies that demonstrate the challenges of highdimensional LPs. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects and the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This feedback is valuable as it highlights a critical area for improvement in the paper, specifically the discussion of computational aspects and the practical limitations of the proposed methods. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues or improve the discussion. Overall, the comment is 4 as it directs the authors\" attention to a crucial area for enhancement, but it could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. While the comment implies that the authors should consider this baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider this baseline. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet shares parameters between the residual blocks, and it suggests a potential baseline for comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. However, the comment lacks any supporting evidence, reasoning, or references to justify why this comparison would be meaningful or beneficial. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the ResNet used in the experiments, asking whether it shares parameters between the residual blocks. This is a relevant point that could impact the validity and comparability of the results. The comment also suggests a potential baseline for comparison, which could be beneficial for the authors to consider. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address the issue or implement the proposed baseline. While it identifies a potential area for improvement, it could be more helpful with additional context or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It notes that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the motivation or what specific changes should be made to the architecture. As a result, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the motivation of the crossencoder architecture, noting that it is not ignoring crossentity comparison but instead attends to all candidates at once. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the motivation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for the crossencoder architecture is poorly explained, specifically stating that it is not ignoring crossentity comparison but instead attends to all candidates at once. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It points out that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the motivation for their architecture. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their design choice. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to justify the decision. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or how it might impact the paper\"s results or analysis. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. This feedback highlights a potential issue with the methodology, prompting the authors to reconsider their approach. However, the comment lacks specific suggestions or guidance on how to address this issue or what alternative design choices might be considered. While it identifies a potential weakness, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the work uses an outdated GNN model and method, which affects the performance of the framework. It also mentions that the baseline algorithms/methods are also outdated. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without actionable guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of an outdated GNN model and method, which affects the performance of the framework. However, it does not specify which part of the paper discusses the GNN model or the baseline algorithms/methods, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the GNN model or baseline algorithms/methods are outdated or how they could be improved. Without clear guidance on what needs to be addressed, the authors may struggle to effectively address the critique. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an outdated GNN model and method, which impacts the performance of the framework. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the use of outdated methods affects the performance. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the work, noting that it uses an outdated GNN model and method, which impacts the performance of the framework. This is a critical observation that could significantly affect the paper\"s credibility and relevance. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it highlights a significant weakness but does not offer actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed method produces the type of explanation mentioned in Figure 1. It suggests that additional adhoc postanalysis might be required to extract shared motifs to explain a set of instances. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or what specific steps the authors should take to improve the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or examples to clarify the process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding how the proposed method produces the type of explanation mentioned in the figure. The comment suggests that additional adhoc postanalysis might be required to extract shared motifs, and it implies that this analysis might be easier with the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanation in Figure 1 is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. The reviewer provides a quote from Line 48 to support this claim, which suggests that the analysis might be easier with the proposed method but still requires additional effort. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the quote provides some context, it does not fully address the issue of clarity or the necessity of additional analysis. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that the explanation provided is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. It references Line 48 to provide context and implies that the proposed method might make this analysis easier but still requires additional effort. While the comment highlights a potential weakness in the explanation, it does not offer specific suggestions or guidance on how to address this issue or improve the clarity of the figure. The feedback is 3 as it points out a specific area for improvement, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides two ways to strengthen the experiment: by either using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. While the comment provides some guidance on how to address the issue, it lacks specific instructions on how to implement these suggestions. The action is explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, which relies on pseudo feature importance due to the unavailability of true feature importance. The comment provides specific guidance on how to strengthen the experiment by suggesting two ways: using a different method to estimate true feature importance or providing a more detailed explanation of the perturbation value. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment relies on pseudo feature importance due to the unavailability of true feature importance. It suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The reviewer provides a logical reasoning by explaining the potential issue with the experiment\"s reliance on pseudo feature importance and the need for a more robust method to estimate true feature importance. However, the comment lacks specific examples or references to support the claim about the correctness of the pseudo feature importance. This makes the claim 3, as the authors would need to further explore the basis of the claim to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests two ways to strengthen the experiment: by using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. This feedback is clear and actionable, as it guides the authors on how to improve the robustness and credibility of their experiment. By addressing these suggestions, the authors can enhance the reliability and trustworthiness of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific properties of Z should be considered or how to address the potential issue of nonconvexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 182184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies the issue of nonconvexity and suggests that it may not be a problem if the function Z has certain properties. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific line in the paper (ln. 182184) and suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. While the comment highlights a potential issue, it lacks depth and does not provide specific guidance or examples of what these properties might be. This limits the comment\"s usefulness in helping the authors understand and address the issue. Therefore, the comment is 3, as it points out a potential weakness but does not offer actionable advice for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies specific lines in the SuppMat that should be moved from red to green. This provides clear and direct instructions for the authors to follow, ensuring they know exactly what changes to make. The action is concrete, as it specifies the exact lines and their corresponding changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the exact lines that need to be moved from red to green, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the SuppMat, specifically mentioning lines that should be moved from red to green. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific lines in the SuppMat that should be moved from red to green, providing clear and actionable feedback. This guidance is valuable as it helps the authors ensure that their SuppMat is accurate and uptodate. However, the comment could be more helpful if it explained why these lines are important or how they contribute to the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to make specific changes to improve the clarity and accuracy of their SuppMat."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on how to conduct this analysis or what aspects should be included. The comment implies that the authors should expand their analysis, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not specify which part of the paper this analysis should be applied to, nor does it provide details on what aspects should be included or how the analysis should be conducted. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. The comment lacks specificity and does not offer a clear path for the authors to follow, making it difficult for them to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on what aspects of the analysis should be expanded or how to conduct it. The comment acknowledges the limitations of the paper\"s length, but it does not offer actionable steps for the authors to take in terms of enhancing their analysis. Without detailed suggestions or examples, the feedback lacks depth and specificity, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the lack of proper experimental settings and the absence of code. It explicitly states that the result reproducibility is critical and that the authors should provide the code. This feedback is clear and direct, giving the authors a clear action to take to improve their draft. The comment is specific about what needs to be added or included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental settings\" and the \"code,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of proper experimental settings and the absence of code, which are critical for result reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly and that the result reproducibility is critical. It also notes the absence of code, which is a significant concern. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of these issues themselves.", "helpfulness_rationale": "The review comment identifies two critical issues with the paper: the lack of proper experimental settings and the absence of code. It highlights the importance of result reproducibility and emphasizes the need for the authors to provide the code. This feedback is clear and actionable, as it directly points out areas where the paper could be improved to enhance its credibility and reliability. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as recommending specific experimental settings or code sharing platforms. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of a proper comparison against online learning approaches and reinforcement learning (RL). It suggests that the authors should clarify why online learning cannot be used and address the challenges of including retraining cost in the evaluation. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes or what aspects of the comparison should be addressed. The authors are left with a general idea of what needs to be done but without detailed instructions on how to execute these actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors mention that online learning formulation overlooks key practical considerations. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of a proper comparison against online learning approaches and reinforcement learning, and the challenges of including retraining cost in the evaluation. It provides a clear direction for improvement by asking questions about the reasons behind the limitations of online learning and how to address these challenges. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of a proper comparison against online learning approaches and reinforcement learning, suggesting that the abstract and other parts of the paper overlook key practical considerations. The reviewer provides a logical reasoning by questioning why online learning cannot be used and highlights the importance of including retraining cost in the evaluation. However, the comment lacks specific examples or references to support the claim, such as detailed comparisons or studies that demonstrate the limitations of online learning. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that the abstract and other sections mention the limitations of online learning formulations but do not provide a proper comparison against online learning approaches or reinforcement learning. It suggests that the authors should clarify why online learning cannot be used and address the challenges of including retraining cost in the evaluation. The comment provides a clear and actionable suggestion for improvement, guiding the authors to address a critical aspect of their work that could enhance its impact and credibility. However, it could be more helpful if it offered specific examples or references to similar studies that have addressed these issues, which would provide the authors with a more detailed roadmap for improvement. Overall, the comment is 4 as it effectively points out a significant oversight and offers a clear direction for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cite works related to metalearning and distinguish their approaches from those already cited. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a clear direction for the authors to expand their literature review and improve the connection between their work and existing research, it does not specify which works should be cited or how to distinguish them. The action is explicit but lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also mentions the work on RL for architecture search and optimizers, which should be linked to continual learning. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the need to cite related works and to distinguish approaches, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a logical reasoning for the need to cite and distinguish related works, it lacks specific examples or references to support the claim about the deeper tie to metalearning. The suggestion to link the RL work is more concrete, but the overall claim is 3 due to the lack of detailed evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to expand their literature review and distinguish their approaches from related works in the field of metalearning. It highlights the importance of linking the work on RL for architecture search and optimizers to continual learning, which is a critical aspect of the paper. By suggesting specific areas for improvement and providing a direction for the authors to enhance their work, the comment offers valuable guidance for enhancing the paper\"s depth and relevance. However, it could be more helpful if it included specific references or examples of related works to guide the authors in their literature review. Overall, the comment is 4 as it provides a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might have an idea of where this feedback is relevant, it is not explicitly grounded. The comment is specific in suggesting alternative approaches to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not provide any supporting evidence, examples, or references to justify why this diversity is important or how it would improve the paper. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand the significance of this suggestion without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the diversity of teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. This feedback is 3 as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other studies have addressed this issue. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. While the comment implies that the authors should include a summary of the supplementary experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a summary of the supplementary experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the main text should be revised or where the summary should be placed. The authors can infer that it relates to the sections discussing the experiments or results, but this inference is not direct. The comment is specific in suggesting the need for a summary of the supplementary experiments, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. This feedback is 3 as it identifies a potential gap in the paper\"s presentation, which could enhance the clarity and comprehensiveness of the main text. However, the comment lacks specific guidance on how to effectively summarize the supplementary experiments or what aspects of the results should be highlighted. While it points out an area for improvement, it does not provide detailed suggestions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a comprehensive comparison with the works mentioned, GFF1 and EfficientFCN2, which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer provides specific references to these works, making it clear what needs to be done. Additionally, the comment mentions that the societal impact is shown on the last page of the manuscript, which is not relevant to the action being requested. Therefore, the action is explicit and concrete, as the authors know exactly what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, \"GFF1\" and \"EfficientFCN2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF1 and EfficientFCN2, which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer suggests a comprehensive comparison with these works. However, the comment does not provide specific details or examples of how these references would enhance the paper or what aspects of the comparison would be beneficial. While the references are cited, the lack of detailed justification or explanation makes the claim 3, as the authors would need to infer the importance of these comparisons themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue by pointing out the absence of important references, specifically mentioning GFF1 and EfficientFCN2, which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, which could significantly enhance the paper\"s contribution and relevance. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript. While the comment highlights a critical area for improvement, it could be more helpful if it provided specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a significant area for enhancement, but it could be more actionable with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. However, it does not provide any guidance on how the authors should address this issue or what specific actions they should take to support their claim. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the slight improvement reported in these tables and the claim about the effectiveness of the proposed prompts. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the slight improvement reported in Table 6 and Table 7 cannot support the claim \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. This is a critical observation that could impact the validity of the authors\" claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental design to better support their claims. Without actionable feedback or specific advice, the authors are left without a clear path forward. Therefore, the comment is rated as 2, as it points out a potential problem but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". While the comment implies that these comparisons could provide valuable insights, it does not explicitly instruct the authors to conduct these comparisons or explain why they are necessary. The action is implicit and somewhat vague, as the authors need to infer that these comparisons would be beneficial. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, it does not specify which part of the paper these comparisons should be included in, making it weakly grounded. The comment is specific in suggesting the need for these comparisons, as it clearly identifies the potential benefits of including them. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, the comment does not provide any justification or reasoning for why these comparisons would be beneficial or how they would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of the paper with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This feedback is 3 as it provides a clear direction for the authors to consider in terms of benchmarking their work against existing approaches. However, the comment lacks depth and does not explain why these comparisons are particularly relevant or how they could enhance the paper. Additionally, it does not offer suggestions on how to integrate these comparisons into the paper or what specific aspects to focus on. While the feedback points to potential improvements, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the analysis, specifically the alignment of features at different spatial locations to the same channel. It suggests that there could be many different designs for this analysis, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they need to explore different designs or variations, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. However, it does not specify which part of the paper this analysis is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment does provide a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes, which adds some level of specificity. However, without explicit references to sections or figures, the comment remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of Cycle FC align features at different spatial locations to the same channel is insufficient. However, it does not provide any specific examples, reasoning, or references to support this claim. The suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes, is vague and lacks detail. Without concrete evidence or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. It provides a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes. This feedback is 3 as it points out a potential area for improvement and offers a direction for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or what specific aspects of the analysis should be expanded. Overall, the comment is 3 as it highlights an area for improvement but lacks depth and actionable steps."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of standard deviations in the paper, which raises concerns about the validity of the results. It suggests that the authors should include standard deviations to provide more transparency and confidence in their findings. While the comment explicitly states the action needed (displaying standard deviations), it does not provide specific guidance on how to present these deviations or what aspects to focus on. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which raises concerns about the validity of the results. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where standard deviations should be displayed. This makes it difficult for the authors to pinpoint the exact location of the issue. While the comment is specific in identifying the absence of standard deviations, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the paper raises concerns about the validity of the results. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to similar studies that have included standard deviations, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the absence of standard deviations. This is a critical observation that could impact the validity and reliability of the results. However, the comment does not provide specific guidance on how to address this issue or what aspects of the results might be affected by the lack of standard deviations. While it highlights a potential problem, it lacks actionable advice or suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide explicit guidance or suggestions on how to achieve this extension. The comment implies that the authors should consider broadening the scope of their work, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the specificity of the setting, suggesting that the approach could be extended to more general settings. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the setting and its suggestion for broadening the scope, but without clear references to specific sections or elements, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide any supporting evidence, reasoning, or references to justify why the current setting is specific or how it could be broadened. The comment lacks detailed explanation or examples, making it difficult for the authors to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a specific concern about the specificity of the setting, suggesting that the approach could be extended to more general settings. It questions the need for a generative model and episodic problem structure, which are currently assumed in the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to broaden the scope of the work. The authors are given a direction to consider, but the feedback is not actionable or detailed enough to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the feature extractor used for dimensionality of each region, specifically asking about the feature extractor used in line 201. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the feature extractor. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the feature extractor used for dimensionality, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the feature extractor used for dimensionality in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the feature extractor used for dimensionality in line 201. This is a clear and actionable point, as it prompts the authors to clarify an important detail in their methodology. By addressing this question, the authors can improve the clarity and transparency of their work, which is beneficial for both the reviewer and the readers. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it implies that the authors should include these details, it does not explicitly instruct them to do so or provide specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should include these details but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what specific aspects of the computation, algorithm, or implementation should be highlighted. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what details should be included or how they could be presented. Without further elaboration or examples, the authors may find it challenging to understand the exact nature of the feedback and how to address it. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of p < 0.4 in Algorithm 1, indicating that the reviewer is seeking clarification or explanation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific information they should include in their response. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed explanation or justification for their choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4 in Algorithm 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a specific question about the choice of p < 0.4 in Algorithm 1, which is a clear and actionable request for clarification. By asking for an explanation or justification of this choice, the reviewer prompts the authors to provide additional information that could enhance the transparency and understanding of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what aspects of the choice might be particularly important for readers to understand. Overall, the comment is 3 as it directs the authors to provide additional clarification but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It specifically mentions the need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback provides clear and concrete actions for the authors to take, such as adding explanations or analysis to these figures. The comment is 5 as it directly instructs the authors on what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanations or analysis for Figures 1, 2, and 3. The comment provides detailed guidance on what needs to be clarified, such as the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. The reviewer suggests that the authors need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This claim is 3 as it logically points out the need for additional analysis or explanation, but it lacks specific examples or references to support the claim. The authors would need to infer the need for clarification themselves, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of explanations or analysis for Figures 1, 2, and 3. It points out that the figures contain negative numbers and suggests that the authors need to clarify these aspects. This feedback is clear and actionable, as it directs the authors to provide explanations or analysis for the figures, which could significantly enhance the understanding and interpretation of the results. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or what kind of analysis might be beneficial. Overall, the comment is 4 as it effectively guides the authors on a critical aspect of their draft that needs improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not provide specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. The comment lacks concrete details or suggestions on how to enhance the explanation or demonstration. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for a clearer explanation or demonstration of the motivation, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the motivation behind applying CMD in federated learning. It suggests that the motivation could benefit from a more explicit demonstration or explanation, which is a valid point. However, the comment lacks specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. While it highlights an area for improvement, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. While the comment implies that the authors should provide more analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more analysis and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper should include this analysis or comparison, making it somewhat specific. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides a logical reasoning by suggesting that such comparisons would clarify the unique advantages of the method. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the claim, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of analysis regarding the effectiveness of data augmentation methods. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison sections. However, the comment could be more helpful if it offered examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward improving their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for an ablation study and provides examples of alternative approaches. However, the authors might need to infer the exact steps to implement the ablation study, making the comment 3.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an ablation study and providing examples of alternative approaches. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment lacks specific reasoning or evidence to support why an ablation study is necessary or how it would benefit the paper. The examples provided are not detailed enough to fully substantiate the claim, making it 3. The authors would need to infer the importance of the ablation study and the specific benefits of the examples provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is actionable and offers a clear direction for the authors to improve their draft by conducting an ablation study to better understand the impact of each component. However, the comment could be more helpful if it provided additional guidance on how to design and conduct the ablation study or suggested specific metrics to use. Overall, the comment is 4 as it identifies a critical area for improvement and offers actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it does not explicitly instruct the authors to perform a specific action, it implies that the authors should consider this scenario and its implications for their model. The comment is 3 as it provides a direction for further exploration, but it lacks concrete guidance on how to implement this exploration or what specific aspects to focus on. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspect of the model\"s performance is being questioned or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting aspect of the model\"s behavior, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address this question or what potential implications it might have for their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It suggests that RLCD (or RLCDRescore) may not be able to scale to larger language models that are better at differentiating responses near the decision boundary. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific steps they should consider to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the shrinking advantage of RLCD over RLAIF as the model size increases, and it raises a question about whether RLCD can scale to larger language models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, and it questions whether RLCD can scale to larger language models. However, the comment lacks specific examples, data, or references to support this claim. Without additional evidence or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It raises a question about whether RLCD (or RLCDRescore) can scale to larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an important aspect of the comparison, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input, and questions whether there is a solution to address this issue. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue or improve the practical contribution of their paper. The authors are left to infer that they need to consider scalability, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed NC measure, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the method when applied to large datasets like ImageNet. However, it does not provide specific suggestions or examples on how to address the scalability issue, which would make the comment more actionable. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the scalability of the proposed NC measure, suggesting that it may not be practical for large datasets like ImageNet. However, the comment lacks specific examples or evidence to support this claim, such as data or references to similar methods that have successfully addressed scalability issues. Without such details, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 2, as it provides a logical concern but lacks sufficient evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It raises a valid concern about the practicality of the method when applied to large datasets like ImageNet. However, the comment does not provide specific suggestions or examples on how to address the scalability issue or improve the practical contribution of the paper. While it highlights a critical area for consideration, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a quantitative analysis to substantiate the computational gains claimed in the paper. It specifies the types of measurements that would be helpful, such as GPU hours, memory usage, or training time. This provides clear and concrete guidance on what the authors need to do to improve their draft. The action is explicit and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for specific measurements or comparisons to substantiate the computational benefits claimed in the paper. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational gains claimed in the paper. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim that these measurements are necessary. The reasoning is 3, as it highlights a potential area for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of quantitative analysis to substantiate the computational gains claimed in the paper. It suggests that specific measurements, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This feedback is clear and actionable, as it directs the authors to include quantitative analysis to support their claims. By addressing this point, the authors can significantly enhance the credibility and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or what specific changes should be made to account for this time. The action is implied and somewhat vague, as the authors need to infer that they should consider this aspect in their evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the time should be considered, but without clear references to sections or details, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this consideration is important or how it affects the efficiency of the method. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the efficiency of the method when comparing it to COLMAP and scenebyscene finetuning. It suggests that the time taken for these processes should be considered, which could impact the method\"s performance in certain scenarios. While the comment highlights an important aspect to consider, it lacks specific guidance or suggestions on how the authors should address this issue or what specific changes should be made to improve the efficiency of the method. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the \"filter manifold network\" (FMN) and its scalability with the number of filter parameters. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these questions, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it implies actions but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the scalability of the FMN with larger input and output channels, and it suggests experimenting with other architectures. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. The reviewer also questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors are left to infer the need for more analysis and discussion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It raises important questions about the scalability of the FMN with larger input and output channels, suggesting that the authors should experiment with other architectures and explore how adaptive convolutions scale with the number of filter parameters. Additionally, the comment questions whether FMN can reasonably scale for larger input and output channels, which is common in many CNN architectures. This feedback is clear and actionable, providing the authors with specific areas to focus on to improve their draft. However, it could be more helpful if it offered suggestions on how to address these questions or provided examples of alternative architectures to consider. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform and suggesting that comparisons to UNets are necessary. While the comment identifies a potential issue with the model, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should make comparisons to UNets, but the comment lacks specific instructions on how to conduct these comparisons or what aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed CoNO model\" and the \"complex UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the contribution of the UNet part and suggests comparisons to UNets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contribution of the UNet part in the CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the claimed performance boost. The reviewer references external works, such as Raonic et al and Gupta et al, to support their claim about the strong performance of UNets on regular gridded domains. This provides a logical basis for the claim, but the comment could be strengthened by providing more detailed comparisons or examples from the referenced works. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform. It suggests that the authors should make comparisons to UNets, as they have shown strong performance on regular gridded domains. The comment provides a logical basis for the suggestion by referencing external works, such as Raonic et al and Gupta et al, which support the importance of UNets in this context. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 3 as it highlights a potential area for improvement but lacks detailed guidance for the authors to fully address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It also suggests that a comparison of computation complexity should be included in the experiment part. While the comment identifies a specific issue with the computational complexity, it does not provide explicit guidance on how to reduce it or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison of computation complexity in the experiment part. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"the calculation of all the flipped previous layer output into the current layer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of computation complexity in the experiment part. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. The comment suggests that a comparison of computation complexity should be included in the experiment part. While the claim is based on logical reasoning and specific observations about the algorithm, it lacks detailed evidence or references to support the assertion that the PSA method requires more computation. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the computational complexity of the proposed PSA method compared to baselines, noting that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their methodology that could impact the paper\"s impact and credibility. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or suggested specific metrics to use. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger, increasing the size of V_mem, Th_i, and U_i^t, and using a larger font for the \"CTRL\" long form explanation. Additionally, it points out the lack of details comparison with other stateoftheart Transformer designs, suggesting a \"table\" manner to emphasize the data for readers. While the comment provides explicit actions and concrete details on how to implement these changes, it could be more helpful if it offered suggestions on how to present the comparison table or what specific metrics to include. Overall, the comment is 4 as it clearly identifies areas for improvement and provides concrete guidance on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures, such as \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other stateoftheart Transformer designs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes several claims about the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other stateoftheart Transformer designs. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claims are 1, as they lack the necessary support to be convincing or actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the figures, suggesting that the fonts could be larger, particularly for the words in the grey box, and that the size of V_mem, Th_i, and U_i^t should be increased. It also points out the need for a more detailed comparison with other stateoftheart Transformer designs, suggesting a \"table\" manner to emphasize the data for readers. While the comment identifies specific areas for improvement, it could be more helpful if it provided guidance on how to present the comparison table or what specific metrics to include. Overall, the comment is 4 as it directs the authors to make concrete improvements in the presentation of their work, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what specific steps to consider regarding the agent\"s behavior during learning. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of reporting results after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It raises a concern about the early stages of training, where the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not specify which part of the paper this issue pertains to, such as the results section or the methodology. While the authors might have an idea of where this issue is discussed, the comment lacks full grounding. It is specific about the concern regarding the agent\"s behavior during learning, but without explicit references to the relevant sections, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a logical observation but lacks specific evidence or references to support the claim. The comment is 3 as it provides a reasonable basis for the concern but could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a thoughtprovoking observation that could prompt the authors to consider how their results might be impacted by the agent\"s behavior during learning. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or explore the agent\"s behavior during learning. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests that the authors rewrite the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This is a clear and direct action for the authors to take, as it provides a specific line and page number for them to address. The comment also indicates that the current sentence is unclear, which further guides the authors on what changes are needed to improve the clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"P. 5, p. 3, l.\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This provides clear guidance on what the authors need to do to improve the clarity of their writing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and a specific suggestion to rewrite a sentence. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" by requesting a rewrite. This is a clear and actionable suggestion that can help the authors improve the readability and understanding of their paper. However, the comment could be more helpful if it provided additional context or guidance on how to rewrite the sentence to improve its clarity. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. While the comment identifies a potential gap in the manuscript, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information about their approach but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED\" and \"the documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the handling of documents as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what needs to be addressed in the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification about the approach taken in handling documents in DocRED, specifically regarding the consideration of documents as an entire sentence and the handling of concepts involving multiple entity mentions. While the questions themselves do not present a claim or opinion, they imply that the manuscript lacks information about these aspects. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they impact the paper. As a result, the comment is considered 2, as it highlights a potential gap in the manuscript but lacks sufficient justification for the authors to address it effectively.", "helpfulness_rationale": "The review comment raises a specific question about the approach taken in handling documents in DocRED, particularly regarding the consideration of documents as an entire sentence and the handling of concepts involving multiple entity mentions referring to the same entity. This feedback is clear and actionable, as it prompts the authors to provide more information about their methodology and how it addresses these complexities. By addressing these questions, the authors can enhance the clarity and completeness of their manuscript, which is valuable guidance for improving the draft. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived marginality or how to improve the contribution. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as the methods or the stage where they are used. This lack of specificity makes it difficult for the authors to pinpoint the exact sections that need improvement or clarification. Additionally, the comment does not provide specific guidance on how to address the issue of marginality or what changes could be made to enhance the contribution. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific methods or stages where the methods are welldesigned or demonstrated, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the paper is marginal, as the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. While the comment identifies a potential issue with the perceived marginality of the contribution, it lacks specific suggestions or guidance on how the authors might address this concern or improve their contribution. The feedback is 3 as it points out a potential weakness, but it does not provide actionable advice or detailed feedback for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. While the comment identifies a potential issue with the clarity of the main contribution, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the motivations for PBSD and its contribution to the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study\" and the \"DSCL part,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the clarity of the main contribution, particularly regarding the motivations for PBSD beyond improving the discriminative representation on tail classes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. This claim is 3 as it highlights a potential inconsistency in the paper\"s focus, but it lacks specific examples or references to support the argument. The authors would need to further explore and clarify the motivations for PBSD to address this concern effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. This feedback is 3 as it points out a potential inconsistency in the paper\"s focus, which could be clarified to enhance the coherence and impact of the contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as by providing additional context or examples. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment implies that the authors should consider including more details about these experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should provide more information but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it does not specify which part of the paper the Appendix is attached to, making it weakly grounded. The comment also mentions the Brusselator as an example of an additional experiment, but it does not specify which part of the Appendix this experiment is discussed in. This lack of specificity makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual statement about the Appendix and its content. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment appreciates the inclusion of a comprehensive Appendix, which provides additional detail about parts of the paper. However, it acknowledges that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment highlights a potential area for improvement by suggesting that the authors should consider including more details about these experiments in the main text, it does not provide specific guidance or suggestions on how to do so. This limits the comment\"s helpfulness, as it points out an area for improvement but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer implies that the description could be misleading if the two methods are not the same. However, the comment does not provide explicit guidance on how the authors should clarify this distinction or what specific changes should be made to the description. While the action is implied, it is not concrete, as the authors are left to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"step 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\" claim of using active learning and asks for clarification on whether the \"active learning pipeline\" method is the same as traditional active learning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of using active learning in step 2, specifically asking whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer provides a logical reasoning by pointing out that the description could be misleading if the two methods are not the same. However, the comment lacks specific examples or references to support the claim that the methods are different. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the authors\" claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. This is an important clarification that could impact the readers\" understanding of the methodology and its applicability. The comment prompts the authors to clarify this distinction, which is crucial for ensuring the accuracy and transparency of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the distinction or examples of how the two methods differ. Overall, the comment is 4 as it identifies a critical issue that the authors need to address to improve the clarity of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the distribution should be clarified, how it should be clarified, or what specific aspects of the distribution are unclear. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where the distribution is discussed. Without explicit references or detailed guidance, the authors may struggle to identify the exact area needing clarification. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of the distribution. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It proposes an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. While the comment implies that the authors should consider this alternative approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. However, the comment does not specify which part of the paper discusses the method or the annotation requirements, making it weakly grounded. The suggestion to explore a selfsupervised approach is specific, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. While the comment provides a logical reasoning for the limitation and suggests an alternative, it lacks specific examples or references to support the claim that a selfsupervised approach would be more appealing. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed method, specifically the requirement for annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in terms of expanding the applicability of their method. However, the comment could be more helpful if it included examples or references to support the argument for the selfsupervised approach. Overall, the comment is 4 as it guides the authors toward a potential improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct additional experiments, but the comment lacks concrete details on how to implement this suggestion.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to demonstrate scalability on more challenging tasks, but without explicit references to sections or figures, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. The claim is 3 as it logically argues that demonstrating scalability on more complex tasks is important. However, it lacks specific examples or references to support the claim that these tasks are indeed more challenging or how LFF could be applied to them. Providing such examples or references would strengthen the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of the LFF method, it is important to show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental setup and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or what specific aspects of the LFF method should be emphasized in these more complex tasks. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract should include a specific measurement, such as \"attain greater expressivity, as measured by the change in linear regions in output space after citation, instead of just \"attain greater expressivity.\" Additionally, it recommends including learning curves for all experiments in an appendix. While the comment provides explicit actions, it does not specify which experiments should include learning curves or how to present them. The authors are given clear guidance on what to add to the abstract and an appendix, but the execution of these actions is not detailed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be changed in the abstract, suggesting a specific measurement to include and recommending the inclusion of learning curves in an appendix. This level of detail provides clear direction for the authors to make improvements. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests changes to the abstract, specifically recommending a specific measurement to include and recommending the inclusion of learning curves in an appendix. The comment provides a logical reasoning for these suggestions, suggesting that the current abstract lacks specificity and could benefit from more detailed information. However, it does not provide specific references or examples to support the claim that the current abstract is lacking in detail. Therefore, the comment is 3, as it provides a logical basis for the suggestions but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract, suggesting that it should include a specific measurement to support the claim of \"attaining greater expressivity.\" This suggestion is clear and offers a concrete way to enhance the clarity and rigor of the abstract. Additionally, the comment recommends including learning curves for all experiments in an appendix, which is a helpful suggestion for providing additional insights and context. However, the comment could be more helpful if it explained why learning curves are important or how they could be presented. Overall, the feedback is 4 as it guides the authors on how to improve the clarity and comprehensiveness of their abstract and appendix."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and application, specifically questioning the need for domain adaptation and the usefulness of the proposed method. It suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. While the comment implies that the authors should provide examples of how the method could be applied in practice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of domain adaptation tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results of mapping one RGB image to another RGB image with a different style, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the motivation and usefulness of the paper, suggesting that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the motivation and usefulness of the paper, suggesting that the proposed method does not have a clear application or demonstrate its value in domain adaptation tasks. The reviewer provides a logical reasoning by pointing out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily justify the need for domain adaptation. However, the comment lacks specific examples or references to support the claim that demonstrating the methodology\"s use on actual tasks would be beneficial. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the motivation and usefulness of the proposed method. It points out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily justify the need for domain adaptation. The reviewer suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by showing the practical applications of their method. However, the comment could be more helpful if it offered examples of such tasks or provided guidance on how to effectively demonstrate the methodology\"s utility. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider other baselines or update their references to more recent works. As a result, the authors are left without a clear understanding of how to address this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"MISA,\" \"M2FNet,\" and \"MMDFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This claim is 3 as it provides a specific reference to MULT and its publication year, which supports the assertion that it is outdated. However, the comment lacks detailed reasoning or examples to fully substantiate why MULT is considered out of fashion or how it impacts the current work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s reference to MULT as the only deep learningbased baseline that considers crosssensory interaction. It points out that MULT was proposed in 2019 and is therefore out of fashion, which could impact the relevance and credibility of the paper\"s claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting alternative baselines or updating the references to more recent works. While it highlights a potential weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a major issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks for all models and the omission of tensor completion results for fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the clarity and fairness of the comparisons. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"comparison against other models,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, namely the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. The comment provides a detailed suggestion for how to improve the clarity and fairness of the comparisons, such as comparing tensor completion results for all models with the same number of model parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the value of the used ranks is omitted, making it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare tensor completion results for all models with the same number of model parameters, which is a logical suggestion to improve the clarity and fairness of the comparisons. However, the comment lacks specific examples or references to support the claim that the current comparison is unclear or lacks detail. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks for all models and the omission of tensor completion results for fair comparison. It provides a clear and actionable suggestion for the authors to compare tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback is valuable as it guides the authors on how to improve the clarity and fairness of their comparisons, ensuring that the results are more robust and informative. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully conducted such comparisons. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should include ATA in the comparison under the leave one out setting in Table 2. This is a clear and direct action for the authors to take, as it provides a specific recommendation to enhance the comparison by including ATA. The comment also references the results in Table 1, which further guides the authors on where to make the change. The action is concrete and specific, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of ATA in the comparison under the leave one out setting. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to ATA in addition to \"+LFP\" under the leave one out setting in Table 2. The claim is based on the assumption that ATA is better than FP according to the results in Table 1. However, the comment does not provide specific evidence or references to support this claim, such as detailed comparisons or specific results from Table 1. This lack of detailed justification makes the claim 3, as the authors would need to make a significant effort to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+\"LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, as ATA is reportedly better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a direct suggestion to enhance the comparison and improve the clarity of their results. By addressing this point, the authors can strengthen their analysis and make their findings more robust. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the normalization module, noting that it appears different in two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in the context of Fig. 4, where the chosen symbols overlap. Additionally, the reviewer points out minor issues with the text, such as overlapping symbols in Fig. 4 and a lack of clarity after equation (4). While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to standardize the pictograms or address the overlapping symbols issue. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"normalization module\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. Additionally, it provides specific feedback on the figures, particularly Fig. 4, where the chosen symbols overlap. The comment also mentions minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the normalization module appears different in two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in Fig. 4, where the chosen symbols overlap. The reviewer also points out minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4). However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the specific issues and how to address them, which could be challenging without additional context or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. This is a clear and actionable point that the authors can address to improve the consistency and clarity of their work. Additionally, the comment highlights the importance of standardizing the pictograms, particularly in Fig. 4, where the chosen symbols overlap. This feedback is valuable as it helps the authors ensure that their figures are clear and easy to understand. The comment also points out minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4), which can be addressed to improve the overall readability. Overall, the comment is 4 as it provides clear and actionable suggestions for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the authors\" claims and the theoretical part of the paper. It questions whether the proposed algorithm is detailed enough to remove subdivision splines and whether it requires extra computation cost for space partitioning. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to clarify the algorithm\"s details and potential computational costs, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the observation and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detail in the theoretical part regarding the proposed algorithm for removing subdivision splines and the potential extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the observation of subdivision splines and the goal of pruning. It points out that the theoretical part lacks detail on how the proposed algorithm would remove these splines, specifically questioning whether it would require extra computation cost. The comment is 3 as it highlights a potential gap in the paper\"s explanation, but it does not provide specific examples or references to support the claim. The authors would need to further explore the theoretical part to address this concern, making the comment 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claims and the theoretical part of the paper. It points out that while the authors claim that only parts of subdivision splines are useful for decision boundaries, the theoretical part lacks detail on how the proposed algorithm would remove these splines. The comment also raises a question about the potential extra computation cost for space partitioning. This feedback is 3 as it highlights a gap in the paper that the authors need to address, but it could be more beneficial if it provided specific suggestions on how to clarify the theoretical part or mitigate the computational cost. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that W1 and W2 are not defined, and it speculates that they might denote the Encoder and Decoder networks. It also mentions that W and V are not defined in the same context, providing specific references to the pages and equations where these terms are mentioned. This feedback is clear and directs the authors to define these terms, which is a concrete action for them to take. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1 and W2\" and \"W and V,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these terms are not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"W1 and W2 are not defined\" and speculates that they might denote the Encoder and Decoder networks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that W1 and W2 are not defined and speculating that they might denote the Encoder and Decoder networks. It provides clear and actionable feedback by pointing out the lack of definitions for these terms and suggesting that the authors clarify their meaning. This feedback is valuable as it directs the authors to a specific area that needs attention and improvement, ensuring that the paper is more clear and accessible to readers. However, the comment could be more helpful if it offered additional guidance on how to define these terms or provided examples of how they might be used in the context of the paper. Overall, the comment is 4 as it effectively highlights a critical issue and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. It suggests that a better comparison should be considered. While the comment implies that the authors should reconsider their comparison, it does not provide specific guidance on how to improve the comparison or what alternative baselines should be used. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with baselines, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the comparison, stating that it is unfair due to the lack of prior knowledge of users or language embedding computation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of baselines, noting that the lack of prior knowledge of users or language embedding computation may unfairly skew the results. This is a valuable observation that could lead to a more robust and fair comparison. However, the comment does not provide specific suggestions on how to address this issue or what alternative baselines could be considered. While it highlights an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. While the comment identifies areas that need clarification or expansion, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or examples, but the comment lacks specific guidance on what exactly is missing or how to improve the draft. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on how to implement them.", "grounding_specificity_rationale": "The comment addresses several issues, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of Figure 4 and the presentation of Pixelshuffle details. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. While the comment identifies areas that need clarification or expansion, it does not provide specific examples or references to support these claims. The authors are left to infer that they need to provide more detailed explanations or examples, but the comment lacks the necessary evidence or reasoning to be 5. Therefore, the comment is categorized as 2, as it provides some justification but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. While the comment highlights important areas for clarification and expansion, it does not provide specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or examples, but the feedback lacks actionable steps. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or analysis regarding the behavior of negative chips and the potential impact of the alternating process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the behavior of negative chips and the potential impact of the alternating process. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also inquires whether this alternating process could help improve performance. This feedback is 3 as it prompts the authors to clarify their methodology and potentially explore avenues for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or improve their work. Overall, the comment offers a starting point for the authors to consider, but it lacks depth and actionable guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide specific guidance on how to do so or what aspects of the evaluation should be prioritized. The action is implicit and somewhat vague, as the authors need to infer the details of the evaluation themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as a specific section or experiment. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for an evaluation on new and old patients, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a relevant and actionable suggestion. It highlights the importance of considering both types of patients to ensure the robustness and generalizability of the approach. However, the comment could be more helpful if it provided specific guidance on how to conduct this evaluation, such as which metrics or criteria to use or how to differentiate between the two patient groups. Despite this, the feedback is 4 as it directs the authors to an important area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights an issue with the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use this dataset in their training. The reviewer questions whether 300WLP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This comment implies that the authors should clarify the use of the 300WLP dataset in their experiments and address the potential bias. However, it does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to clarify the dataset usage, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental methodology, specifically the use of the 300WLP dataset. It also specifies the issue by questioning whether the dataset is used in all experiments or just some, and whether it provides an unfair advantage to the proposed method. This level of detail allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly outlines the concern about the dataset usage and its potential impact on the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset. The reviewer notes that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. The reviewer also questions whether 300WLP is used in all experiments or just some, suggesting that this could provide an unfair advantage to the proposed method. This claim is 3 as it highlights a potential issue with the experimental setup, but it lacks specific examples or references to support the claim that the use of 300WLP provides an unfair advantage. The authors would need to further investigate and address this concern to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. This raises a concern about whether the use of 300WLP provides an unfair advantage to the proposed method. The comment questions whether 300WLP is used in all experiments or just some, which is a crucial piece of information for the authors to clarify. This feedback is clear and actionable, as it directs the authors to address the potential bias in their experimental setup. However, it could be more helpful if it provided specific guidance on how to address this issue or suggested ways to mitigate the potential bias. Overall, the comment is 4 as it highlights a critical area for improvement in the experimental methodology."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the technique should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying potential issues with the novelty of the technique, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any evidence, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. While it identifies a potential weakness in the novelty of the algorithm, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the novelty of their work. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path forward. Therefore, the comment is 2, as it points out a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It also points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their assumptions about the observations and their aggregation process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the integral in Equation (1)\" and references specific works, \"Law et al., NeurIPS\"18\" and \"4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to the bag observation model in Law et al., NeurIPS\"18 or the spatial aggregation process in 4. The reviewer provides references to these works, which supports the claim by referencing established models and processes. However, the comment lacks detailed explanation or analysis of how these references relate to the integral in Equation (1) or the authors\" formulation. While the references provide some context, the comment could be strengthened by further elaboration on the implications of these references for the authors\" work. Therefore, the comment is 3, as it provides some support but lacks detailed justification or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. The comment provides a clear and actionable suggestion for the authors to reconsider their assumptions about the observations and their aggregation process. However, it could be more helpful if it offered specific guidance on how the authors might address this issue or what alternative aggregation methods might be considered. Overall, the comment is 4 as it highlights a critical area for improvement and provides a direction for the authors to explore."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks indepth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. This feedback is clear and provides a direct action for the authors to take, which is to include an analysis of the training dynamics. The comment is specific in its request for an explanation, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of indepth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely an explanation of the training dynamics. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks indepth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of indepth analysis and suggesting that the authors provide an explanation for the observed inverse scaling over compute. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened by including a deeper analysis. However, the comment could be more helpful if it provided examples or suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of mathematical definition for certain architectural details, specifically mentioning multihead attention. It also questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer implies that a formal definition would be beneficial for readers to understand the architecture. While the comment does not explicitly instruct the authors to provide a formal definition, it clearly points out areas where clarification is needed. The action is implicit but concrete, as the authors can infer that they need to provide a formal definition or clarification in these areas. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"multihead attention,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of mathematical definition for architectural details like multihead attention and the purpose of the split arrow in Figure 2. The comment provides a clear request for a formal definition to help readers understand the architecture, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of mathematical definition for certain architectural details, specifically mentioning multihead attention. It questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer assumes that these are the inputs for the attention layer, namely query, keys, and values. The comment suggests that a formal definition would be beneficial for readers to understand the architecture. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the lack of mathematical definition is problematic. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of mathematical definition for certain architectural details, such as multihead attention. It questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer, specifically query, keys, and values. The reviewer assumes these to be the inputs and questions whether the same vectors are used for keys and values. The comment suggests that a formal definition of these concepts would greatly help readers understand the architecture. While the comment highlights an important area for clarification, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a clear understanding of the problem but may need to infer the exact steps to take to improve their draft. Therefore, the comment is 3, as it identifies a critical area for clarification but lacks detailed guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. While the comment implies that the authors should modify their experimental setup, it does not provide explicit instructions on how to implement this change or what specific tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or the discussion of the results. The authors can infer that it relates to the latter part, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes that tasks could be made more complex to test the policy\"s adaptability. However, the comment lacks specific examples or references to support this claim or to justify why the current setting is insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. This feedback is 3 as it identifies a potential area for improvement in the experimental setup. However, the comment lacks specific guidance on which tasks to consider or how to implement this change. Additionally, it does not provide detailed reasoning or examples to support the claim that tasks need to be more complex. While the suggestion is 3, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the comprehensiveness of the experimental analyses and the method itself, noting that the focus is primarily on the presentation of results. It suggests that the authors should provide more detailed analyses of the method and its performance, particularly in light of the baseline\"s underperformance. While the comment implies that the authors should include more detailed analyses, it does not specify exactly what aspects need to be addressed or how to conduct these analyses. The action is implicit and somewhat vague, as the authors need to infer the specific details of what is expected. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"majority of the experiments\" and the \"analyses of the method itself and the experimental outcomes,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the analyses are not comprehensive enough and questioning the extent to which the performance improvement can be attributed to the authors\" claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiments focus on the presentation of results and that the analyses of the method and experimental outcomes are not comprehensive enough. It suggests that the authors\" method underperforms the baseline in some instances, which raises questions about the extent to which the performance improvement can be attributed to the authors\" claim. The comment provides some logical reasoning by pointing out the potential limitations of the method and its claims, but it lacks specific examples or references to support the claim about the baseline performance. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the majority of the experiments focus on the presentation of results rather than comprehensive analyses of the method and experimental outcomes. It highlights the potential underperformance of the authors\" method compared to the baseline and questions the extent to which the performance improvement can be attributed to the authors\" claim. This feedback is valuable as it points out a critical area for improvement in the paper, namely the depth and comprehensiveness of the experimental analyses. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as which aspects of the method or results should be further explored or explained. Overall, the comment is 3 as it directs the authors\" attention to a critical area for improvement, but it lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to broaden the scope of the paper or what specific aspects of multitask models should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the multitask models are problematic or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper\"s focus on multitask models limits its applicability. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper\"s focus on multitask models limits its applicability, which is a valid point. However, it does not provide any specific suggestions or guidance on how the authors might broaden the scope of their work or address this limitation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the literature review ignores several relevant papers, specifically mentioning 1 and 2. It suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the current work. The reviewer provides a specific question about the Assumption 2 and the rate of QSGD in the stochastic regime, implying that the authors should consider these papers for further analysis. While the comment does not explicitly instruct the authors to include these papers, the action is implicit and concrete, as it clearly points out the need for additional analysis and provides a specific direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section\" and \"Literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of relevant papers, 1 and 2, and suggests that VRMARINA and DASHAMVR could be relevant to the current work. The comment provides a clear direction for the authors to consider these papers and address the Assumption 2 and QSGD rate in the stochastic regime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning 1 and 2. The reviewer provides a specific example of VRMARINA and DASHAMVR, which are mentioned in these papers, and suggests that they could be relevant to the current work. The reviewer also provides a question about the Assumption 2 and the rate of QSGD in the stochastic regime, which adds a logical basis to the claim. However, the comment lacks specific references to these papers or detailed analysis of their relevance, making it 3. The authors would need to follow up on the references to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the literature review, noting that it ignores several relevant papers. It specifically mentions 1 and 2, which are believed to be relevant to the current work. The reviewer suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it provides specific guidance on which papers to consider and how they might impact the current work. By addressing these points, the authors can significantly enhance the rigor and comprehensiveness of their literature review. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how to improve the presentation or what aspects are particularly challenging to understand. Without concrete advice or examples, the authors are left without a clear understanding of what changes need to be made to enhance the clarity of their draft. As a result, the comment lacks actionability, leaving the authors without direction on how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is hard to follow, but it does not specify which part of the paper is particularly challenging or where the presentation lacks clarity. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need improvement. Additionally, the comment does not provide specific guidance on how to enhance the clarity of the presentation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation of the paper is hard to follow. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or justification, the authors are left without a clear understanding of what aspects of the presentation are problematic or how they could be improved. As a result, the claim is 1, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment states that the presentation of the paper is hard to follow, but it does not provide any specific details or suggestions on how to improve the clarity or organization of the paper. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the presentation need attention or how to enhance the readability. This lack of specificity and direction makes the comment 2, as it provides some insight but not enough to be fully beneficial for the authors. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: whether the authors have any additional insights into modest performance gains on Clothing1M and how the algorithm performs on other realworld datasets like WebVision, evaluated by DivideMix. While these questions imply that the authors should provide additional information or analysis, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights or data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions about the performance of the algorithm on Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for additional insights or performance evaluations on specific datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could help the authors gain additional insights into the performance of their algorithm on realworld datasets. By asking about modest performance gains on Clothing1M and the algorithm\"s performance on WebVision, evaluated by DivideMix, the reviewer encourages the authors to provide more detailed evaluations and comparisons. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional insights would be beneficial. While it points out areas for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies potential areas for enhancement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct additional experiments on different LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. While the comment implies that more experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments but are not given specific details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on different LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results discussion. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific LLMs are necessary or how they would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the experimental setup by suggesting that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. This feedback is 3 as it points out an area where the authors could enhance their work by including additional comparisons. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects to focus on, such as the impact of different LLMs on the results. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper, noting that it does not describe the hyperparameters used by each defense nor how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to include this information, but the lack of concrete guidance on how to do so makes the action implicit. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding the hyperparameters used by each defense and how those hyperparameters are derived. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the need for a maximally charitable evaluation of defenses that optimizes hyperparameters against the attack and demonstrates how much clean data is required to remove the attack. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim that such an evaluation is necessary or how it would be conducted. This makes the claim 3, as the authors would need to infer the importance and relevance of this suggestion on their own. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by including this information. However, the comment could be more helpful if it offered examples of how such an evaluation might be conducted or what specific hyperparameters should be considered. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear path for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the theoretical results do not have immediate practical implications, but acknowledges that this is understandable given the novelty of the work. It also expresses a desire for more practical takeaways for practitioners, specifically mentioning the idea of querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate this suggestion or what specific aspects of the paper should be revised to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should focus on making their results more practical and actionable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the paper could provide more practical takeaways for practitioners. It mentions a specific takeaway point regarding querying a cluster proportionally to the square root of its size, but does not specify which part of the paper this relates to. The authors can infer that it pertains to the theoretical results or methodology sections, but this inference is not direct. The comment is specific in its suggestion for practical applications but lacks grounding as it does not explicitly mention which part of the paper it addresses. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results do not have immediate practical implications, which is 3. The reviewer acknowledges the novelty of the work but suggests that more practical takeaways should be provided. The comment provides a specific example of a takeaway point, which is the querying of a cluster proportionally to the square root of its size. However, the reviewer does not provide a detailed explanation or evidence to support why this takeaway point is not novel or how it could be improved. The lack of detailed justification or references makes the claim 3, as it provides some support but not enough to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the theoretical results do not have immediate practical implications. It acknowledges the novelty of the work but suggests that more practical takeaways should be provided for practitioners. The comment provides a specific example of a takeaway point, which is the querying of a cluster proportionally to the square root of its size. However, it does not clarify whether this finding is novel or how it could be further developed. While the comment highlights an area for improvement, it lacks detailed guidance or suggestions on how to address the issue. Therefore, it is 3, as it points out a potential weakness but does not provide actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. While the comment identifies an area for clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The authors are left to infer that they need to provide more information or explanation, but the comment lacks concrete guidance on what specific details should be included. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of separators and asking for additional information on what they contribute beyond T/I/O. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This is a request for clarification and does not make a subjective claim or express an opinion. It is a factual inquiry seeking more information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This feedback is 3 as it identifies a potential gap in the paper that needs clarification. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information should be provided. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. While it implies that the authors should consider alternative approaches, it does not explicitly instruct them to do so or provide specific guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative pooling strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. It does not present an opinion, judgment, or suggestion that requires verification. It is a request for clarification and does not contain subjective claims or assertions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This is a thoughtprovoking observation that could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific guidance or suggestions on how to explore alternative pooling strategies or what specific aspects of mean pooling should be questioned. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison of the real search cost in terms of GPU days. The comment is specific and actionable, giving the authors a direct and concrete step to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a comparison of the real search cost in terms of GPU days. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback is 3 as it identifies a potential area for improvement in the presentation of data, which could provide a more comprehensive view of the system\"s performance. However, the comment lacks depth and does not explain why this comparison is important or how it would enhance the understanding of the system\"s performance. To be more helpful, the comment could provide additional context or examples to support the suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VQGAN\" and \"Computer Vision Figures dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training details of the VQGAN, specifically whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, particularly inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. This question highlights a potential gap in the paper that could impact the reader\"s understanding of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include works such as  Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and compare them to their work conceptually. Additionally, it recommends discussing how their work differs from other chatbox research works, such as  He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). These suggestions provide clear and explicit actions for the authors to take, including identifying relevant works and discussing their differences. The comment is concrete and provides specific guidance on how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests including works such as  Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discussing how their work differs from other chatbox research works, such as  He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of these works and the need for a discussion on differences, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include specific works, such as  Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and  He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. The comment also recommends discussing how their work differs from other chatbox research works. While the suggestion is based on logical reasoning and common knowledge about relevant works, it lacks specific examples or detailed justification for why these works are important or how they differ from others. This makes the claim 3, as it provides a direction for improvement but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include relevant works, such as  Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and  He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. It also recommends discussing how their work differs from other chatbox research works. This feedback is 4 as it guides the authors on how to enhance their draft by incorporating relevant references and providing a more comprehensive discussion of their work. However, the comment could be more helpful if it included specific questions or suggestions for how to integrate these works into the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed methods, DualIS and DualDIS, in terms of their generic applicability on crossmodel retrieval tasks, specifically mentioning the minor improvements in MSVD (Table 3). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the generic applicability or suggestions for further experiments to explore. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS,\" allowing the authors to accurately identify the specific methods being discussed. It also specifies the issue by pointing out that the methods are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. However, the comment does not provide specific details or examples of these tasks or the performance improvements, making it difficult for the authors to understand the basis of the claim. The lack of detailed evidence or references to support the claim renders it 1. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed methods, DualIS and DualDIS, by pointing out that they are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This feedback is 3 as it highlights an area where the methods may not be as effective as expected, providing the authors with a specific issue to address. However, the comment could be more helpful if it offered suggestions on how to improve the generic applicability or provided examples of tasks where the methods performed poorly. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests that a simpler approach, such as running vanilla Adam on the final network with 40 random initial points, could achieve the same result. The comment implies that the authors should reconsider their experimental setup and potentially simplify it. However, it does not provide explicit instructions or concrete steps on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their experimental setup. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests that a simpler approach, such as running vanilla Adam on the final network with 40 random initial points, could achieve the same result. However, the comment does not specify which part of the paper this concern is related to, such as the experimental section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the experimental setup, suggesting a simpler alternative. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the experimental strengths of the approach, specifically the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests that a simpler approach, such as running vanilla Adam on the final network with 40 random initial points, could achieve the same result. This claim is 3 as it provides a logical reasoning for why the current approach might not be necessary, but it lacks specific examples or references to support the claim. The authors would need to further explore the implications and potential impact of this suggestion to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests that a simpler approach, such as running vanilla Adam on the final network with 40 random initial points, could achieve the same result. This feedback is 3 as it points out a potential weakness in the experimental setup and offers a suggestion for simplification. However, the comment could be more helpful if it provided additional context or justification for why the current approach is not as robust as suggested. Overall, the comment identifies a potential issue but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship or what specific steps to take to improve the study. As a result, the authors are left without any clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the study, namely the lack of establishment of the relationship between the top selected patches and the disease. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this relationship should be discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying the issue of incomplete study, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease is not yet established. This is a critical point that could impact the validity and reliability of the study. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or what steps they could take to establish this relationship. Without actionable advice or detailed feedback, the authors are left with a clear area for improvement but without a clear path forward. Therefore, the comment is 3, as it points out a critical weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a typographical error in the phrase \"for \"inbetween\" uncertainty\" by noting that the first quotation mark should be a forward mark rather than a backward mark. This is a clear and concrete action for the authors to take, as they are provided with specific guidance on how to correct the error. The comment is 5 as it directly instructs the authors on what to change to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the quotation marks, providing detailed guidance on how to correct the typographical error. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a typographical error in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific typographical error in the paper, noting that the first quotation mark in the phrase \"for \"inbetween\" uncertainty\" should be a forward mark rather than a backward mark. This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and readability of their draft. However, the comment does not provide any additional context or explanation about why this error is important or how it might impact the overall understanding of the paper. While it is helpful in pointing out a specific issue, it could be more beneficial if it included suggestions for how to ensure consistency in typography throughout the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the performance of FedSP in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting improvements or additional analyses. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of FedSP is not the best in these tables on some datasets. However, it does not provide detailed guidance on what specific aspects of FedSP are not performing well or how the authors might address this issue. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Tables 1 and 2 on some datasets. However, it does not provide any specific data, comparisons, or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance of FedSP in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve the performance. Without detailed guidance or examples, the comment does not help the authors understand what specific aspects of FedSP need improvement or how to improve them. Therefore, it is rated as 2, as it points out a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the clarity of certain aspects in the paper, specifically asking for more explicit information about Omega and the link function, as well as the theorem used for the regret guarantee. While the questions are clear, they do not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations or references, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but does not offer specific steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the clarity of certain elements, such as Omega, the link function, and the theorem used for the regret guarantee. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification about specific elements in the paper, such as Omega, the link function, and the theorem used for the regret guarantee. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved by requesting more explicit information about Omega and the link function, as well as the theorem used for the regret guarantee. By asking these questions, the reviewer highlights potential gaps in the paper that could be clarified to enhance the reader\"s understanding. However, the comment does not provide detailed guidance on how to address these issues or suggest specific ways to improve the clarity of the paper. While it points out areas for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. However, it does not provide any guidance or suggestions on how the authors should address this issue or improve their work. There is no explicit or implicit action for the authors to take, nor is there any indication of what the implications of this observation might be. As a result, the comment lacks actionability and does not provide any direction for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment mentions \"the models are learned directly from pixels without a Markovian state,\" which suggests that the models are not Markovian. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the models being learned directly from pixels without a Markovian state, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation or how it affects the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific aspect of the models being learned directly from pixels without a Markovian state, which could be a potential issue or limitation. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and explicit action. The comment is specific in identifying the need for references and provides a concrete direction for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"sequence example\" and \"Example 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the use of the Hamming distance over entire parts of the sequence as a scoring loss, which is a specific practice in the context of CRF. The comment suggests providing references for this approach, which is a clear and specific request for additional information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of the Hamming distance over entire parts of the sequence as a scoring loss in the context of CRF, suggesting that this is a \"common\" practice. The reviewer acknowledges that they are not familiar with this approach and asks for references to support it. While the comment identifies a potential gap in the paper\"s explanation, it lacks specific references or examples to substantiate the claim that this is a \"common\" practice. This makes the claim 3, as the authors would need to make an effort to find and integrate references to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and actionable suggestion. By addressing this point, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided specific references or examples of works that use this approach. Overall, the comment is 4 as it identifies a potential gap in the paper and offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment provides a clear action to take, it lacks specific guidance on how to implement these changes or what specific metrics should be included. The authors are given a general direction but may need to infer the details of execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation or metrics sections. The suggestion to change the name and mention metrics is specific, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also recommends mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the claim that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are wellknown and used as standard practice. However, the comment lacks specific examples or references to support the claim that the metrics are wellknown and standard practice. This makes the claim 3, as the authors would need to infer the reasoning behind the suggestion themselves.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to change the name of the \"Evaluation\" element to \"Metrics,\" which is a clear and concise improvement. It also recommends removing the corresponding sections and mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the rationale that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are wellknown and used as standard practice. By making these changes, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided examples of specific metrics to include or explained why these changes would enhance the paper\"s clarity. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it does not provide specific guidance on how to do this or what aspects of the dataset should be highlighted or discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their exploration of the dataset but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper should have more exploration or what aspects of the dataset should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this exploration is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to effectively integrate the dataset into the paper. The comment does not provide actionable steps or examples of what aspects of the dataset should be explored or how it could enhance the paper. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. While the comment provides a specific suggestion to use more objective terms, it does not offer concrete guidance on what terms to use or how to present the improvement in a more objective manner. The action is implicit and somewhat vague, as the authors need to infer the specific terms to use and the exact way to present the improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"axes\" and \"squished,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement and points out that the axes are squished, making it difficult to characterize the improvement as remarkable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"remarkable\" is subjective and that the axes are squished, making it difficult to characterize the accuracy improvement as remarkable. However, the comment does not provide any supporting evidence, reasoning, or references to justify why \"remarkable\" is inappropriate or how the squished axes affect the interpretation of the improvement. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. This feedback is actionable and constructive, as it offers a clear direction for the authors to improve the clarity and precision of their language. By addressing these points, the authors can enhance the credibility and objectivity of their claims. However, the comment could be more helpful if it provided examples of alternative, objective terms to use or explained why \"remarkable\" is not appropriate. Overall, the comment is 4 as it offers clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could benefit from using longer video sequences, such as 16 frames, to address issues with inconsistent motion, changing color, or object disappearing over time. It also mentions that running the LSTM over many time steps could be interesting. While the comment implies that the authors should consider these changes, it does not provide explicit instructions or concrete steps on how to implement them. The authors are left to infer the actions needed to improve their draft, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the synthesized results for UCF101, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with inconsistent motion, changing color, or object disappearing over time and suggests using longer video sequences. Additionally, it provides a positive assessment of the paper, noting its interesting idea and extensive experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes a claim about the synthesized results for UCF101, suggesting that the problem of inconsistent motion, changing color, or object disappearing over time could be addressed by using longer video sequences. The reviewer provides a specific example of the issue in the synthesized results, which adds some level of verifiability to the claim. However, the comment lacks detailed reasoning or references to support the claim fully. The suggestion to use longer video sequences is logical, but the lack of specific examples or detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a positive assessment of the paper, noting its interesting idea and extensive experiments. It also identifies a specific issue with the synthesized results for UCF101, noting inconsistent motion, changing color, or object disappearing over time. The reviewer suggests that using longer video sequences could address these issues. While the comment highlights a potential area for improvement, it lacks detailed guidance or suggestions on how to implement this change. The feedback is 3 as it points out a specific problem and offers a direction for improvement, but it could be more actionable with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment states a fact about the limitations of pruning techniques on GPUs, which is not an actionable statement. It does not provide any guidance or suggestions for the authors to address this issue or improve their draft. As a result, the comment lacks actionability and is not helpful for the authors to make any changes to their work. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses. It is a general statement about the limitations of pruning techniques on GPUs, which does not provide any context or reference to a specific section, table, or figure in the paper. As a result, the comment is 1 and lacks specificity, making it difficult for the authors to understand what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point states a fact about the limitations of pruning techniques on GPUs, which is a general observation. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is a factual statement and should be labeled as \"No.\"", "helpfulness_rationale": "The comment provides a factual observation about the limitations of pruning techniques on GPUs, which is relevant but not actionable. It does not offer any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive criticism, the comment does not help the authors improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with 5 being unfair because 5 is designed for a more complex problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the evaluation. The comment lacks actionable details, such as suggesting alternative evaluation methods or providing specific examples of how the comparison could be improved. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the numerical evaluation and the comparison with 5, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the complexity of the problem. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the unfair comparison with 5, which is designed for a more complex problem. The comment provides a logical reasoning by explaining that the comparison is not fair because 5 does not require knowledge of camera pose parameters. However, the comment lacks specific examples or references to support the claim that the comparison is unfair or how it affects the validity of the evaluation. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the complexity of the problem. This feedback is valuable as it highlights a potential weakness in the paper\"s evaluation, which could impact the credibility of the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending alternative evaluation methods or suggesting ways to improve the comparison with 5. Despite this, the comment still offers a clear direction for the authors to improve their draft, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this experiment to strengthen their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"PGD attack\" and the \"32bit logit,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of the effect of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. This provides clear guidance on what the authors should consider in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack. The reviewer suggests that intuition suggests that having a 32bit logit should improve robustness against a more powerful adversary. However, the comment lacks specific evidence or references to support this claim, making it 3. The authors would need to make a logical inference to understand the basis of the suggestion, which is not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the study of numbers of bits in logits and their effect on robustness against a larger epsilon in the PGD attack. It suggests that intuition suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to conduct this experiment or what specific aspects to focus on. The feedback is 3 as it points out a potential area for enhancement, but it lacks actionable details that would fully support the authors in making improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the impact of the method on insurance payments for men and women. While it does not explicitly instruct the authors to provide this information, the question implies that the authors should include this analysis in their paper. The action is implicit but concrete, as the authors can infer that they need to include this information to address the reviewer\"s concern. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment poses a question about the impact of the method on insurance payments for men and women, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this question should be addressed. Additionally, the comment lacks specificity regarding what aspects of the insurance payments should be analyzed or how the method affects them. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the impact of the method on insurance payments for men and women. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a specific question about the impact of the method on insurance payments for men and women. This question highlights a potential area for further analysis and provides a clear direction for the authors to consider. However, the comment does not offer any suggestions or guidance on how to address this question or what specific aspects of the insurance payments should be analyzed. While it identifies a potential gap in the paper, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to Foester et al. (NIPS 2016) as an example. This provides a clear and concrete action for the authors to take, as they are given a specific area to address and a reference to guide their understanding. The comment is 5 as it directly tells the authors what to do and provides a concrete example to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta solvers\" and the \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL, and provides a reference to Foester et al. (NIPS 2016) to guide the authors in their understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers, and suggests that the authors should clarify the difference between them and centralized RL. The reviewer provides a reference to Foester et al. (NIPS 2016) to support this claim. However, the comment lacks detailed explanation or analysis of why the meta solvers are considered centralized controllers, which would help the authors understand the basis of the claim. The reference to Foester et al. provides some support, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is 3, as it provides a starting point for the authors to explore but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the classification of the meta solvers as centralized controllers. It suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al. (NIPS 2016) as an example of centralized RL, which is a clear and actionable suggestion for the authors to consider. This feedback is 4 as it guides the authors to clarify a key aspect of their work, which could enhance the understanding and clarity of their paper. However, it could be more helpful if it included additional details or examples on how the authors might address this issue. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October, suggesting that the authors should consider this issue in their paper. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the availability of papers on arxiv. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of splitting papers according to their publication years on the ACL anthology, noting that many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October. However, the comment does not specify which part of the paper discusses the splitting of papers, making it weakly grounded. The comment is specific in pointing out the issue of papers being available on arxiv before being published in the ACL anthology. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. The reviewer provides an example of the BERT paper being available on arxiv in October, which supports the claim. However, the comment could be strengthened by providing more examples or detailed reasoning on why this issue is significant. As it stands, the claim is 3, as it relies on a specific example but lacks comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s methodology, noting that it splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. This is a relevant observation that could impact the paper\"s credibility and relevance. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential problem, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for consideration but does not offer detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should consider providing examples to explain the concept of M_T, which is defined over the probabilities of atomic events. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific in its request for examples, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of M_T and the notation used, and suggests providing examples to clarify the concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of M_T is over the probabilities of atomic events and that the notation is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of M_T, noting that it is defined over the probabilities of atomic events and that the notation is not clear. It suggests that the authors consider providing examples to clarify this concept. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to present these examples or what specific aspects should be explained. This limits the comment\"s helpfulness, as it points out an issue but does not fully support the authors in addressing it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two concerns: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to clarify the use of \u03b2 and the difference between QRS and RS, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the proposed relaxation of rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. The comment provides a clear direction for improvement by suggesting that the authors clarify the use of \u03b2 and the difference between QRS and RS. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the use of an arbitrary parameter \u03b2 in rejection sampling and questions the lack of clarity regarding the difference between QRS and RS in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should have used Importance sampling instead of rejection sampling. Additionally, the comment lacks specific examples or detailed explanations to support the claim about the difference between QRS and RS. As a result, the claim is not verifiable, making it difficult for the authors to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the observed performance enhancements are modest and implies that there is room for further refinement in the future. However, it does not provide specific guidance on how to achieve this refinement or what aspects of the work need improvement. The action is implicit and vague, as the authors are left to infer that they need to make improvements but without clear direction on what those improvements should be. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, such as specific experiments or results. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the work need refinement or how to achieve this refinement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation and how it relates to their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work need improvement. Without actionable advice or detailed feedback, the authors are left with a general observation without clear direction for improvement. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity to be fully beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230234 and 234235, and to clarify what \"MLP\" refers to in Figure 2. These are clear and direct actions that the authors can take to improve their draft. Additionally, the comment highlights a missing reference, which is also actionable. The feedback is specific and provides concrete guidance on what needs to be added or clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in Section 3.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for references for two passages and clarifies what \"MLP\" refers to in Figure 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of requests for references and clarifications, which are factual in nature and do not contain subjective claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying specific lines in Section 3.2 that lack references and clarifying what \"MLP\" refers to in Figure 2. This guidance is clear and directs the authors to specific areas that need attention, ensuring that the paper is wellreferenced and accurate. Additionally, the comment highlights a missing reference, which is important for the paper\"s completeness. Overall, the comment is 5 as it offers concrete steps for the authors to improve their draft, making it fully comprehensive and beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the cause of this similarity. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the experimental results or what specific aspects of the method need to be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, specifically mentioning the performance being similar to IRM. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the experimental results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method. However, it does not provide any specific reasoning or evidence to support this claim. The mention of \"IRM\" suggests that the reviewer believes the performance is similar to a known method, but this alone is not enough to substantiate the claim. Without further explanation or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their experimental results. Without detailed guidance or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment implies that the authors should provide a clearer explanation or rationale for this distinction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of detecting both entities in the example and asking for clarification on the difference between detecting both entities and just detecting the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment identifies a potential area of confusion or misunderstanding in the paper, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a vague understanding of what needs to be clarified, which limits the comment\"s helpfulness. Therefore, the comment is 3, as it points out a potential area for improvement but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is no empirical validation and suggests including experiments to validate the bounds. This provides a clear and direct action for the authors to take, which is to conduct experiments to validate the bounds. The comment is specific in its request for empirical validation and offers a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of empirical validation, which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of experiments to validate the bounds. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is no empirical validation and suggests including experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical validation for the bounds. It suggests that including experiments to validate the bounds would be beneficial. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of empirical validation. However, the comment could be more helpful if it offered examples of what types of experiments might be appropriate or how to design them. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. However, it does not provide any explicit guidance or suggestions on how the authors should address this confusion or clarify their terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider their terminology. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \"nonsequential information such as chunks,\" suggesting that the term \"chunks\" might be considered sequential information. This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the phrase \"nonsequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. This question highlights a potential confusion in the paper that could be clarified to improve the clarity and coherence of the text. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their terminology. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a discrepancy between equation 9 and figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it or what specific changes should be made to the figure or the methodology. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the figure and possibly use bilinear sampling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions, and suggesting that bilinear sampling might provide better results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The reviewer suggests that the figure is misleading and proposes an alternative method, bilinear sampling, as a potential solution. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the misleading nature of Figure 1. The suggestion to use bilinear sampling is based on logical reasoning but could be strengthened with more detailed justification or references. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a discrepancy between equation 9 and Figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. This feedback is 3 as it points out a potential issue with the figure and provides a suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to address the discrepancy or why bilinear sampling might be a better approach. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the upper bound in Theorem 1, which is assumed to be 0 for a separate node with 0 neighbors. The reviewer seeks clarification on how to explain this exception. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the theorem. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification or explanation for the exception, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound in Theorem 1 and seeks clarification on how to explain an exception involving a separate node with 0 neighbors. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the upper bound in Theorem 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the upper bound in Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. This is a relevant point that could lead to a clarification or correction in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what changes might be necessary. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). It suggests that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous papers. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to enhance the novelty of their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and comparing the paper to the mentioned papers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The comment provides a specific comparison with the papers, noting that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous works. This comparison provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific sections of the papers that support the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it lacks technical novelty and is similar to two mentioned papers (Xing and Tsang, 2022a, b). It provides a specific comparison with the papers, highlighting the similarities in the idea, coattention mechanism, and architecture. This feedback is 3 as it points out an area where the paper could be improved by differentiating itself from existing work. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the novelty of their work. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. It suggests that this observation should be revised or deleted from the discussion. However, the comment does not provide explicit instructions on how to revise or delete the content. The action is implicit and somewhat vague, as the authors need to infer that they should revise or delete the content. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific observation about the training time reduction and suggests that it should be revised or deleted from the discussion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation about the training time reduction being less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. It points out that this observation is not revisited in the discussion, suggesting that it should be addressed or deleted. This feedback is 3 as it highlights an area where the authors may need to clarify or revise their discussion. However, the comment lacks depth and does not provide specific guidance on how to address the issue or what aspects of the discussion should be revised. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the problem being discussed is specific to binding affinity prediction or applies to other downstream tasks. It implies that the authors should provide a justification for why the problem is specific to binding affinity prediction. However, the comment does not explicitly instruct the authors to provide this justification or specify how it should be presented. While the action is implied, it is not concrete, as the authors are left to infer what additional information is needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem to other downstream tasks or whether it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a justification or explanation of why the problem is specific to binding affinity prediction. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. This is a relevant point that could prompt the authors to clarify the scope and limitations of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific analyses or solutions could be proposed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the handling of rumors generated by GPT, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the need for further analysis or solutions regarding the challenges of detecting rumors generated by GPT, and it questions the rationale behind why GPTgenerated rumors are similar to natural rumors. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It suggests that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. The comment provides a logical reasoning by questioning the experimental result and suggesting that the rationale might be flawed. However, it lacks specific examples or references to support the claim that GPTgenerated rumors are easier to detect than natural rumors. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further analysis or solutions, namely the handling of rumors generated by GPT. It questions the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect, suggesting that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor. The comment highlights a gap in the paper that could be addressed with additional analysis or suggestions for improvement. However, it does not provide specific guidance or examples on how the authors might address this issue or what kind of analysis could be conducted. While it points out an important area for further exploration, the comment lacks actionable advice, making it 3 but not comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, stating that it is limited and not about a formal and principled solution but rather about heuristics. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution of the paper, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. This feedback highlights an area where the paper could be improved by providing a more comprehensive and rigorous approach to the technical contribution. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the heuristics should be improved. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and concrete, as it instructs the authors to adjust the font size to make it more readable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a factual observation about the font size in Figure 6 being too small. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the font size in Figure 6, noting that it is too small. While this feedback is clear and actionable, it does not provide any context or explanation as to why the font size is important or how it affects the overall presentation of the figure. Additionally, it does not offer suggestions on how to address this issue, such as recommending a specific font size or discussing the impact of font size on readability. Despite these limitations, the comment is 3 as it directs the authors to a specific area for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the probability mass function (PMF) is not being fully utilized in the experimental setting and recommends considering various PMFs for each learner class. It also mentions that the quasiuniform distribution used in MixBoost is dependent on a single parameter and suggests that individual consideration of each learner class would add depth to the experimental setting. However, the comment does not provide specific guidance on how to implement this suggestion or which PMFs to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"probability mass function\" and the \"MixBoost\" setting, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the use of a quasiuniform distribution and suggests considering various probability mass functions for each learner class. This provides clear guidance on what needs to be addressed in the experimental setting. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the probability mass function is not being fully utilized in the experimental setting, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that a quasiuniform distribution is not ideal. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setting, noting that the probability mass function is not being fully utilized in the MixBoost setting. It suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. While the comment highlights a potential area for improvement, it lacks specific guidance on how to implement this suggestion or which probability mass functions to consider. The feedback is 3 as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this issue, provide additional context, or clarify their methodology. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how the authors should address this concern. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment raises a valid question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. This is an important point that could impact the interpretation and comparison of results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss connections with a specific reference, a, which uses supervised learning in QBF solving. It also mentions that QBF generalizes SMT. While the comment provides a clear action to take, it does not offer specific guidance on how to integrate this discussion into the paper or what aspects of the reference are particularly relevant. The authors are given a direct action to take but may need to infer the exact steps to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the connections with a, which uses supervised learning in QBF solving, and how QBF generalizes SMT. This level of detail provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper is missing relevant references, specifically mentioning a, which uses supervised learning in QBF solving. The reviewer claims that this reference is relevant to the paper\"s topic, especially since QBF generalizes SMT. However, the comment does not provide specific reasoning or evidence to support why a is particularly relevant or how it relates to the paper\"s content. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the absence of relevant references, particularly a, which uses supervised learning in QBF solving. It suggests that discussing connections with a could be beneficial, as QBF generalizes SMT. This feedback is clear and actionable, as it directs the authors to consider incorporating this reference and its potential implications for their work. However, the comment could be more helpful if it provided additional guidance on how to integrate the reference or what specific aspects of the reference are relevant to the paper. Overall, the comment is 4 as it highlights a relevant reference and suggests a potential area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It also suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide specific guidance on how to do so or what specific alternative relationships to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the comment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training process and the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests considering alternative relationships and provides a reference to a related work for further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss is replaced by other relationships. The reviewer supports this claim by referencing a related work, Navon et al. (2020), which explores learning the Pareto Front with Hypernetworks. This reference provides a basis for the claim, suggesting that the authors should consider alternative relationships. However, the comment could be strengthened by providing more detailed reasoning or examples of how the alternative relationships might be explored. Overall, the claim is 4, as it is supported by a reference but could be further developed with additional justification or examples.", "helpfulness_rationale": "The review comment identifies a specific aspect of the training process that could be improved by considering alternative relationships between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that the mono tonic relationship might be replaced by other relationships, which could lead to a continuous parameterization of the Pareto Front. The comment also references a related work by Navon et al. (2020) to provide context and support for the suggestion. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific guidance on how to explore alternative relationships or how to incorporate this insight into the paper. Overall, the comment is 4 as it provides a valuable suggestion for enhancing the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what aspects of the computation cost or running time should be compared, nor are there suggestions for how to present this information or what specific insights should be drawn from it. As a result, the authors are left without any clear direction on how to address this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment poses a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost or running time should be compared or how this comparison should be presented. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time, but it does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the comparison in terms of computation cost or running time, which could be an important aspect of the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison should be considered. Without actionable feedback or context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a specific suggestion for improvement, it lacks concrete guidance on how to implement this change or what specific aspects of the paper need to be revised to address this issue. The authors are left with a general idea of what to do but without detailed instructions on how to execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, suggesting that the examples chosen do not convincingly demonstrate the need for interprocess communication and recommending a focus on problems where the loss function does not decompose as the sum of sample losses. The comment provides a clear direction for improvement by suggesting a focus on Hogwild and other ERMbased distributed algorithms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples chosen in the paper do not convincingly demonstrate the need for interprocess communication, particularly in the second paragraph where samplingbased Bayesian methods are mentioned. The reviewer suggests that the paper\"s results are irrelevant in this context and recommends focusing on problems where the loss function does not decompose as the sum of sample losses. The comment provides a logical reasoning for the claim by pointing out that the paper\"s results are not relevant to the context of interprocess communication. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the context and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This feedback is specific and offers a concrete direction for the authors to enhance their paper by addressing a potential weakness in the introduction. By suggesting a specific area of focus, the comment empowers the authors to make a meaningful change to their draft. However, it could be more helpful if it provided additional context or examples of how the authors might apply this suggestion to their work. Overall, the comment is 4 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address these concerns or improve the paper in response. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the privacy preservation issue and the example of traffic signal control, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate these claims. Without detailed justification or examples, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. While the comment identifies a potential weakness in the paper\"s argument, it lacks specific guidance or suggestions on how the authors might address this issue or improve the paper. The feedback is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of fairness in the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pretraining module. It suggests that to ensure fairness, the authors should compare CPEF with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design of CPEF. This feedback provides a clear and explicit action for the authors to take, specifying which model to compare and why. The suggestion is concrete, as it directly instructs the authors on how to improve the fairness and clarity of their comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of fairness in the comparison between CPEF and PMEF. The comment suggests that the authors should compare CPEF with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design of CPEF. This provides clear guidance on how to improve the fairness and clarity of the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF is unfair due to the lack of a pretraining module in PMEF. The reviewer suggests that a fair comparison would involve comparing CPEF with another pretrained model, such as ExpertBert, to highlight the advantage of the innovative pretraining module design of CPEF. This claim is 3 as it provides a logical reasoning for the need for a fair comparison, but it lacks specific examples or references to support the claim that PMEF lacks a pretraining module. The suggestion to compare CPEF with ExpertBert is a helpful addition, but the overall claim could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It points out that PMEF lacks a pretraining module, which makes the comparison unfair. The reviewer provides a clear and actionable suggestion by recommending that the authors compare CPEF with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design of CPEF. This feedback is 5 as it guides the authors on how to improve the fairness and clarity of their comparison, ensuring that the advantages of CPEF are accurately demonstrated. By addressing this issue, the authors can significantly enhance the robustness and credibility of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and fix the hyperlinks. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hyperlinks for footnotes 3 and 4 do not work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address to improve the quality of their draft. By pointing out this issue, the reviewer helps the authors ensure that their paper is presented professionally and accurately. However, the comment could be more helpful if it provided additional guidance on how to verify and fix the hyperlinks. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is explicit and provides concrete details on what changes need to be made, making it 5. The authors know exactly what needs to be revised to improve the clarity of their discussion.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This provides full grounding as it explicitly mentions the sections and elements being addressed, allowing the authors to identify and address the issues. The comment is specific in detailing what needs to be revised, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples of areas that need improvement, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This feedback is 4 as it provides logical reasoning and specific examples to support the claim. However, it could be strengthened by referencing external works or providing more detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the clarity of the discussion in the modeling section. It suggests revising the architecture section to better formalize the architecture and clarify the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is 5 as it guides the authors on how to improve the clarity and accuracy of their discussion, which is crucial for effective communication of their work. By addressing these points, the authors can significantly enhance the comprehensibility and impact of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph that clarifies it. While the comment provides a specific suggestion to improve the clarity of the section, it does not offer detailed guidance on how to achieve this clarity or what specific changes should be made to the description. The action is implicit and somewhat vague, as the authors need to infer that they should start the section with the clarifying paragraph. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, suggesting that it is hard to understand and recommending starting the section with the final paragraph that clarifies it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand and suggests starting the section with the final paragraph that clarifies it. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand. It suggests starting the section with the final paragraph that clarifies the description, which provides a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to improve the clarity of the description or provided examples of what aspects are difficult to understand. Overall, the comment is 3 as it points out a specific area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it implies that the authors should consider this option, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not specify which part of the paper this limitation or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an alternative approach, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not provide any supporting evidence, reasoning, or references to justify why the current approach is limited or how attentionbased training might improve it. Without such information, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples on how to implement this change or what benefits it might offer. The comment is 3 as it points out a potential direction for improvement, but it could be more beneficial with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment raises a question about the division of tables into three types, specifically questioning the column header as one type. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes should be made to the tables. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggesting that one type, the column header, should work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the division of tables into three types, specifically questioning the column header as one type. However, it does not provide any supporting evidence, reasoning, or references to justify why this division is problematic or how it could be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the division of tables into three types, specifically questioning the inclusion of the column header as one type. While it identifies a potential issue, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the concern or what changes could be made to improve the clarity or organization of the tables. As a result, the feedback is not helpful, as it does not offer constructive advice that could help the authors enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. It provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment does not explicitly instruct the authors to use these methods or provide guidance on how to integrate them into their work. While the action is implied, it is not as clear as it could be, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attack methods\" and \"toy setting with classification tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not consider other classical attack methods in NLP and suggests specific examples from other papers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of these methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment lacks detailed reasoning or evidence to support why these methods are more effective or why the current methods are inadequate. While the examples are provided, the justification for the claim is not fully developed, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the attack methods used are naive and that the paper does not consider other classical attack methods in NLP. It provides specific examples of alternative methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. This feedback is clear and actionable, as it guides the authors to consider a broader range of attack methods that could enhance the robustness and generalizability of their work. However, the comment could be more helpful if it explained why these alternative methods are more effective or how they might be integrated into the paper. Overall, the comment is 4 as it directs the authors to consider a wider range of attack methods, but it could be further improved with additional guidance or rationale."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the impact of mitigation methods or suggestions for improving image quality. As a result, the authors are left without any clear direction on how to improve their draft in response to this comment. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation methods on the image generation capabilities of diffusion models, suggesting that this could lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the mitigation methods affecting image quality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, which could lead to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their mitigation methods. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance on how to address these concerns or what specific steps the authors should take to mitigate these risks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper this concern is related to, such as a specific section or experiment where this issue might arise. Without explicit references to sections or experiments, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specific guidance on how to address these concerns or what steps to take to mitigate the risks. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. While the comment identifies a critical issue, it lacks specific guidance or suggestions on how the authors might address this concern or mitigate the risks. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what implications it might have for their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise about the dominance of function words over content words in a Japanese sentence, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it lacks any actionable feedback or suggestions for improvement. Without further explanation or context, the authors are left without a clear understanding of what this observation means for their work or how they might address it. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, 1 and 2, which discuss the properties of kmeans clustering and its applicability to different datasets. This explicit suggestion and the inclusion of references provide clear guidance on what the authors should consider as a more reasonable baseline. The action is concrete, as it specifies the change needed and offers concrete references to support the claim. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this baseline is used. The comment does provide references to external works, which could help the authors identify the relevant section, but without explicit mention, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer supports this claim by referencing two external sources, 1 and 2, which discuss the properties of kmeans clustering and its applicability to different datasets. These references provide a logical basis for the claim, making it 4. However, the comment could be strengthened by further explaining why the average is not ideal or how the minimum objective would be more appropriate. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the paper by recommending the use of the minimum kmeans objective over multiple seeds as a baseline instead of the average. This feedback is based on a logical reasoning that the average of multiple kmeans objectives may not be the most appropriate baseline, as it does not necessarily represent the minimum objective. The reviewer supports this suggestion by referencing two external sources, 1 and 2, which discuss the properties of kmeans clustering and its applicability to different datasets. This level of detail and support makes the comment 5, as it provides clear and actionable guidance for the authors to enhance their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment implies that the authors should clarify these differences, it does not provide specific guidance on how to do so or what aspects of the task should be clarified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to clarify the differences against Argument Mining/Discussion Summarization, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the task described in the paper is closer to Argument Mining rather than Summarization. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why the task is closer to Argument Mining, making it difficult for the authors to understand and address the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While it identifies a potential issue with the task classification, the comment lacks specific guidance or suggestions on how to clarify these differences or what aspects of the task should be emphasized. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically questioning whether both are required for uncertainty calibration. It suggests that the authors clarify this point and provides a specific example of where the confusion arises (lines 155160). Additionally, it questions the motivation of reducing entropy to make predictions more confident, as this contradicts the paper\"s goal of calibrating networks. While the comment provides a clear direction for clarification, it does not offer specific guidance on how to address the issue or suggest alternative explanations. The action is explicit but somewhat vague in terms of execution, as the authors need to determine the exact changes required to clarify the confusion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the confusion regarding the relationship between temperature calibration and uncertainty calibration, and it questions the motivation of reducing entropy to make predictions more confident. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, suggesting that the training regularization term (H) requires temperature calibration, but temperature calibration is applied after training. The reviewer questions this contradiction and asks for clarification. The comment also points out that reducing entropy can make predictions more confident, which is against the paper\"s motivation to calibrate networks. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to further explore the reasoning behind the confusion and the implications of the suggested approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the relationship between temperature calibration and uncertainty calibration. It points out that the training regularization term (H) requires temperature calibration, but temperature calibration is applied after training. This is a critical clarification that could help the authors avoid misunderstandings in their work. Additionally, the comment questions the motivation of reducing entropy to make predictions more confident, as this contradicts the paper\"s goal of calibrating networks. While the comment provides valuable insights, it could be more helpful if it offered suggestions on how to clarify these points or address the issues raised. Overall, the comment is 4 as it highlights important areas for clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of an important reference, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. It also highlights the importance of discussing similarities and differences with Lista and placing the paper in appropriate context. While the comment identifies the missing reference and the need for contextualization, it does not provide specific guidance on how to integrate these elements into the paper. The action is clear but lacks detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing reference, \"Lista,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the importance of discussing similarities and differences with the reference and placing the paper in appropriate context. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. The reviewer suggests that the paper should discuss similarities and differences with \"Lista\" and place itself in appropriate context. While the comment identifies the missing reference, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of discussing similarities and differences, and the contextualization of the paper. Therefore, the comment is 3, as it provides a starting point but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a critical omission in the paper, specifically the absence of an important reference, \"Lista,\" which is relevant to the idea of unrolling. It highlights the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This feedback is clear and actionable, as it directs the authors to include a missing reference and provide a more comprehensive discussion of their work in relation to existing literature. However, the comment could be more helpful if it offered specific suggestions on how to integrate these elements into the paper or provided examples of how similarities and differences might be discussed. Overall, the comment is 4 as it guides the authors toward improving the clarity and contextualization of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the linear program in Theorem 3 needs to be explained more intuitively. It acknowledges that this is a main theorem but suggests that providing an explanation of the objective and constraints in (3) would be beneficial for the reader. This feedback is clear and provides a concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of the objective and constraints in (3) of the linear program. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 needs to be explained more intuitively. While it acknowledges that this is a main theorem, it does not provide specific reasoning or examples to support why the explanation is necessary or how it would benefit the reader. The comment lacks detailed justification or references to common practices or standards, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need to provide a more intuitive explanation of the linear program in Theorem 3. It acknowledges that this is a main theorem but emphasizes the importance of explaining the objective and constraints in (3) to enhance the reader\"s understanding. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work that could enhance its clarity and accessibility. However, the comment could be more helpful if it included specific suggestions on how to present this explanation or examples of how similar theorems are typically explained. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the FLOT cost matrix in Algorithm 1 is not defined, which is a clear and explicit action for the authors to take. The comment provides a specific issue to address, indicating that the cost matrix should be defined. However, it does not offer guidance on how to define it or provide examples of what such a definition might look like. While the action is explicit, the lack of concrete details on implementation makes the comment somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"FLOT cost matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of a definition for the FLOT cost matrix in Algorithm 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their work. However, the comment lacks depth and does not provide suggestions on how to define the matrix or what implications this might have for the paper. While it highlights an important area for improvement, it could be more helpful with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the algorithm, specifically regarding the use of \"avg\" and the meaning of \"j\"\" and \"i\"\". While it identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take to address these issues. The authors are left to infer that they need to clarify these points, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the use of \"avg\" and the meaning of \"j\"\" and \"i\"\". This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the use of \"avg\" and the meaning of \"j\"\" and \"i\"\". It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification and does not make a claim that needs justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several areas of confusion and potential improvement in the paper, specifically regarding the clarity of Algorithm 2 and the use of \"avg.\" It points out that \"j\"\" and \"i\"\" are not defined, which is a critical oversight. The comment acknowledges the authors\" response and suggests that they keep the initial scores, indicating that the authors have addressed some concerns. However, it also highlights that the algorithm remains unclear, which is a significant issue that needs to be addressed. Overall, the comment provides actionable feedback by pointing out specific areas that need clarification and improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on the definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. It also recommends showing the advantages of the proposed method compared to existing methods. While the comment provides clear and specific actions for the authors to take, it does not offer detailed guidance on how to present this evidence or what specific aspects to focus on. The authors are given a clear direction but may need to infer the exact steps to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the definition and suggests providing evidence to support the sparsity assumption across various noisy cases. Additionally, it recommends comparing the proposed method with existing methods to show its advantages. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It suggests that the authors provide evidence to support the sparsity assumption across various noisy cases and recommends comparing the proposed method with existing methods to show its advantages. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim that the sparsity assumption is not wellfounded. The suggestion to provide evidence is logical, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the definition of the sparsity of the residual term in the paper. It suggests that the authors provide evidence to support the sparsity assumption across various noisy cases and recommends comparing the proposed method with existing methods to show its advantages. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and robustness of their work. By addressing these points, the authors can enhance the understanding and credibility of their method. However, the comment could be more helpful if it provided specific examples or references to existing methods that demonstrate the advantages of the proposed method. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the terminology. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the term \"connectivity,\" explaining that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"connectivity,\" noting that it is misleading as it does not refer to the structural connections between the brain and body. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and precision of the terminology. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what alternative terminology might be more appropriate. While it points out a relevant concern, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what aspects are missing or how to address these issues. The authors are left to infer that they need to improve the clarity, quality, novelty, and reproducibility of their work, but without concrete suggestions or examples, they may struggle to know where to focus their efforts. The lack of explicit instructions or detailed feedback makes this comment 3, as the authors have an idea of what needs to be improved but not how to achieve it.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment references \"Clarity, Quality, Novelty And Reproducibility,\" but does not provide specific examples or details from these sections. This lack of specificity and grounding makes it challenging for the authors to understand and address the issues effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or examples, the authors may struggle to understand the exact issues and how to address them. Therefore, the claim is considered 2, as it provides some indication of the problem but lacks sufficient detail for the authors to fully understand and act upon it.", "helpfulness_rationale": "The review comment identifies several areas where the paper is lacking, including clarity, quality, novelty, and reproducibility. However, it does not provide specific examples or detailed feedback on what aspects of these categories are missing or how they could be improved. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or guidance, the authors may struggle to understand and address the issues effectively. The comment lacks actionable suggestions or detailed feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance on what the authors should do to improve their draft. It suggests that the authors should study the essentialness of using an orthogonal matrix weight for the local window MLP, which is not currently presented in the paper. This feedback is clear and concrete, as it specifies the need for further exploration and validation of the orthogonal matrix weight. The authors know exactly what needs to be done to address this point, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the importance of studying the essentialness of using an orthogonal matrix weight for the local window MLP. The comment provides a clear direction for the authors to improve their draft by suggesting that they should explore the validity of using an orthogonal matrix weight. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Step 2 and Step 3 are important for validating the use of an orthogonal matrix weight in the local window MLP. The reviewer suggests that Step 2 can be done regardless of the weight matrix, and that Step 3 is crucial for validating the use of an orthogonal matrix weight. However, the comment lacks specific examples or references to support these claims, making it 3. The authors may find it challenging to fully understand and address the claims without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of exploration into the essentialness of using an orthogonal matrix weight for the local window MLP. It suggests that Step 2, which involves the transpose of the matrix, can be done regardless of the weight matrix, and that Step 3 is crucial for validating the use of an orthogonal matrix weight. The comment provides a clear and actionable suggestion for the authors to further explore and validate the use of an orthogonal matrix weight, which could enhance the paper\"s contribution. However, the comment could be more helpful if it offered specific examples or references to support the claim about the importance of Step 3. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any explicit or implicit actions for the authors to take, such as suggesting further analysis or experiments to address the issue. The comment lacks guidance on how the authors might investigate or resolve the drop in accuracy. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the drop in accuracy after a certain order around 45 and asks if it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the drop in accuracy in Figure 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any suggestions or guidance on how the authors might address this issue or investigate the cause of the drop in accuracy. While it prompts the authors to consider a potential explanation, such as overfitting, it lacks actionable feedback or detailed analysis that could help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the models and datasets used are too toylike and recommends using CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also asks about the foreseeable challenges in experimenting on language tasks. While the comment provides specific suggestions for improvement, it lacks concrete guidance on how to implement these changes or what specific aspects of the models and datasets need to be addressed. The authors are left to infer that they should consider these changes and address the questions raised, but the feedback does not offer detailed instructions on how to do so. Therefore, the comment is 3, as it provides a direction for improvement but lacks explicit guidance on execution.", "grounding_specificity_rationale": "The comment addresses the issue of the models and datasets being too toylike and suggests the inclusion of CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also asks about the foreseeable challenges in experimenting on language tasks. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the model selection or dataset used. The comment is specific in detailing what needs to be addressed, such as the inclusion of more challenging datasets and models. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the models and datasets used are too toylike and suggests the inclusion of CIFAR100, ResNet 34 or 50, and ViTtiny or small. The reviewer also asks about the foreseeable challenges in experimenting on language tasks. While the comment provides a logical reasoning for the need for more challenging datasets and models, it lacks specific examples or references to support the claim that the current models and datasets are too toylike. The suggestion to include CIFAR100 is a specific example, but the comment could be strengthened by providing more detailed reasoning or examples of how these changes would improve the study. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the models and datasets used in the paper, noting that they are too toylike and suggesting the inclusion of more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also raises a question about the foreseeable challenges in experimenting on language tasks. While the comment provides clear and actionable feedback on improving the model selection and dataset choice, it could be more helpful if it offered additional guidance on how to address the language task challenge or provided specific examples of how these changes would impact the study. Overall, the comment is 4 as it directs the authors to make significant improvements in their model selection and dataset choice, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of natural ablation studies, specifically mentioning the scratchGAN model and its performance with pretraining. It suggests that this is a crucial baseline to include, especially given the central argument against pretraining. Additionally, the comment includes minor comments and questions that do not directly impact the main issue but could be helpful for clarification or additional analysis. While the main action is clear\u2014to include the natural ablation studies\u2014the minor comments and questions are not explicitly addressed, making the action 3. The authors know what needs to be done but may need to consider the minor points as well.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of natural ablation studies, specifically mentioning scratchGAN and its performance with pretraining. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a baseline study that is crucial for understanding the central argument against pretraining. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the absence of natural ablation studies, specifically mentioning scratchGAN and its performance with pretraining. The comment suggests that this is a crucial baseline to include, as it relates to the central argument against pretraining. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this baseline is crucial or how it would impact the central argument. Without additional context or explanation, the claim remains 3, as it lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of natural ablation studies, specifically mentioning scratchGAN and its performance with pretraining. This is a crucial baseline that the authors should consider including, as it relates to the central argument against pretraining. Additionally, the comment includes minor comments and questions that could be helpful for clarification or additional analysis. However, while the main suggestion is clear and actionable, the minor comments and questions are not explicitly addressed, which limits the overall helpfulness of the comment. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth in addressing all aspects of the feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, and that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. The reviewer suggests that these decisions should be explained in the paper to help readers understand them without needing to check the code. The comment provides clear and concrete actions for the authors to take, ensuring that they know exactly what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the handling of comparisons between episodes with different lengths and the use of padding to compare trajectories. The comment provides a detailed explanation of the issue, including the use of a normalization factor of 1/T and how this affects the distance metric. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides a detailed explanation of the issue, noting that the authors pad the shorter sequence by replicating its last state to compare both trajectories. Additionally, the comment points out that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. This reasoning is supported by logical reasoning and specific examples, making the claim 4. However, the comment could be strengthened by providing references to similar issues in the literature or additional examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the paper, namely the lack of clarity regarding how the authors handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides a detailed explanation of the problem, noting that the authors pad the shorter sequence by replicating its last state to compare both trajectories, and that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. This feedback is clear and actionable, as it directs the authors to clarify their methodology in the paper to ensure readers can understand the decisions made without needing to check the code. By addressing this issue, the authors can significantly improve the clarity and comprehensibility of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential oversight in the experiment, noting that the Vision Transformer was not considered and questioning its applicability to larger image datasets like ImageNet. It also raises a question about the pruning strategy in selfattention layers. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should consider the Vision Transformer and address the pruning strategy question, but the comment lacks specific guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the omission of the Vision Transformer model and questions its applicability to larger datasets like ImageNet. Additionally, it raises a question about the pruning strategy in selfattention layers. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the omission of the Vision Transformer model in the experiment and questions its applicability to larger datasets like ImageNet. It also suggests that the pruning strategy in selfattention layers might differ. However, the comment lacks specific references or detailed reasoning to support these claims. While it identifies potential issues, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is 3, as it provides a starting point for the authors to explore but requires further elaboration to be fully actionable.", "helpfulness_rationale": "The review comment identifies a potential oversight in the experiment by noting the absence of the Vision Transformer model, which is an important SOTA model in image classification. It also raises a question about the applicability of the pruning strategy in selfattention layers to larger datasets like ImageNet. This feedback is 3 as it prompts the authors to consider a relevant model and address a potential limitation in their experiment. However, the comment could be more helpful if it provided specific suggestions on how to incorporate the Vision Transformer or how to evaluate the pruning strategy. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of comparison against baselines and notes that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. It suggests that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparison (or codesearch). While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include comparisons against baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but does not offer specific steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison against baselines and the need for architectureagnostic similarity comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparison against baselines and that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. The reviewer supports this claim by referencing the widelyunderstood nature of binary analysis applications and the existence of architectureagnostic similarity comparison (or codesearch) in many papers. This provides a logical basis for the claim, but the comment could be strengthened by providing specific examples or references to these papers. Therefore, the comment is 3, as it provides a logical reasoning but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of comparison against baselines and the limited scope of the functionality similarity comparison study. It highlights that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparison (or codesearch). This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific suggestions on how to address this gap, such as which baselines to consider or how to implement the suggested architectureagnostic similarity comparison. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the preprocessing in SI 6.5 is identical to that in Mnih et al. 7, but the evaluation is slightly different because no human starts are used. This is a clear and direct action for the authors to take, as it provides a specific point to address in their draft. The comment is concrete, as it specifies the exact part of the paper where the mention should be made and the issue with the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to mention that the preprocessing is identical to that in Mnih et al. 7, despite the evaluation being slightly different due to the absence of human starts. This provides clear guidance on what needs to be added to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in SI 6.5 is slightly different from that in Mnih et al. 7 because no human starts are used. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation in SI 6.5, noting that the preprocessing is identical to that in Mnih et al. 7, but the evaluation is slightly different due to the absence of human starts. This feedback is clear and actionable, as it directs the authors to make a specific mention in the paper to clarify this difference. By addressing this point, the authors can improve the clarity and accuracy of their evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively communicate this difference in evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the figures, including the size of the text, the clarity of the inputs and outputs, and the selfcontained nature of the captions. While it points out these problems, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to make the figures more readable and better linked to the main text, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the figures, such as the small text size and unclear explanations of inputs and outputs. The comment further details the problem with the captions, stating that they are not selfcontained and difficult to link to the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the figures in the paper are difficult to parse due to small text size and unclear explanations of inputs and outputs. It also mentions that the captions are not selfcontained and hard to link to the main text. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specific aspects that need improvement, such as font size or caption clarity. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that the text is too small and the inputs and outputs are not clearly explained. It also points out that the captions are not selfcontained and difficult to link to the main text. This feedback is clear and actionable, as it provides the authors with a concrete understanding of what needs to be improved in the figures. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending font size changes or providing examples of how to improve the clarity of the figure captions. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper claims advantages over previous work in terms of efficiency but does not provide any metrics to substantiate these claims. This implies that the authors need to include metrics or comparisons to demonstrate the efficiency of their proposed method. While the action is explicit in requiring the inclusion of metrics, it is somewhat vague in detailing which metrics should be used or how they should be presented. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss advantages over previous work in terms of efficiency. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of metrics to demonstrate the efficiency of the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method. However, it does not provide any supporting evidence or examples to substantiate this claim. Without specific metrics or comparisons to previous work, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that while the authors claim advantages over previous work in terms of efficiency, they do not provide any metrics to substantiate these claims. This is a significant oversight, as metrics are essential to demonstrate the effectiveness of the proposed method. The comment is clear and actionable, as it directly instructs the authors to include metrics to support their claims. However, it could be more helpful if it provided specific suggestions on which metrics to use or how to present them effectively. Overall, the comment is 4 as it highlights a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to expand the contribution or what specific aspects of the paper could be strengthened. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered limited or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment lacks specific reasoning or evidence to support why the contribution is considered limited. It does not provide examples, comparisons, or references to similar work that might substantiate the claim. As a result, the claim is not 5, making it difficult for the authors to understand and address the critique. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any specific feedback or suggestions on how the authors could enhance the contribution or what aspects of the paper could be improved. The comment lacks actionable guidance or detailed critiques, leaving the authors without clear direction on how to strengthen their work. Therefore, the comment is rated as 2, as it identifies a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment provides clear and direct actions, it does not specify how to implement these changes or what specific details should be included. The authors are left to infer the necessary changes, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing more details about the statespace, whether it is finite or continuous, and the actions involved. The comment also questions the space in which theta lies and suggests that the authors should be precise in their explanations. This level of detail provides clear guidance on what needs to be improved, making the comment 5.", "verifiability_rationale": "The review point consists of questions asking for more details about the statespace, whether it is finite or continuous, and the actions involved. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a lack of detail in the paper, specifically asking for more information about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment highlights areas where the paper could be more detailed, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out potential gaps in the paper, but it lacks actionable advice or detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the method\"s effectiveness on general reasoning tasks or suggestions for potential improvements. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper discusses the method or where this comparison is made. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential weakness in the method, noting that it is less effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the method\"s effectiveness on general reasoning tasks. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The reviewer also mentions that the authors acknowledge this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the proof technique and its applicability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. The reviewer provides a specific reference to Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve the proof technique. The feedback is 3 as it points out a specific area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional molecule generation framework based on GDSS, which was recently proposed in 2, as a baseline. The comment provides explicit actions for the authors to take, such as including the continuous diffusion model as a baseline and considering the conditional framework based on GDSS. The suggestions are concrete and provide clear guidance on how to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison of the continuous diffusion model (e.g., GDSS) as a baseline in Table 3 and the suggestion to use a conditional molecule generation framework based on GDSS. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. The reviewer provides a logical reasoning by pointing out that the continuous diffusion model should be considered as a baseline for the conditional generation task. However, the comment lacks specific examples or references to support the claim that GDSS does not explicitly present a conditional framework. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include the continuous diffusion model (e.g., GDSS) as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also suggests using a conditional molecule generation framework based on GDSS, which was recently proposed in 2, as a baseline. This feedback is valuable as it directs the authors to include a relevant baseline and provides a specific suggestion for improvement. However, the comment could be more helpful if it explained why the continuous diffusion model is particularly relevant or how the proposed conditional framework would enhance the analysis. Overall, the comment is 4 as it offers clear and actionable guidance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation is the best choice due to its ability to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment does not provide explicit instructions or concrete steps on how to implement this change or what specific aspects of the current approach need to be adjusted. While the suggestion is clear, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this change could be implemented. The comment also lacks specificity regarding why LiDARbased segmentation is considered the best choice or how it would improve the paper. Without explicit references or detailed reasoning, the authors cannot confidently determine which parts of the paper need attention or how to address the suggestion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice for the downstream task than object detection, citing the ability of LiDAR to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific examples or detailed reasoning to support why LiDARbased segmentation is considered superior to object detection. The claim is 3, as it provides a logical argument but lacks the depth and evidence needed for full verifiability. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a subjective opinion on the choice of downstream task, suggesting that LiDARbased segmentation is a better option than object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation can learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific guidance or suggestions on how the authors might implement this change or what aspects of their current approach might need adjustment. While the feedback identifies a potential area for improvement, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Operator (IPO). However, it does not provide any guidance on how the authors should address this issue or suggest specific actions to resolve the contradiction. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors uncertain about what steps to take. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the objective of Equation (12) and its potential contradiction with the Inverse Proportionality Operator (IPO). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential contradiction and suggesting that the authors address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the objective of Equation (12) is in contradiction with the Inverse Proportionality Operator (IPO). However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Operator (IPO). This is a critical observation that could impact the validity and applicability of the work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the contradiction. While it points out a potential problem, it does not offer actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. While the comment explicitly states the action to take, it lacks concrete guidance on how to implement this change or why it is necessary. The authors are left to infer that they should make this change to enhance clarity, but without specific instructions or examples, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of \"t\" in the kernel and the suggestion to replace it with the size of T to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. However, the comment does not provide any reasoning or evidence to support why \"t\" is unclear or why replacing it with the size of T would improve clarity. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a specific improvement to the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of T. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the readability and understanding of the methodology. However, the comment could be more helpful if it explained why \"t\" is unclear or why the change would improve clarity. Despite this, the suggestion is valuable and offers a straightforward way for the authors to improve their draft, making the comment 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the adaptation capacity. The comment lacks actionable details, such as recommending specific experiments or modifications to the model architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment does not specify which part of the paper this concern is related to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its concern about the adaptation capacity and the potential impact on concepts with different levels of geometric information. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. The reviewer provides a logical reasoning by mentioning that DINO representations are observed to contain rich geometric information, which could affect the adaptation capacity. However, the comment lacks specific examples or references to support the claim that the adaptation capacity might be affected for concepts with different levels of geometric information. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. While the comment identifies a potential concern regarding the adaptation capacity, it lacks specific suggestions or guidance on how the authors might address this issue or improve their model. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This is a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be added to, such as the results or discussion sections. The authors can infer that it relates to the experimental evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what needs to be added. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s contribution by including a comparison with established methods. However, the comment lacks specific examples or references to these stateoftheart loss functions, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification. This is a clear and actionable suggestion that could enhance the paper\"s contribution by demonstrating the effectiveness of the proposed method against established benchmarks. By including such a comparison, the authors can provide a more comprehensive evaluation of their work and potentially improve its impact. However, the comment could be more helpful if it specified which loss functions should be included or provided examples of how they might be used in the context of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as giving the EF and D2 transcription norms, correcting specific phrases in the text, and addressing issues with repeated words in a table. Additionally, it points out a discrepancy in the DOI number and the link behind the title. These actions are clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and tables in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the phrasing in lines 029 and 188, the repeated words in Table 3, and the discrepancy in the DOI number. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of technical corrections and observations, such as correcting phrasing, addressing repeated words, and pointing out discrepancies in the DOI number. These are factual statements that do not involve subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of technical corrections and observations, which can be beneficial for the authors in improving the clarity and accuracy of their work. It points out specific errors in phrasing and references, such as correcting \"lightweight\" to \"in a lightweight\" and \"PLN\" to \"NLP.\" Additionally, it highlights a discrepancy in the DOI number and the link behind the title. These corrections and observations are actionable and can help the authors improve the clarity and consistency of their work. However, the comment could be more helpful if it provided additional context or suggestions for how to address these issues. Overall, the comment is 3 as it offers specific guidance but lacks depth in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests spelling out \"F.L.T.R\" in Figure 4 and recommends crossreferencing notation and figures to avoid confusion. The comment also points out that M and N are not defined and that the text in Figure 1 is too small to read. These specific suggestions give the authors clear guidance on how to improve the clarity and readability of their paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as spelling out \"F.L.T.R\" in Figure 4 and recommending crossreferencing notation and figures. The comment also suggests that M and N are not shown in the figures, providing detailed feedback on how to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation is confusing and suggests spelling out \"F.L.T.R\" in Figure 4. It also mentions that the text in Figure 1 is too small to read and recommends crossreferencing notation and figures. While the comment identifies specific issues with the notation and figure presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to crossreference notation and figures is a logical step, but the comment could be strengthened with more specific examples or explanations. Therefore, the claim is 3, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies specific issues with the notation and figure presentation in the paper, which can be confusing for readers. It suggests spelling out \"F.L.T.R\" in Figure 4 and recommends crossreferencing notation and figures to avoid confusion. Additionally, it points out that the text in Figure 1 is too small to read and that M and N are not shown in the figures. These suggestions are clear and actionable, providing the authors with concrete steps to improve the clarity and readability of their paper. However, the comment could be more helpful if it explained why these issues are problematic or how they impact the overall understanding of the paper. Overall, the comment is 4 as it offers specific and actionable feedback, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should clarify or rename the variable to avoid confusion. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1\" and \"Phase 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2, suggesting that this might be confusing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"$p$\" to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific issue that could be clarified or addressed to improve the clarity of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify or rename the variable to avoid confusion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper could benefit from a more detailed mathematical formulation, particularly in the appendix, to enhance the understanding of the approach. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and align it with the main contribution of the paper, which is improvements on the WiC task. The comment provides specific suggestions for reworking the figure to better align with the WiC task, offering actionable steps for the authors to improve their draft. The explicit nature of these suggestions and the concrete guidance on how to implement them make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the highlevel description, suggesting that a more detailed (e.g., mathematical) formulation would be helpful, and with the figure, pointing out that it is too abstract and confusing. The comment provides specific suggestions for improvement, such as adding text labels and aligning the figure with the main contribution of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description could benefit from a more detailed (e.g., mathematical) formulation, which is a logical suggestion for improving the clarity of the approach. The reviewer also points out that the figure is confusing and recommends adding text labels to clarify its purpose and align it with the main contribution of the paper. The comment provides a clear rationale for these suggestions, making them 4. However, it could be strengthened by providing specific examples or references to similar approaches that use mathematical formulations or detailed figures. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the paper\"s highlevel description and figure. It suggests that a more detailed (e.g., mathematical) formulation would be beneficial, particularly in the appendix, to enhance the understanding of the approach. Additionally, it points out that the figure is confusing and recommends adding text labels to clarify its purpose and align it with the main contribution of the paper, which is improvements on the WiC task. The comment offers a clear and constructive suggestion for reworking the figure to better align with the WiC task, providing the authors with a concrete step to improve their draft. Overall, the feedback is 5 as it guides the authors on how to enhance the clarity and coherence of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include additional benchmarking tasks outside of AitW. However, it does not provide specific guidance on which tasks should be included or how they should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should consider additional benchmarking tasks but are not given concrete steps on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which parts of the paper should include these tasks or which specific benchmarking tasks should be considered. Without explicit references to sections or specific tasks, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be beneficial for the paper. However, it does not provide specific tasks or examples of what these tasks could be, nor does it explain why these tasks are important or how they would enhance the paper. While the suggestion is 3 in identifying an area for improvement, it lacks depth and actionable guidance, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on the comparison results between YOSO and linformer in terms of iterationwise convergence and accuracy in downstream tasks. It also suggests that an explanation should be provided to analyze the difference in performance. The feedback is clear and provides specific actions for the authors to take, such as including the steps vs PPL of linformer with YOSO in Figure 4 and analyzing the performance difference. The comment is concrete and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments: YOSO takes linformer as baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the lack of comparison results between YOSO and linformer in terms of iterationwise convergence and accuracy in downstream tasks. Additionally, it suggests an explanation for the difference in performance between YOSO and linformer. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of comparison results between YOSO and linformer in terms of iterationwise convergence and accuracy in downstream tasks. It suggests that linformer demonstrates better performance in these tasks, and asks for an explanation of this difference. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to make a significant effort to verify the claim themselves, as the comment lacks detailed evidence or reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the pretraining experiment part does not provide steps vs PPL of linformer with YOSO in Figure 4. It also questions the comparison result of YOSO with linformer on iterationwise convergence and suggests an explanation for the difference in performance between the two models. Additionally, it points out that linformer demonstrates better accuracy in downstream tasks such as SST2. The comment provides clear and actionable feedback by asking for specific comparisons and explanations, which can help the authors improve the clarity and rigor of their experimental results. However, it could be more helpful if it offered suggestions on how to present these comparisons or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their experimental analysis."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. While it identifies the issue, it does not provide explicit guidance on how the authors should address this discrepancy. The comment lacks concrete suggestions or actions for the authors to take, such as suggesting a correction or clarification in the abstract or text. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and the text, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract statement about requiring the proposal distribution to upper bound the target everywhere is not true, as the authors themselves clarify in the text. However, the comment does not provide specific references or examples from the text to support this claim, making it difficult for the authors to verify the accuracy of the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a critical issue that could impact the validity and clarity of the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this discrepancy or clarify the text. While it points out a potential problem, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an important issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion regarding the name \"PointNet\" in Figure 1, noting that it is not mentioned in the paper and that there is another paper with the same name. The reviewer suggests that the authors should clarify this issue by referring to the correct paper or providing additional context. While the comment explicitly identifies the problem and suggests a solution, it does not provide detailed guidance on how to implement this correction. The action is clear but somewhat vague in terms of execution, as the authors need to determine the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"PointNet,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of \"PointNet\" as \"PointNet\" in Figure 1, noting that this name does not appear in the paper and that there is another paper with the same name. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to \"PointNet\" in Figure 1 is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to the correct paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which supports the claim by providing a clear example of the correct name. This reference is sufficient to justify the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the labeling of \"PointNet\" in Figure 1, noting that it is confusing as the name does not appear in the paper and there is another paper with the same name. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their paper. By addressing this issue, the authors can improve the clarity and accuracy of their figure captions, which is valuable guidance for improving the draft. However, the comment could be more helpful if it suggested how to handle the confusion in the caption or provided additional context on the significance of the name. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the policy gradient and the phrases in question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in identifying the need for clarification and the potential issues with the lines mentioned. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and observations about the policy gradient in Equation 6 and its relation to the optimal problem. It also points out an unnecessary phrase in Line 78 and a potential issue with Line 132. These are factual observations and questions that do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect to ensure that the policy gradient is indeed solving the optimal problem. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification and potential improvements, it does not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it highlights areas that need attention, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it does not explicitly instruct the authors to make a specific change or provide guidance on how to address this question, it does prompt the authors to consider the implications of these assumptions and the potential differences between them. The action is implicit but concrete, as the authors can infer that they need to explore the implications of these assumptions and potentially make a change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these assumptions are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry about the difference between these distributions, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm, seeking clarification on the difference between these distributions. While it identifies a potential area of confusion or misunderstanding, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, making it 2 for the authors in terms of improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the limitations of freezing the partitioning in the first iteration, which seems like a risky choice. This feedback is clear and provides a specific action for the authors to take, which is to address the limitations of this choice. The comment is concrete because it specifies the need for a discussion on the limitations, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the risky choice of freezing the partitioning in the first iteration and the need to discuss its limitations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. The reviewer suggests that at least the limitations of this choice should be discussed. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors may understand the concern but would need to make a significant effort to address it without detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of freezing the partitioning in the first iteration, which could be considered a risky choice due to its potential impact on the coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided additional context or examples of how this choice might impact the results or analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. However, it does not offer any specific guidance or suggestions on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification about the section. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the intent of this section, indicating that the authors need to clarify or provide more context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the intent of Section 5.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It acknowledges that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific guidance on what aspects need clarification or how to clarify them. It lacks concrete suggestions or examples of what the authors should focus on to improve the clarity of their approach. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights that many aspects of the approach need clarification and expresses concern about the interaction between knowledge about objects and verbs. It mentions that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not specify which parts of the paper need clarification or provide detailed comments. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects need clarification or how the approach should be explained. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification and expresses concern about the interaction between knowledge about objects and verbs. The reviewer mentions that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of specificity and detailed evidence or references makes the claim 3, as it provides a general direction for improvement but does not fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper needs clarification, particularly regarding the interaction between knowledge about objects and verbs in the approach. It expresses concern about the lack of explanation for how this interaction allows the paper to overcome reporting bias. The comment highlights that the paper dives into technical details too quickly, without providing a clear overview of the approach and its benefits. While it points out a critical issue, the comment lacks specific suggestions or guidance on how the authors might clarify these aspects or improve the presentation of their work. This limits the comment\"s usefulness, as it provides insight but does not offer actionable steps for the authors to address the feedback. Therefore, the comment is 3, as it identifies a significant area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity. This feedback provides clear and concrete actions for the authors to take, such as creating a new section or expanding the existing one to address the clarity issues. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the threat model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, including the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This claim is 3 as it logically suggests that such clarification would enhance the clarity of the paper, particularly around the assumed whitebox access to the victim model. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the threat model. It suggests that the authors should define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and comprehensibility of their work. By addressing these points, the authors can improve the understanding and applicability of their threat model, particularly in the context of whitebox attacks. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests an explanation for the decision to use early stopping only based on link prediction accuracy. It does not provide suggestions for alternative explanations or methods to consider. The action is clear and concrete, as the authors know exactly what needs to be addressed: providing an explanation for the decision. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for the decision to use early stopping only based on link prediction accuracy. The comment provides a clear direction for improvement by asking for an explanation of the decisionmaking process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping only based on link prediction accuracy, suggesting that an explanation is needed. However, it does not provide any reasoning or evidence to support why this decision might be problematic or inadequate. Without additional context or examples, the claim lacks verifiability, as it does not provide a clear basis for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further explanation, namely the decision to use early stopping only based on link prediction accuracy. It suggests that the authors should provide an explanation for this choice, such as why not to average with type accuracy. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their methodology. However, the comment could be more helpful if it provided additional context or examples of alternative approaches that could be considered. Overall, the comment is 4 as it guides the authors toward a clearer explanation of their methodology, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It explicitly asks the authors to provide concrete details on how to set a reasonable classimbalanced task, given the few examples available for each class. This feedback is clear and actionable, as it directly instructs the authors on what information is missing and how to address it. The request for concrete details provides a specific action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how to set a reasonable classimbalanced task in the fewshot learning setting, given the limited number of examples per class. The comment provides a clear request for concrete details, which adds to the specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim made in the paper regarding classimbalanced tasks in the fewshot learning setting. It suggests that the authors should provide concrete details on how to set a reasonable classimbalanced task, given the limited number of examples per class. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is problematic or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to respond to it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It questions how to set a reasonable classimbalanced task given the limited number of examples per class. The comment is 3 as it prompts the authors to provide concrete details on how they address this issue, which is a critical aspect of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to set a reasonable classimbalanced task. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the chatgpt baseline is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a clear action to test a fewshot approach and includes a suggestion for enhancing the baseline, it lacks specific guidance on how to implement these changes or what specific aspects of the fewshot approach should be tested. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the chatgpt baseline, suggesting that it is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. However, the comment does not specify which part of the paper discusses the chatgpt baseline or the fewshot approach, making it weakly grounded. The suggestion to include discourse relation information is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the chatgpt baseline is \"very rudimentary\" and suggests testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a logical reasoning for the need to test a fewshot approach and includes a specific suggestion for enhancing the baseline, it lacks detailed evidence or references to support the claim that the chatgpt baseline is indeed rudimentary. The suggestion for including discourse relation information is 3, as it provides a direction for improvement but lacks detailed justification or examples. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the chatgpt baseline, noting that it is \"very rudimentary\" and recommends testing a fewshot approach. It also suggests including discourse relation information in the prompts, potentially in a ChainofThought style approach. This feedback is clear and actionable, as it provides a concrete direction for improving the baseline and enhancing the evaluation of the paper. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how the fewshot approach might be tested. Overall, the comment is 4 as it provides valuable insights and suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It points out that the authors only state that they estimate a layer\"s sensitivity by pruning, but do not provide details on how the actual pruning was done. The comment implies that the authors should provide more information on the pruning process to clarify the methodology. While the action is implicit, it is clear and concrete, as it specifies the need for more detailed information on the pruning process. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail on how the ground truth of sensitivity is achieved and the need for more information on the pruning process. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. The reviewer suggests that the authors should provide more information on the pruning process to clarify the methodology. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is 3, as it provides a general direction for improvement but lacks the necessary evidence or justification to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved. It points out that the current explanation, which mentions pruning, lacks details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to provide more information on a crucial aspect of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies specific parts of the text that could be written more clearly, such as line 97 regarding proper rotation matrices and line 105106 regarding the matrix being non positive semidefinite. It provides clear and concrete actions for the authors to take, such as explicitly explaining the concepts in these sections. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the text, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the definition of a proper rotation matrix and the problem of the matrix being non positive semidefinite. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification regarding specific terms and concepts in the text. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific parts of the text that could be written more clearly, providing actionable feedback for the authors. By pointing out the lack of clarity in lines 97 and 105106, the comment guides the authors to explicitly explain the concepts of proper rotation matrices and the problem of the matrix being non positive semidefinite. This feedback is clear and constructive, offering a direct path for the authors to improve the clarity and comprehensibility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is explicit and provides a concrete suggestion for how the authors might improve their draft by changing the terminology. The action is clear and specific, leaving no ambiguity about what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The comment also references the activationpooling operator introduced by Cohen and Shashua, which helps clarify the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The reviewer provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This reference provides a logical basis for the suggestion, making the claim 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It offers a clear and actionable piece of feedback by providing a concrete example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is valuable as it helps the authors improve the clarity and consistency of their terminology, potentially enhancing the readability and comprehensibility of their paper. However, the comment could be more helpful if it explained why this change might be beneficial or how it would impact the overall understanding of the paper. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for their methods or related work. This is a clear and direct action that the authors can take to improve the presentation of their figures. The comment provides a specific suggestion for how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1\" and \"Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they should be shrunk to leave more space for the authors\" methods or related work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, and it provides a specific suggestion to shrink the captions to leave more space for the authors\" methods or related work. This claim is 3 as it logically suggests a way to improve the presentation of the figures, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to experiment with different caption sizes to determine the optimal size for their purposes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to shrink the captions to leave more space for the authors\" methods or related work. This feedback is valuable as it directs the authors to a specific area that could be improved, offering a concrete way to enhance the clarity and presentation of their figures. However, the comment could be more helpful if it included examples of how the captions could be revised or if it explained why this change would be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al, 2021, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider including this work as a benchmark. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inclusion of several works but the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide specific reasoning or evidence to support why Vidgen et al, 2021, should be included as a benchmark. The absence of detailed justification or references makes the claim 3, as the authors would need to infer the importance of including Vidgen et al, 2021, based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This feedback is 3 as it points out a potential oversight in the paper and provides a suggestion for improvement. However, the comment could be more helpful if it offered additional context or reasoning on why Vidgen et al, 2021, is relevant or how it could be integrated into the evaluation. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10) and ideally with errorbars. It also points out that the plotted curves are from single runs, which could be subject to significant fluctuations, and suggests that the models are small, making it unacceptable not to provide statistics. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results comparing standard vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with errorbars and providing statistics. This level of detail provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with errorbars, as the plotted curves are from single runs and might be subject to significant fluctuations. The reviewer also suggests that the models are small, making it unacceptable not to provide statistics. The comment is 4 as it provides a logical reasoning for why the results should be presented in a more robust manner, and it references the small size of the models as a justification. However, the comment could be strengthened by providing specific examples or references to similar studies that have used similar methods. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on the presentation of results comparing standard vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs (at least 10) with errorbars, which is a standard practice in scientific research. This suggestion is based on the observation that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the reviewer points out that the models are small, making it unacceptable not to provide statistics. This feedback is 5 as it guides the authors on how to improve the presentation and robustness of their results, ensuring that they are more reliable and informative. By addressing these points, the authors can significantly enhance the quality and credibility of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, which is a specific solver. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the draft. The authors are left to infer that they need to improve the approach\"s universality and adaptability, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it provides a direction for improvement but not detailed guidance on execution.", "grounding_specificity_rationale": "The comment critiques the proposed approach for learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in detailing what needs to be addressed, such as the need for universality and adaptability. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. The comment provides logical reasoning by explaining the limitations of current operator learning methods compared to specialized numerical solvers, suggesting that the proposed approach needs to be more universal and adaptable. However, the comment lacks specific examples or references to support the claim about the limitations of current operator learning methods. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed approach, noting that it is merely learning a surrogate model for solving linear/linearized systems arising in FEM. It highlights the need for careful choice of basis functions and meshes and points out that the approach heavily relies on FEniCS, a specific solver. The comment suggests that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal and do not need to be adapted to specific PDEs. While the comment provides a clear critique of the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve the universality and adaptability of their method. The feedback is 3 as it points out a potential weakness but does not offer actionable steps for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the clarity of the experimental setup. The comment is specific and provides concrete guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the impact of different versions of the experimental environment on training and inference speed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This claim is 3 as it logically suggests that different versions of the experimental environment could impact training and inference speed. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of providing this information themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about the experimental environment, including the CUDA and PyTorch versions. This feedback is clear and actionable, as it directly addresses a potential issue with the clarity and reproducibility of the experimental setup. By providing this additional detail, the authors can ensure that their work is more robust and easily replicable. However, the comment could be more helpful if it included suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve their draft to account for the limitations of realistic datasets. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of controlling multiple aspects of variation with precision in the context of using fully realistic datasets. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of variation are particularly challenging or how the authors might address these challenges. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work in response to the limitations of realistic datasets. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the agent can plan ahead is too vague to be understood concretely. However, the comment does not provide explicit guidance on how to improve the clarity or what specific aspects need to be clarified. While it highlights areas for improvement, the lack of concrete suggestions or examples makes it 3. The authors can infer that they need to clarify the paragraph and figure, but the comment lacks detailed instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L156166,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the difficulty in understanding the paragraph regarding the Gittins strategy and the figure. The comment provides clear guidance on what needs to be addressed, such as the vagueness of the description and the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph is difficult to understand, particularly regarding the Gittins strategy and the figure. The reviewer suggests that the description is vague and that the figure is hard to understand. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors may find it challenging to address the issues without detailed guidance or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and that the figure is hard to understand, with the phrase \"Dashed lines indicate that the agent can plan ahead...\" being too vague to be understood concretely. This feedback is valuable as it highlights a clear area for improvement in the clarity and comprehensibility of the text. However, the comment could be more helpful if it provided suggestions on how to clarify the paragraph or improve the figure, such as by offering specific examples or rephrasing. Overall, the comment is 3 as it directs the authors to a specific area needing attention, but it lacks detailed guidance on how to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and actionable, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (078079 and 08) and the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the evaluation metric to clarify the scale of the improvement and for comparability with other works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It references a previous work, Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020), where a similar expression was used. This claim is 3 as it provides a logical reasoning for why the evaluation metric should be included and references a specific example to support the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how this inclusion would enhance the clarity and comparability of the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work, which is relevant to the current paper. This feedback is specific and offers a concrete suggestion for improving the clarity and comprehensiveness of the paper. By addressing these points, the authors can enhance the transparency and reproducibility of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the standard deviation of the noise in the simulation study is stated as 3 but appears to be too low based on observations. While the comment implies that the authors should investigate this further, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this study. The action is implicit and somewhat vague, as the authors need to infer that they should explore higher noise levels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the behavior of the model under higher noise levels. The comment suggests that the standard deviation of the noise in the simulation study is too low, based on observations, and recommends studying the model\"s behavior under higher noise. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise in the simulation study is too low, based on observations compared to the true trajectories. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to verify the validity of the observation. The suggestion to study the behavior of the model under higher noise is logical, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the standard deviation of the noise in the simulation study, suggesting that it may be too low based on observations compared to the true trajectories. It recommends studying the behavior of the model under higher noise levels, which could provide valuable insights into its robustness. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct this study or what aspects of the model behavior should be examined. This limits the comment\"s helpfulness, as it provides a direction but not detailed instructions for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and suggests that this could limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to ensure the applicability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds of the approach, specifically mentioning the o(1) terms and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential limitation of the approach due to the o(1) terms, but it does not provide details on how this limitation affects the applicability of the approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds of the approach have o(1) terms and that this could limit the applicability of the approach. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the approach, specifically the use of o(1) terms in the bounds, which could limit the applicability of the approach. However, it does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure the applicability of their approach. The comment highlights a concern but lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects of DVP performance should be examined. As a result, the authors are left without any clear direction on how to address this interest. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not specify which part of the paper this interest pertains to, such as a specific section or experiment. Without explicit references to sections or experiments, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of DVP performance should be examined or how the results should be interpreted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses interest in seeing how DVP performs on videos with different lengths. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual statement about the authors\" interest in the topic. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it lacks any specific guidance or suggestions on how the authors might explore this topic or what aspects of DVP performance should be examined. Without actionable feedback or detailed instructions, the comment does not provide much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how the authors should address this issue. The comment lacks explicit guidance on how to clarify the target or what specific changes should be made to improve the clarity. As a result, the authors are left without clear instructions on how to improve the draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. However, it does not specify which part of the paper this confusion arises from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does not provide specific guidance on how to address this issue, such as suggesting where the clarification should be added or what aspects of the paper are unclear. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. The reviewer acknowledges that the clarification is provided in the conclusion but does not provide any supporting evidence or reasoning to justify this confusion. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the confusion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\"s focus or what aspects of the paper are unclear. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without guidance on how to address the confusion or enhance the clarity of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. It provides a clear and concrete action for the authors to take, specifying the exact calculation that needs to be performed. This level of detail makes the comment 5, as the authors know exactly what steps to take to address the issue. Therefore, the comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely evaluating the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KLdivergence. The comment provides a specific suggestion for improvement by asking the authors to check whether the approximation error approaches zero. However, the comment lacks detailed reasoning or references to support why this evaluation is necessary or how it would impact the results. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that it has ignored the KLdivergence term in equation (3). It provides a clear and actionable suggestion by asking the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is valuable as it directs the authors to a specific area for improvement, which could enhance the rigor and accuracy of their work. However, the comment could be more helpful if it included additional context or examples of how this evaluation might be conducted or what potential implications it might have. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the connection or depth of the analysis. The comment implies that the authors should make improvements, but it lacks concrete details on how to implement them. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not specify which part of Section 2 is lacking a connection or how the theoretical analysis could be improved. The authors can infer that the comment relates to the theoretical analysis and its connection to the methodology section, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be improved. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without detailed justification or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between Section 2 and the methodology section, suggesting that the theoretical analysis is simplistic and closely related to a specific reference. While it points out a potential weakness, it lacks specific guidance or suggestions on how to address this issue or improve the theoretical analysis. The comment highlights an area for improvement but does not provide actionable steps or detailed feedback, making it 3. The authors can infer that they need to strengthen the connection between Section 2 and the methodology section, but the comment does not fully support them in doing so. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should discuss the situations in which the losses help, particularly in specular areas. While the comment implies that the authors should provide more detail on this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the losses\" effectiveness in specific situations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations in which the losses help, particularly in specular areas. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a particular area for further discussion, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the losses discussed in the paper might be particularly helpful in specular areas. However, it does not provide any evidence, examples, or references to support this claim. The comment lacks specific reasoning or data to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors discuss the situations in which the losses help, particularly in specular areas. This feedback is 3 as it identifies a potential area for further exploration and explanation in the paper. However, the comment lacks specific guidance on how to conduct this discussion or what aspects of the losses should be emphasized. While it points out a potential gap in the paper, it does not provide detailed suggestions or examples to help the authors effectively address the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses doubt about the paper\"s current strength for the ICLR conference, but it does not provide any specific guidance or suggestions on how the authors might improve their draft to meet the standards of the conference. There is no explicit or implicit action for the authors to take, nor are there any concrete details on what aspects of the paper need improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is being addressed, making it 1. It also lacks specificity as it does not provide details on what aspects of the paper are insufficient for the ICLR conference or how the authors might improve their draft to meet those standards. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"doubtful\" for the ICLR conference, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the criteria or standards expected for the ICLR conference, the authors are left without a clear understanding of what needs to be improved or how to address the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment expresses doubt about the paper\"s current strength for the ICLR conference, but it does not provide any specific feedback or suggestions on how the authors might improve their draft to meet the standards of the conference. Without actionable guidance or detailed insights into what aspects of the paper are insufficient, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, it does not provide any explicit guidance or suggestions on how the authors might clarify or enhance their contributions. The comment implies that the authors should make their contributions more explicit, but it does not offer concrete steps or examples of what these contributions might be. As a result, the action is implicit and vague, leaving the authors uncertain about how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the major contributions of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the major contributions and the issue of analyzing previous work not constituting a contribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding its major contributions and that analyzing previous work does not constitute a contribution. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the major contributions are unclear and that analyzing previous work does not constitute a contribution. This feedback is valuable as it highlights a critical area for improvement in the paper, namely clarifying the novelty and significance of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as by providing examples of contributions or by explaining how the paper builds upon existing work. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also mentions that the answer is difficult to find in reference 30. This provides a clear and concrete action for the authors to take, which is to clarify the definition and usage of n_t in the algorithm. The comment is specific and provides a direct path for the authors to follow in order to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the \"appropriate number\" in line 225 and notes that the answer is difficult to find in reference 30. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of \"appropriate number\" in Algorithm 2, specifically in line 225, and notes that it is difficult to find the answer in reference 30. This claim is 3 as it highlights a potential issue with the clarity of the algorithm, but it lacks specific examples or references to the exact phrases or sections that need clarification. The reviewer could provide more detailed guidance on how to improve the clarity, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also points out that the answer is difficult to find in reference 30. This feedback is clear and actionable, as it directs the authors to clarify the definition and usage of n_t in the algorithm. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered additional guidance on how to address the issue. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be publicly available. While the comment implies that the authors should make the code available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the code available to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. The comment is specific in its request for the code to be publicly available, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code should be made publicly available. Without additional context or explanation, the claim lacks verifiability, making it challenging for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the difficulty in reproducing the results and questions the availability of the code. While it identifies a potential issue with reproducibility, it does not provide specific guidance or suggestions on how to address this problem. The comment lacks depth and does not offer actionable advice or examples of how the authors might improve the reproducibility of their results. As a result, the feedback is 3, as it points out a potential problem but does not fully support the authors in resolving it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the claims about the mixing time being better in practice are not adequately supported by the experiments. It suggests that the evidence provided is limited, which is a clear indication that the authors need to provide more robust data or analysis to substantiate their claims. However, the comment does not specify what additional evidence or analysis would be needed, leaving the authors to infer the necessary steps to take. While the action is implicit, it is concrete because it clearly identifies the issue and provides a direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claims about the mixing time being better in practice, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient support for these claims in the experiments and the limited evidence provided to practitioners. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims about the mixing time being better in practice are not sufficiently supported by the experiments. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made about the mixing time being better in practice. It points out that the experiments do not provide sufficient support for these claims, leaving the evidence limited for practitioners. This feedback is clear and actionable, as it highlights a critical area where the authors need to strengthen their evidence to substantiate their claims. However, the comment could be more helpful if it suggested specific ways to improve the experimental design or provided examples of how to present the data more effectively. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider this extension and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the protected feature to a vector form, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. This is a 3 suggestion as it could potentially enhance the paper\"s contribution by allowing for more comprehensive analysis and interpretation of the data. However, the comment lacks specific guidance on how to implement this extension or what benefits it might bring to the paper. Without further explanation or examples, the authors may find it challenging to fully understand and act upon the suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the reviewer should denote the vector representations of the words in the equation and whether they are L2normalized. Additionally, it asks for clarification on whether the nearest neighbor examples are computed using cosine or dotproduct. These questions are direct and specific, providing clear guidance on how the authors can improve their draft. The action is explicit and the authors know exactly what needs to be done to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223\" and \"following ones,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including denoting the vector representations of the words, whether the vectors are L2normalized, and the method used for computing nearest neighbor examples. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific aspects of the paper, such as the notation used for vector representations and the method for computing nearest neighbor examples. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas for clarification and improvement in the paper. It points out that the notation for vector representations of words is not clearly defined and suggests that the authors denote these somehow. Additionally, it asks whether the vectors are L2normalized and whether the nearest neighbor examples are computed using cosine or dotproduct. These questions provide the authors with actionable steps to improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to denote the vector representations or provided examples of how this could be done. Overall, the feedback is valuable but could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should run experiments multiple times and report statistics, as a way to address the reproducibility issue in deep RL. It references a recent paper that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a clear action to take, it does not specify how many times the experiments should be run or what specific statistics should be reported. The authors are given a general direction but may need to infer the exact details of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that experiments should be run multiple times and that statistics should be reported to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. However, the comment does not specify which part of the paper this issue pertains to, such as the experimental section or the discussion on reproducibility. While the authors might infer that it relates to the experimental results or methodology, the comment lacks explicit grounding. It is specific about the need for multiple experiments and statistics, but without clear grounding, it is 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that experiments should be run multiple times to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a reference to an external source, it lacks detailed reasoning or specific examples of how running multiple experiments would improve reproducibility. The suggestion is 3, as it provides a logical basis but requires more detailed explanation or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with deep RL, specifically the reproducibility of their results and the significance of their improvements. It suggests that experiments should be run multiple times and that statistics should be reported to address this issue. The comment references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL, providing a relevant external reference to support the suggestion. While the comment highlights a significant area for improvement, it could be more helpful by offering specific guidance on how to implement these changes or what metrics to use for reporting statistics. Overall, the comment provides valuable insight into a critical aspect of the paper and offers actionable suggestions, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for minor issues with the ending punctuation of equations. It also explicitly states that they should ensure consistency in the punctuation, providing clear and concrete guidance on what needs to be done. The action is direct and specific, leaving no ambiguity about how the authors should address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ending punctuation of equations, instructing the authors to ensure consistency in the punctuation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the ending punctuation of equations in Figure 2, Line 433, and Line 468. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor issue with the punctuation of equations in Figure 2, Line 433, and Line 468. It provides specific guidance by instructing the authors to ensure consistency in the ending punctuation of equations, which is a clear and actionable suggestion. This feedback is valuable as it helps the authors improve the accuracy and consistency of their figures, enhancing the overall quality of their draft. However, the comment could be more helpful if it explained why this consistency is important or provided examples of how to achieve it. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution. However, it does not provide any guidance on how the authors should address this issue or suggest ways to differentiate their method. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment suggests that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution. However, it does not specify which part of the paper discusses $kNNECD$ or $kNNMT$, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the similarity between the two methods, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a similarity between the proposed method, $kNNECD$, and an existing method, $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any specific suggestions or guidance on how the authors might differentiate their method or address this issue. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This feedback implies that the authors should clarify the nature of the figures and potentially conduct additional experiments to validate their findings. While the action is implicit, it is clear and concrete, as it specifies what the authors need to do to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially, and suggests conducting realworld experiments to support the phenomenon shown in the figures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This claim is 3 as it logically suggests that realworld experiments could provide additional validation for the results presented in the figures. However, the comment lacks specific examples or references to support the need for such experiments, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This feedback is valuable as it prompts the authors to consider the validity and robustness of their results, which is an important aspect of scientific research. However, the comment could be more helpful if it provided specific guidance on how to conduct these realworld experiments or what aspects of the phenomenon should be evaluated. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance the credibility of their findings."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors did not provide information on the number of parameters used in each approach in Section B.3. This is a clear and direct request for additional information, which the authors can easily address by including this detail in their draft. The action is explicit and concrete, as it specifies exactly what needs to be added to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on the number of parameters used in each approach. This provides clear guidance on what the authors need to add to improve the clarity of their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a request for clarification regarding the number of parameters used in each approach in Section B.3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the number of parameters used in each approach in Section B.3. This is a clear and actionable point that can help the authors improve the clarity and completeness of their paper. By addressing this issue, the authors can ensure that their readers have a better understanding of the experimental setup and results. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This provides a clear and direct action for the authors to take, which is to include these elements in their draft to enhance understanding. The suggestion is concrete, as it specifies exactly what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment suggests adding an example and a figure to help explain the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the definition is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an example and a figure, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why this addition would be beneficial or how it would enhance the understanding of the concept. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to determine the necessity or impact of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This feedback is 3 as it identifies a specific area where the paper could be improved by providing visual aids to enhance understanding. However, the comment lacks depth and does not explain why examples or figures would be beneficial or how they could be integrated into the paper. While it points out a potential improvement, it does not offer detailed guidance or suggestions on how to implement this change. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. The comment lacks actionable details, such as recommending ways to differentiate the method or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the method is considered common or how it can be improved to enhance its novelty. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel because it is related to a common approach in semisupervised learning, specifically selftraining methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning, specifically selftraining methods. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this concern or improve the novelty of their method. Without actionable feedback or constructive guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the assumption among classes not being practical, but it does not provide any explicit or implicit actions for the authors to take. It mentions that the formulation or definition is trivial but suggests that the optimization and theoretical property analysis could provide insights. However, it does not specify what aspects of the optimization or theoretical property analysis should be addressed or how the authors should incorporate these findings into their work. Without clear guidance or actionable steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption among classes and suggests that the formulation or definition is trivial but highlights the importance of optimization and theoretical property analysis. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and the potential value of optimization and theoretical property analysis, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the formulation or definition is trivial, but it lacks specific examples or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption among classes, noting that it is not practical. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment mentions the importance of optimization and theoretical property analysis, but it lacks actionable advice or detailed feedback on how to incorporate these aspects into the paper. Without specific suggestions or examples, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation results in Table 1 are based on only three trials for each case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting a larger sample size or a different statistical method. The action is implicit and somewhat vague, as the authors need to infer that they should increase the number of trials or consider alternative statistical methods to make their results more meaningful. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation results, noting that the three trials per case are not statistically significant and that the deviations reported are not meaningful. The comment further explains why this is problematic, suggesting that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials per case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. The comment provides a logical reasoning that the small sample size makes the reported results insignificant, but it lacks specific examples or references to statistical methods or standards to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation results presented in Table 1, noting that the three trials per case are not statistically significant. It points out that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. This feedback is clear and actionable, as it highlights a critical flaw in the evaluation methodology that the authors need to address to ensure the validity and reliability of their results. By suggesting that the authors should consider using a larger sample size or a different statistical method, the comment provides valuable guidance for improving the draft. However, it could be more helpful if it offered specific suggestions on how to increase the sample size or which statistical methods to use. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific guidance on which papers should be included or how to improve the depth of the feature comparison. The authors are left to infer that they need to include these papers, but without concrete instructions or examples, the action remains vague. Therefore, the comment is 3, as it identifies an issue but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment explicitly mentions the feature comparison with prior work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the shallow comparison and the absence of two relevant papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is \"shallow\" and mentions the absence of two relevant papers. However, it does not provide specific details about which papers are missing or how they would enhance the comparison. Without these details, the claim lacks sufficient evidence or justification to be 5. The authors would need to infer the relevance of the missing papers and determine how they could improve the comparison. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the shallow feature comparison with prior work and the absence of two relevant papers. This feedback is clear and actionable, as it points out a gap in the literature review that the authors can address to enhance the depth and relevance of their analysis. However, the comment could be more helpful if it provided the names or titles of the missing papers, which would guide the authors in their literature search. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims of equivalence without verification. While the comment provides a specific suggestion for improvement, it does not offer concrete guidance on how to apply this suggestion or what specific changes should be made to the wording or claims. The authors are left to infer that they should be more cautious in their usage of the word \"equivalent,\" but without detailed instructions on how to implement this change, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it suggests a more cautious usage of the word \"equivalent\" and advises caution when making claims without verification. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims without verification. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their claims and provide verification when making such claims. This feedback is clear and actionable, as it points out a potential weakness in the paper\"s language and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered examples of how the authors might verify the equivalence or provided guidance on how to use the word more cautiously. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses a lack of understanding regarding the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests that there is a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed analysis of the views. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis and the need for more comprehensive evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the multiview clustering approach is not effective and that the paraphrase similarity view dominates over other views. The reviewer provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but notes that there is no further analysis of the differences and similarities between the views. This lack of analysis makes it difficult to draw solid conclusions about the effectiveness of the different views. The comment is 3 as it provides a specific example and highlights a gap in the analysis, but it lacks detailed evidence or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the effectiveness of the multiview clustering approach, specifically the dominance of the paraphrase similarity view over other views. It highlights the need for a more detailed analysis of the differences and similarities between the views, as well as the lack of such analysis in the paper. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, the comment could be more helpful if it provided specific suggestions on how to conduct the analysis or what aspects should be considered. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This implies that the authors should provide a more detailed explanation of the architecture in their paper. However, the comment does not specify which parts of the paper need more detail or how to present the architecture information. While the action is implied, it is not explicitly stated, and the lack of concrete guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear explanation of the architecture and the reliance on external work for details. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This suggests that the paper lacks selfcontainment. However, the comment does not provide specific examples or references to the architecture or the external work, making it difficult for the authors to understand the exact issue and address it. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specifics of the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained and that the authors rely on external work for details. This is a critical observation that could impact the selfcontainment and clarity of the paper. However, the comment does not provide specific guidance on how to improve the explanation or suggest ways to make the architecture more accessible to readers. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out an inconsistency in the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback provides a clear and direct action for the authors to take, which is to ensure consistency in the typesetting of these terms. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent typesetting of these terms throughout the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"BertScore\" and \"BLEURT\" are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback is clear and actionable, as it points out a specific area where the authors can improve the consistency and readability of their paper. However, the comment could be more helpful if it provided examples of how the inconsistency affects the clarity or understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can enhance the overall quality of their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback implies that the authors should include these results to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. While the action is implied, it is not as clear as it could be, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or analysis sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the inclusion of detailed experimental results. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that increasing the model size can hurt performance, citing a recent paper by Ni et al. that demonstrates the scaling law applies to dense retrieval models. However, the comment does not provide specific details or references to the Ni et al. paper, making it difficult for the authors to fully understand or verify the claim. Without additional context or references, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback is 3 as it points out a potential weakness in the authors\" argument regarding the impact of model size on performance. However, the comment lacks specific guidance on how to present these results or what aspects of the results should be emphasized. While it identifies an area for improvement, it does not provide detailed instructions or examples, making it 3 but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific weaknesses in the presentation quality of the paper, such as the figures, tables, and the management of figures and tables. It provides a list of examples, including the use of a \"Dataset\" column in tables that is not informative, the management of Figure 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. While the comment highlights these issues, it does not provide explicit guidance on how to address them or suggest specific improvements. The authors are left to infer that they need to improve the presentation quality, but without detailed instructions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures and tables, such as Figs 1&2, Table 1, and Table 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these figures and tables, such as the use of a \"Dataset\" column in tables that is not informative, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation quality of the paper is a weakness, specifically mentioning examples such as Figs 1&2, tables with a \"\" for the method, the \"Dataset\" columns in the tables, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. These examples provide a clear rationale for the claim, offering specific observations that can help the authors understand and address the issues. However, the comment could be strengthened by providing more detailed explanations or references to similar practices in highquality publications like NeurIPS. Despite this, the claim is 4, as it is supported by specific examples and logical reasoning.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the presentation quality of the paper, such as the use of a \"Dataset\" column in tables that is not informative, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. By providing examples and detailed descriptions of these issues, the comment offers clear and actionable feedback that can help the authors improve the presentation quality of their paper. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered guidance on how to improve the clarity and informativeness of the tables and figures. Overall, the comment is 4 as it highlights specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include related experiments to demonstrate the utility of the information axis tool. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to conduct additional experiments, but the lack of explicit instruction makes it somewhat vague.", "grounding_specificity_rationale": "The comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not specify which part of the paper this suggestion pertains to, such as the analysis or conclusion sections. The authors can infer that it relates to the analysis or conclusion sections, but this inference is not direct. The comment is specific in suggesting the need for related experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support this claim. The comment is based on a logical assumption that additional experiments would be beneficial, but it lacks the necessary evidence or reasoning to fully substantiate the claim. Therefore, the comment is considered 2, as it provides a suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors include additional experiments to validate their claims. However, the comment lacks specific guidance on which experiments to conduct or how to conduct them effectively. While it points out a gap in the paper, it does not provide detailed instructions or examples on how to address it. Therefore, the comment is 3, as it offers a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they could take to investigate it further. As a result, the comment lacks actionability and does not provide any direction for the authors to improve their draft. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about the current setup or the Greek language. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the Greek language might be causing issues or how the authors might address these issues. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for information about whether other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. While it raises an interesting question, it does not provide any actionable feedback or suggestions for the authors to address this issue or improve their work. Without further context or guidance, the authors may find it challenging to understand how this information could be relevant to their paper or how to incorporate it into their analysis. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" The reviewer implies that the authors should clarify this point to improve clarity. However, the comment does not provide specific guidance on how to clarify this point or what aspects need to be addressed. While the action is implicit, it is clear that the authors need to make changes to improve the clarity of the text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement \"we manually observed the generated examples and find the results acceptable.\" This provides clear guidance on what aspect of the text is unclear and needs improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, noting that it makes a particular point unclear. It points out that the statement \"we manually observed the generated examples and find the results acceptable\" is difficult for readers to understand and evaluate. While the comment highlights an area for improvement, it does not provide detailed guidance or suggestions on how to clarify the text or what specific aspects need clarification. This limits the comment\"s helpfulness, as it offers some insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to conduct experiments on realworld datasets, but the lack of explicit instruction makes it somewhat vague.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper discusses the synthetic versus realworld datasets or the outofdistribution setting. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this suggestion fits, the comment lacks full grounding. It is specific about the need for realworld datasets but does not provide detailed guidance on how to implement this change. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is 3 as it identifies a potential area for improvement in the paper\"s experimental setup. However, the comment lacks specific guidance on how to conduct these experiments or what aspects of the synthetic datasets might be problematic. While it points out a potential issue, it does not provide detailed instructions or examples on how to address it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on what specific aspects of the explanation are unclear or how they could be clarified. The comment implies that the authors should clarify these points, but it lacks concrete instructions or examples of what needs to be improved. As a result, the authors are left with a vague understanding of what changes are needed to make the explanation clearer. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the last paragraph of Section 3 (lines 207210), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the explanations are vague and provides a specific example of the last paragraph in Section 3. This level of detail helps the authors understand what needs to be clarified or improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the vagueness and how it affects the clarity of the explanation. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the explanations in the paper, particularly in the last paragraph of Section 3 (lines 207210) regarding the single image case. This feedback is valuable as it points out a specific area where the authors can improve the clarity and comprehensibility of their explanations. However, the comment could be more helpful if it provided suggestions on how to clarify these vague explanations or offered examples of how similar concepts have been explained in other works. Despite this, the comment still highlights an important area for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, it does not provide explicit instructions or concrete steps on how to extend the analysis to multiple trucks and drones. The authors are left to infer that they should consider this extension, but without specific guidance on how to implement it, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or discussion sections. The authors cannot confidently determine which part of the paper needs to be addressed, making this comment weakly grounded. The suggestion is specific in terms of what the authors should consider, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the suggestion.", "helpfulness_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this change or what benefits it might bring. The comment highlights a potential enhancement but does not provide actionable steps or detailed reasoning to support the authors in making this change. Therefore, the comment is 3, as it points out a direction for improvement but does not fully guide the authors on how to achieve it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or make their approach more novel. There is no guidance on potential modifications, alternative approaches, or additional research directions that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, specifically mentioning that it follows the strategies used in ELECTRA. However, it does not specify which part of the paper discusses this approach, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the lack of novelty, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, the comment does not provide any specific examples or references to the strategies used in ELECTRA, nor does it explain how the proposed approach is similar or different from those used in ELECTRA. Without detailed comparisons or references, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the novelty of the proposed approach to pretraining, noting that it follows the strategies used in ELECTRA. While this observation highlights a potential issue, it does not provide specific guidance or suggestions on how the authors might address this limitation or differentiate their approach. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward to enhance the originality or impact of their work. Therefore, the comment is rated as 2, as it identifies a weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function. It also points out that even a basic bisecting line search will converge linearly, questioning the impact of quadratic convergence on runtime. The reviewer suggests that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is concrete but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of motivation or need for the Newton algorithm and the suggestion to conduct experiments to motivate the analysis/algorithm. The comment provides a clear direction for improvement by suggesting experiments that could help justify the use of the Newton algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function and that even a basic bisecting line search will converge linearly. The reviewer argues that while quadratic convergence is better than linear convergence, the impact on runtime is unclear. The comment suggests conducting experiments to motivate the need for the analysis/algorithm. This claim is 3 as it provides a logical reasoning for questioning the necessity of the Newton algorithm, but it lacks specific examples or references to support the argument about the impact on runtime. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function. It questions the significance of the analysis/algorithm, noting that even a basic bisecting line search will converge linearly. The reviewer suggests that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment highlights a potential weakness in the paper, it does not provide specific guidance on how to address this issue or what experiments to conduct. The feedback is 3 as it points out a potential area for improvement, but it lacks detailed suggestions or actionable advice for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results appear to indicate that \"better NMT systems are also better at idiomatic translations.\" However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. It lacks concrete steps or detailed advice on how to make the methods more idiomspecific or how to improve the results. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed upweighing and KNN methods\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the methods appear to be similar for idiomatic and random data, suggesting that the results indicate that \"better NMT systems are also better at idiomatic translations.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods are not idiomspecific, as the impact on idiomatic and random data appears similar. The reviewer supports this claim by referencing Figure 3, which presumably shows the results of the methods on different language and score combinations. However, the comment lacks specific details or examples from the figure to fully substantiate the claim. While the reference to Figure 3 provides some context, the comment could be strengthened by including more detailed analysis or specific observations from the figure. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results appear to indicate that \"better NMT systems are also better at idiomatic translations.\" This feedback highlights a potential weakness in the methodology and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue, such as proposing alternative methods or suggesting ways to make the methods more idiomspecific. While it identifies a critical area for improvement, the lack of actionable guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the volume calculation and the number of biases, suggesting that the authors should clarify the volume and the number of biases. It also mentions that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The reviewer implies that the current setup is confusing and suggests that the authors should address this issue. However, the comment does not provide specific guidance on how to clarify the volume or the number of biases, nor does it offer suggestions on how to resolve the confusion regarding the number of biases. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the volume calculation and the number of biases, suggesting that the authors should clarify the volume and the number of biases. Additionally, it points out the confusion regarding the number of biases and the number of kernels, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the volume calculation and the number of biases are incorrect, suggesting that the resulting volume should be WxHx1 and that the bias is a scalar. The reviewer also points out that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The comment is 3 as it provides a logical reasoning for the discrepancy in the volume calculation and the number of biases, but it lacks specific examples or references to support the claim. The authors would need to further investigate the issue to fully understand and address the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the volume calculation and the number of biases, suggesting that the resulting volume should be WxHx1 and that the bias is a scalar. It also points out that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. This feedback is 3 as it highlights a potential issue with the paper\"s mathematical modeling, which could lead to confusion for readers. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their modeling. To be more helpful, the comment could provide examples of how the authors might correct the volume calculation or clarify the number of biases. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the equation. The comment lacks actionable details, such as suggesting alternative approaches or methods to mitigate the loss of dynamic information. As a result, the authors are left without a clear understanding of how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equation, noting that subtracting s from the dynamic information could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting s from the dynamic information in Equation 8 could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. This is a valuable observation that could help the authors improve the accuracy and completeness of their model. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending alternative approaches or methods to mitigate the loss of dynamic information. While it points out a relevant concern, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses two questions about the impact of the number of MC samples and the network structure on performance. While it does not explicitly instruct the authors to conduct experiments or provide specific guidance on how to address these questions, the questions themselves are clear and actionable. The authors can infer that they need to conduct experiments to investigate the relationship between the number of MC samples and network structure and their impact on performance. The comment is 3, as it provides a clear direction for the authors to follow but lacks explicit instructions on how to implement the suggested experiments.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of MC samples and the network structure on performance, but it does not specify which part of the paper these questions pertain to. The authors may infer that it relates to the experimental section, but this inference is not direct. The comment is specific in its request for empirical evidence and the need to explore the relationship between the number of MC samples and network structure, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for empirical evidence and exploration of the relationship between the number of MC samples and network structure on performance. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two questions about the impact of the number of MC samples and the network structure on performance, prompting the authors to explore these aspects empirically. While the questions are clear and actionable, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects of the network structure and MC samples should be examined. However, the authors can infer that they need to conduct experiments to address these questions, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the smoothed GT shapes should be shown in Figures 3 and 5 to enhance the understanding of the reconstruction quality. This is a clear and direct action for the authors to take, as it provides a specific request for visual clarity. The comment also mentions a minor concern, which could be addressed by providing additional context or explanation. Overall, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include the smoothed GT shapes, but without full grounding, the authors may struggle to identify the exact figures being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the understanding of the reconstruction. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to enhance the clarity of the paper by showing the smoothed GT shapes in Figures 3 and 5. This suggestion directly addresses a potential issue with the visual presentation of the results, which could help readers better understand the quality of the reconstruction. The comment is clear and constructive, offering a concrete way for the authors to improve their draft. However, it could be more helpful if it provided additional context or explanation on why this visual clarification is important or how it might impact the interpretation of the results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, particularly in the language and vision tasks used for evaluation. It notes that while there is a comparison of training loss and a comparison of the rank of possible solutions, there is no direct comparison of test accuracy. The comment implies that the authors should include direct comparisons of test accuracy to demonstrate the improvement over the baseline. However, it does not explicitly instruct the authors to make these comparisons, leaving the action implicit. The comment is 3 as it provides a clear direction for improvement but lacks concrete guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prior approach PRANC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of direct comparisons with PRANC in the language and vision tasks used to evaluate the proposed approach. The comment provides a clear direction for improvement by suggesting the inclusion of direct comparisons of test accuracy. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in the language or vision tasks used to evaluate the proposed approach. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. The comment suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline that it directly modifies. This claim is 3 as it logically points out the need for direct comparisons to substantiate the claims of improvement. However, it lacks specific examples or references to similar studies that might provide a more robust basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, noting the lack of direct comparisons with the prior approach PRANC in the language or vision tasks used to assess the proposed approach. It highlights the importance of including direct comparisons of test accuracy to demonstrate the improvement over the baseline that is directly modified by the authors. This feedback is clear and actionable, providing the authors with a specific area to address in order to strengthen their evaluation and substantiate their claims. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or provided examples of similar studies that have successfully demonstrated such comparisons. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear direction for enhancing the evaluation section."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It explicitly asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and providing more details on the coverage. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the selection of 21 event types from Freebase and asking about their coverage on the 33 event types in the ACE data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the selection process is problematic. The authors would need to make a significant effort to understand and address the concern, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and their coverage on the 33 event types in the ACE data. This is an important point that could impact the applicability and robustness of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the generalizability of their work. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. While the comment implies that these tasks should be included, it does not explicitly instruct the authors to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to include additional tasks to demonstrate the language modeling capabilities, but the comment lacks concrete guidance on which tasks to include or how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section 5.3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of experiments on tasks that better reflect language modeling capabilities, such as language modeling, machine translation, or text summarization. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not conduct experiments on tasks that better reflect language modeling capabilities, such as language modeling, machine translation, or text summarization. The reviewer suggests that these tasks should be included to strengthen the evaluation of the language modeling capability. However, the comment lacks specific examples or references to support the claim that these tasks are more representative of language modeling capabilities. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. The authors would need to further explore the rationale behind the suggestion to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of experiments on tasks that better reflect language modeling capabilities. It suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental design and demonstrate the importance of their work. By addressing this suggestion, the authors can significantly improve the robustness and comprehensiveness of their evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to cite and discuss important references for domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for references and discussions on domain adaptation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely references and discussions on domain adaptation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact references that are missing. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of important references for domain adaptation. It explicitly instructs the authors to cite and discuss these references in the revised manuscript. This feedback is clear and actionable, providing the authors with a direct and specific way to enhance the paper\"s comprehensiveness and relevance. By addressing this issue, the authors can significantly improve the quality and depth of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions to take. It lacks concrete details on how to verify the suspicion or improve the model. As a result, the authors are left without clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the hyperparameters and the potential issue with the model\"s performance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the suspicion. As a result, the claim is 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. This is a relevant observation that could impact the validity of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or verify the suspicion. It does not provide actionable steps or detailed analysis to help the authors improve their draft. As a result, the comment is 3, as it points out a potential issue but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that certain aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. The comment lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of what needs to be addressed or how to address it. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"w.r.t. to corpora and datasets,\" indicating that it pertains to the experimental setup. However, it does not specify which part of the paper this pertains to, such as a particular section or table where these aspects are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what is unclear or poorly motivated about the corpora and datasets, making it difficult for the authors to understand the exact issues that need to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, it does not provide any specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand which aspects are unclear or poorly motivated. Without specific examples or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that certain aspects, such as corpora and datasets, are unclear or poorly motivated. However, it does not provide any details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be addressed or how to address it. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the proposed method does not show significant improvement over existing RL methods, but it does not provide any specific guidance or suggestions on how the authors could address this issue. There is no explicit or implicit action for the authors to take, such as suggesting ways to improve the method or providing examples of existing RL methods that could be benchmarked. Without actionable advice, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed method does not show significant improvement over existing RL methods, but it does not specify which part of the paper discusses this improvement or where the comparison is made. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of the method are lacking or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method does not show significant improvement over existing RL methods. However, it does not provide any specific examples, comparisons, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the proposed method does not show significant improvement over existing RL methods, which is a critical observation that could impact the paper\"s contribution. However, the comment lacks specificity and does not provide any guidance on how the authors might address this issue or what aspects of the method need improvement. Without actionable feedback or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the model size. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"size of the model\" and the \"hourglass modules,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the model size to competing approaches and the lack of information on the size of each hourglass module. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\"s analysis or conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the size of the model, specifically the depth or number of parameters, and the lack of information on the size of each hourglass module. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the model size, which could be crucial for comparison with competing approaches. However, the comment could be more helpful if it suggested how this information should be presented or what specific details should be included. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, it does not provide explicit guidance on how the authors should address this issue or clarify their claim. The comment lacks concrete suggestions on how to improve the clarity or accuracy of the claim. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that prior work, such as ClimateBench or ClimateSet, already does this, providing a clear indication of what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, the comment does not provide specific examples or references to these works, nor does it explain how the authors\" claim differs from what has already been done. Without detailed evidence or reasoning, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a misleading claim in the paper regarding the treatment of climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already does this, which undermines the originality of the proposed approach. This feedback is 3 as it highlights a potential issue with the clarity and originality of the claim, but it lacks specific suggestions on how the authors might address this misleading aspect or improve the clarity of their claim. While it provides some insight, the comment could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"metric learning theory\" and \"generalization theory of neural networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide specific suggestions on how to address this issue or improve the results. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, the comment lacks specific references to the theoretical works mentioned, such as Bartlett et al. (2017), which would provide context and support for the claim. Without these references, the authors may find it challenging to verify the claim or understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the metric learning theory is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or improve their work. Without specific advice or constructive criticism, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should move some visual results from the supplementary to the main paper. It also points out that there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The reviewer suggests condensing the illustration of the proposed network architecture from three figures to two, and using the extra space for visual results. This feedback provides clear and concrete actions for the authors to take, such as selecting specific visual results to include and condensing the figures. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the main paper and the supplementary material, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that some visual results should be moved from the supplementary to the main paper, and it provides a specific suggestion to condense the illustration of the proposed network architecture from three figures to two. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that visual results should be moved from the supplementary to the main paper, as there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The comment provides a logical reasoning by pointing out the lack of visual results in the main paper and suggesting that condensing the illustration of the proposed network architecture could make room for visual results. However, the comment lacks specific examples or references to support the claim that visual results are necessary or how they would enhance the paper. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should move some visual results from the supplementary to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment of the paper, and recommends condensing the illustration of the proposed network architecture from three figures to two. This suggestion is clear and constructive, as it offers a concrete way for the authors to improve the presentation and clarity of their work. By addressing these points, the authors can enhance the reader\"s understanding and engagement with their research. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should change the notation, provide additional clarification, or revise the terminology. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, which is confusing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the confusion regarding the use of \"r\" for both risks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is confusing or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable observation that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending alternative notations or explaining the context in which these terms are used. Despite this, the feedback is 4 as it points out a specific area for improvement, which the authors can act upon to enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether a test example is crucially different, such as a patient being \"British\" versus \"American,\" and whether this can be detected using the corpus residual value. While the comment implies that the authors should consider this issue, it does not provide explicit guidance on how to address it or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in its question about detecting crucial differences, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a relevant concern or how it could be addressed. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to respond to it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a thoughtprovoking question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. This question highlights a potential issue with the analysis and prompts the authors to consider whether their method can detect such differences. While the comment does not provide specific suggestions or guidance on how to address this issue, it does encourage the authors to think critically about their analysis and consider potential limitations. Therefore, the comment is 3 as it prompts the authors to consider a relevant aspect of their work that could be improved. However, it could be more helpful if it offered actionable steps or examples of how to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. It provides a rationale for this suggestion, noting that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. While the comment explicitly states the action to take, it does not provide specific guidance on how to implement this change or what additional considerations might be necessary. The action is clear but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"WebQuestionsSP\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of dataset, suggesting that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. The reviewer provides a logical reasoning by explaining that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. However, the comment lacks specific references or examples to support the claim that WebQuestions is more suitable for the task. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using a more popular dataset, WebQuestions, instead of WebQuestionsSP for their testbed. It offers a logical reasoning that using WebQuestions would be more intuitive and straightforward, and could facilitate direct comparison with mainstream QA research. This feedback is valuable as it guides the authors to make a more appropriate choice for their dataset, which could enhance the clarity and relevance of their work. However, the comment could be more helpful if it provided additional context or examples of how WebQuestions could be beneficial for their research. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the need for making claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity, and that any potential training speed increases or cost savings must be demonstrated. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It mentions that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence or demonstrations are needed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claims and the need for evidence, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. The reviewer provides a logical reasoning by pointing out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment lacks specific examples or references to support the claim that sparsity is not beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. While the comment identifies a potential weakness in the paper\"s claims, it does not provide specific suggestions or guidance on how the authors might address this issue or demonstrate the benefits of sparsity. The feedback is 3 as it highlights a potential area for improvement, but it lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to differentiate their design or what aspects could be improved to enhance novelty. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of novelty in the paper, specifically mentioning that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what aspect of novelty is lacking, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the novelty of the paper, specifically noting that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It clearly states the need for verifying the effectiveness of the framework on these datasets and suggests that these results should be presented in the main paper. This provides a direct and concrete action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, specifically ImageNet derivatives. This allows the authors to accurately identify the part of the paper being addressed, which is the analysis or results section. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on ImageNet1k or ImageNet100. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, specifically ImageNet derivatives. It provides a logical reasoning by stating that verifying the effectiveness of the framework on these datasets is important. However, the comment does not provide specific examples or references to support the claim that these datasets are necessary for a comprehensive evaluation. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. The authors would need to make a significant effort to understand and address the suggestion fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include analysis or results on other datasets, such as ImageNet derivatives. This feedback is clear and actionable, as it highlights the need for additional experiments to verify the effectiveness of the framework on a broader range of datasets. By addressing this suggestion, the authors can enhance the generalizability and robustness of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct these additional experiments or what specific aspects of the framework should be tested on ImageNet derivatives. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the model design, specifically mentioning that the architecture and learning details are fragmented or missing. It provides a clear suggestion for the authors to address this issue by either providing a plot of model illustration, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the novelty of the Neurochaos Learning method. The explicit action and concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model design\" and \"model architecture and learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the fragmented or missing details of the model design, and provides a concrete suggestion to address this issue by providing a plot, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the novelty of the Neurochaos Learning method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details, specifically mentioning the importance of demonstrating integrated details to facilitate reproducibility. The reviewer suggests providing a plot, pseudocode table, or code repository to address this issue. However, the comment lacks specific examples or references to support the claim that the model design is unclear or that Neurochaos Learning is not wellknown. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides a clear and actionable suggestion for the authors to address this issue by either providing a plot of model illustration, pseudocode table, or code repository. This feedback is valuable as it guides the authors on how to improve the clarity and reproducibility of their work, especially considering the novelty of the Neurochaos Learning method. However, the comment could be more helpful if it included specific examples or detailed guidance on how to present the model details effectively. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is explicit and provides a clear action for the authors to take, which is to update the paper to reflect the correct usage of these models. The suggestion is concrete, as it specifies the exact change needed in the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between how BigFive and MBTI are described in the abstract and introduction sections as models to be extended, versus their usage as datasets in the experiments. The comment provides a clear suggestion to correct this discrepancy by stating the models as datasets throughout the paper, unless there is a specific reason to extend the explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are stated as models to be extended in the abstract and introduction sections, while they are used as datasets in the experiments. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. The comment is 3 as it logically points out a discrepancy in the paper\"s description of these models. However, it lacks specific examples or references to support the claim that the models are not extended beyond their use as datasets. This makes the claim 3, as the authors would need to make a logical inference to address the issue.", "helpfulness_rationale": "The review comment identifies a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is clear and actionable, as it directs the authors to correct the discrepancy in their description of these models. By following this suggestion, the authors can improve the clarity and consistency of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include rejection rates or consider misclassifications as rejections in their experiments. This is a clear and direct action, as it specifies exactly what needs to be added or changed in the paper. The comment provides concrete guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rejection rate\" and \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of rejection rates or the consideration of misclassifications as rejections in the results. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests that one could view a misclassification as a rejection. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is an issue or how it affects the paper\"s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that one could view a misclassification as a rejection, and recommends including rejection rates or considering misclassifications as rejections in the results. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this point, the authors can enhance the transparency and completeness of their experimental results. However, the comment could be more helpful if it explained why the inclusion of rejection rates is important or how it would impact the interpretation of the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the generalization gaps in their work, specifically regarding the finetuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of generalization to the TSP instances, particularly the finetuning step in DIMES. It also specifies what needs to be clarified, namely, the difference between DIMES and other methods on TSP100 indistribution testing performance with/without metalearning. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the generalization gaps in their work, specifically regarding the finetuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment identifies a potential issue with the generalization of DIMES, it lacks specific examples or references to support the claim that these gaps need clarification. The suggestion to compare DIMES with other methods is logical but not fully substantiated. Therefore, the claim is 3, as it provides a direction for improvement but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the generalization of the finetuning step in DIMES and suggests that the authors clarify the difference between DIMES and other methods on TSP100 indistribution testing performance with/without metalearning. This feedback is clear and actionable, as it provides a specific area for improvement and offers a direction for comparison with other methods. By addressing these points, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This provides clear and direct actions for the authors to take, ensuring they know exactly what information is needed to improve their draft. The request for the hyperparameters is specific, and the mention of reproducibility highlights the importance of sharing these details. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what information is needed to improve the reproducibility of the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for information, specifically asking for the final thresholds used for the results and the full set of hyperparameters. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for a claim.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by requesting information on the final thresholds used for the results. This is important for reproducibility and transparency, as it allows other researchers to verify and replicate the findings. Additionally, the comment suggests sharing the full set of hyperparameters, which could further enhance the reproducibility of the work. While the comment is clear and actionable, it could be more helpful if it provided additional guidance on how to present this information or why it is important for reproducibility. Overall, the feedback is valuable but could be more comprehensive with a few additional details. Therefore, it is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. However, it does not provide any explicit or implicit actions for the authors to take. The comment implies that the authors should clarify their methodology or consider alternative methods for answer detection, but it does not specify how to do so or what specific changes should be made. Without concrete guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the potential inconsistency in the authors\" claim and suggesting that it depends on the method/features used for answer detection, such as POS/dependency parse features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. It suggests that the authors\" claim is dependent on the method/features used for answer detection, such as POS/dependency parse features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. It points out that the authors\" conclusion may depend on the method or features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it highlights a potential weakness in the authors\" argument and suggests a direction for further exploration or clarification. However, the comment could be more helpful if it provided specific suggestions on how to address this inconsistency or how to better substantiate the claim. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly instructs the authors to optimize Figure 1 to use less whitespace. This is a clear and direct action, providing the authors with a specific task to improve the visual presentation of their data. The comment is concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, optimizing the use of whitespace in Figure 1. This provides clear guidance on how to improve the visual presentation of the data. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests optimizing Figure 1 to use less whitespace. However, it does not provide any reasoning, evidence, or examples to support why this optimization is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment provides a specific and actionable suggestion to optimize Figure 1 by using less whitespace. This feedback is clear and direct, giving the authors a concrete step to improve the visual presentation of their data. By addressing the issue of excessive whitespace, the authors can enhance the clarity and readability of their figure, making it more effective in communicating their findings. However, the comment could be more helpful if it provided additional guidance on how to achieve this optimization, such as suggesting alternative layouts or techniques. Overall, the comment is 4 as it identifies a specific area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. While the comment implies that the authors should conduct some form of analysis or provide evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional analysis or evidence to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vector space where morphological variants are just close together,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the resulting space is meaningful and suggests providing evidence or analysis to support the claim. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. The reviewer does not provide specific examples or references to support their claim, making it 3. The authors would need to infer the need for such evidence or analysis themselves, as the comment lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. This feedback is valuable as it prompts the authors to consider the significance of their results beyond just improved embeddings. However, the comment could be more helpful if it provided specific suggestions on how to conduct the analysis or what kind of evidence would be most relevant. While it identifies an important area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper needs improvement, specifically noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the comment lacks concrete details on how to achieve these improvements. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying areas for improvement, such as the uneven distribution of space and the missing related work sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment lacks specific examples or references to support the claim that the writing is uneven or that the related work section is incomplete. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some indication but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing quality of the paper, noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. This feedback is 3 as it highlights areas where the paper could be improved in terms of balance and comprehensiveness. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending which sections to prioritize or which related work to include. While it provides some direction, the lack of detailed advice limits its utility for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific line (Line 140) and raises a concern about the first column of Qo being replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to resolve it. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their assumptions, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo by vo to form P\"o, which results in the first state not being reachable anymore. The comment further assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment lacks specific reasoning or evidence to support these claims, such as examples or references to similar studies. This makes the claim 3, as the authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. While the comment highlights a potential problem, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of the recurrent model, suggesting that the sequential relationship might be easier to model. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these areas to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not specify which part of the paper discusses FLOPs or inference time, making it weakly grounded. The suggestion to explore accuracy or specific properties is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks specific examples or references to support the claim that exploring accuracy or specific properties would lead to improvements. The suggestion is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for the authors to explore if there are improvements in accuracy or specific properties if they did not find improvements in FLOPs or inference time. It offers an example of the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is actionable and provides a clear direction for the authors to consider when evaluating their results. However, the comment could be more helpful if it included specific examples or references to support the claim about the sequential relationship. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings was tested. While it implies that the authors should address this assumption, it does not explicitly instruct them to do so. The comment is 3 because it provides a clear direction for the authors to consider testing the assumption, but it lacks concrete guidance on how to conduct the test or what specific aspects to focus on. Therefore, the authors can infer that they need to test the assumption but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption that \"d_e are good replacements for entity embeddings,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks whether this assumption was tested and provides a clear direction for the authors to consider testing it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. This is an important point that could impact the validity and reliability of the paper\"s conclusions. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of testing would be appropriate. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the components of the \"scoring function\" and the different threshold values/ranges. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included to clarify the methodology. The action is implicit and vague, as the authors are left to infer that they need to provide more information about the scoring function and threshold values. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"scoring function\" and the different components and threshold values/ranges, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the components and threshold values/ranges. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"scoring function\" and different threshold values/ranges are unclear, but it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specificity and does not offer any evidence or references to substantiate the claim. As a result, the authors may find it challenging to understand and address the issue without further guidance. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the components of the \"scoring function\" and the different threshold values/ranges. It highlights a lack of clarity in the methodology, which is an important aspect for readers to understand. However, the comment does not provide actionable suggestions or guidance on how the authors might clarify these aspects in their paper. While it points out a potential weakness, it lacks depth and specificity, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the table or what specific changes could be made to enhance the information presented. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the factors in a table do not effectively convey more messages than pure text, and there is no additional information. However, it does not specify which table or part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the table\"s effectiveness, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific issue with the table, suggesting that the factors included do not effectively convey more messages than pure text. It highlights the lack of additional information and implies that the table is not contributing to the overall understanding of the paper. However, the comment does not provide any suggestions or guidance on how the authors might improve the table or what specific changes could be made to enhance its utility. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the simulation should be considered. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what kind of physical interactions are being considered or how they might impact the simulation. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it highlights an area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the simulation should be considered. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. The comment provides explicit actions for the authors to take: to include more datasets with categorical features and to employ one hot encoding for the dataset with categorical features. These actions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Model Comparison\" and the \"wide range\" of datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features and that the authors do not employ one hot encoding for this dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model comparison is inadequate due to the selection of datasets, which only includes one with categorical features. The reviewer supports this claim by explaining that categorical features are generally more challenging for deep learning and that the lack of one hot encoding for this dataset could negatively affect performance. This reasoning is logical and based on common knowledge, making the claim 4. However, the comment could be strengthened by providing specific examples or references to studies that support the challenges of categorical features in deep learning. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their model comparison by including more datasets with categorical features and employing one hot encoding for the dataset with categorical features. By addressing these points, the authors can significantly enhance the robustness and credibility of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. While the comment identifies a potential issue with the choice of datasets, it does not provide explicit guidance on how to address this issue or suggest specific alternatives. The authors are left to infer that they should consider alternative datasets, but the comment lacks concrete details on which datasets would be more suitable or how to incorporate them into the study. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of two unpopular IoT datasets for benchmarking is a strange and unhelpful choice, as they are not widely followed or used. The reviewer supports this claim by referencing specific datasets and their publication dates, which provides some evidence for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of why these datasets are not suitable for benchmarking. As it stands, the claim is 4, as it provides some evidence but lacks comprehensive justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of datasets for benchmarking, specifically the two unpopular IoT datasets mentioned. It provides a specific critique of these choices, noting that they are relatively recent but not widely followed and that one of them is quite old. The comment suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. This feedback is clear and actionable, as it points out a specific area for improvement and provides concrete suggestions for alternative datasets that could be more suitable for benchmarking. However, the comment could be more helpful if it explained why these specific datasets were chosen and how the authors might select better options. Overall, the comment is 4 as it directs the authors to consider alternative datasets for benchmarking, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"pruning\" and \"distributed settings,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients. This is a logical claim based on the observation that pruning is often used with large networks and that distributed settings are common for training. However, the comment lacks specific examples or references to support the claim that finding global top Q values is necessary to avoid breaking acceleration techniques like quantization and sparsification. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. This feedback is valuable as it highlights a potential gap in the authors\" discussion of pruning and its implications on distributed settings. However, the comment could be more helpful if it provided specific examples or references to support the claim about the impact on acceleration techniques. Overall, the comment is 3 as it directs the authors\" attention to an important aspect of their work that requires further consideration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether some subfigures in Figures 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures and potentially correct any errors, it does not provide explicit instructions on how to do so or what specific subfigures might be affected. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking whether some subfigures in Figures 1 and 2 have been swapped by mistake. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the possibility of subfigures in Figures 1 and 2 being swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or verify the accuracy of the figures. The comment lacks actionable feedback or detailed analysis, making it 3 as it points out a potential problem but does not assist the authors in resolving it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the improvement in sensitivity provided by the dropout probe and its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also points out the potential risk of false positives due to the increased sensitivity. The reviewer suggests that this should be a substantial part of the discussion. While the comment implies that the authors should address this issue in their discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the potential risks of false positives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe\" and its ability to improve sensitivity, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential risk of false positives due to the increased sensitivity. This provides clear guidance on what needs to be addressed in the discussion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dropout probe improves sensitivity and identifies a causal role for syntactic representations that previous approaches might have missed. However, it also suggests that this increased sensitivity could lead to an increased risk of false positives. The comment provides a logical reasoning by pointing out the potential tradeoff between sensitivity and false positives, which is a common concern in many scientific studies. However, it lacks specific examples or references to support the claim about the increased risk of false positives. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant improvement in sensitivity provided by the dropout probe, which allows it to find a causal role for syntactic representations that previous approaches might have missed. However, it also points out a potential risk of increased false positives due to the increased sensitivity. This is a valuable observation that could lead to a substantial part of the discussion. The comment provides a clear direction for the authors to consider and address the tradeoff between sensitivity and false positives. While it does not offer specific suggestions on how to manage this risk, it highlights an important aspect that the authors should consider in their discussion. Therefore, the comment is 4, as it provides actionable feedback that can help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer explicitly states that they could not find the regret bound in the supplementary, which implies that the authors should include it. However, the comment does not provide specific guidance on how to present the regret bound or where it should be located in the paper. While the action is clear, the lack of detailed instructions on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed minibatch method being cast to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the regret bound is not provided in the supplementary material and references a specific work for comparison. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support the claim. This reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support their claim. This feedback is clear and actionable, as it directs the authors to include the missing regret bound in the supplementary material. However, the comment could be more helpful if it provided additional guidance on how to present the regret bound or why it is important for the paper. Overall, the comment is 4 as it highlights a critical oversight in the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the paper formatting does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the paper style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as adjusting the formatting style to conform to the NeurIPS guidelines and reorganizing the content accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper formatting, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the formatting, such as the font size of the abstract and the bottom page margins, and suggests that these issues could be resolved by following the NeurIPS formatting style. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that following the NeurIPS formatting style would resolve these issues. However, the comment does not provide any supporting evidence or references to justify why the current formatting is problematic or how it affects the readability or impact of the paper. Without additional context or examples, the claim remains 3, as the authors may need to infer the significance of these formatting issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out specific problems, such as the font size of the abstract and the bottom page margins, and suggests that fixing the paper style could gain some space and allow the inclusion of the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with a concrete step to improve the formatting and organization of their paper. However, it could be more helpful if it included suggestions on how to achieve the desired formatting or examples of how similar papers have addressed these issues. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND and ICM). However, it does not provide any explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or comparison of these methods, but it lacks concrete instructions on how to structure this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on these methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"exploration methods in RL literature, such as countbased methods and intrinsic motivations (RND, ICM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being referred to. Without detailed explanations or references, the claim is not 5, as it relies on general knowledge of RL literature. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). This is a critical oversight, as these methods are widely used and relevant to the field. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending which methods to discuss or how to structure the comparison. While it points out a significant gap in the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights an important area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it implies that the authors should make the annotations larger, it does not provide specific guidance on how to achieve this or what size would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should make the annotations larger but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the enlargement of annotations for better visibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 could be enlarged for better visibility. However, it does not provide any supporting evidence, reasoning, or examples to justify why the annotations are currently too small or how enlarging them would improve visibility. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it provides a specific suggestion for improvement, it lacks depth and does not explain why the current annotations are too small or how enlarging them would impact the clarity of the figure. The comment could be more helpful if it included additional context or examples to guide the authors on how to implement this suggestion effectively. As it stands, the feedback is 3, as it points out a potential issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes should be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the claim regarding the existence of multiple entities in both sentences and documents, including relation classification. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the existence of multiple entities in both sentences and documents, including relation classification. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. This is a clear observation that could lead to a more accurate understanding of the context and scope of the work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their claims. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 4, noting that one of the labels on the color bar should likely say \"worse\" instead of \"better.\" This is an explicit observation that the authors can directly address by changing the label. The action is clear and concrete, as the authors know exactly what needs to be corrected. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, noting that one of the labels should say \"worse\" instead of \"better.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a specific figure in the paper, noting that one of the labels on the color bar is incorrect. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that one of the labels on the color bar is incorrect. This is a clear and actionable observation that the authors can easily address to improve the accuracy and clarity of their visual presentation. However, the comment does not provide additional context or suggestions on how to improve the figure or what other labels might be mislabeled. While it points out a specific error, it lacks depth and could be more helpful by offering additional guidance or explanation. Therefore, the comment is 3, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely, changing \"training/validation/test\" to \"training/validation/test sets.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, noting a specific error in the text regarding the use of \"training/validation/test\" instead of \"training/validation/test sets.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and actionable suggestion that can help the authors improve the accuracy and clarity of their manuscript. By addressing this error, the authors can ensure that their paper is more precise and professional in its presentation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and concerns about the paper, but it does not provide explicit or implicit actions for the authors to take. It asks for clarification on the inference process and the coefficient of the p(L, E | X) term in line 307, but it does not instruct the authors on how to address these questions or provide guidance on how to improve the clarity of the writing. The comment also mentions missing hyperparameter details and suggests that ablation studies may not be welltuned, but it does not provide specific suggestions for improvement. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, but it does not specify which part of the paper these issues pertain to. It mentions \"line 307\" but does not provide context or details about what is being referred to. The comment also lacks specificity in terms of what is unclear or missing in the paper, such as the coefficient of the p(L, E | X) term or the hyperparameter details. Without clear references or specific guidance, the authors cannot effectively address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions are presented as observations without detailed explanation or justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. It questions the inference process and the coefficient of the term, asking for clarification on the basis of these elements. Additionally, it points out the lack of hyperparameter details and suggests that ablation studies may not be welltuned, which could impact the confidence of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their writing. While it identifies areas for improvement, the feedback lacks actionable steps or detailed advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and recommends adding extra brackets around the term or defining the bracketed term separately if space allows. This provides a clear and explicit action for the authors to take, which is to clarify the definition by adding brackets or defining the bracketed term. The comment is specific and provides concrete guidance on how to improve the clarity of the definition. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to clarify the definition by adding extra brackets or defining the bracketed term separately if space allows. This level of detail provides the authors with clear guidance on how to improve the clarity of the definition. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and proposes adding extra brackets or defining the bracketed term separately to clarify it. However, the comment does not provide any specific reasoning or examples to support why the current definition is confusing or how the proposed changes would improve clarity. Without additional context or explanation, the authors may find it challenging to understand and implement the suggested changes. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the definition of the quantile, which is described as \"a little confusing.\" It provides a clear and actionable suggestion to improve clarity by adding extra brackets around the term or defining the bracketed term separately if space allows. This feedback is valuable as it directly addresses a potential source of confusion and offers a concrete way to enhance the clarity of the definition. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context on how the suggested changes would improve understanding. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model mentioned in Line 152 is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. This feedback is explicit and provides a clear action for the authors to take, specifying the exact change needed to update the text. The suggestion is concrete, as it provides a specific alternative phrase to use, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the outdated nature of the model mentioned and the suggestion to replace it with a more current description. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model mentioned in Line 152 is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model mentioned in Line 152 is no longer stateoftheart. It provides a clear and actionable suggestion to replace the outdated reference with a more appropriate description, such as \"very high performing model\" or similar. This feedback is valuable as it helps the authors maintain the accuracy and relevance of their work by updating their references to current standards. However, the comment could be more helpful if it included a rationale or explanation for why the original reference is no longer relevant. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is identified as the main weakness of the method. However, the comment does not provide any guidance on how the authors should address this issue or suggest specific actions to improve the performance. The authors are left without any concrete steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed compression\" and \"PQ,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the proposed compression performs worse than PQ when a small code length is allowed, which is the main weakness of the method. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional details or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is considered the main weakness of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the performance of their method. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as 2, as it points out a weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment explicitly instructs the authors to provide a detailed explanation to verify these statements. While the action is clear, it is somewhat vague in terms of how to present the explanation, as it does not specify the exact format or content of the explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references, and the laborintensive nature of designing effective architectures. It also mentions the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. However, the comment does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for proofs and references, and the need for a detailed explanation of the multiscale architecture design. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the appropriateness of subjective statements, the need for proofs and references, and the laborintensive nature of designing effective architectures. It also questions the implicit multiscale methods used by models with skip connections. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or examples makes the claims 3, as the authors would need to make a significant effort to address the feedback effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment provides specific feedback on what the authors need to address, such as the need for detailed explanations and references to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to improve the paper in these areas. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how the proposed method compares with prior art. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what aspects of the comparison should be addressed or how the authors should present this information. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section \"3),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking how the proposed method compares with prior art. However, it lacks specificity regarding what aspects of the comparison should be addressed or how the authors should present this information. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point poses a question about how the proposed method compares with prior art. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question about how the proposed method compares with prior art. While it highlights an important area for consideration, it does not provide any guidance or suggestions on how the authors might address this comparison or what specific aspects of prior art should be considered. Without actionable feedback or direction, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that the authors should explore potential biases in the data and compare them across different languages/nationalities. While the comment does not explicitly instruct the authors to conduct this analysis, it provides a clear direction for improvement by highlighting a specific area that could be expanded upon. The action is implicit but concrete, as it points to a specific aspect of the analysis that could be enhanced. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring potential biases in the data and comparing them across different languages/nationalities. This provides clear guidance on what the authors could address to improve their analysis. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that there might be interesting observations to be made about biases towards different languages/nationalities. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such observations would be interesting or valuable. Without additional context or evidence, the claim remains somewhat vague, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the analysis, suggesting that the \"language/nationality\" section could be more detailed by exploring potential biases across different languages/nationalities. It implies that there might be interesting observations to be made about these biases, which could enhance the analysis and contribute to the paper\"s overall quality. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what specific observations might be interesting. This limits the comment\"s helpfulness, as it points out an area for improvement but does not provide detailed guidance on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. While the question implies that the authors should consider exploring other properties, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore other feature properties. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this discussion might be relevant. The authors can infer that it relates to the methodology or approach sections, but this inference is not direct. The comment is specific in its suggestion to explore other properties of features, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the approach. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a pertinent question about the use of other properties of features in addition to norm, suggesting that this could be necessary and helpful for the approach design. This is a valuable point as it prompts the authors to consider alternative ways to enhance their methodology. However, the comment lacks specific guidance or examples on which properties might be beneficial or how to incorporate them into the approach. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential area for enhancement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. However, it does not provide explicit guidance on how to address these weaknesses or suggest specific changes. The authors are left to infer that they should make changes to the method, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. The comment also questions why the d is a simpler network. However, it does not provide specific suggestions or examples on how to address these issues, making the comment somewhat specific but fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is mostly constructed on top of previous methods, lacks network changes or losses, and questions the use of two SIRENs for f and d. The reviewer also questions why the d should be a simpler network. While the comment identifies specific weaknesses, it lacks detailed reasoning or examples to fully substantiate the claims. The authors would need to infer the basis of these criticisms and determine how to address them. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. It questions why the d should be a simpler network and suggests that the method is mostly constructed on top of previous methods. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how to address these weaknesses. The authors are left with a general understanding of the issues but without actionable steps to improve their draft. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the RQ1 mentioned in the paper is redundant and does not provide additional information. It proposes an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a specific reference to a related work that could guide the authors in conducting this analysis. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1\" and \"RQ2\" and \"RQ3 tsne plots,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the redundancy of RQ1 and the potential analysis of the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reference to a specific work provides additional guidance on how to conduct this analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information. It suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a reference to a related work, which supports the claim by offering a specific example of how such an analysis could be conducted. This provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by including more detailed reasoning or examples from the reference to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the RQ1 mentioned in the paper and suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. It provides a specific reference to a related work that could guide the authors in conducting this analysis. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their draft by exploring a new area of analysis. However, the comment could be more helpful if it provided additional guidance on how to conduct the analysis or explained why the suggested analysis is important. Overall, the comment is 4 as it offers a specific and constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any specific guidance on what these tasks might be or how the authors should address this expectation. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the importance of PE in tasks beyond link prediction. Without concrete instructions or examples, the authors may find it challenging to know how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not specify which part of the paper this expectation is based on, nor does it provide details on what specific tasks should be discussed or how the authors should address this suggestion. Without explicit references to sections or specific tasks, the authors cannot confidently determine which parts of the paper need attention. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any supporting evidence, reasoning, or examples to justify why this expectation is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on what tasks or aspects of PE should be discussed. The comment does not offer actionable advice or examples, leaving the authors without clear direction on how to address this suggestion. As a result, the feedback is not helpful, as it does not provide the authors with a concrete path to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. While it implies that the authors should provide a comparison or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the difference between the authors\" work and other works focusing on semantic face editing. However, it does not specify which part of the paper this comparison should be made, nor does it provide details on what aspects of the work need to be compared. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a valid point by asking the authors to elaborate on the difference between their work and other works focusing on semantic face editing. This is a constructive suggestion that could help the authors better position their contribution in the context of existing research. However, the comment lacks specific guidance on how to address this difference or what aspects of the work should be compared. While it identifies an important area for improvement, it does not provide detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to reduce the use of footnotes and move important content into the main body of the paper. It provides a specific example by suggesting moving details around parameter settings to the appendix. This feedback is clear and concrete, giving the authors a direct action to take to improve the draft. The suggestion to move content to the appendix is also detailed, providing specific guidance on how to structure the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the extensive use of footnotes in the paper, suggesting that much of the content is important and should be moved into the main body. It provides a specific example by suggesting moving details around parameter settings to the appendix. This allows the authors to identify the section where footnotes are used excessively, making the comment fully grounded. The comment is also specific in detailing what needs to be addressed, such as moving content to the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively in the paper, which is distracting. It suggests that much of the content is important and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting moving details around parameter settings to the appendix. This suggestion is based on logical reasoning and common sense, as excessive footnotes can indeed be distracting and may not be necessary for the main content. However, the comment could be strengthened by providing more detailed examples or references to similar studies that have successfully reduced footnote usage. Overall, the claim is 4, as it provides a clear rationale and example for improvement.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the excessive use of footnotes. It suggests that much of the content is important and should be moved into the main body of the paper, which would improve the readability and clarity of the paper. The comment provides a specific example by suggesting moving details around parameter settings to the appendix, which is a clear and actionable suggestion. Additionally, it encourages the authors to reconsider the use of footnotes and prioritize the main content of the paper. This feedback is 5 as it offers a concrete way for the authors to improve the organization and flow of their paper, making it more accessible to readers. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts. It also mentions that the inclusion of zeroshot generation results seems strange and might satisfy general curiosity about the capabilities of the LLM in this setting. However, the comment does not provide explicit instructions on how to incorporate these suggestions or what specific aspects of the discussion should be included. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts. It also mentions the inclusion of zeroshot generation results, which seems strange in the context of the paper. However, the comment does not specify which part of the paper these suggestions pertain to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a discussion about fewshot demonstrations and the inclusion of zeroshot generation results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results seems strange in the context of the paper, implying that it might not be relevant or necessary. However, the comment does not provide specific reasoning or evidence to support this claim, such as explaining why zeroshot generation results are not relevant or how they might detract from the paper\"s focus. Without detailed justification or examples, the claim remains 3, as it lacks the necessary support to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive critique by suggesting that the inclusion of zeroshot generation results might be somewhat strange in the context of the paper. It acknowledges the interesting and relevant experiments but questions the relevance of the zeroshot generation results. The comment also suggests that a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts, would be beneficial. While the feedback identifies areas for improvement, it lacks specific guidance on how to incorporate these suggestions or what aspects of the discussion should be included. This limits the comment\"s helpfulness, as it provides insight but does not offer detailed instructions for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific problem, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to update the caption or add references to the body text, but the comment lacks concrete details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that \"OAA\" is never referenced in the body text and suggesting that there might be more content in the appendix that is missing or the caption is out of date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"OAA\" is never referenced in the body text of Figure 3, suggesting that there might be more content in the appendix that is missing or the caption is out of date. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment highlights a specific problem, it lacks depth and does not provide actionable guidance or suggestions on how to address the issue. The authors are left with a clear indication of a problem but without detailed instructions on how to resolve it. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to clarify in the introduction that the proposed solution is a fix of 12, rather than a new PIC approach. It provides a specific suggestion to make this clarification by mentioning the reference in lines 2930. The comment is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (2930) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of whether the proposed solution is a fix of 12 or a new PIC approach. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors need to clarify in the introduction that the proposed solution is a fix of 12, rather than a new PIC approach. The reviewer supports this claim by referencing specific lines in the paper (2930) where the proposed solution is introduced as a new PIC approach. This provides a clear and specific example of the issue, making the claim verifiable. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the introduction section of the paper. It points out that the authors need to clarify that the proposed solution is a fix of 12, rather than a new PIC approach, as it is currently presented. This feedback is clear and actionable, as it provides a direct suggestion for improvement by suggesting a specific line in the paper where the clarification should be made. By addressing this issue, the authors can enhance the clarity and accuracy of their introduction, which is crucial for the overall understanding and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference 2. However, it does not provide explicit instructions or suggestions on how the authors should address this question or investigate the impact of the GS module on the effective receptive field. The comment lacks concrete guidance on what specific analyses or experiments the authors should conduct to answer this question. As a result, the authors are left without clear direction on how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module\" and suggests that the effective receptive field can be computed from a reference 2. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks a question about the effectiveness of the GS module and suggests that the authors investigate how the effective receptive field changed after applying it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the effectiveness of the GS module in propagating context information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference 2. This is an interesting point that could lead to a valuable exploration of the impact of the GS module on the effective receptive field. However, the comment lacks specific guidance or suggestions on how the authors might investigate or analyze this effect. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network computing the value functions for the states during the finetuning stage. While the comment provides a clear action\u2014adding another head to the network\u2014it does not specify how to implement this addition or what specific changes are needed in the code or methodology. The authors are left with a general idea of what to do but without detailed guidance on execution. Therefore, the comment is 3, as it provides a clear action but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the LSTM is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting an additional step for the finetuning stage, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage to compute the value functions for the states. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement this suggestion or what specific changes are needed. The authors are given a general idea of what to do but are not provided with detailed instructions or examples on how to execute this suggestion effectively. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC and asks whether G4RL requires HRAC\"s regularization in the latent space. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HRACG4RL,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind combining G4RL with HRAC and asks whether G4RL requires HRAC\"s regularization in the latent space. This is a relevant question that could help the authors understand the basis of their method and its potential limitations. However, the comment does not provide any suggestions or guidance on how to address this question or improve the draft. While it points out an area for clarification, it lacks actionable feedback that would help the authors improve their work. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works related to supervised, multilingual systems. While the comment implies that the authors should include this acknowledgment, it does not provide specific guidance on which works to mention or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works related to supervised, multilingual systems, providing clear guidance on what needs to be addressed in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works related to supervised, multilingual systems. However, it does not provide specific examples or references to these older works, nor does it explain why acknowledging them is important. Without additional context or reasoning, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works related to supervised, multilingual systems. While it identifies a potential gap in the literature review, it does not provide specific examples of older works to consider or explain why acknowledging them would be beneficial. The comment is 3 as it points out an area for improvement, but it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling method, which appears to underperform uniform sampling. The reviewer points out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their results. The authors are left to infer that they need to reconsider their sampling method or provide additional analysis to support their claims. While the comment highlights a potential issue, it lacks concrete instructions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the results in Table 2, particularly the linear/exponentialdecay sampling method, which appears to underperform uniform sampling. The comment further explains the potential issue by suggesting that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the linear/exponentialdecay sampling method, which appears to underperform uniform sampling. The reviewer argues that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is rather close. This claim is 3 as it provides a logical reasoning based on the assumption of predictor accuracy in the good subregion. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling method, which appears to underperform uniform sampling. The reviewer points out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is rather close. This feedback highlights a potential issue with the results and suggests a possible explanation for the observed underperformance. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or what additional analyses could be conducted to support their claims. Overall, the comment identifies a potential weakness but lacks detailed guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the time complexity of the proposed method, including the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the time complexity. The comment lacks concrete details on how to implement these improvements, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the time complexity, such as the potential for many users associated with a typical item and the larger number of hidden units compared to matrix factorizationbased methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. While the comment provides some reasoning by mentioning these factors, it lacks specific examples or detailed explanations to fully substantiate the claim. The authors would need to infer the exact impact of these factors on the time complexity, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. It highlights that these factors could contribute to a high time complexity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the time complexity. While it points out a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the figures would be clearer if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a specific action for the authors to take, which is to add this information to the figures to enhance clarity. The comment is explicit and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment suggests that many of the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting what needs to be clarified, namely the types of autoencoders used in the figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figures. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that many of the figures would be more clear if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is 3 as it identifies a specific area for improvement in the clarity of the figures, which could enhance the readers\" understanding of the content. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it is important. Additionally, it does not address other aspects of the paper, such as the content or methodology. Therefore, the comment is 3, as it points out a specific area for improvement but lacks comprehensive guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison with a NeRFbased method, specifically mentioning the recent Zero1to3 and pointe. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides explicit actions to include comparisons and question the relevance, it lacks concrete details on how to implement these suggestions. The authors are given a clear direction but may need to infer the specifics of how to conduct the comparisons and address the relevance issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment does not specify which part of the paper these comparisons or the relevance issue should be addressed in, making it weakly grounded. The comment is specific in suggesting the inclusion of comparisons and the relevance issue, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that a comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe, is missing. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment lacks specific examples or detailed reasoning to support these claims. The suggestion to include comparisons is 3, as it provides a direction for improvement, but the critique of the relevance is not fully substantiated. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of comparisons with NeRFbased methods, such as Zero1to3 and pointe. This suggestion is clear and can help the authors improve the comprehensiveness and relevance of their work. Additionally, the comment questions the relevance of the occlusion experiment, which could be a critical area for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples of how these comparisons could enhance the paper. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the use of subscripts s and t in Figure 1. While the comment implies that the authors should provide an explanation for \"multiaspect\" and clarify the subscripts in Figure 1, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation and clarify the subscripts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (14 and 47) and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a brief explanation of \"multiaspect\" and the use of subscripts s and t in Figure 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the use of subscripts s and t in Figure 1. However, it does not provide any reasoning or evidence to support why these elements are unclear or problematic. The comment lacks specific examples or references to justify the need for an explanation or the use of subscripts. As a result, the claim is not verifiable, as it does not provide sufficient justification for the authors to understand or address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the paper, namely the need for a brief explanation of the term \"multiaspect\" and the use of subscripts s and t in Figure 1. While it highlights these issues, the comment lacks depth and does not provide detailed guidance on how to address them. It does not offer suggestions on what kind of explanation would be helpful or how to clarify the subscripts. As a result, the feedback is 3, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the methodology used to extract parts of sentences and documents, specifically asking about the rules of extraction and their potential impact on the experiment. While the comment implies that the authors should provide more detailed analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p,\" which likely refers to a specific parameter or variable used in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises questions about the methodology used to extract parts of sentences and documents, and it asks for a more detailed analysis of the rules of extraction and their potential impact on the experiment. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used to extract parts of sentences and documents. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the methodology used to extract parts of sentences and documents, specifically asking about the rules of extraction and their potential impact on the experiment. This feedback is valuable as it prompts the authors to provide more detailed analysis and explanation of their methodology, which could enhance the transparency and robustness of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or what additional details to include in the analysis. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This is a clear and direct request for additional details that the authors can easily address by providing the requested information. The action is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what information is needed, providing clear guidance on what needs to be added to the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for additional information about the computational requirements and runtime of the experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it prompts the authors to provide additional information about the computational requirements and runtime of the experiments. This is important as it can help the authors understand the feasibility and scalability of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this information or what aspects to focus on. Despite this, the feedback is clear and actionable, guiding the authors to enhance the transparency and reproducibility of their work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors only apply the meta sampler in a decoupled way, specifically when the features are fixed. It also requests more discussion on this aspect and asks for clarification on when the authors start applying the meta sampler. While the comment implies that the authors should provide more information on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta sampler\" and the \"linear classifier,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether the meta sampler is applied in a decoupled way and requests more discussion on this topic. Additionally, it asks for clarification on when the meta sampler is applied, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It highlights a potential area for clarification and expansion in the paper, which could enhance the understanding of the methodology. However, the comment does not provide detailed guidance or suggestions on how to address this issue or what specific aspects of the discussion should be expanded. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and encourages them to follow a cited AAAI paper on fairnessaware metrics like Equality Odds (EO). While the comment provides a specific recommendation to conduct more experiments and mentions a relevant paper, it does not explicitly instruct the authors on how to implement these suggestions or what specific aspects of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a vanilla metric and suggests conducting more experiments on datasets like COMPAS and Drug Consumption. It also references a specific paper, \"Exacerbating Algorithmic Bias through Fairness Attacks,\" which provides a clear context for the authors to understand the feedback. However, the comment lacks specificity regarding what aspects of the paper need improvement or how the authors should conduct these experiments. While it provides a clear direction, the lack of detailed guidance on execution makes it fully grounded but underspecific. Therefore, this comment aligns with category 4.", "verifiability_rationale": "The review point suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and mentions a specific paper for reference. However, the comment does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would improve the paper. The mention of the cited paper provides some context, but the claim lacks detailed justification or examples to fully substantiate the suggestion. Therefore, the comment is 3, as it provides a direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors use their own defined vanilla metric and lack related fairnessaware metrics like Equality Odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption, and references a specific paper for guidance. While the comment provides a clear direction for improvement, it lacks detailed guidance on how to conduct these experiments or what specific aspects of the paper should be revised. The feedback is 3 as it points out a gap in the paper but could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to either state the content as a remark or move it to a Discussion section, or to remove it altogether. This provides a clear and direct action for the authors to take, ensuring that the content is either appropriately labeled or removed from the paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L107114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether the content is speculative or overly opinionated and suggests that it should be stated as a remark or moved to a Discussion section. This provides clear guidance on how to handle the content. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"L107114 seems speculative or overly opinionated.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (L107114) as potentially being speculative or overly opinionated. It suggests that this content should be either stated as a remark or moved to a Discussion section, or removed altogether. This feedback is clear and actionable, providing the authors with a concrete suggestion on how to address the issue of potentially overly subjective content. However, the comment could be more helpful if it explained why this section is considered speculative or overly opinionated, which would give the authors a better understanding of the rationale behind the suggestion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is concrete, as it specifies the baselines to consider, but it is somewhat vague because it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the evaluation or experimental sections, but this inference is not direct. The comment is specific in suggesting the inclusion of these baselines, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these baselines are relevant or how they would impact the evaluation. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why these specific baselines are relevant. While it points out a potential enhancement, it could be more helpful if it included more detailed reasoning or examples of how these baselines could be integrated into the evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies two missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing readers with intuitive knowledge of the value of h and the robustness of the method with respect to different neighborhood sizes is essential. Additionally, it questions the use of different hyperparameter sets per dataset and suggests that the authors provide insights into how performance varies with a constant set of parameters. The comment is clear and provides specific actions for the authors to take, such as conducting an analysis of h and standardizing hyperparameter sets. The explicit nature of the suggestions and the concrete details on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for an analysis of the robustness of the method with respect to different neighborhood sizes and the use of different hyperparameter sets per dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the value of neighborhood size h and its influence on the model\"s performance are missing elements in the paper. It suggests that this is a key parameter and that providing insights into its value and robustness is essential. The comment also questions the use of different hyperparameter sets per dataset, suggesting that standardizing these parameters would be beneficial. While the comment provides a logical reasoning for the importance of these elements, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two important missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing readers with intuitive knowledge of the value of h and the robustness of the method with respect to different neighborhood sizes is essential. Additionally, it questions the use of different hyperparameter sets per dataset and suggests that the authors provide insights into how performance varies with a constant set of parameters. This feedback is clear and actionable, as it directs the authors to address specific gaps in their work that could significantly impact the reader\"s understanding and interpretation of the results. By providing detailed guidance on how to enhance the paper, the comment is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment implies that the authors should consider these questions and potentially address them in their paper, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects of the model. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the model\"s performance or analysis. The comment is specific in its inquiry about the impact of missing modalities and the potential for leveraging additional modalities. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point poses a question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities affect the model\"s ability to construct higherorder interactions and polynomial tensors. The comment does not make a claim or express an opinion but rather seeks clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it prompts the authors to consider a critical aspect of their model\"s robustness and generalizability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or explore the impact of missing modalities. Overall, the comment is 3 as it directs the authors to consider an important aspect of their model but lacks detailed guidance on how to implement the suggested exploration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides a specific example of how this could be done by showing the frequency of these words in the dataset. The comment is explicit in its request for additional data analysis, providing concrete guidance on what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The comment provides a specific example of how this could be done, making it clear and actionable. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The reviewer provides a specific example of how this could be done, which is to show the frequency of these words in the dataset. This suggestion is based on logical reasoning and common knowledge about the nature of datasets and data analysis. However, the comment lacks references or detailed justification for why this analysis is necessary or how it would enhance the paper. Therefore, the claim is 3, as it provides a logical suggestion but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by requesting the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It offers a clear example of how this could be done, which is to show the frequency of these words in the dataset. This feedback is actionable and can help the authors enhance the clarity and depth of their analysis. However, the comment could be more helpful if it explained why this analysis is important or how it would contribute to the paper\"s overall contribution. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, specifically mentioning DrugOOD. It suggests that the authors should verify the stability of their model on this benchmark, which is a clear and explicit action. However, the comment does not provide specific guidance on how to conduct this verification or what metrics to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific benchmark dataset, DrugOOD, and the work by SPE, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of verification of the stability of the OGEAug on OOD benchmarks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, specifically mentioning DrugOOD. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not verified the stability of their model, the OGEAug, on outofdistribution (OOD) benchmarks like DrugOOD. It points out that the stability of the model is not validated on this dataset, despite the fact that SPE is validated on this dataset. This feedback is clear and actionable, as it directs the authors to verify the stability of their model on OOD benchmarks, which is a crucial aspect of model robustness. However, the comment could be more helpful if it provided additional guidance on how to conduct this verification or what specific metrics to use. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider freezing some layers of the model while only training a few layers or using parameterefficient methods like LoRA. These suggestions are explicit and provide clear actions for the authors to take, such as considering these methods for experimental comparison. The comment also specifies the potential benefits of these approaches, making it clear what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests considering freezing some layers of the model or using parameterefficient methods like LoRA for experimental comparison. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the model training or parameter efficiency sections, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors consider alternative methods, such as freezing some layers or using LoRA, for parameterefficient model training. While it provides a logical reasoning for considering these methods, it lacks specific examples or references to support the claim that these methods are \"natural to think about\" or \"valuable for experimental comparison.\" This makes the claim 3, as the authors would need to infer the benefits and applicability of these methods themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors consider alternative methods for parameterefficient model training, such as freezing some layers or using LoRA. This feedback is actionable and provides a clear direction for the authors to explore additional approaches that could enhance their experimental comparison. By suggesting these methods, the reviewer highlights a potential area for improvement that could enhance the rigor and comprehensiveness of the study. However, the comment could be more helpful if it provided specific examples or references to these methods, which would guide the authors more directly in implementing these suggestions. Overall, the comment is 4 as it identifies a valuable area for exploration and provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to expand the related work section and compare their work to strong baselines that use coordinates. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to expand this section and compare it to strong baselines that use coordinates. This level of detail provides full grounding and specificity, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing it to strong baselines that use coordinates. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for expanding the related work section and comparing it to strong baselines that use coordinates. This feedback is specific and offers a concrete direction for improvement, which can help the authors enhance the comprehensiveness and relevance of their work. By addressing this suggestion, the authors can strengthen their paper by demonstrating the novelty and effectiveness of their approach in comparison to existing methods. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the experiments should be expanded to include multiple seed experiments. This provides a clear and direct action for the authors to take, as it specifies a specific improvement that would enhance the robustness and significance of the evaluation. The comment is specific in detailing what needs to be added to the experiments, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Single Seed Experiments\" and suggests expanding the experiments to include multiple seeds. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for multiple seed experiments to provide a more robust evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. This claim is 3 as it logically argues that multiple seed experiments would offer a more comprehensive assessment. However, it lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s experiments, specifically the use of a single seed for training. It suggests that multiple seed experiments would provide a more robust evaluation, which is a valid point. However, the comment does not offer specific guidance on how to implement these additional experiments or what aspects of the results would be most valuable. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, asking for clarification on the motivation behind this choice. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, indicating a lack of clarity in the motivation behind this choice. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, suggesting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It highlights a potential lack of clarity in the paper regarding the rationale behind this choice. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify their motivation. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, making it less accessible for many potential users. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more accessible or suggestions for alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, which makes it less accessible for many potential users. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this requirement affects the accessibility of the method. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible for many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the accessibility of the method. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the accessibility of the proposed method, noting that an entire multiGPU setup is required for optimizations. This is a relevant point that could impact the practicality and adoption of the method by users who may not have access to such a setup. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting ways to make the method more accessible. While it highlights a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing citation for the public skipgram data set in L425. This is a clear and direct action for the authors to take, as it specifies the exact part of the paper that needs to be revised. The comment provides concrete guidance on what needs to be added, making it 5. Authors know exactly what to do to address this issue, ensuring that the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing citation for the public skipgram data set. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing citation for the public skipgram data set in L425. This is a factual statement that does not require any verification or justification. It is a request for clarification or correction, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the missing citation for the public skipgram data set in L425. This is a clear and actionable piece of feedback that the authors can easily address by adding the missing citation. By pointing out this oversight, the comment helps the authors improve the accuracy and completeness of their work. However, it could be more helpful if it provided additional context or explanation about the significance of the data set or its relevance to the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref2 as a baseline. It provides a clear and concrete action for the authors to take, which is to compare their system with another that captures semantics. However, the comment does not specify which aspects of the current system should be compared or how to implement the comparison. While the action is explicit, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that captures semantics, potentially using Ref2 as a baseline. However, it does not specify which part of the paper this comparison should be made, such as a specific section or experiment. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not direct. The comment is specific in suggesting a potential baseline and a comparison approach, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the current system with another system that captures semantics, potentially using Ref2 as a baseline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered actionable. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref2 as a baseline. This is a constructive suggestion that could help the authors improve the evaluation of their system by providing a more comprehensive comparison. However, the comment lacks specific guidance on how to implement this comparison or which aspects of the current system should be compared. While it identifies a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the data used for training, validating, and testing. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should clarify the data sources, but it lacks concrete steps or examples of what should be done to improve the clarity. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the quantitative results and the need for clarity regarding the data used for training, validating, and testing. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what specific data sources or methods should be used to clarify the results. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point questions the clarity of the quantitative results, specifically asking for more information on the data used for training, validating, and testing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the results are unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the quantitative results, specifically questioning the clarity of the data used for training, validating, and testing. This is a relevant point that could impact the reproducibility and understanding of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect of their work. While it points out a potential issue, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not provide specific guidance on how the authors should address these issues or what steps to take to improve the model. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the assumptions and learning difficulties, but without clear grounding, the authors cannot confidently determine which part of the paper needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the assumptions are not met or that learning difficulties exist. Without such evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. It prompts the authors to consider whether these issues are related to assumptions or learning difficulties. While the comment identifies a potential problem, it lacks specific guidance or suggestions on how the authors might address these issues or improve their model. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment requests that the authors provide a rationale for why their SE framework can help improve the system and how it does so. It suggests that the authors should not just present their achievements but also explain why and how they managed to achieve them. The reviewer references a specific work, 1 Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not explicitly instruct the authors to use this reference or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their approach and its benefits. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a rationale and explanation of how the SE framework can help improve the system. The reference to 1 Luo, et al. provides additional context and guidance for the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale and explanation behind the SE framework\"s ability to improve the system. It suggests that the authors should provide a detailed explanation of why and how the framework can help, rather than just presenting results. The reviewer references a specific work, 1 Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not provide specific examples or detailed reasoning from the referenced work to support the claim. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of a clear rationale and explanation for why the SE framework can help improve the system. It suggests that the authors should not just present their achievements but also provide a detailed explanation of why and how they managed to achieve them. The comment references a specific work, 1 Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. This reference could be useful for the authors to consider in their response. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested ways to improve the explanation. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific steps to take to improve the generalization of the system. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion that the system should be able to generalize to more views, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it could be addressed. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. While it identifies a potential weakness in the approach, it lacks specificity and does not provide actionable guidance or suggestions on how to address this limitation. The comment is 3 as it points out an area for improvement, but it does not offer detailed feedback or suggestions for enhancing the generalization of the system. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It notes that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might adapt their metrics or suggest alternative approaches for evaluating continual learning in such settings. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the metrics used for evaluating continual learning, loss after switch, and recovery time after switch, which are key aspects of the paper. It also specifies the issue by pointing out that these metrics would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This claim is 3 as it provides a logical reasoning based on the nature of the metrics and their applicability to different scenarios. However, it lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It points out that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This feedback is valuable as it highlights a potential weakness in the paper\"s methodology and suggests a direction for improvement. However, the comment could be more helpful if it provided suggestions on how the authors might address this limitation or adapt their metrics for different settings. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. While the comment identifies an area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should clarify this aspect of their work, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"user decoder\" and \"agent decoder,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the user decoder only uses information up to time step t and does not consider information from all time steps. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind the user decoder\"s use of information from only time step t and not from all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the paper\"s overall contribution. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically questioning why it only uses information up to time step t and does not consider information from all time steps. This feedback identifies a potential area of confusion or limitation in the paper, prompting the authors to clarify their methodology or rationale. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out the missing discussion on arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on \"arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice and analyzing its sensitivity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on \"arbitrary hyperparameter \u03b3\" is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This claim is 3 as it highlights a specific omission in the paper, but it lacks detailed justification or examples to fully substantiate the importance of this discussion. The authors may need to infer the significance of this omission themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the lack of discussion on \"arbitrary hyperparameter \u03b3,\" including how to set it in practice for a given graph and analyzing its sensitivity. This feedback is clear and actionable, as it points out a critical area that needs to be addressed in the paper to ensure that the authors provide a comprehensive understanding of their work. By addressing this issue, the authors can significantly improve the clarity and accessibility of their draft, making it more valuable to both themselves and the broader research community. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider a controlled baseline that ablates heads at different locations in the model to address the confounding factor of head \"location\" in the induction and FV heads. This feedback provides a clear and explicit action for the authors to take, which is to implement a controlled baseline that can help isolate the impact of head location on ICL performance. The comment is specific in its suggestion and provides concrete guidance on how to proceed, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of induction heads and FV heads being located at different layers within the model, which could contribute to differences in ICL performance when ablating induction heads versus FV heads. It suggests that a controlled baseline should be considered to isolate the impact of head location on ICL performance. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the discussion of induction and FV heads and their impact on ICL performance. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head \"location\" within the model. The reviewer proposes a controlled baseline that ablates heads at different locations to isolate this factor. However, the comment lacks specific examples or references to support the claim that head location is a significant contributor to the observed differences. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the difference in ICL performance when ablating induction heads versus FV heads. It suggests that the location of these heads within the model could be a contributing factor. The comment provides a clear and actionable suggestion to address this issue by proposing a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it guides the authors in understanding and isolating the impact of head location on ICL performance, which could lead to improved analysis and interpretation of the results. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it provides a clear direction for the authors to improve their analysis and understanding of the results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, which is to add the missing section. The comment is specific and provides concrete guidance on what needs to be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a section on synonym identification that describes how the multiplechoice task is approached. This provides clear guidance on what needs to be added to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This feedback is clear and actionable, as it directs the authors to add a missing section that would provide important context and explanation for the multiplechoice task. By addressing this gap, the authors can enhance the clarity and completeness of their paper. However, the comment could be more helpful if it offered suggestions on how to structure or present this section, such as highlighting key aspects or examples to include. Overall, the comment is 4 as it effectively points out a critical area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the action is implicit, it is concrete because it specifies what needs to be added (an overview of the workflow and the model). This provides the authors with a clear direction on how to enhance their draft, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, nor does it provide details on what aspects of the workflow and model should be covered. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in suggesting the need for an overview but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning or examples to support why this overview is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. This feedback is 3 as it identifies a potential area for improvement in presenting the key components of the paper. However, the comment lacks specific guidance on what aspects of the workflow and model should be covered or how this overview should be structured. While it points out a need for clarity, it does not provide detailed suggestions on how to achieve it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It also notes that this information cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should discuss this issue and provide a rationale for why it is important. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to debias the sketch and the statistical dimension d_lambda of the design matrix A, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of not being able to compute this dimension accurately without the same runtime as ridge regression, and raises a similar concern regarding the surrogate sketch. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the debiasing approach requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without the same runtime as ridge regression. The reviewer also notes that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. The claim is 3 as it provides a logical reasoning for the need to compute d_lambda and the potential impact on the approach. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It highlights that this information cannot be computed accurately without the same runtime as required for ridge regression, which could lead to bias and potentially defeat the purpose of the approach. The comment also notes that this issue is not discussed in the paper, which is a significant oversight. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or discuss it in the paper. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3 as the expected quantities are scalars but shown as a vector. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is 5 as it clearly specifies what needs to be done to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, redefining the figure to accurately represent the expected quantities as scalars. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figure should be redefined as the expected quantities are scalars but shown as a vector. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific issue with Figure 3, noting that the expected quantities are scalars but shown as a vector. This feedback is clear and actionable, as it directs the authors to redefine the figure to accurately represent the expected quantities. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why the current representation is misleading or offering guidance on how to present the data more effectively. Overall, the comment is valuable but could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance on how to improve the experiment setup or what aspects need attention. The comment lacks explicit instructions or concrete suggestions on how to address the issues raised. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not specify which part of the paper this pertains to, such as specific sections or experiments where the ablations are discussed. Without explicit references to sections or experiments, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what questions arise or how the experiment setup could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the ablations deserve better experiment setup due to the many questions that arise. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance or examples on what questions are being raised or how the experiment setup could be improved. Without actionable advice or detailed suggestions, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is not helpful as it lacks depth and specificity, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. While the comment implies that the authors should conduct additional experiments, it does not specify which experiments to conduct or how to conduct them. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the argument about the proposed models being particularly useful for learning representations for lowfrequency words, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and suggesting that the authors should explore this aspect further. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed models are particularly useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable suggestion. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of providing empirical evidence and the potential benefits of doing so, but the lack of detailed justification or examples makes the claim 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened by including empirical evidence. However, the comment could be more helpful if it provided suggestions on which experiments or data sets to use for this purpose. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the global feature by comparing it with different resolutions of voxel features. It also points out that the resolution of the 3D voxel is important and that using a single global feature at a resolution of 1x1x1 could be beneficial. While the comment provides a clear direction for the authors to explore the importance of the global feature, it does not explicitly instruct them to conduct these comparisons or specify how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of global features and the resolution of the 3D voxel. The comment suggests comparing the importance of the global feature with different resolutions of voxel features and notes that using a single global feature at a resolution of 1x1x1 could be beneficial. This provides clear guidance on what the authors should consider in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the study of global features may introduce unnecessary overhead due to the high computational and memory cost of voxellike features. It proposes a comparison with different resolutions of voxel features to demonstrate the importance of the global feature. While the comment provides a logical reasoning for the potential overhead, it lacks specific examples or references to substantiate the claim fully. The suggestion to compare with different resolutions is a helpful direction, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to study the global feature by comparing it with different resolutions of voxel features. It highlights the potential issue of high computational and memory cost associated with voxellike features and suggests that using a single global feature at a resolution of 1x1x1 could be beneficial. This feedback is valuable as it guides the authors to explore the importance of the global feature and potentially optimize their method. However, the comment could be more helpful if it provided specific examples or references to similar studies that have demonstrated the benefits of using global features. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly points out the absence of an error analysis on the movie dataset and highlights the need for clarity on the cases where the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis in their draft. The comment is specific and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely an error analysis on the movie dataset, and why it is important for other researchers to understand the cases where the model fails. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper\"s contribution. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this omission. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers who may continue this work. However, the comment does not provide specific guidance on how to conduct the error analysis or what aspects should be covered. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. While the comment implies that the authors should investigate these trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these trends. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the trends in the table, noting that PM+CL behaves differently than PM or CL alone and suggesting exploring development set trends with respect to these hyperparameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. However, the comment does not provide specific examples or detailed reasoning to support why these trends are important or how they could be explored. The suggestion is 3 as it points out a potential area for improvement but lacks the necessary evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends due to the behavior of PM+CL compared to PM or CL alone. The reviewer suggests exploring development set trends with respect to these hyperparameters, which could provide valuable insights into the impact of these variables. This feedback is clear and actionable, as it directs the authors to investigate a specific area that could enhance the understanding and interpretation of their results. However, the comment could be more helpful if it included suggestions on how to conduct this analysis or what specific trends to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of Figure 5, noting that there are many lines on top of each other, making it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added or clarified, but it is somewhat vague in its execution, as the authors need to infer the exact steps to take. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the difficulty in understanding the figure due to the overlapping lines and suggests reporting additional metrics like flops or model size to provide a more concrete understanding of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the overlapping lines and suggests that the authors could report additional metrics like flops or model size to provide a more concrete understanding of the results. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is unclear or how the suggested metrics would improve clarity. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 5, noting that the overlapping lines make it difficult to understand. It suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. This feedback is clear and actionable, as it directly addresses a problem with the presentation and offers a concrete suggestion for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or why reporting these metrics is important. Overall, the comment is 4 as it effectively points out a specific area for improvement and provides a clear direction for the authors to enhance the clarity of their work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific guidance on what details are missing or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment mentions the \"questions section below,\" which implies that it is referring to a specific part of the paper. However, without explicit mention of a section or table, the authors cannot confidently determine the exact part being addressed. The comment also lacks specificity regarding what details are missing or how they should be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide specific examples or reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to identify which details are missing or how they could address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific details or suggestions on what these missing details are or how they could be addressed. Without actionable guidance or examples, the authors are left without a clear understanding of what needs to be improved or added to the draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends simplifying the description and explaining the architecture and computations better. It also suggests reducing Figure 7, Section 8, and specific lines (3964) to gain more space. These explicit actions provide clear guidance on what the authors need to do to improve the draft. The comment is concrete, as it specifies which parts of the paper need to be simplified and reduced, giving the authors a clear path to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of the paper being too dense and difficult to follow, suggesting that it needs simplification and better explanation of the architecture and computations. It provides specific examples of sections and lines that could be reduced to gain more space. However, it does not explicitly mention which sections or lines should be reduced, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as simplifying the description and explaining the architecture and computations better. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to understand the concepts and contributions. It suggests simplifying the description and explaining the architecture and computations better. The comment provides specific examples of sections and lines that could be reduced to gain more space. This claim is 3 as it provides some reasoning and examples, but it lacks detailed justification or references to support the claim that the paper is too dense. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is too dense and difficult to follow. It suggests simplifying the description and explaining the architecture and computations better, which is a crucial improvement for the clarity and accessibility of the paper. The comment provides specific examples of sections and lines that could be reduced to gain more space, offering actionable guidance for the authors. This feedback is clear and constructive, providing the authors with a clear path to improve the draft. However, it could be more helpful if it included suggestions on how to simplify the description or what specific aspects of the architecture and computations should be explained in more detail. Overall, the comment is 4 as it effectively identifies a critical area for improvement and offers concrete steps for the authors to take."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of comparison to be made, but it is somewhat vague in terms of how to implement it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests a specific comparison to be made regarding the evaluation of oversmoothing, particularly with respect to the EIGNN model and variants that focus on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this evaluation is currently included in, making it weakly grounded. The comment is specific in suggesting a particular comparison to be made, but without explicit references to sections or figures, the authors may struggle to identify the exact location of the evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this comparison is necessary or how it would benefit the evaluation. Without additional context or examples, the claim remains 3, as it lacks the necessary support to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific comparison that could be made in the evaluation of oversmoothing, specifically by comparing the EIGNN model with variants that focus on dealing with oversmoothing, such as GCNII. This feedback is actionable as it provides a clear direction for the authors to enhance their evaluation by including a comparison that could offer insights into the performance of the EIGNN model under standard settings on realworld datasets. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted or what specific aspects to focus on. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to add a separate section or subsection to introduce the inference strategy, but the comment lacks concrete details on what this section should include or how to implement it. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment explicitly mentions the \"approach method\" and the \"inference strategy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly the use of multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting the absence of a separate part or subsection to introduce the inference strategy, particularly the use of multiple prompts in the test stage. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by providing a dedicated section to explain the inference strategy. However, the comment could be more helpful if it offered suggestions on how to structure this section or what specific aspects to cover. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Figure 4 is confusing and notes that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in the figure and its caption. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure and the lack of explanation in the text or caption. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The comment claims that Figure 4 is confusing and points out that the columns are not explained in the text or caption. However, it does not provide any specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the confusion or how to address it. Without additional context or explanation, the authors may find it challenging to understand and resolve the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing and that the columns are not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns and provide an explanation in the text or caption. By addressing this issue, the authors can improve the clarity and accessibility of their figure, making it more understandable for readers. However, the comment could be more helpful if it provided suggestions on how to clarify the columns or offered examples of how similar figures have been explained effectively. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment results could be discussed more, specifically questioning whether the MaxGapTop2UCB algorithm is better than others based on the Streetview experiment. It also points out the lack of clarity regarding the realworld applications of the problem setting and the computational complexity of the proposed algorithms. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects should be discussed in the paper. The authors are left to infer that they need to provide more detailed discussions and address the computational complexity, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Streetview experiment\" and the \"realworld applications of this new problem setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the conclusion from the Streetview experiment and asking about the computational complexity of the proposed algorithms in the context of ranking problems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the conclusions drawn from the Streetview experiment and the realworld applications of the problem setting. It suggests that the authors should discuss the results more and questions whether MaxGapTop2UCB is better than other algorithms. The reviewer also points out the complexity of the proposed algorithms in the context of ranking problems, which is a valid concern. However, the comment lacks specific examples or references to support the claim about the complexity or the need for more discussion on the results. This makes the claim 3, as it provides some reasoning but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: discussing the experiment results and clarifying the realworld applications of the problem setting. It questions whether the MaxGapTop2UCB algorithm is better than others based on the Streetview experiment and points out the complexity of the proposed algorithms in the context of ranking problems. The comment also highlights the lack of clarity regarding the realworld applications and suggests that the authors should discuss the applicability to sorting/ranking. While the feedback provides clear direction for improvement, it could be more helpful if it offered specific suggestions on how to enhance the discussion or what aspects of the results should be emphasized. Overall, the comment is 3 as it guides the authors toward improving the clarity and depth of their discussion, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. The reviewer implies that more explanations are needed to understand the discrepancy. However, the comment does not provide explicit guidance on what specific explanations should be given or how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given concrete steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for more explanations, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the low results obtained using only ML in the ablation experiments, suggesting that they are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or comparisons, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. This prompts the authors to consider providing more explanations for the discrepancy. However, the comment does not offer specific suggestions or guidance on what kind of explanations might be helpful or how the authors might address this issue. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. However, it does not provide explicit guidance on how to include ablation analysis or what specific components should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include ablation analysis but without clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper lacks this analysis, such as the specific sections or experiments where it should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of lacking ablation analysis, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. This is a critical observation that highlights a gap in the experimental analysis, which could be crucial for understanding the impact of different components on the overall performance. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which components should be analyzed or how to conduct the ablation analysis. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies an important area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any guidance or suggestions on how the authors should address this observation or what implications it might have for their work. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" which likely refers to a specific figure or table in the paper. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not detail what aspect of the noise rate of similarity labels compared to class labels is problematic or how it affects the paper. Without additional context or suggestions for improvement, the authors may find it challenging to address the issue effectively. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand or verify the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any actionable feedback or suggestions for the authors to address this observation or how it might impact their work. Without additional context or guidance, the authors are left without a clear understanding of how to proceed or what improvements could be made. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the verification of the hypothesis, specifically noting that the experiment is not welldesigned. It suggests that the base model should be trained on the original dataset along with the adversarial set to better highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to modify the experimental design to include the comparison between the original dataset and the mixture. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to compare the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This provides clear guidance on how to improve the experiment and strengthen the hypothesis verification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is interesting but not wellverified by the designed experiment. It references Section 3.1 to support this claim, specifically mentioning that models in conventional methods are trained on the original training set in addition to the generated adversarial examples, while the base model is trained on the adversarial set only. The reviewer suggests that comparing the model trained on the original dataset with that trained on the mixture would highlight the impact of the augmented adversarial examples. This claim is 4 as it provides a logical reasoning and a specific suggestion for improvement, which could be further strengthened by referencing additional studies or examples. However, the comment could be more fully supported with specific references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental design, specifically the lack of comparison between the model trained on the original dataset and the model trained on the mixture of original and adversarial examples. This feedback is valuable as it points out a specific area where the authors can improve the verification of their hypothesis. By suggesting a comparison between the two models, the comment provides a clear and actionable suggestion for enhancing the experiment\"s robustness and credibility. However, the comment could be more helpful if it included suggestions on how to design this comparison or what specific metrics to use. Overall, the comment is 4 as it directs the authors to a meaningful improvement in their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. There is no guidance on what aspects of the experiments are lacking or how they could be improved. Without explicit or implicit suggestions for improvement, the authors are left without a clear understanding of what changes are needed to enhance the credibility of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the CNN experiments, but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what aspects of the experiments are not convincing or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of supporting information makes the claim 1, as it does not provide sufficient justification for the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment states that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without further explanation or guidance, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of actionable feedback limits the usefulness of the comment, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper and suggests that if the authors computed these results themselves, they should mention it. This provides a clear and direct action for the authors to take, ensuring that they either report the results from the original paper or acknowledge their selfcomputation. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"model (3) (Chung et al. 2016) for CsEn,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the results were taken from the original paper or computed by the authors themselves. This provides clear guidance on what needs to be corrected or clarified in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper, suggesting that the authors should mention if they computed these results themselves. The comment is 3 as it provides a specific reference to the original paper, which could help the authors verify the claim. However, the comment lacks detailed reasoning or explanation about why the results should be reported or how they might impact the paper. The authors would need to make a significant effort to verify the claim, which is not fully supported by the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper. It suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, as it provides a direct and specific suggestion for improvement. By addressing this issue, the authors can ensure that their work is accurate and transparent, which is valuable for enhancing the credibility and reliability of their study. However, the comment could be more helpful if it provided additional context or explanation about why this issue is important or how it affects the overall paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer implies that discussing how to design prompts effectively is crucial. However, the comment does not provide specific guidance on how to achieve this or what aspects of prompt design should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to focus on prompt design but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper discusses these prompting methods or where the authors should focus their attention. The authors can infer that it relates to sections discussing prompt design, but this inference is not direct. The comment is specific in its suggestion to discuss prompt design effectively, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer argues that different prompts may result in varying performance outcomes, emphasizing the importance of discussing how to design prompts effectively. However, the comment lacks specific examples or references to support the claim that different prompts lead to varying performance outcomes. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer highlights the importance of discussing how to design prompts effectively, given that different prompts may lead to varying performance outcomes. This feedback is clear and actionable, as it directs the authors to focus on a critical aspect of their work that could significantly impact its impact and effectiveness. However, the comment could be more helpful if it provided specific suggestions or examples of effective prompt design strategies. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the comment implies that the authors should include such comparisons, it does not provide explicit instructions or detailed guidance on how to conduct these comparisons or what specific aspects to focus on. The action is clear but somewhat vague, as the authors know they need to compare their results but may not be entirely sure of the exact steps to take. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be included in, such as the results or discussion sections. The authors can infer that it relates to the results or evaluation sections, but this inference is not direct. The comment is specific in suggesting a comparison with SoTA approaches, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific improvement by recommending the authors compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is actionable as it provides a clear direction for enhancing the paper by demonstrating the relevance and impact of the proposed method in the context of existing work. However, the comment could be more helpful if it included additional guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it identifies a clear area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the rationale behind using freezing in MLS selection, but it is vague because it lacks concrete steps on how to implement this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MLS selection,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of freezing in MLS selection and suggesting that adaptive methods could be used instead. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests that adaptive methods could be used instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why adaptive methods are preferable or how they would improve the selection process. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the use of freezing in MLS selection and suggests that adaptive methods could be a better approach. This feedback prompts the authors to reconsider their methodology and potentially improve their selection process. However, the comment lacks specific guidance or suggestions on how to implement the adaptive method or what aspects of the current methodology might be problematic. While it identifies an area for improvement, it does not provide detailed instructions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This is a clear and direct action that the authors can take to improve their draft. The comment is specific in its request for a detailed plan, which provides a concrete direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations mentioned in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more detailed plan on how to address the limitations in future work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they intend to address the limitations mentioned in the paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive approach to addressing the drawbacks. However, the comment could be more helpful if it offered specific suggestions on what elements should be included in the plan or how to prioritize these limitations. Overall, the comment is 4 as it guides the authors toward a more comprehensive approach to their work, but it could be more detailed to be fully beneficial."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should perform a similar analysis on the proposed knowledgeCLIP model as done in existing work that combines text and KGs. This feedback implies that the authors should conduct an experiment to test the robustness of their model in handling negation or changes in entities in the text. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear direction for further investigation. The action is explicit and concrete, as it specifies the type of analysis to be conducted, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed knowledgeCLIP model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting an analysis similar to existing work that combines text and KGs, providing a clear direction for improvement. This feedback is detailed and actionable, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the proposed knowledgeCLIP model should be evaluated in a similar manner as existing work that combines text and KGs. It references an external work, providing a specific example of a closelyrelated analysis that could be applied to the proposed model. This reference provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct an analysis similar to existing work that combines text and KGs. It references an external work that has performed closelyrelated analyses, such as adding negation or changing entities in text to test the robustness of the KGaugmented method. This feedback is valuable as it encourages the authors to explore and validate their proposed knowledgeCLIP model in a more comprehensive manner. By suggesting a specific direction for further investigation, the comment offers a clear path for improvement that can enhance the robustness and generalizability of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, and questions the reason for this choice. It also suggests that the authors consider adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides explicit actions for the authors to take, such as clarifying the reason for the choice and considering adding variance. Additionally, it offers specific guidance on how to improve the draft by suggesting a change in notation. The actions are concrete and detailed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of p m in the numerator and p c in the denominator, suggesting that the authors clarify the reason for this choice. Additionally, it recommends adding the variance for further improvement and suggests using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, questioning the reason for this choice. It suggests that the authors consider adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides logical reasoning by suggesting that using \u03bc g instead of \u03bc f would be consistent with the equation. However, it lacks specific examples or references to support the claim that using variance would improve the results. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the use of p m in the numerator and p c in the denominator in Eq. 3. It questions the reason for this choice and suggests that the authors consider adding the variance for further improvement. Additionally, it recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. This feedback is clear and actionable, as it provides specific guidance on how to clarify the notation and improve the paper. By addressing these points, the authors can enhance the clarity and coherence of their work. However, the comment could be more helpful if it included examples or detailed explanations of why the variance is important or how it could be incorporated. Overall, the comment is 4 as it offers concrete suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should provide a more comprehensive discussion about the computational complexity of the proposal and raises a question about whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed discussion and address the computational cost issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"additional cost\" and the \"computational complexity of the proposal,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the computational cost and its potential impact on the approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the computational cost of the proposed approach and questions whether it becomes prohibitive in certain settings. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It suggests that the paper should provide a more comprehensive discussion about the computational complexity and raises a question about whether the approach becomes prohibitive in certain settings. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a direction to consider but are not provided with actionable steps or detailed advice on how to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to clarify how novel values in the test set are handled for clarity. This is a direct and concrete action, as it specifies a specific area that needs more explanation. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how novel values in the test set are handled. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors clarify how novel values in the test set are handled for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where clarity is needed, specifically regarding how novel values in the test set are handled. By pointing out this potential source of confusion, the comment provides the authors with a clear and actionable suggestion for improving the draft. However, the comment could be more helpful if it offered additional guidance on how to clarify this aspect or provided examples of how other studies handle similar issues. Overall, the feedback is valuable but could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that similar methods have already been proposed for multitask learning and were not discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a discussion of related work or a comparison with existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Similar methods have already been proposed for multitask learning and has not been discussed in this paper 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on similar methods for multitask learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar methods have already been proposed for multitask learning and were not discussed in the paper. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the discussion of similar methods for multitask learning. It points out that similar methods have already been proposed and were not discussed in the paper. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or incorporate related work into their discussion. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FedMITR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the amount of computation required for FedMITR compared to other methods, indicating a potential area for improvement or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment poses a question about the expected computation of FedMITR compared to other methods, suggesting that this might be an area for comparison. While it highlights a potential weakness or area for improvement, it does not provide specific guidance or suggestions on how to address this issue. The comment is 3 as it points out a potential gap in the paper, but it lacks actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it unclear whether this suggestion is being implemented. The comment provides a specific action\u2014using a generic external knowledge base\u2014but lacks concrete guidance on how to implement it or address the confusion in the writing. The authors are left with a clear action but without detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests avoiding \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, it acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment references \"1) and 2)\" and Figure 3, it does not specify which parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting the use of a generic external knowledge base, but without detailed guidance on how to address the confusion in the writing, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using a generic external knowledge base (as shown in Figure 3) can avoid \"1) and 2)\" and that the writing is confusing. However, the comment lacks specific examples or detailed reasoning to support the claim that the external knowledge base would be beneficial or how it would address the confusion in the writing. Without additional context or evidence, the authors may find it challenging to understand and implement the suggestion. Therefore, the claim is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment provides a specific actionable suggestion, it lacks depth and does not offer detailed guidance on how to effectively implement the external knowledge base or address the confusion in the writing. The feedback is 3 as it points out a potential solution but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of the choice, and whether other influential losses have been considered. While the questions are explicit, they do not provide concrete guidance on how to address them. The authors are left to infer that they should provide more information about their methodology and consider alternative approaches, but the comment lacks specific suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of this choice, and whether other influential losses have been considered. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the questions are specific, the lack of grounding in the comment makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also asks whether other influential losses have been considered, such as replacing the min with a mean or NDCG. These questions are relevant and could prompt the authors to reconsider their methodology and potentially improve the robustness of their results. However, the comment lacks specific guidance or suggestions on how to address these questions or improve the paper. While it identifies areas for potential enhancement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of indepth analysis on experimental results, specifically questioning why improvements are limited on one dataset and significant on another. This provides a clear and direct action for the authors to take, which is to conduct a more detailed analysis of the experimental results. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for an indepth analysis of the experimental results, particularly regarding the improvements of models on the offense detection dataset and the coarse stereotype set. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited improvement of models on the offense detection dataset and the significant improvement on the coarse stereotype set. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of indepth analysis on experimental results. It points out that the improvements of models are limited on one dataset and significant on another, which is a crucial aspect that could impact the interpretation and understanding of the results. By highlighting this issue, the comment provides the authors with a clear direction for enhancing the depth and clarity of their analysis. However, the comment could be more helpful if it offered specific suggestions on how to conduct the indepth analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests several actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. The reviewer also mentions that the current method might not work due to the small number of conv layers. However, the comment does not provide specific guidance on how to implement these suggestions or what specific changes should be made to the method. The action is implicit and somewhat vague, as the authors need to infer the details of how to apply these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the method of training on labeled data and incorporating input mask explanation annotations, as well as the use of modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. It suggests that the current method might not work due to the small number of conv layers. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the use of modern baselines and the potential limitations of the current method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method might not work due to the small number of conv layers and the use of modern backbone baselines like Resnet50 or DenseNet121. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to similar interventions that have failed, making it difficult for the authors to understand the basis of the skepticism. As a result, the claim is 3, as it provides a logical argument but lacks sufficient evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical analysis of the proposed method, suggesting that the current approach might not work due to the small number of conv layers and the use of modern backbone baselines like Resnet50 or DenseNet121. The reviewer also recommends incorporating input mask explanation annotations for a few examples and using modern backbone baselines for the feature extraction layer. While the comment identifies potential weaknesses and areas for improvement, it lacks specific guidance on how to implement these suggestions or what specific changes should be made to the method. The feedback is 3 as it points out potential issues but could be more beneficial with more detailed instructions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method. This implies that the authors should make a comparison between the baseline and the proposed method using the same hyperparameters and resources. However, the comment does not provide specific guidance on how to achieve this or which hyperparameters should be tuned. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of multiple hyperparameters and the extensive hyperparameter search, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of ensuring that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment highlights the extensive hyperparameter search, it lacks specific examples or references to support the claim that this is necessary for a fair comparison. The reasoning is based on a general assumption, and without detailed evidence or examples, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the extensive hyperparameter search and the need to ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is a relevant point that could impact the validity and fairness of the results. However, the comment lacks specific guidance on how to achieve this or which hyperparameters should be tuned. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but does not fully support the authors in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. While the comment provides explicit guidance on what needs to be corrected, it does not offer specific suggestions on how to revise the definition or equation to ensure accuracy. The action is clear but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is incorrect about the definition of perplexity and the equation mentioned, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. The reviewer also notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the paper regarding the definition of perplexity, noting that it is not correctly defined. It also points out that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. This feedback is clear and actionable, as it provides the authors with specific guidance on how to correct the errors in their work. However, the comment could be more helpful if it offered suggestions on how to revise the definition or equation to ensure accuracy. Overall, the comment is 4 as it directs the authors to a critical area needing correction, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action for the authors to take, as it specifies the exact improvement needed and provides a concrete direction for testing. The comment is specific and provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and the \"compared baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing baselines, such as MVGRL4 and gptgnn5, and suggests adding more baselines of graph contrastive learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL4 and gptgnn5. However, the comment does not provide any supporting evidence or reasoning to justify why these baselines are necessary or how their inclusion would improve the study. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficiency of the baseline for the graph classification task. It points out the absence of certain baselines, such as MVGRL4 and gptgnn5, and suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting specific additions and tests that could enhance the robustness and comprehensiveness of the study. However, the comment could be more helpful if it explained why these additional baselines are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern with the evaluation of the proposed strategies, specifically mentioning the need to test the defense against an adversarial attack. It suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. However, the comment does not provide specific guidance on how to implement this evaluation or what specific aspects of the defense should be tested. The action is implicit and somewhat vague, as the authors can infer the need for an adversarial evaluation but may not know exactly how to conduct it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation of the proposed strategies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern about the defense against an adversarial attack, including the need to evaluate the defense against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of the proposed strategies is insufficient, specifically mentioning the need to test the defense against an adversarial attack. The comment provides a logical reasoning by highlighting the potential vulnerability of the defense against an adaptive attack against their edge mapbased defense strategies. However, the comment lacks specific examples or references to support the claim that an adversary could optimize the perturbation to successfully attack the model. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the evaluation of the proposed strategies, specifically highlighting the need to test the defense against an adversarial attack. It points out that the current defense strategy considers purifying the input image before passing it to the model, but it does not address the potential vulnerability of the defense against an adaptive attack against their edge mapbased defense strategies. The comment suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. This feedback is clear and actionable, providing the authors with a specific direction for improving the evaluation section of their paper. However, it could be more helpful if it included examples or references to similar studies that have successfully addressed this issue. Overall, the comment is 4 as it guides the authors toward a critical area for improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the legends for tables 1, 2, and 3 longer and clarify whether the numbers are percent errors or percent correct. This feedback provides clear and direct guidance on what changes need to be made to improve the clarity of the tables. The action is explicit and concrete, as it specifies exactly what needs to be done to enhance the legends. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the legends for these tables, and it provides guidance on what should be clarified, such as whether the numbers are percent errors or percent correct. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a factual observation and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a clear and direct suggestion that can help improve the clarity and readability of the tables, making the comment 5. By addressing this issue, the authors can enhance the comprehensibility of their results, which is crucial for effective communication of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental results lack standard deviations, making it difficult to assess the significance of the results. This is a clear and direct action for the authors to take, as it instructs them to include standard deviations in their results. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the inclusion of standard deviations\u2014and why this is important for assessing the significance of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, making it difficult to assess the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why standard deviations are necessary or how their absence affects the interpretation of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting the absence of standard deviations. This is a clear and actionable point that can help the authors improve the clarity and significance of their findings. By including standard deviations, the authors can provide more robust and interpretable data, which is crucial for assessing the significance of their results. However, the comment could be more helpful if it offered suggestions on how to present these deviations or explained why they are important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the provided analysis seems weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the solution and discretization, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not offer specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the theoretical work on sampling and particlebased optimization methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the analysis, specifically mentioning the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is \"somewhat weak\" due to the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This claim is 3 as it references theoretical work on sampling and particlebased optimization methods, which provides a basis for the expectation of detailed analysis. However, the comment lacks specific examples or references to that theoretical work, making it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper\"s analysis is considered weak, namely the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This feedback is clear and actionable, as it points out specific gaps in the analysis that need to be addressed to strengthen the paper. By highlighting these areas, the comment provides the authors with a concrete direction for improving the draft. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar issues have been addressed in related works. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the realism of the generated images or suggestions for potential improvements. As a result, the authors are left without any clear direction on how to enhance the quality of their results. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of limited realism in the generated images, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it highlights an area for improvement, but it lacks specific suggestions or guidance on how to address the issue. The authors are informed of a potential weakness but are not provided with actionable steps to enhance the realism of their generated images. Therefore, the comment is 3, as it points out a problem but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the size and elements of G, which is the graph used in the DGCN model. It also suggests adding the dimensions of G, X, and W to provide a better understanding of the model. These actions are clear and concrete, as they specify exactly what needs to be added or clarified in the paper. The authors know exactly what steps to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of G, the size and elements of G, and the dimensions of G, X, and W. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the construction of G, the graph used in the DGCN model. It suggests describing the size and elements of G and adding the dimensions of G, X, and W to enhance understanding. This is a request for additional information rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of the paper where additional information is needed, specifically regarding the construction of G, the graph used in the DGCN model. It suggests that the authors should describe the size and elements of G and provide the dimensions of G, X, and W to enhance understanding. This feedback is clear and actionable, as it directs the authors to clarify and expand upon a critical aspect of their work. By addressing these points, the authors can improve the clarity and comprehensibility of their paper, making the comment 4. However, it could be more helpful if it included suggestions on how to present this information effectively. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this discrepancy or improve their draft. As a result, the authors are left without any guidance on how to respond to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding Cycle Consistency loss is not entirely true, as it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper regarding the Cycle Consistency loss, specifically noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify or correct the discrepancy. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer provides a clear explanation of what hyperspectral imaging is, which helps the authors understand the issue. However, the comment does not explicitly instruct the authors on how to address this issue, such as by changing the term or providing a more accurate description. While the action is implied, the lack of concrete guidance on how to implement the suggested change makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that \"hyperspectral\" is confusing because it is not a standard term in the field of hyperspectral imaging. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing because it is not a standard term in the field of hyperspectral imaging. The reviewer provides a clear explanation of what hyperspectral imaging is, which supports the claim. However, the comment could be strengthened by referencing specific sources or literature that establish the standard terminology in the field. Despite this, the claim is 4 due to the logical reasoning and the provided explanation.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper by pointing out that the term \"hyperspectral\" is not a standard term in the field of hyperspectral imaging. It provides a clear and concise explanation of what hyperspectral imaging is, which is helpful for the authors in understanding the issue. However, the comment could be more helpful if it suggested alternative terms or provided guidance on how to clarify the term in the paper. Overall, the comment is 3 as it directs the authors to a specific area for clarification, but it lacks depth and actionable suggestions for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also mentions that the concept of peak in Figure 5 is not described. While the comment provides explicit actions to take, such as revisiting the explanation of energy and adding clarification about the concept of peak, it does not specify how to implement these changes or what specific details should be included. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to take. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing a possible interpretation of high energy on a character. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and that it should be refreshed in Section 5.2, where it is used several times. The reviewer also questions the interpretation of high energy on a character, suggesting it might indicate that the current morpheme should be split at that point. Additionally, the reviewer points out that the concept of peak in Figure 5 is not described. While the comment provides a logical suggestion for clarifying the concept of energy, it lacks specific examples or references to support the claim that the current explanation is insufficient. Therefore, the claim is 3, as it provides a reasonable basis for improvement but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also points out that the concept of peak in Figure 5 is not described, which is a clear area for improvement. This feedback is valuable as it directs the authors to clarify and enhance the explanation of energy and the concept of peak, which could improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it included examples or additional details on how to interpret the energy concept or what specific aspects of the peak should be described. Overall, the comment is 4 as it identifies important areas for improvement and provides clear guidance on how to address them."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. It specifically mentions that ablation studies in Sections 3 and 4 demonstrate the effectiveness of each component, but the comment implies that a more detailed explanation is needed. While the action is implicit, it is concrete because it specifies what additional information is needed (e.g., how the performance of combining the Linformer and window attention in Big Bird is improved). Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the contribution of each component to the final performance improvements. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. While it mentions ablation studies in Sections 3 and 4, it does not provide specific examples or detailed reasoning to support why this additional information is necessary. The claim is 3 as it highlights a potential gap in the paper, but it lacks the necessary evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about how each component contributes to the final performance improvements. It references ablation studies in Sections 3 and 4, which is a clear indication of where the authors can enhance their explanation. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to present this information. While it highlights a critical area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific gaps in the paper regarding the details of the models, particularly the grammar over kernels and the probabilities associated with it. It explicitly asks for clarification on how the grammar is applied in practice, how inference is performed, and what the hypothesis space of kernels consists of. These questions provide clear and concrete actions for the authors to take, such as expanding the explanation of the grammar over kernels and the probabilities associated with it. The comment is explicit and provides detailed guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the grammar over kernels\" and \"probabilities associated with the grammar,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail in explaining the grammar over kernels and how inference is performed. The comment provides a clear direction for improvement by asking for more detailed explanations of these concepts. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of detail in the explanation of the grammar over kernels and the probabilities associated with it, which makes it difficult to understand how the approach is applied in practice. The reviewer questions how inference is performed and what the hypothesis space of kernels consists of. While the comment identifies specific areas that need clarification, it does not provide detailed reasoning or examples to support the claim that these details are missing. This makes the claim 3, as the authors would need to further explore the paper to understand the full extent of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where more detail is needed, specifically regarding the grammar over kernels and the probabilities associated with it. It points out that the current explanation is insufficient and raises questions about how inference is performed and what the hypothesis space of kernels consists of. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving the clarity and depth of their explanation. By addressing these points, the authors can enhance the understandability and comprehensibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the role of visual information, verify the effectiveness of the ablation study, and ensure that the experiment results are significant. The lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10\" and \"w/o perception module and w perception,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the ablation study, the lack of verification, and the questionable significance of the experiment results due to the sample size. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown, questioning the effectiveness of the ablation study and the significance of the experiment results due to the sample size. The comment provides some support by mentioning that the w/o perception module and w perception exhibit similar performance, which suggests that the perception module might not be necessary. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the effectiveness of the ablation study or the significance of the experiment results. This makes the claim 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. It highlights specific concerns, such as the performance of the w/o perception module and w perception, and the implementation detail of w/o perception. While the comment provides some insight into potential weaknesses, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional suggestions or examples on how to improve the draft. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This implies that the authors should include references to these works to provide a more comprehensive comparison. The comment is explicit in its request for inclusion of these references, making it clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the end of Section 4.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of references to previous works on Lasso screening, such as Ren et al. (2017), which should be included for a more comprehensive comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This claim is 3 as it highlights a potential omission in the paper\"s literature review, but it lacks specific references to the works that should be included. The reviewer provides a specific example of a relevant work, which would strengthen the claim. However, the comment does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This feedback is clear and actionable, as it points out a gap in the literature review that the authors should address to provide a more comprehensive analysis. By including these references, the authors can enhance the credibility and depth of their work. However, the comment could be more helpful if it suggested how to integrate these references into the paper or provided additional guidance on how to conduct a more thorough comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the documentation. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed information about the hyperparameters. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the model, noting that many components have hyperparameters that are not fully provided. This provides full grounding as it allows the authors to identify the part of the paper being discussed, which is the model components and their hyperparameters. However, the comment lacks specificity as it does not detail what specific hyperparameters are missing or how they should be provided. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model, noting that many components have hyperparameters that are not fully provided. This is a clear and actionable observation that could help the authors improve the clarity and completeness of their model description. However, the comment lacks depth and does not provide suggestions on how to address this issue or what specific hyperparameters should be provided. While it highlights an area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This feedback implies that the authors should clarify the meaning of \"%p\" in their results notation. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a possible explanation or alternative notation. While the action is implicit, it is clear that the authors need to clarify the notation, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This provides clear guidance on what needs to be addressed to improve the clarity of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This claim is 3 as it highlights a potential issue with the clarity of the results notation. However, it lacks specific examples or references to similar notation in the literature, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the results notation, particularly regarding the claim of an improvement for CIFAR10 of 3%p. By pointing out the lack of clarity regarding the \"%p\" notation, the comment highlights an area where the authors need to improve the presentation of their results. However, the comment does not provide suggestions or guidance on how to clarify the notation or what alternative notation might be used. While it identifies a clear issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be beneficial to include qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. While the comment provides a clear direction for improvement, it does not specify how to implement these changes or what specific qualitative results should be included. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests including qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. However, the comment does not specify which part of the paper these results should be included in, making it weakly grounded. The suggestion is specific, as it clearly outlines what the authors should include to improve their draft. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these additions would be beneficial. The absence of detailed justification or evidence makes the claim 3, as the authors would need to infer the benefits of these additions themselves.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also suggests showing failure cases and analyzing limitations. This feedback is valuable as it offers a concrete way for the authors to enhance the presentation of their results, which could help demonstrate the effectiveness of their method. However, the comment could be more helpful if it provided specific examples of what qualitative results or failure cases should be included. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title is ambiguous and recommends clarifying that it pertains to machine comprehension of text, not human reading comprehension. This feedback provides a clear and explicit action for the authors to take, which is to clarify the title to avoid confusion. The comment is specific in its suggestion and offers concrete guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"title\" and provides a specific suggestion to clarify that it pertains to machine comprehension of text, not human reading comprehension. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified in the title to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying that it pertains to machine comprehension of text, not human reading comprehension. This claim is 3 as it provides a logical reasoning for the clarification, but it lacks specific examples or references to support the claim that \"reading comprehension\" and \"readability\" typically refer to human reading comprehension. The authors might find it challenging to fully understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title of the paper, suggesting that it may be misleading as it pertains to machine comprehension of text, not human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for clarifying the title to avoid confusion. By doing so, the authors can ensure that their paper is more accurately understood by their target audience. However, the comment could be more helpful if it offered additional guidance on how to clarify the title or suggested alternative wording that would better convey the intended meaning. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a specific claim made by the authors on line 238, which is incorrect according to the Central Limit Theorem (CLT). It highlights that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment explicitly identifies the issue with the claim and provides a clear explanation of why it is incorrect. However, it does not offer any guidance on how the authors should address this issue or suggest alternative statements to correct the claim. The action is explicit but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made by the authors regarding the Central Limit Theorem (CLT) and why it is incorrect. The comment provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim made by the authors regarding the Central Limit Theorem (CLT) and its applicability to a finite linear combination of random variables. The reviewer provides a detailed explanation of why the claim is incorrect, citing specific aspects of the CLT that do not hold in a nonasymptotic regime. This logical reasoning and reference to the CLT makes the claim 5, as it provides a clear and robust basis for the critique. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and its applicability to a finite linear combination of random variables. It points out that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it provides the authors with a precise understanding of the inaccuracy in their claim and offers guidance on how to correct it. By addressing this issue, the authors can improve the accuracy and credibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the authors need to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific direction for the analysis, making it 5. The authors know exactly what needs to be done to address the reviewer\"s concern, ensuring that this feedback is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the time complexity of the proposed policies mentioned in Section 4. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should analyze the time complexity of the proposed policies mentioned in Section 4. However, it does not provide any supporting evidence, reasoning, or examples to justify why this analysis is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by suggesting that the authors analyze the time complexity of the proposed policies mentioned in Section 4. This feedback is clear and actionable, as it directs the authors to a specific part of the paper where additional analysis could enhance the understanding and evaluation of the proposed policies. However, the comment could be more helpful if it provided additional guidance on how to conduct the analysis or what specific aspects of time complexity should be considered. Overall, the comment offers a clear direction for improvement but could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the evaluation is discussed, the comment lacks full grounding. It is specific in its critique of the use of an automatic metric, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an automatic metric is less convincing than a human metric. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. This feedback highlights a potential weakness in the paper\"s evaluation methodology, which could impact the credibility of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what alternative human metrics could be used. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be strengthened by including experiments across more diverse domains, specifically mentioning those in TDMPC 2. While the comment implies that the authors should expand their experiments to include more diverse domains, it does not provide explicit instructions on how to do so or which specific domains to consider. The action is implicit and somewhat vague, as the authors need to infer the need for more diverse experiments and determine which domains to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments prove the point made by the authors and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more diverse domains, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments prove the authors\" point effectively but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. This claim is 3 as it provides a logical reasoning for expanding the experiments to enhance the paper\"s impact. However, it lacks specific examples or detailed justification for why these additional domains are necessary or how they would contribute to the paper. The suggestion is somewhat supported by the mention of TDMPC 2, but further elaboration would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the experiments effectively prove the point made by the authors but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional experiments to enhance the paper\"s impact. However, the comment lacks specific guidance on how to implement this suggestion or which specific domains should be considered. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should show confidence intervals and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. The comment provides explicit actions for the authors to take, such as including confidence intervals and expanding the evaluation to more datasets. However, it does not specify which datasets should be used or how to calculate the confidence intervals. While the actions are clear, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results and the limited evaluation on two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of not showing confidence intervals and the need to evaluate on more datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. The reviewer supports this claim by referencing external works that discuss the importance of confidence intervals and the need for more datasets to evaluate robustness. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of confidence intervals or by explaining why the two datasets used are insufficient. Despite this, the claim is 4 due to the references to external works, which provide a solid foundation for the critique.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should include confidence intervals to demonstrate statistical significance and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the robustness and credibility of their results. However, the comment could be more helpful if it offered suggestions on how to calculate confidence intervals or which datasets to consider. Overall, the comment is 4 as it effectively directs the authors to address these critical areas for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on what specific aspects of the interpretability tax should be evaluated or how the evaluation should be conducted. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the interpretability tax should be evaluated or how it should be measured. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This is a relevant point that could impact the understanding and interpretation of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the interpretability tax should be evaluated. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the main contribution of the paper is not in proposing novel techniques but rather in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. The authors are left without guidance on how to address this feedback or what specific changes could be made to enhance the novelty or contribution of their work. As a result, the comment lacks actionability, making it 1.", "grounding_specificity_rationale": "The comment discusses the simplicity of the LUQ design and the standard nature of the approaches presented in Section 5, suggesting that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not specify which part of the paper this discussion pertains to, such as the sections on the LUQ design or the approaches presented in Section 5. The comment lacks grounding, as it does not specify where in the paper these issues are discussed. Additionally, it is not specific about what needs to be addressed or improved regarding the contribution or the existing techniques. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the LUQ design is straightforward and that the approaches in Section 5 are standard and explored in previous literature. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 1, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the straightforward nature of the LUQ design and the standard approaches presented in Section 5, suggesting that the main contribution of the paper is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not provide specific suggestions or guidance on how the authors could enhance the novelty or contribution of their work. The comment lacks actionable feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it identifies a limitation but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it implies that the authors should provide evidence or analysis of the training stability, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide training losses to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses, but without clear grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left to infer that they should provide evidence or analysis of the training stability, but without detailed instructions or examples, the comment does not fully support the authors in improving their draft. Therefore, the comment is 3, as it points out a potential weakness but does not offer actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as being the same concept. The reviewer suggests that these are actually different perspectives on applying stronger constraints for samples with higher popularity. While the comment identifies a potential issue with the paper\"s claims, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims and provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper overclaims the strength of the proposed BC loss by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as the same concept. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as the same concept. The reviewer supports this claim by explaining that these elements are actually different perspectives on applying stronger constraints for samples with higher popularity. This reasoning is logical and provides a clear explanation for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims regarding the strength of the proposed BC loss in the theoretical analysis. It points out that the paper overclaims by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as the same concept. The reviewer explains that these elements are actually different perspectives on applying stronger constraints for samples with higher popularity. This feedback is 3 as it highlights a potential misrepresentation in the paper\"s claims, but it lacks specific guidance on how the authors might address this issue or improve their analysis. The comment could be more helpful if it provided suggestions on how to clarify or rephrase the claims to avoid overclaiming. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations, specifically mentioning that automatic scores are not effective and human evaluation scores are not affordable. It also questions the applicability of the framework FFAEVAL and similar frameworks like Chatbot Arena for evaluating a single dialogue system. The reviewer suggests that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to improve the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the relevance and applicability of their method in the context of current evaluation systems. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract section\" and the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of the proposed method to the authors\" motivations, particularly regarding the use of automatic scores and human evaluation scores. The comment further explains why it believes arenabased evaluation systems may not be suitable for evaluating a single dialogue system, providing a clear rationale for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method may be less relevant to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. The reviewer supports this claim by suggesting that the framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. This reasoning is based on the assumption that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. However, the comment lacks specific examples or references to support the claim that arenabased evaluation systems are ineffective for single dialogue systems. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It suggests that the framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. This feedback is 3 as it points out a potential limitation in the applicability of the proposed method, which could impact the authors\" motivations and the evaluation process. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or what alternative methods might be considered. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer suggests that this could result in unfair comparisons. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their training approach or provide additional context to justify the running speed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup\" and \"training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer supports this claim by referencing the authors\" claim of a 1.5x slower running speed. However, the comment does not provide specific examples or references to substantiate the claim further, such as detailed comparisons with other methods or specific performance metrics. While the claim is logically sound, the lack of detailed evidence or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. This observation is relevant and highlights a potential source of bias in the comparison with other methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to consider the differences between classification and regression tasks, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the use of focal loss in regression tasks and the potential inaccuracy caused by lower weight for easy samples. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of focal loss in regression tasks and suggests that it may not be appropriate due to its classificationspecific properties. The reviewer provides a logical reasoning that focal loss could lead to inaccurate results in regression tasks, as it has lower gradients on easy samples. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its classificationspecific properties. It points out that focal loss has lower gradients on easy samples, which could lead to inaccurate results in regression tasks. The comment highlights a gap in the authors\" consideration of the differences between classification and regression tasks, implying that the paper may lack a comprehensive understanding of the problem domain. While the comment raises an important point, it could be more helpful if it provided specific suggestions on how the authors might address this issue or what alternative methods might be considered. Overall, the comment is 3 as it directs the authors\" attention to a potential weakness in their work, but it lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of scalability should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of scalability should be considered or how the authors might address this question. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to verify whether the proposed model\"s improvements over the RL without feedback model are statistically significant. This is a clear and direct action for the authors to take, as it provides a specific task to ensure the robustness of their findings. The comment is concrete in its request for statistical verification, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the proposed model\"s improvements over the RL without feedback model. The comment provides a clear direction for the authors to follow, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed model\"s improvements over the RL without feedback model are not statistically significant, based on a comparison of rows 3 and 4 in Table 6. However, the comment does not provide any supporting evidence, such as data or statistical analysis, to substantiate this claim. Without such evidence, the authors may find it challenging to verify the claim themselves. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed model\"s improvements over the RL without feedback model, noting that the improvements are not statistically significant as evidenced by the comparison of rows 3 and 4 in Table 6. The comment suggests that the authors verify if these improvements are statistically significant, providing a clear and actionable piece of feedback. This guidance is valuable as it directs the authors to a specific area that needs further investigation, ensuring that their findings are robust and reliable. However, the comment could be more helpful if it included additional context or examples of how to conduct the statistical analysis. Overall, the comment is 4 as it effectively points out a potential weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. However, it does not provide explicit guidance or suggestions on how to address this issue or what specific actions the authors should take. The comment is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"in continuation to the above remark,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how to relax the need to visit all ballaction pairs with each iteration and what would happen if partial coverage is considered. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification or suggestions regarding relaxing the need to visit all ballaction pairs with each iteration and exploring partial coverage. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. While it raises an interesting point, it lacks specific guidance or suggestions on how to address this issue or what specific assumptions or approaches could be considered. The comment is 3 as it prompts the authors to consider alternative approaches, but it does not provide actionable steps or detailed feedback. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. While it does not explicitly instruct the authors to use RoBERTabase, the implication is clear that they should consider this option. The comment is 3 as it provides a concrete suggestion for improvement but lacks explicit guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"encoder\" and compares it to \"RoBERTabase,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the observed improvement could be achieved with a better encoder, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about the potential improvement in performance with a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTabase might be a better choice or how it could lead to improved performance. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the potential improvement in performance with a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. While it does not provide specific guidance or suggestions for improvement, it does prompt the authors to consider alternative encoders that could enhance their work. This feedback is 3 as it points out a potential area for improvement but lacks depth and actionable steps. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. While the action is explicit, it lacks concrete details on which specific datasets should be included or how to integrate them into the paper. The authors are given a clear direction to expand their dataset selection, but the lack of detailed guidance on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment suggests adding more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results discussion. The authors can infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of additional datasets, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific datasets are important or how they would contribute to the paper\"s claims. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a specific area for improvement by recommending additional datasets to test the technique. However, the comment lacks depth and does not provide detailed guidance on how to integrate these datasets or what specific aspects of the technique should be tested on these datasets. While it points out a potential area for improvement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to use these methods or explain how to incorporate them into their evaluation. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. However, it does not specify which part of the paper these suggestions pertain to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting potential baselines. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. While the comment provides specific examples of potential baselines, it lacks detailed reasoning or evidence to support why these particular methods would be beneficial or how they would enhance the evaluation. The suggestion is based on general knowledge of existing methods, but without further explanation or justification, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. This suggestion is based on the authors\" need to evaluate the appearance decomposition part and larger outdoor scenes, respectively. By providing these examples, the reviewer helps the authors identify potential baselines that could enhance their evaluation and improve the robustness of their results. However, the comment could be more helpful if it explained why these specific methods were chosen or how they would contribute to the evaluation. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" While the action is implicit, it is clear that the authors need to provide a method for achieving fair policy learning without negatively impacting the predictive model\"s performance. However, the comment does not specify how to achieve this or what specific steps to take, leaving some ambiguity. Therefore, the comment is 3, as it provides a direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request to demonstrate fair policy learning without negatively impacting performance, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" This feedback is 3 as it identifies a potential weakness in the paper, specifically the impact of the proposed method on the predictive model\"s performance. However, the comment lacks specific guidance or examples on how to achieve this goal or what aspects of the method might be causing performance degradation. While it points out an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. This provides a clear and direct action for the authors to take, specifying where the details should be added and what needs to be included. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of implementation details of the proposed methods, which is a critical aspect of the paper. It suggests that these details should be included in Section 4.1, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area that needs attention and guidance on how to enhance the clarity and completeness of their work. However, the comment could be more helpful if it offered additional insights or examples on what kind of implementation details are important or how they could be presented effectively. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contribution. The comment is explicit in its request for empirical evaluation and comparison, providing concrete guidance on what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that there is no practical value demonstrated and that the theoretical contributions may be significant but not adequately presented. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, which is a subjective claim. The reviewer supports this claim by stating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. However, the comment does not provide specific examples or references to support the claim that the theoretical contributions are significant or that the lack of empirical evaluation is a significant issue. This makes the claim 3, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of empirical evaluation and comparison with other methods. It highlights that the theoretical contributions may be significant but are not adequately demonstrated in the paper, making it unclear what the practical value of the contribution could be. The comment suggests that even a theoretical paper should attempt to argue for its significance, and it concludes that the current submission is not suitable for publication at NeurIPS. This feedback is clear and actionable, providing the authors with a specific direction to enhance the empirical evaluation and comparison sections of their paper. However, it could be more helpful if it offered suggestions on how to conduct the empirical evaluation or what specific comparisons should be made. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback implies that the authors should clarify the use of P in these instances to avoid confusion. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a change in notation or clarifying the context in which P is used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the clarity of their manuscript. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the manuscript, including \"P mostly represents a probability but sometimes for a cumulative distribution function (e.g., Eqs. (3) and (4) and L44, all in Appendix), which leads to confusion.\" This allows the authors to accurately identify the parts of the manuscript being addressed. The comment is also specific because it clearly specifies the issue of using P for both probability and cumulative distribution functions, which leads to confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of P in the manuscript is confusing because it is used to represent both a probability and a cumulative distribution function. This claim is 3 as it provides a specific example (P used in Eqs. (3) and (4) and L44) to illustrate the confusion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why this confusion is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 3, as it provides some support but could be strengthened with additional justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that P is used to represent both a probability and a cumulative distribution function, which leads to confusion. This feedback is clear and actionable, as it points out a specific area where the manuscript could be improved by clarifying the use of P. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a change in notation or explaining the context in which P is used. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the use of artificial patterns in analysis and ablation studies, suggesting that natural spurious correlations are more complex and different in every example. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to their analysis or ablation studies. The comment lacks actionable details, such as recommending the use of natural spurious correlations or suggesting specific methods for identifying and analyzing them. As a result, the authors are left without a clear understanding of how to apply this feedback to improve their draft. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of using artificial patterns in analysis and ablation studies, suggesting that natural spurious correlations are more complex and different in every example. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the use of artificial patterns, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that neural networks learn natural rare spurious correlations, which is unknown to the community. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of artificial patterns in analysis and ablation studies, suggesting that natural spurious correlations are more complex and different in every example. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve the robustness and generalizability of their results. However, the comment lacks specific suggestions or guidance on how to address this issue or what specific changes could be made to incorporate natural spurious correlations. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or explore more general tasks. The authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the paper\"s applicability to more general tasks, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited in its application to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL. However, the comment does not provide specific references or examples from PRMRL to substantiate this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s applicability to navigation problems and suggests that the method discussed is already discussed in PRMRL. It points out that combining RL and planning has been explored in PRMRL, which could be relevant to more general tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore more general tasks. While it highlights an area for improvement, the feedback lacks actionable advice or detailed suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should consider whether all feature spaces are wellsuited for 1NN and warns that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends standardizing feature dimensions to avoid this issue. While the comment provides a clear action\u2014to evaluate the suitability of feature spaces and standardize dimensions\u2014it does not offer specific guidance on how to implement this suggestion or what metrics to use for evaluation. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suitability of feature spaces for 1NN and the potential issue with nonspherical Gaussian feature spaces. The comment provides a clear suggestion to standardize feature dimensions to avoid this issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the feature spaces used in the paper may not be wellsuited for 1NN and that nonspherical Gaussian feature spaces may perform poorly. The comment provides a logical reasoning by explaining that standardizing feature dimensions can avoid this issue. However, the comment lacks specific examples or references to support the claim that nonspherical Gaussian feature spaces perform poorly. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It points out a potential issue with the suitability of feature spaces for 1NN and suggests standardizing feature dimensions to avoid performance issues. This feedback is clear and constructive, as it offers a concrete step for the authors to take in order to improve their draft. By addressing this issue, the authors can enhance the robustness and generalizability of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but finds it less convincing and points out specific issues with the setting. However, the comment does not provide explicit guidance on how to define the contrastive gap or what specific aspects of the example should be addressed. While the authors can infer that they need to provide a formal definition, the comment lacks concrete details on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is central to the work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the definition of the contrastive gap is unclear and that an example was provided but found less convincing. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" is unclearly defined, despite being central to the work. It acknowledges that an example was provided but finds it less convincing, citing specific issues with the setting. However, the comment lacks detailed reasoning or references to support why the example is less convincing or how the definition could be improved. Without explicit examples or references, the claim is 3, as it provides some justification but not enough detail for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but finds it less convincing, providing a detailed critique of the setting. This feedback is valuable as it highlights a key area for improvement, guiding the authors to clarify and strengthen the definition of the contrastive gap. However, the comment could be more helpful if it offered specific suggestions on how to improve the example or provided examples of how the definition could be clarified. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov decision process (MDP). It suggests that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it does not provide explicit guidance on how to clarify the description or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description, but it is concrete in that it points to specific lines that need attention. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inaccuracy of the statement regarding rewards in standard MDP formulations and suggests clarifying the description of each action. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it lacks detailed reasoning or references to standard MDP formulations or examples to fully substantiate the claim. This makes the claim 3, as the authors would need to further explore the topic to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov decision process (MDP). It points out that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. This feedback is 3 as it highlights a potential misconception in the paper and provides a specific area for clarification. However, the comment could be more helpful if it offered suggestions on how to clarify the description or provided examples of standard MDP formulations. Overall, the comment is 3 as it directs the authors to a specific area needing improvement, but it lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work 29, 5, 6. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. The reviewer provides a specific suggestion to include the explanation of why the chosen baseline makes the most sense. However, the comment does not explicitly instruct the authors to add this explanation or provide guidance on how to integrate it into the paper. While the action is implied, it is not as concrete as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those mentioned in related work 29, 5, 6. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines and providing a rationale for why they are relevant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, such as those mentioned in related work 29, 5, 6. However, it does not provide any specific reasoning or evidence to support why these baselines are necessary or how they would enhance the study. The comment also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered, but it does not elaborate on these responses. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of including these baselines and the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work 29, 5, 6. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks specific guidance on how to integrate these baselines into the paper or why they are particularly relevant. While it points out a potential enhancement, it does not provide detailed instructions or examples on how to implement this suggestion. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the meaning of \u03b4 in the statement of Lemma 5. While it does not explicitly instruct the authors to clarify this term, it implies that the authors should provide a definition or explanation for \u03b4. The action is implicit but concrete, as the authors can infer that they need to address this question to improve the clarity of their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \u03b4 in the statement of Lemma 5. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the meaning of \u03b4 in the statement of Lemma 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the meaning of \u03b4 in the statement of Lemma 5. While it identifies a potential area of confusion or ambiguity in the paper, it does not provide any guidance or suggestions for clarification or improvement. The comment lacks actionable feedback or context that would help the authors address the issue. As a result, it is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the uniform setting of \u03b1_m in line 113, noting that this implies the contributions from all modalities are the same. It suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider dynamically weighting the modalities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform setting of \u03b1_m and suggests that dynamically weighting the modalities is important in multimodal fusion. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that setting \u03b1_m uniformly to 1/M implies that the contributions from all modalities are the same, which is not accurate. The reviewer supports this claim by referencing works in multimodal fusion that demonstrate the importance of dynamically weighting modalities. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to these works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the uniform setting of \u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. It suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. This feedback is 3 as it points out a potential weakness in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples or references to multimodal fusion works that demonstrate the importance of weighting modalities. As it stands, the authors are left with a general suggestion to explore this further, which may not be immediately actionable without additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. However, it does not provide any guidance on how the authors should address this issue or suggest alternative phrasing. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the pervasive use of the phrase \"to meet\" and how it is difficult to understand. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. This feedback is clear and actionable, as it points out a specific area where the language could be improved for clarity. However, the comment could be more helpful if it provided suggestions for alternative phrasing or clarified the intended meaning of the phrase. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in Figure 1. While this is an observation that the authors should be aware of, it does not provide explicit guidance on how to correct this discrepancy or suggest a specific action to take. The comment is 3 because it identifies an issue but lacks concrete instructions on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the task loss being labeled differently in the text and the figure, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistency in labeling the task loss in the text and Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in Figure 1. This is a minor but important detail that the authors should correct to maintain consistency in their work. However, the comment does not provide any suggestions or guidance on how to address this issue or why it is important. While it points out a specific error, it lacks depth and actionable advice, making it 3 but not comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the method should be considered for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the network depth is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\"s limitations should be addressed or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. This is a relevant question that could prompt the authors to consider potential limitations of their method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the method should be considered for improvement. Without actionable feedback or detailed analysis, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work should be evaluated in machine translation, which is seen as a more convincing approach due to its lower uncertainty per word. While the comment implies that the authors should consider this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider machine translation as an additional evaluation method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work should be evaluated in machine translation, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but the comment lacks full grounding as it does not explicitly mention the section. The suggestion is specific, as it highlights the need for evaluation in machine translation, but it is 1 as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work only uses answer generation and summarization, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the proposed method in machine translation would be more convincing due to its lower uncertainty per word. This claim is 3 as it provides a logical reasoning for why machine translation might be a more appropriate evaluation method. However, it lacks specific examples or references to support the claim that machine translation is inherently less uncertain than other tasks. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation, which exhibits lower uncertainties per word, would be more convincing. This feedback is 3 as it points out a potential weakness in the evaluation approach and suggests an alternative method for demonstrating the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific examples or references to support the claim about the differences in uncertainties between tasks. Overall, the comment offers a valuable suggestion for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and \"multiple stochastic masks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout method used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. This feedback is valuable as it prompts the authors to clarify and provide more detailed information about their methodology, which could enhance the transparency and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar methods have been presented in the literature. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to demonstrate the effectiveness. This provides clear and concrete actions for the authors to take, such as including these comparisons and benchmarks to strengthen their claims. The comment is specific in detailing what additional information is needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further justifications, comparisons with other singlestage attacks, and benchmarks with SOTA algorithms to justify the effectiveness of the technical contributions. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that showing only the performance drop on fusion models is insufficient and that comparisons with other singlestage attacks are necessary to demonstrate effectiveness. The comment also implies that without proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms, it is difficult to justify the technical contributions. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to make a significant effort to understand and address the critique, as the reasoning is not fully articulated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the need for further justification of the proposed twostage optimization approach. It suggests that showing only the performance drop on fusion models is insufficient and that comparisons with other singlestage attacks and benchmarks with stateoftheart algorithms are necessary to demonstrate the effectiveness. This feedback is clear and actionable, as it provides specific guidance on what additional information is needed to strengthen the paper\"s claims. By addressing these points, the authors can significantly improve the clarity and robustness of their technical contributions. However, the comment could be more helpful if it included examples of specific comparisons or benchmarks that would be beneficial. Overall, the comment is 4 as it effectively directs the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not specify the type of GPUs used for testing or the inference time. This is an explicit observation that the authors can directly address by including this information in their draft. The comment provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be added to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the absence of information about the type of GPUs used for testing and the inference time, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be added, namely the type of GPUs and inference time, providing clear guidance on what needs to be included in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used for testing or the inference time. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting the lack of information about the type of GPUs used for testing and the inference time. This is a clear and actionable point that the authors can address to improve the transparency and reproducibility of their results. However, the comment could be more helpful if it provided suggestions on how to present this information or why it is important for the paper. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. While the comment identifies specific issues, it does not provide explicit instructions on how to address them. The authors can infer that they need to correct the table and the paragraph, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"Page 3, Line 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the monotonic increase in performance of RSD4PG with respect to \u03bb values and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point makes a claim about the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and questions what happens when \u03bb is even smaller. The reviewer also points out missing symbols and references in the text. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to further investigate and address the issues themselves, which requires more detailed guidance or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues in the paper, such as the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. These are important points that the authors should address to improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered guidance on how to present the missing information. Overall, the comment is 3 as it points out specific areas for improvement, but it lacks detailed guidance for the authors to fully address the issues."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. While the comment identifies a specific area of concern, it does not provide explicit instructions on how to address this issue or what changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to make a correction but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, noting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, as it points out a potential error in the experimental setup that the authors can address to improve the accuracy of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve this issue, such as explaining why this distinction is important or offering alternative approaches to consider. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that a specific sentence is confusing and suggests that the authors should clarify it. However, it does not provide any explicit guidance on how to improve the sentence or what specific changes should be made to make it clearer. The authors are left to infer that they need to revise the sentence, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, which is that it is confusing and not immediately obvious. However, the comment does not provide specific guidance on how to clarify the sentence or what aspects are confusing. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and suggests that the authors should clarify it. However, the comment does not provide any reasoning, examples, or references to support why the sentence is confusing or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific sentence that is confusing and suggests that the authors should clarify it. While it highlights a potential issue with the clarity of the text, it does not provide detailed guidance or suggestions on how to improve the sentence or what specific aspects are confusing. The comment is 3 as it points out a potential weakness, but it lacks depth and actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several instances where citations are missing or needed, specifically in lines 7879, 129130, 156158, and 217218. While it identifies these areas, it does not provide explicit instructions on how to include the missing citations or what specific references should be used. The actions are implicit and somewhat vague, as the authors need to infer that they should include citations but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for citations in lines 7879, 129130, 156158, and 217218. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of claims that require specific citations to support the assertions. For example, the claim about diffusion models outperforming generative adversarial networks is not substantiated with a reference. Similarly, the claim about previous work having limited success is also unsupported. The reviewer requests citations for these claims, which would provide the necessary evidence to support the claims. Therefore, the comment is considered 1 due to the lack of supporting evidence or references.", "helpfulness_rationale": "The review comment identifies specific areas where citations are missing or needed, which is a clear and actionable piece of feedback. It highlights specific lines in the paper where references should be included, providing the authors with a concrete list of places to improve their draft. However, the comment could be more helpful if it offered suggestions on which specific works or references might be relevant for each of these citations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between Figures 1 and 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback implies that the authors should reconcile these figures to ensure consistency. However, the comment does not provide explicit instructions on how to address this issue, such as suggesting specific changes or clarifications. While the action is implied, it lacks concrete guidance on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the figures, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This claim is 3 as it highlights a discrepancy between the figures, but it lacks detailed explanation or justification for why this inconsistency is problematic or how it affects the paper\"s overall message. The authors might need to further investigate the implications of this inconsistency and determine if it affects the validity or interpretation of the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between Figures 1 and 2, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback highlights an inconsistency in the figures, which could impact the clarity and coherence of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending changes to the figures or explaining the rationale behind the discrepancy. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify or modify the description of N_l^(s) to ensure that each node can attend to its own lowerlevel representation, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the ability of each node to attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This is a relevant point that could impact the understanding and interpretation of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their explanation. While it identifies a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify how Lemma 7 is applied to this inequality. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the inequality after line 433 follows from Lemma 7, and it suggests that the authors should clarify how Lemma 7 is applied in this context. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how an inequality follows from a lemma. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the derivation of an inequality after line 433, asking how it follows from Lemma 7. This is a clear and actionable point, as it prompts the authors to clarify the connection between the two elements. By addressing this question, the authors can improve the clarity and coherence of their paper, making it easier for readers to understand the derivation and application of the inequality. However, the comment could be more helpful if it provided additional guidance on how to present this information or suggested specific ways to clarify the connection. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the paper\"s main contribution is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to clarify the main contribution. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations and evidence to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of the main idea and the automation process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. The reviewer suggests that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of specific evidence or references makes the claim 3, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, noting that the novel properties of the proposed method and its ability to cope with dynamic largescale multitasking are unclear. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. This feedback is valuable as it highlights specific areas where the authors need to provide more detailed explanations and evidence to support their claims. However, the comment could be more helpful if it offered suggestions on how to clarify these aspects or provided examples of how similar methods have been effectively communicated. Overall, the comment is 4 as it directs the authors to critical areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the bottomup method 9 in their tables and evaluate its performance on the standard MS COCO dataset to see if there is a drop in performance in easy (non occluded) settings. While the comment explicitly states what needs to be done, it does not provide detailed guidance on how to implement these changes or what specific aspects of the method should be included in the tables. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bottomup method 9 and its results on the crowdpose dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is to include the bottomup method in the tables and evaluate its performance on the MS COCO dataset. This provides clear guidance on what changes need to be made to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method 9 has reported results on the crowdpose dataset outperforming all methods, including the paper\"s own method, with a ResNet50. The comment also recommends evaluating the method on the standard MS COCO dataset to see if there is a drop in performance in easy settings. While the claim is based on a specific external work, it lacks detailed justification or references to support the claim that the bottomup method outperforms all methods, including the paper\"s own method. The suggestion to evaluate on the MS COCO dataset is logical, but the claim about the bottomup method\"s performance is not fully substantiated. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include the bottomup method 9 in their tables and evaluate its performance on the standard MS COCO dataset. This suggestion is based on the reported results of the bottomup method on the crowdpose dataset, which could help the authors compare their method with a wellestablished baseline. By including this information, the authors can enhance the transparency and robustness of their work. However, the comment could be more helpful if it provided additional context or analysis on why this comparison is important or how it might impact the overall evaluation of the method. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. It provides an example from the TACRED slot filling guidelines to illustrate the depth of understanding required. However, the comment does not explicitly instruct the authors to revise their claim or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claim and provide more detailed information about their understanding of annotation guidelines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim of using \"annotation guideline\" and provides a specific example of the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to identify the exact part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the overstatement of using annotation guidelines and the need to provide more detailed information about the understanding of annotation guidelines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. The reviewer provides an example from the TACRED slot filling guidelines to illustrate the depth of understanding required. This example is specific and provides a clear rationale for the claim, making the comment 4. However, the comment could be strengthened by referencing additional examples or sources to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper\"s claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. The reviewer provides a specific example from the TACRED slot filling guidelines to illustrate the depth of understanding required, which is a valuable contribution to the authors. This feedback is clear and actionable, as it prompts the authors to reconsider their claim and potentially revise their approach to better align with the complexity of annotation guidelines. However, the comment could be more helpful if it suggested specific ways to address this issue or provided additional guidance on how to incorporate more comprehensive understanding of annotation guidelines. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the BERTbaseline. This provides a clear and concrete action for the authors to take, specifying exactly what additional comparisons are needed to strengthen the experiment comparison. The comment is specific and direct, giving the authors a clear path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment comparison\" and the need to compare the method to \"token pruning and token combination baselines.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional baselines for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because it only compares the method to the BERTbaseline. The reviewer suggests that the authors should also compare their method to token pruning and token combination baselines. While the comment identifies a potential issue with the experiment comparison, it does not provide specific examples or references to support the claim that these additional comparisons are necessary. The reasoning is 3, as it highlights a potential gap in the comparison but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experiment comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should also compare their method to token pruning and token combination baselines. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental analysis by including additional comparisons. By addressing this suggestion, the authors can strengthen their evaluation and provide a more comprehensive understanding of their method\"s performance. Therefore, the comment is 4, as it offers a valuable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison to these methods. The comment is specific in identifying the missing comparison and offers concrete guidance on how to enhance the experimental section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular comparison that should be included, namely a comparison to coordinateaware methods like TFN or SchNet. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This claim is 3 as it logically suggests that including such comparisons would provide a more comprehensive evaluation of the methods. However, the comment lacks specific examples or references to these methods, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental section, noting that it only compares methods that are unaware of the point coordinates, except for input features. It suggests that a comparison to coordinateaware methods, such as TFN or SchNet, would be appropriate. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental section by including a more comprehensive comparison. However, the comment could be more helpful if it explained why these methods are particularly relevant or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any guidance on how the authors should address this issue or what specific weaknesses should be explored. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment points out that the authors did not show the possible weaknesses of the proposed model, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what weaknesses should be explored or how they could be demonstrated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the model\"s weaknesses, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific weaknesses should be explored. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of related work and experimentation with other extractthengenerate methodologies in the paper. It implies that the authors should include a related work section and experiment with other methods to demonstrate the novelty and effectiveness of their proposed system. While the comment does not explicitly instruct the authors to add a related work section or conduct additional experiments, the action is implied and concrete, as it specifies what needs to be done to address the reviewer\"s concerns. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the idea of long document summarization and questions the novelty of the proposed system compared to previous extractthengenerate methodologies. It specifically mentions the absence of a related work section and the lack of experimentation with other extractthengenerate methodologies. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. While the authors can infer that it relates to the sections discussing the methodology and results, the comment is not fully grounded as it does not explicitly mention these sections. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the novelty and effectiveness of the proposed system compared to previous extractthengenerate methodologies. It questions the lack of a related work section and experimentation with other methods. However, the comment does not provide specific examples or references to support the claim that the system does not offer anything new or innovative. Without such evidence or reasoning, the claim remains 1, as it lacks the necessary justification to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a related work section and experimentation with other extractthengenerate methodologies. It questions the novelty and effectiveness of the proposed system compared to previous approaches. While the comment highlights an important area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a critical area for enhancement, but it lacks actionable advice or detailed guidance on how to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The authors are left to infer that they should explore these directions but without specific guidance on how to do so. The comment lacks actionable details, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in suggesting alternative approaches but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints. However, it does not provide any supporting evidence, reasoning, or references to justify why these directions are more appealing or effective. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, as it does not provide sufficient justification or evidence to support the claim. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. While these suggestions are interesting and could potentially improve the paper, the comment lacks specific guidance or detailed explanation on how to implement these directions. It does not provide examples or detailed steps on how to explore these alternatives, making it difficult for the authors to understand the exact actions they need to take to address the feedback. The comment is 3 as it identifies potential areas for improvement but could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is not sufficient and recommends providing more information on the advantages or differences of the proposed method, specifically in comparison to BGLN. While the comment implies that additional work on GLN is needed, it does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should add more information on GLN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the introduction of related work and the need for more work on GLN, including the differences from BGLN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be provided to reflect the advantages or differences of the proposed method, specifically in comparison to BGLN. However, the comment lacks specific examples or detailed reasoning to support why the current introduction is insufficient or how the additional work on GLN would enhance the paper. Without specific examples or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and recommends providing more information on the advantages or differences of the proposed method, particularly in comparison to BGLN. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed to enhance its comprehensiveness and clarity. However, the comment could be more helpful if it provided specific suggestions on how to present this additional information or what aspects of the method should be highlighted in comparison to BGLN. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks guidance on how the authors might improve their draft in response to this observation. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Moon\"s approach\" and \"Variational dropout,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of hyperparameters, particularly the use of only one dropout rate for Moon\"s approach compared to Variational dropout, which has inputoutput and recurrent dropout parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of hyperparameters in Moon\"s approach, specifically noting that Variational dropout has inputoutput and recurrent dropout parameters, while Moon\"s approach only uses one dropout rate. This observation highlights a potential inconsistency in the paper\"s approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this inconsistency is problematic or how it affects the paper\"s conclusions. Without additional context or explanation, the claim remains 3, as it lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of hyperparameters in Moon\"s approach, specifically noting that Variational dropout has inputoutput and recurrent dropout parameters, while Moon\"s approach only uses one dropout rate. This observation highlights a potential inconsistency in the paper\"s approach and could prompt the authors to reconsider their choice of hyperparameters. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a clear and specific action for the authors to take, which is to conduct these experiments and compare their results against other approaches. The comment is explicit and provides concrete details on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. This provides clear guidance on what aspects of the paper need to be addressed. The comment is also specific in detailing what kind of experiments should be conducted and how they could be conducted, such as using publicly available simulators and comparing against other approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the current experiments are insufficiently largescale and do not include nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. The reviewer questions whether this is due to a lack of time or severe scalability issues with the method. The comment proposes conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace, and suggests using publicly available simulators for these experiments. This provides a logical reasoning for the need to conduct largerscale experiments and suggests specific domains to consider. However, the comment lacks specific examples or references to support the claim that conducting these experiments would be beneficial. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a logical rationale for these suggestions, noting that conducting such experiments would help determine whether the method has severe scalability issues or if it is simply a matter of time. The feedback is 5 as it offers specific and detailed guidance on how to enhance the experimental section of the paper, which could significantly impact the authors\" understanding and interpretation of their results. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not provide any guidance on what specific quantitative measurement should be used or how to implement it. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, a quantitative measurement to assess occupation bias. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided a quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This is a relevant point that could impact the validity and generalizability of the study. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific quantitative measurement could be used. While it points out a gap in the paper, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and its potential impact on the findings. It specifically questions whether such a method might amplify updates for weights associated with hard features. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete suggestions on how to address this concern. The authors can infer that they might need to explore the impact of adaptive gradient methods on their findings, but the comment lacks detailed guidance on how to conduct this exploration or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises a question about the use of adaptive gradient methods instead of SGD and its potential impact on the findings. It specifically questions whether such a method might amplify updates for weights associated with hard features (x2). However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue might be relevant. While the authors might have an idea of where this question fits, the lack of explicit grounding makes it weakly grounded. The comment is specific in its inquiry about the potential impact of adaptive gradient methods, providing clear guidance on what aspect needs to be considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and its potential impact on the findings. It suggests that such a method might amplify updates for weights associated with hard features (x2). However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of adaptive gradient methods instead of SGD and its potential impact on the findings. It specifically questions whether such a method might amplify updates for weights associated with hard features, which could be an important consideration for the authors. While the comment identifies a potential area for exploration, it lacks specific guidance or suggestions on how the authors might address this concern or what specific aspects of the methodology might be affected. The feedback is 3 as it prompts the authors to consider a potential impact on their findings, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting additional teacher architectures or suggesting more recent methods to compare. The lack of actionable advice makes it difficult for the authors to know how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experiments and the types of teacher architectures used, as well as the comparison with methods proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the need for more diverse teacher architectures and more recent methods for comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and that there are limited types of teacher architectures. It also mentions that most compared methods are proposed before 2019. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. While it highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The comment lacks actionable advice or detailed feedback on how to enhance the experiments or broaden the scope of the comparison. As a result, the authors are left with a general understanding of the problem but without clear steps to improve their draft. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to include information from 2hop neighbors or how to clarify the effectiveness of the method. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of information and the need to clarify the effectiveness of the method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"no information from 2hop neighbors is included\" and questions the effectiveness of the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of information from 2hop neighbors and the unclear effectiveness of the method. It highlights a gap in the analysis that could be addressed to enhance the paper\"s comprehensiveness and rigor. However, the comment does not provide specific suggestions or guidance on how to incorporate this information or clarify the method\"s effectiveness. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends using the real DICOM image as experiment data instead of the PNG image and suggests using the FastMRI challenge dataset for this purpose. It also advises comparing inference speeds between different methods. This feedback provides clear and concrete actions for the authors to take, such as changing the image format and including a specific dataset for evaluation. The suggestions are direct and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"real dicom image\" and suggests using the FastMRI challenge dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, recommending the use of the real DICOM image and suggesting the FastMRI challenge dataset for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using the real DICOM image as experiment data instead of the PNG image and recommends using the FastMRI challenge dataset for comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the DICOM image is preferred or how it would impact the results. This lack of justification makes the claim 1, as the authors are left without clear guidance on how to address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending the use of the real DICOM image as experiment data instead of the PNG image. It also suggests using the FastMRI challenge dataset for comparison, which is a clear and concrete suggestion. Additionally, it advises comparing inference speeds between different methods, offering a practical and valuable direction for the authors to improve their draft. This level of detail and specificity makes the comment 5, as it guides the authors on how to enhance their experimental setup and analysis. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the binder design needs further optimization and validation, specifically mentioning that ProtPainter only provides empirical conformation estimation. However, it does not provide any explicit guidance on how to optimize or validate the binder design, nor does it suggest specific methods or experiments to conduct. The action is implied but lacks concrete details, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"binder design\" and \"ProtPainter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further optimization and validation of the binder design. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ProtPainter only provides empirical conformation estimation for binder design, suggesting that further optimization and validation are required. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further optimization and validation, specifically the binder design using ProtPainter. It highlights the need for additional work to ensure the robustness and reliability of the binder design. However, the comment lacks depth and does not provide specific suggestions or examples of how the authors might optimize or validate the binder design. While it points out a potential weakness, it does not offer actionable guidance or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the model in Figure 7 was trained, specifically inquiring about the stimulus used and the duration of the cycle. It also raises a question about whether the time scale of adaptation would shorten if the duration of the cycle changes, referencing a specific work by Smirnakis et al. in Nature 1997. The comment provides clear and direct actions for the authors to take, such as clarifying the training process and addressing the potential impact of cycle duration changes on adaptation. The explicit nature of the request and the concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the training process and the potential impact of cycle duration changes on the time scale of adaptation. The comment provides a clear direction for the authors to address the issue by asking for clarification on the training process and its potential implications. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training process of the model in Figure 7, specifically inquiring about the stimulus used and the duration of the cycle. It also references a specific work by Smirnakis et al. in Nature 1997 to support the claim that the time scale of adaptation might change with cycle duration. While the comment does not make a subjective claim or opinion, it does require clarification and evidence to be fully understood. Therefore, it is classified as \"3\" as it provides some basis for the question but lacks detailed justification or references.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of the paper that requires clarification regarding the training process of the model in Figure 7. It asks for clarification on the stimulus used and the duration of the cycle, which are crucial details for understanding the methodology. Additionally, it raises a relevant question about the potential impact of cycle duration changes on the time scale of adaptation, referencing a specific work by Smirnakis et al. in Nature 1997. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and completeness of their methodology section. However, the comment could be more helpful if it offered suggestions on how to address the potential impact or provided additional references to support the claim. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about what happens if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what potential implications it might have for their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the potential consequences of this association, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment raises a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. While it identifies a potential area of interest, it does not provide any guidance or suggestions for how the authors might address this question or what insights they might gain from exploring it. Without actionable feedback or direction, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation is needed, specifically on CIFAR10 in the full label and lower label scenarios. While the comment implies that additional evaluation is necessary, it does not provide specific guidance on what aspects of the evaluation should be expanded or how to conduct it. The authors are left to infer that they should conduct more evaluations, but without concrete instructions on what to evaluate or how to do it, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation is needed, specifically on CIFAR10 in the full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting what kind of evaluation is needed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation is needed, specifically on CIFAR10 in the full label and lower label scenarios. However, it does not provide any supporting evidence, reasoning, or examples to justify why this additional evaluation is necessary or how it would benefit the paper. Without such information, the claim remains 1, as it lacks the necessary context and justification to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more evaluation is needed, specifically on CIFAR10 in the full label and lower label scenarios. This feedback is 3 as it identifies a potential area for improvement in the evaluation section of the paper. However, it lacks specific guidance on what aspects of the evaluation should be expanded or how to conduct it. The authors are left to infer that they should conduct more evaluations, but without detailed instructions or examples, the comment does not fully support the authors in making improvements to their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and ensure they are using the same amount of data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparisons made in the table, questioning whether they are comparing apples to apples by using the same amount of data. The comment provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. The reviewer provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This provides a logical basis for the claim, as it highlights a potential issue with the comparisons made in the table. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed this issue. Therefore, the comment is 3, as it provides a clear rationale but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This feedback is clear and actionable, as it guides the authors on how to improve the comparisons in their table to ensure they are making valid and meaningful assessments. By addressing these points, the authors can enhance the clarity and robustness of their analysis. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add references or reconsider the placement of Alg 1, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it highlights areas for improvement but does not offer detailed instructions on how to achieve them.", "grounding_specificity_rationale": "The comment addresses several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. These are specific and actionable points that the authors can address to improve the clarity and completeness of their work. Additionally, the comment highlights a potential oversight in the lack of references to Laplacian eigenmaps, which could be important for the context of the paper. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered additional context or examples to guide the authors. Overall, the comment is 4 as it identifies specific areas for improvement but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and provide more motivation for the CBN approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the section and provide more motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of Section 2.1 is problematic or where the ResNet architecture is discussed, making it weakly grounded. The comment is specific in its critique of the inclusion of Section 2.1 and the need for more motivation and intuition for the CBN approach, but without clear references, it is difficult for the authors to pinpoint the exact issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. The reviewer argues that Batch Normalization is a general technique and that the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or references to support the claim that the inclusion of Section 2.1 is unnecessary or that the ResNet architecture could be better utilized. Without detailed reasoning or evidence, the claim is 3, as it provides a logical argument but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors focus on providing more motivation and intuition for their proposed methodology. However, the comment could be more helpful if it provided specific suggestions on how to enhance the motivation and intuition sections or how to better integrate the ResNet architecture into the paper. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to clarify the explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the assumption of multiplying in equation (1) by a dense projection matrix and points out the potential contradiction of expecting a sparse matrix as a result. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the assumption of multiplying in equation (1) by a dense projection matrix, suggesting that the resulting matrix would be expected to be sparse. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. This is a relevant point that could impact the clarity and accuracy of the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify their explanation. While it points out a potential weakness, it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This is a clear and concrete action that the authors can take to address the issue of lacking direct evidence for the motivation. The comment provides a specific suggestion for how to present the evidence, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of direct evidence for the motivation and suggests plotting a figure to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct, as the problem is stated as \"a predictor suffers from accuracy decline due to longterm and continuous usage.\" The reviewer suggests that the authors should plot a figure showing the decline in accuracy over time (search steps) in different settings to support their claim. This claim is 3 as it provides a logical suggestion for addressing the issue, but it lacks specific examples or references to similar studies that have successfully used such figures to demonstrate the decline in accuracy. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of direct evidence for the motivation of the study. It suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This feedback is clear and actionable, providing the authors with a concrete step to address the identified weakness. However, the comment could be more helpful if it explained why this figure is necessary or how it would strengthen the paper. Overall, the comment is 4 as it guides the authors toward a specific improvement that can enhance the clarity and credibility of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises several questions about the definition and calculation of excessive risk in the paper, particularly in relation to the optimal solution and data from different groups. It suggests that the authors should explain more about the concept of excessive risk and how it is calculated in practice, including the expectation. Additionally, it questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment provides a clear direction for the authors to clarify their explanation of excessive risk, it does not offer specific guidance on how to address each question. The action is explicit but somewhat vague, as the authors need to determine the exact details of how to respond to each point. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"line 103\" and \"Figure 3 and Figure 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the definition of excessive risk, how it is calculated in practice, and the comparability of values among different groups. The comment also seeks clarification on the relevance of excessive risk as a fairness metric. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the definition and calculation of excessive risk, particularly in relation to the optimal solution and data from different groups. It suggests that the values of excessive risk in Figure 3 and Figure 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The reviewer questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment identifies a potential issue with the definition and calculation of excessive risk, it lacks specific examples or references to support the claim that the values are positive. This makes the claim 3, as the authors would need to provide additional evidence or clarification to fully address the reviewer\"s concerns.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion regarding the definition and calculation of excessive risk in the paper. It questions the relevance of the concept of excessive risk for fairness and points out that the values in Figures 3 and 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The reviewer also raises questions about the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. This feedback is clear and actionable, as it prompts the authors to clarify their explanation of excessive risk and its practical application. By addressing these points, the authors can significantly improve the clarity and coherence of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It also references a specific paper (1 Kunstner et al., 2019) to provide context and guidance on how to address the issue. While the comment does not explicitly instruct the authors to revise their statement, it clearly identifies a potential area for improvement and provides a reference to support the claim. The action is implicit but concrete, as the authors can infer that they need to rephrase their statement and consider the reference provided. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more careful statement about initialization. The comment provides a reference to a specific paper (1 Kunstner et al., 2019) to support the claim about initialization. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in natural gradient descent (NGD) and suggests that it should be treated as pretraining. The reviewer supports this claim by referencing a specific paper (1 Kunstner et al., 2019) that discusses the limitations of empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how initialization affects NGD. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It provides a specific reference to a relevant paper (1 Kunstner et al., 2019) to support the claim about initialization and its role in natural gradient descent (NGD). This feedback is clear and actionable, as it guides the authors to reconsider their statement and potentially revise it to better align with the literature. However, the comment could be more helpful if it offered additional suggestions on how to improve the statement or provided more context on why initialization is important in this context. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a useful reference."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the lack of clarity regarding how named entities were extracted from datasets and the need for an Englishproofreading to improve the readability of the paper. While the first point is explicit in asking for clarification on the extraction process, the second point is more implicit in suggesting an improvement. However, both points are concrete in their request for clarification and actionable in that the authors know they need to provide more information or improve the readability of the paper. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for clarification on how named entities were extracted from datasets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for an Englishproofreading to improve the readability of the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding how named entities were extracted from datasets and suggests that an Englishproofreading would significantly improve the readability of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: clarity regarding the extraction of named entities from datasets and the need for an Englishproofreading to enhance the readability of the paper. While it highlights these issues, it does not provide detailed guidance or suggestions on how to address them. The feedback is 3 as it points out areas that could be improved, but it lacks depth and actionable advice that would help the authors make significant improvements to their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which would improve the condition slightly. This feedback is explicit and provides a concrete action for the authors to take, as it clearly specifies what change to make and why it might be beneficial. The authors know exactly what to do to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L200\" and \"L303,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement \"for every arm a,\" suggesting that it implies a single optimistic parameter, and provides a specific alternative suggestion for improving the condition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a logical reasoning by pointing out that this statement is misleading, as it does not account for the possibility of multiple optimistic parameters. The reviewer also suggests an alternative approach by proposing a different condition, which is based on a specific mathematical formula. This provides a clear and logical argument for the claim, making it 4. However, the comment could be strengthened by providing a more detailed explanation or reference to support the alternative approach. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which could improve the condition slightly. This feedback is clear and actionable, as it points out a potential misinterpretation and offers a specific alternative that could enhance the clarity and rigor of the paper. However, the comment could be more helpful if it explained why the current interpretation is problematic or how the suggested alternative would benefit the paper. Overall, the comment is 4 as it provides a concrete suggestion for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the terms \"L\" and \"E\" should be defined in the immediate vicinity and highlights the inconsistency in whether they are italicized or not. This provides a clear and concrete action for the authors to take, as they are instructed to define these terms and ensure consistency in their presentation. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the presentation of \"L\" and \"E\" and the inconsistency in whether they are italicized or not. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the inconsistency in the presentation of \"L\" and \"E\" and the inconsistency in whether they are italicized or not. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of \"L\" and \"E\" in the paper, noting that they are inconsistently italicized. This is a clear and actionable observation that can help the authors improve the clarity and consistency of their writing. By pointing out this inconsistency, the comment provides the authors with a concrete step to take in order to enhance the readability and accessibility of their paper. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as providing examples of how to consistently present these terms or suggesting alternative formatting options. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the experimental section is weak and suggests that more experiments are required. However, it does not provide specific guidance on what additional experiments should be conducted or how they should be structured. The authors are left to infer that they need to expand their experimental section, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and needs more experiments. However, it does not specify which part of the experimental section is considered weak or what specific experiments are needed. Without explicit references to sections, figures, or experiments, the authors cannot confidently determine which parts of the paper need improvement. The comment lacks specificity and is 1, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a weakness in the experimental section, suggesting that more experiments are required. However, it lacks specificity and does not provide any guidance on what additional experiments should be conducted or how they could enhance the paper. Without specific suggestions or examples, the authors are left without actionable feedback on how to improve their experimental section. Therefore, the comment is not helpful, as it does not provide the authors with a clear path to address the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript should include more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that additional comparisons are needed, it does not specify which models or techniques should be included or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparisons but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which models or techniques should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these comparisons could be added, the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these comparisons are necessary or how they would enhance the manuscript. Without such support, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies an area where the manuscript could be strengthened by expanding its comparisons to include a broader range of models and techniques. However, the comment lacks specific suggestions on which models or techniques to include or how to conduct these comparisons. While it points out a potential area for improvement, it does not provide detailed guidance on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies four specific errors in the text, including incorrect grammar and spelling. It provides explicit corrections for each error, such as \"Despite being compact\" to \"Despite being compact\" and \"We refer to multiway arrays\" to \"We refer to multiway arrays.\" Additionally, it corrects \"HPFN to a even deeper ConAC\" to \"HPFN to an even deeper ConAC\" and clarifies \"Effect of the modelling mixed temporalmodality features\" to \"Effect of modeling mixed temporalmodality features.\" These corrections are direct and concrete, providing clear guidance for the authors to make the necessary changes to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections to errors in the text, such as incorrect grammar and spelling. It explicitly mentions lines 2, 56, 158, and 265, allowing the authors to accurately identify the parts of the paper being addressed. Each correction is clearly specified, providing full grounding. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of corrections to errors in grammar and spelling, which are factual statements. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific errors in the text, including incorrect grammar and spelling, which are important to correct for clarity and professionalism. It provides clear and actionable feedback by pointing out the errors and offering corrections, such as \"Despite being compact\" to \"Despite being compact\" and \"We refer to multiway arrays\" to \"We refer to multiway arrays.\" Additionally, it corrects \"HPFN to a even deeper ConAC\" to \"HPFN to an even deeper ConAC\" and clarifies \"Effect of the modelling mixed temporalmodality features\" to \"Effect of modeling mixed temporalmodality features.\" This feedback is clear and precise, helping the authors improve the clarity and accuracy of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of Eqs. The reviewer does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or correct the issue. Without any guidance or direction, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the context of the equations, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the context of Eqs. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. This question highlights a potential confusion in the paper, which could be clarified to improve the understanding of the authors\" work. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to make the work more innovative or differentiate it from existing work. As a result, the authors are left without any clear direction on how to enhance their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the model extension are considered incremental or straightforward. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assessment and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve their work. Without actionable guidance or constructive criticism, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While the comment implies that the authors should conduct a comparison between the two designs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison between sequential and combinational designs, but without explicit references to sections or figures, the authors may struggle to identify where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the method may perform better in combinational logic. The comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on how to conduct this comparison or what specific aspects to focus on. The authors are left with a general suggestion but no detailed instructions on how to implement it. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a discussion of the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is concrete, as it specifies the metric to be analyzed and provides a clear direction for improvement, but it is somewhat vague because it does not provide detailed guidance on how to conduct the analysis or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides clear guidance on what aspect of the experiment needs further analysis or discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline combining LDA and LSTM (LDA+LSTM) can capture sequential information and provide topic assignment for each word. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it relates to the experiment section. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by discussing the performance of a baseline combining LDA and LSTM (LDA+LSTM) in terms of the topic switch percent metric. This feedback is clear and actionable, as it prompts the authors to include a discussion of the baseline\"s performance in their experiment section. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or analyze the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide more information about the motivation and potential applications of their work, but the comment lacks specific suggestions on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the motivation and potential applications of the work, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the motivation is unclear or that the potential benefits are unclear. The comment is 3 as it highlights areas for clarification, but it does not provide sufficient evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It highlights the difficulty in predicting the state of an object when it is occluded and questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. This feedback is valuable as it prompts the authors to consider the broader implications and potential impact of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these questions or what aspects of the motivation or potential applications should be emphasized. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance on how to implement them."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is explicit and provides a clear action for the authors to take, which is to include experiments with GPT3.5. The comment is concrete because it specifies the exact change needed to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of the proposed approach. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not direct. The comment is specific in suggesting the inclusion of GPT3.5 experiments but lacks grounding as it does not explicitly mention which part of the paper should include this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. However, the comment does not provide any supporting evidence or reasoning to justify why GPT3.5 is a better option or how it would enhance the evaluation. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly advises the authors to include a more costeffective option in their experiments. However, the comment could be more helpful if it explained why GPT3.5 is a better choice or how it would impact the evaluation. Despite this, the suggestion is valuable as it encourages the authors to consider a broader range of options for their experiments. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what to add, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of bold numbers for the baselines of previous work, particularly for WMT17WIKT where the best result in terms of BLEU is in the baselines. This provides clear guidance on what needs to be added to the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 4 should include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with Table 4, suggesting that bold numbers should be included for the baselines of previous work, particularly for WMT17WIKT where the best result in terms of BLEU is in the baselines. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of the data. However, the comment could be more helpful if it explained why this change is important or how it would enhance the clarity or impact of the table. Overall, the comment is valuable for guiding the authors in making a specific improvement to their draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take by asking for examples. The comment is concrete because it specifies the exact part of the paper where the examples should be provided, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors\" mentioned in those lines. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for verifiability.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area in the paper where examples of \"unreliable neighbors\" are mentioned. By asking for examples, the reviewer prompts the authors to provide more detailed explanations or examples to support their claims. However, the comment could be more helpful if it offered suggestions on how to present these examples or what specific aspects to focus on. While it provides a clear direction for improvement, it lacks depth and could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of support for the claim about the synergies between DQD and PPO, specifically noting the absence of mention of the TD3GA algorithm in the main paper. It also suggests that the comparison to TD3GA should be central to the paper. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include a discussion of TD3GA and its relevance to the synergies between DQD and PPO. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the TD3GA algorithm and the importance of comparing it to TD3. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the synergies between DQD and PPO are insufficiently supported, specifically mentioning the absence of the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA is crucial to understanding these synergies. The comment provides a logical reasoning for why the omission of TD3GA is problematic, but it lacks specific examples or references to support the claim that TD3GA is necessary for understanding the synergies. This makes the claim 3, as it provides a clear rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the paper. This feedback is clear and actionable, as it points out a specific omission and provides a direction for improvement. By addressing these concerns, the authors can enhance the clarity and robustness of their claims about the synergies between DQD and PPO. However, the comment could be more helpful if it offered suggestions on how to incorporate the TD3GA algorithm or provided examples of how it could be integrated into the paper. Overall, the comment is 4 as it effectively guides the authors on how to strengthen their claims and improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why the treesliced Wasserstein distance outperforms the original optimal transport distance, as observed in Sections 6.1 and 6.2. This request is clear and provides a specific action for the authors to take, which is to provide an explanation for this observation. The comment is concrete in its request for clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for an explanation of why the treesliced Wasserstein distance outperforms the original optimal transport distance, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the observation that the treesliced Wasserstein distance outperforms the original optimal transport distance, suggesting that an explanation is needed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation in the paper regarding the treesliced Wasserstein distance outperforming the original optimal transport distance. It asks the authors to explain this observation, which is a clear and actionable request for further clarification. By prompting the authors to provide an explanation, the comment helps guide them in understanding and potentially resolving a potential issue or misunderstanding in their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this observation. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the word \"confident\" in the sentence is unclear and suggests rephrasing it to clarify whether it pertains to model confidence or human interpretability. While the comment implies that the authors should rephrase the sentence to improve clarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should revise the sentence to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence containing the word \"confident,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, suggesting that the word \"confident\" should be rephrased to clarify whether it pertains to model confidence or human interpretability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the word \"confident\" in the sentence, suggesting that it may refer to model confidence or human interpretability. The reviewer provides a logical reasoning by questioning the word choice, which is a common practice in academic writing. However, the comment lacks specific examples or references to support the claim that the word is unclear or misleading. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the word \"confident\" in the sentence, suggesting that it may be unclear whether it pertains to model confidence or human interpretability. While the comment highlights a potential source of confusion, it does not provide specific suggestions for rephrasing the sentence to improve clarity. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable guidance or detailed advice on how to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the practicality of the proposed work, specifically regarding the use of known causal relationships between features. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the practicality of their work or what specific steps they could take to ensure the validity of their causal relationships. As a result, the comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the paper\"s proposal to use known causal relationships between features, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment also highlights a concern about the practicality of using prior knowledge, which is relevant to the paper\"s focus on causal relationships. However, it does not specify what aspects of the paper\"s approach or results are problematic or how they could be improved. This lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed work relies on known causal relationships between features, which may not always be available or accurate. The reviewer supports this claim by mentioning that most researchers focus on mining causal relationships from data automatically. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3, as it requires more detailed support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s approach, noting that the use of known causal relationships between features may not always be available or accurate. It highlights a practical concern by mentioning that most researchers focus on mining causal relationships from data automatically. This feedback is 3 as it points out a potential limitation in the paper\"s applicability, prompting the authors to consider the practicality of their approach. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how others have addressed similar challenges. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of polishing in figures and empirical results, which affects clarity and confidence in empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. However, the comment does not explicitly instruct the authors on how to address these issues or provide guidance on how to improve the clarity and polish of the figures and results. The action is implicit and somewhat vague, as the authors can infer that they need to improve the presentation of their results, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the lack of polishing in figures and empirical results, including missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks polishing in figures and empirical results, which affects clarity and confidence in empirical findings. The comment provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and confidence in the empirical findings of the paper. It points out specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These observations highlight areas where the paper could be improved in terms of polish and presentation, which are crucial for ensuring the validity and impact of the results. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending specific improvements or examples of how similar studies have handled these challenges. Overall, the comment is 4 as it highlights important areas for improvement, but it lacks detailed guidance on how to achieve those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcomes of taskspecific finetuning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to enhance the novelty or what specific aspects of the findings could be further explored. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work and its findings, specifically mentioning the expected outcomes of taskspecific finetuning. However, it does not specify which part of the paper this observation is based on, such as specific sections or results where these findings are presented. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention or improvement. The comment is specific in its critique of the novelty, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited due to the expected outcomes of taskspecific finetuning. However, it does not provide any supporting evidence or examples to substantiate this claim. The comment lacks specific reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcomes of taskspecific finetuning. It suggests that the novelty is expected given the general trend of taskspecific finetuning increasing confidence for specific tasks while potentially reducing generalizability. While the comment identifies a limitation in the novelty of the findings, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it highlights a potential weakness, but it lacks actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. It explicitly states that this would further test the conjecture and provide valuable insights, even if the phenomenon weakens in this setting. The comment is clear and provides a direct action for the authors to take, which is to include these numbers in their report. The action is concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, specifically mentioning the nontail classes. This provides a clear direction for the authors to consider, as it specifies the part of the paper where the additional information should be included. However, the comment does not explicitly mention which section or part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific, as it details what additional information would strengthen the case of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this additional information is necessary or how it would impact the paper\"s conclusions. Without such justification, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. This feedback is actionable as it provides a clear and specific direction for the authors to enhance their work by including additional data that could further substantiate their findings. The comment also acknowledges the potential weakening of the phenomenon in this setting but emphasizes the importance of including the numbers for completeness and insight. While the comment could be more detailed in explaining why this additional information is valuable, it still offers a valuable suggestion for improvement. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. It implies that the authors should provide additional feedback to explain this choice and potentially justify it. However, the comment does not explicitly instruct the authors to provide this feedback or specify what additional information should be included. While the action is implied, it is not concrete, as the authors are left to infer what specific feedback is needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this metric is discussed. The authors can infer that it relates to the discussion of metrics or experimental results, but this inference is not direct. The comment is specific in its question about the choice of metrics, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of weight updates is a better metric. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of metrics used in the paper, specifically questioning the rationale behind using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. This is a relevant point that could lead to a deeper understanding of the paper\"s methodology and its implications. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide additional feedback to improve the paper. While it identifies a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the objective should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the objective, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. This is a relevant point that could help the authors clarify the purpose and significance of their proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies an area for clarification, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It also suggests that the paper should explore the effects of varying the number of InContext Examples. While the comment provides explicit actions for the authors to take, such as including more details on the experiment setup and exploring different datasets, it does not specify how to implement these actions or provide concrete guidance on how to address the issues. Therefore, the comment is 3, as it clearly identifies areas for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"experiments\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment suggests exploring the effects of varying the number of InContext Examples and provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. The comment also highlights the reliance on a single dataset, which could limit the generalizability of the results. While the comment provides some logical reasoning by pointing out the limitations of the evaluation, it lacks specific examples or references to support the claim that these issues impact the generalizability of the results. Therefore, the comment is 3, as it provides a logical basis for the critique but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several critical issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It suggests that the paper should explore the effects of varying the number of InContext Examples and provides a clear direction for improvement by recommending the inclusion of more detailed information on the experiment setup. This feedback is actionable and offers a concrete way for the authors to enhance the comprehensiveness and generalizability of their evaluation. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how other studies have handled similar challenges. Overall, the comment is 4 as it effectively points out areas for improvement and provides a clear direction for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the contrastive learning framework used in the paper is the same as SimCLR, which is a direct observation. However, it does not provide any guidance or suggestions on how the authors should address this observation or what changes they should make to their framework. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the contrastive learning framework used in the paper is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the comparison to SimCLR. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which could be a potential issue or a point of comparison. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this observation or differentiate their work from SimCLR. Without actionable feedback or constructive advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This implies that the authors should include these comparisons in Section 4.3 to showcase the unique advantages or potential shortcomings of their proposed method in a broader context. The action is clear and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests that including these comparisons would provide a broader context for the proposed method. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these comparisons and determine how they would enhance the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback highlights the importance of including such comparisons to showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By suggesting these comparisons, the comment provides clear and actionable guidance for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered specific examples or references to similar studies that have included such comparisons. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so or provide guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these references. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the references to include, but it is 1 in the context of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, the comment does not provide any reasoning or explanation as to why these references are relevant or how they could enhance the paper. Without additional context or justification, the claim lacks verifiability, as it does not provide sufficient evidence or guidance for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. While this feedback identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how the authors should integrate these references into their work or what aspects of the related work are most relevant to their study. The comment is 3 as it points out a potential gap in the literature review, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should include comparisons with existing text GANs and test SeqGAN with a pretrained version, but the comment lacks specific guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The comment is specific in detailing what is missing, namely the comparison with existing GANs and the testing of SeqGAN with a pretrained version. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. However, the comment lacks specific examples or references to existing GANs or SeqGAN implementations to support the claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a comparison against existing text GANs, many of which have opensource implementations. It also points out that SeqGAN is mentioned but not tested with a pretrained version. This feedback is clear and actionable, as it highlights specific areas where the paper could be strengthened by including comparisons with existing models and testing SeqGAN with a pretrained version. However, the comment could be more helpful if it provided examples of existing GANs or suggested specific ways to implement these comparisons and tests. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. While the comment implies that the paper lacks depth in this area, it does not provide specific guidance on how to address this issue or what aspects of the algorithmic aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to expand on the algorithmic aspects but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing the algorithmic aspects or the introduction of the Blackwell winner. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithmic aspects should be addressed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This claim is based on the observation that the novelty of the paper seems limited after introducing the Blackwell winner. However, the comment lacks specific examples or detailed reasoning to support why the algorithmic aspects are crucial or how they could enhance the paper\"s contribution. The lack of specific evidence or detailed justification makes the claim 3, as it provides a logical basis but requires more detailed support to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This feedback is 3 as it identifies a potential area for improvement by suggesting that the paper could provide more depth on the algorithmic aspects. However, the comment lacks specific guidance on what aspects of the algorithmic aspects should be covered or how they could be integrated into the paper. While it points out a potential weakness, it does not offer detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that Table 4 and 5 should be split into two tables each, with one table per measure. This provides a clear and concrete action for the authors to take, as it specifies the exact change needed to improve the readability of the tables. The suggestion is specific and actionable, leaving no ambiguity about what the authors should do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of the tables by splitting them into two tables each, with one table per measure. This gives the authors a clear idea of what needs to be addressed to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that splitting tables 4 and 5 into two tables each would improve their readability. This claim is based on a logical reasoning that splitting the tables would make it easier to follow the data presentation. However, the comment does not provide specific examples or references to support this claim, such as how other papers or studies have successfully implemented this structure. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, with one table per measure. This is a clear and constructive piece of feedback that can help the authors enhance the clarity and organization of their data presentation. By following this suggestion, the authors can make their tables more intuitive and easier to navigate, which is a valuable improvement for the overall readability of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. This is a clear and direct action for the authors to take, as it provides a specific request for clarification that can be easily implemented. The comment is explicit and concrete, as it specifies exactly what needs to be added to the figure to improve its clarity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of \"valid\" and \"orig\" in the context of Fig. 5. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the understanding of the figure. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Fig. 5, noting that the terms \"valid\" and \"orig\" are used without explanation. This feedback is clear and actionable, as it suggests that the authors should specify what these terms mean in the context of the figure. By providing this guidance, the comment helps the authors improve the clarity and accessibility of their visual presentation. However, the comment could be more helpful if it offered suggestions on how to present this information, such as through a figure legend or additional text. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons with the most closely related work more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. The comment is explicit in its suggestion and offers a specific improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely making comparisons more systematic with respect to the tuning of each method. This provides clear guidance on how to enhance the originality and comparative analysis of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with the most closely related work more systematic, specifically by comparing the best performance of each method. The comment provides a logical reasoning by suggesting that such comparisons would enhance the originality and depth of the paper. However, it lacks specific examples or references to the Zemel et al. (2013) work, which would strengthen the claim. Therefore, the comment is 3, as it provides a reasonable suggestion but could be more fully supported with additional details.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need to make comparisons with the most closely related work more systematic. It suggests that the authors should compare the best performance of each method, which could enhance the originality and depth of the paper. This feedback is clear and actionable, providing the authors with a concrete step to improve their draft. However, the comment could be more helpful if it included specific examples or guidance on how to implement these comparisons. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not provide specific guidance on which method to compare or how to adapt it to language tasks. The action is implicit and somewhat vague, as the authors need to infer the specific method and adaptation steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to one of the methods mentioned in the computer vision setting, specifically mentioning lossbased sampling as an example. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison could be included. While the authors might infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in suggesting a potential improvement by including a comparison to computer vision methods, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some could be adapted to language tasks relatively easily. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to infer the specific methods and adaptations themselves, making the comment 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This feedback is 3 as it provides a specific suggestion for enhancing the paper by including a comparison that could offer insights into the applicability of computer vision methods to language tasks. However, the comment could be more helpful if it included specific examples of methods that could be adapted or how to adapt them. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion for how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need to estimate the time complexity of the learning algorithm to prove its scalability properties, which provides full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the estimation of time complexity to prove scalability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a clear and actionable suggestion that can help the authors strengthen their claims about the algorithm\"s performance. However, the comment could be more helpful if it provided additional guidance on how to estimate the time complexity or examples of how this information might be presented in the paper. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the connection themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the connection between the third point of definition one and properties of universal kernels, as discussed in chapter 4 of Steinwart and Christmann. This provides clear guidance on what the authors need to explore or clarify in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that such a connection exists. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the connection between the third point of definition one and properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This is a clear and actionable suggestion for the authors to explore a potential connection that could enhance their work. By providing a specific reference to a relevant source, the comment offers a direction for further research and potential insights that could strengthen the paper. However, the comment could be more helpful if it provided additional context or guidance on how to integrate this connection into the paper. Overall, the comment is 4 as it directs the authors to a potentially valuable area for exploration, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit actions for the authors to take to improve the discussion. There is no guidance on what aspects of the discussion need to be expanded or clarified, nor are there suggestions for how to present the information more effectively. As a result, the authors are left without any actionable steps to follow in order to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the discussion is lacking or how it could be improved, making the comment weakly grounded but specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and not \"very clearly explained.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. However, it does not provide any suggestions or guidance on how the authors might improve the clarity or depth of this discussion. Without actionable feedback or specific examples, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, as it points out a weakness but lacks depth and specificity in its critique."}
