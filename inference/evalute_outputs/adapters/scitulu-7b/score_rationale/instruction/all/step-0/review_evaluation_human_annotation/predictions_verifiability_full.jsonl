{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more analysis around the quality of the collected dataset and the potential noise it might contain. While it implies that the authors should conduct additional analysis, it does not specify what kind of analysis is needed or how to conduct it. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the artificially created dataset and its potential noise, specifically mentioning the \"pristine\" set of tweets and outofcontext images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that more analysis is needed around the quality of the dataset and the amount of noise it might have. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the dataset might have noise due to the artificial creation process, and it provides a specific example of misinformation and outofcontext images. However, the comment lacks detailed evidence or references to support this claim, such as specific examples of misinformation or outofcontext images. Without such evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is 3, as it provides a logical reasoning but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, suggesting that it might contain noise due to its artificial creation process. It provides a specific example of misinformation and outofcontext images, which is a valuable observation. However, the comment could be more helpful by suggesting ways to address this issue, such as how to assess the quality of the dataset or how to mitigate potential noise. While it highlights an important area for improvement, the lack of actionable guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific theoretical aspects to explore or methods to demonstrate convergence. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these aspects should be addressed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the theory profs or convergence properties should be explored or demonstrated. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. This feedback is clear and actionable, as it points out a critical area where the paper could be strengthened by providing more theoretical analysis and experimental evidence. However, the comment could be more helpful if it offered specific suggestions on how to address this gap, such as which theoretical aspects to explore or how to demonstrate convergence. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It implies that these options might be better alternatives to the ones chosen. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they should consider these alternatives but are not given clear instructions on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"261\" and \"272,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of operators and suggesting that the \"and\" operator or elementwise max might be better options. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. The reviewer suggests that these options might be better alternatives to the ones chosen. However, the comment lacks specific reasoning or evidence to support why these alternatives are better or how they relate to the current choices. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand and address the suggestion without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these options might be better alternatives to the ones chosen, as they correspond to the ideas of union and intersection from the \"or\" operator and elementwise min. This feedback is 3 as it prompts the authors to reconsider their choices and potentially improve the clarity and effectiveness of their work. However, the comment could be more helpful if it provided specific examples or reasoning to support the suggestion, which would guide the authors in making more informed decisions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that it might introduce noise due to the averaging of multiple contextual representations. However, it does not provide explicit guidance on how to clarify the description or address the issue of noise. The authors are left to infer that they need to clarify the description and possibly reconsider the averaging approach. While the comment identifies a potential problem, it lacks concrete instructions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, pointing out that the averaging of multiple contextual representations might introduce noise and suggesting that only one instantiation is likely correct. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging multiple contextual representations might introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is likely correct and that averaging multiple representations could lead to noise. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and potential consequences to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the averaging of multiple contextual representations might introduce noise. It provides a logical reasoning that only one instantiation is likely correct, which could lead to noise. This feedback is clear and actionable, as it points out a potential weakness in the description and suggests a possible improvement. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or address the issue of noise. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the selection of 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the potential impact of this selection on the underestimation of performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the selection of 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. This is a relevant question that could prompt the authors to reconsider their methodology or provide additional context to explain their choice. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a discrepancy in the description of the data sources, specifically noting that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be revised to improve the clarity of the description. The action is concrete and leaves no ambiguity, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the description of the data sources, suggesting that the authors should revise the description to mention Li et al. (2019a) earlier to clarify and improve the precision of the information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a discrepancy in the description of the data sources, specifically noting that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This claim is 3 as it provides a logical reasoning for the suggested revision, but it lacks specific examples or references to support the claim fully. The authors would need to make an effort to verify the claim by revisiting the lines in question and considering the suggested revision. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific discrepancy in the description of the data sources, noting that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback is clear and actionable, as it provides a concrete suggestion for how the authors can revise their description to avoid confusion and ensure clarity. By addressing this issue, the authors can improve the accuracy and comprehensibility of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for a supporting explanation. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should clarify the purpose of the reported duration and potentially include information about the time spent by the user waiting for the model to generate a response. While the action is implied, it is clear and concrete, as it guides the authors to provide a more detailed explanation or clarification in their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and requests a supporting explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests a supporting explanation. It does not make a subjective claim or express an opinion but rather seeks clarification. Therefore, it is a factual request for information and does not require verification. It is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of explanation for the purpose of the average duration reported in Table 1. It raises a valid question about whether this duration includes time spent by the user waiting for the model to generate a response. This feedback is clear and actionable, as it prompts the authors to provide a more detailed explanation or clarification in their draft. By addressing this point, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it suggested specific ways to present this information or provided examples of how other studies have addressed similar issues. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests clarification on the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action for the authors to take, as it clearly identifies the specific area that needs clarification. The comment is specific in detailing what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification on the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of clarity needed in the paper, specifically regarding the splits used for obtaining the ATIS numbers in Table 4. By asking for clarification, the reviewer provides actionable feedback that can help the authors improve the transparency and understandability of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 3 as it directs the authors to a clear area for improvement but lacks depth in its guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, and it recommends correcting the wording. However, the comment does not provide specific guidance on how to rephrase the sentence or what alternative phrasing would be more appropriate. While the action is implicit, as the authors can infer that they need to revise the wording, the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.791,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting that the authors should correct the phrase \"on par or better\" to avoid a cognitive bias among NLP researchers. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers to phrase results in a certain way, specifically by mapping instances where they perform worse to \"on par\" and the rest to \"better.\" The reviewer suggests that the wording in the paper should be corrected, but does not provide specific examples or references to support this claim. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. The authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It points out a potential cognitive bias among NLP researchers to phrase results in a certain way, which could lead to misinterpretation. The reviewer suggests correcting the wording to avoid this bias, but does not provide specific suggestions or examples of alternative phrasing. While the comment highlights an important area for improvement, it lacks detailed guidance on how to address the issue, making it 3. The authors are given a clear direction but may need to infer more detailed guidance to fully resolve the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to clarify or explain these points, but without concrete guidance, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the interpretation of results, particularly regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions about the interpretation of results in Table 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. While the comment identifies areas of confusion, it does not provide any actionable feedback or suggestions for improvement. It lacks depth and specificity, leaving the authors without clear guidance on how to address the issues raised. Therefore, the comment is rated as 2, as it points out potential areas for improvement but does not offer detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the inconsistent spacing between accuracy and standard deviation. This is an explicit observation that the authors can directly address by ensuring consistent spacing in their tables. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects the presentation\"s aesthetics. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that inconsistent spacing between accuracy and standard deviation in Tables 2 and 3 affects the presentation\"s aesthetics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting inconsistent spacing between accuracy and standard deviation. This is a clear and actionable observation that the authors can address to improve the presentation of their data. By pointing out this inconsistency, the comment provides valuable feedback that can help the authors enhance the aesthetics and readability of their tables. However, the comment could be more helpful if it offered suggestions on how to standardize the spacing or provided examples of how other tables in the field handle this issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing antecedent in the text and suggests checking the references for format issues, such as capitalization and bibliographic details. While the comment explicitly identifies the missing antecedent and provides specific guidance on what to check, it does not offer detailed instructions on how to implement these checks or what specific issues to focus on. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number \"781,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the references, suggesting that they should be checked for format, such as capitalization and bibliographic details. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that there is a missing antecedent in the text and suggests checking the references for format issues, such as capitalization and bibliographic details. However, the comment does not provide any specific examples or references to support the claim that the references are missing or incorrectly formatted. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text, noting the missing antecedent in the sentence \"both tasks.\" It also provides clear and actionable feedback by suggesting that the references should be checked for format issues, such as capitalization and bibliographic details. This feedback is valuable as it directly addresses a potential oversight in the paper, offering the authors a concrete step to improve the accuracy and consistency of their references. However, the comment could be more helpful if it provided examples of what specific issues to look for or how to address them. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or what specific aspects of the paper could be revised to enhance its originality. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered a lack of novelty, namely the application of similar ideas to videotext models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, specifically mentioning that adversarial attacks on text have been done on many NLP and imagetext models. It further notes that the paper summarizes this work and only adds a new effort by applying similar ideas to videotext models. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to substantiate the claim fully. This makes the comment 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models. It highlights that the paper summarizes this work and only adds a new effort by applying similar ideas to videotext models. While the comment points out a potential issue with the paper\"s originality, it does not provide specific suggestions or guidance on how the authors might address this lack of novelty or enhance the originality of their work. The feedback is 3 as it alerts the authors to a potential weakness, but it lacks actionable advice or detailed insights to help the authors improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It provides a clear and concrete suggestion to improve the organization of the section by recommending separate paragraphs for lexical features and sentencelevel features. This explicit guidance offers a direct action for the authors to take, making the comment 5. Authors know exactly what changes to make to improve the clarity and coherence of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the intertwined explanations for features and the suggestion to organize the section with separate paragraphs for lexical features and sentencelevel features. This provides clear guidance on how to improve the clarity and coherence of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It suggests that the section would be more coherent with separate paragraphs for lexical features and sentencelevel features. While the comment provides a logical reasoning for the suggested improvement, it lacks specific examples or references to support the claim that the current organization is confusing. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and clarity of the explanations for features in Section 3.2. It suggests that the section would be more coherent and easier to understand with separate paragraphs dedicated to lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the organization and readability of their draft. By following this advice, the authors can enhance the clarity and comprehensibility of their explanations, which is valuable for improving the overall quality of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a more concise presentation or offering suggestions for prioritizing content. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not specify which section or part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the assumptions or experimental results are problematic or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that dedicating a whole section and experimental results for the assumptions is a significant amount of space. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it could be improved. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any specific guidance or suggestions on how the authors might address this issue, such as by streamlining the content or focusing on the most important aspects. The comment lacks actionable feedback, leaving the authors without a clear path forward to improve their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that an ablation study may be needed to demonstrate the importance of the postprocessing steps proposed in the paper. While it implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct an ablation study, but the comment lacks concrete guidance on how to implement this suggestion.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of integrated gradients to measure attribution and the proposed postprocessing steps to filter out \"falsepositive\" neurons. It also suggests an ablation study may be needed, providing clear guidance on what needs to be addressed. However, the comment does not specify which part of the paper should include the ablation study, making it fully grounded but underspecific. Therefore, this comment aligns with category 4.", "verifiability_rationale": "The review point claims that using integrated gradients to measure attribution has been studied in existing papers and suggests that an ablation study may be needed to demonstrate the importance of the postprocessing steps proposed in the paper. However, the comment lacks specific references to these existing studies or detailed reasoning to support the claim that an ablation study is necessary. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the use of integrated gradients to measure attribution has been studied in existing papers. It also suggests that the paper proposes postprocessing steps to filter out \"falsepositive\" neurons but does not demonstrate their importance. The comment recommends conducting an ablation study to address this issue. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear suggestion for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it suggests a method by matching the head of noun phrases. However, it does not provide explicit guidance on how to handle the situation when the head word is not a pronoun. The comment implies that the authors should consider this issue and provide a solution, but it lacks concrete instructions or examples on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to identifying antecedents in the context of a prediction involving a pronoun. It suggests a method by matching the head of noun phrases, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing the issue with identifying antecedents in the context of a pronoun, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about identifying antecedents in the context of a prediction involving a pronoun. It suggests a method by matching the head of noun phrases, but it does not provide any supporting evidence, examples, or references to justify the claim that this method is insufficient. The comment lacks detailed explanation or examples to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the methodology proposed by the authors, specifically regarding the identification of antecedents in the context of a prediction involving a pronoun. It suggests a potential solution by matching the head of noun phrases, which is a reasonable approach. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or address the limitations of the proposed method. While it points out a potential weakness, it does not offer actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It implies that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to incorporate these baselines or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"MST baseline\" and suggests that it might be an example of a model that only considers different senses but not sememes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the inclusion of more baselines based on related work to clarify the comparison between the proposed models and those that only consider different senses. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. The reviewer suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and proposes that the paper would be stronger with the inclusion of more baselines based on related work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their comparison and strengthen their paper. However, the comment could be more helpful if it offered specific examples or references to related work that could be used as baselines. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract could be improved by providing an example of the inconsistency between evaluating with gold answers and human evaluation. While the comment implies that the authors should include this example, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an example to make the abstract more effective. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: adding an example of the inconsistency between evaluating with gold answers and human evaluation. This specificity helps the authors understand the issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract is wellwritten and invokes intrigue, but it also provides a specific suggestion for improvement. The reviewer recommends adding an example of the inconsistency between evaluating with gold answers and human evaluation, such as models being ranked differently. This suggestion is based on logical reasoning and common knowledge about the importance of consistency in evaluation methods. However, the comment could be strengthened by providing a more detailed example or reference to support the claim. Overall, the claim is 4, as it is supported by a logical suggestion but lacks specific examples or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges that the abstract is wellwritten and invokes intrigue, which is a positive observation. It also provides a specific suggestion for improvement by recommending the inclusion of an example to illustrate the inconsistency between evaluating with gold answers and human evaluation. This feedback is actionable and constructive, as it guides the authors on how to enhance their abstract to better convey the significance of their work. However, the comment could be more helpful if it provided a specific example of the inconsistency or suggested how to present it effectively. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect of their work. The comment lacks actionable details, such as recommending specific ways to present the selection process or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the selection of frame similarity factors and attributes similarity factors is unclear, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or sections need clarification, making the comment weakly grounded. However, it is specific in detailing what needs to be addressed regarding the selection process. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. It points out that the explanation of these choices is unclear, which is a valid observation that could help the authors improve the clarity and transparency of their work. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the selection process. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This provides a clear and direct action for the authors to take, which is to include these discussions in their draft. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"joint learning process\" and the specific models \"RNN\" and \"CopyRNN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the convergence of the joint learning process and how stable points in the probabilistic metric space are obtained. This provides clear guidance on what the authors need to include in their discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This claim is 3 as it logically suggests that understanding the convergence process is important for reproducing results. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to determine the exact nature of the discussions required and how they would impact the understanding of the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that discussions are required on the convergence of the proposed joint learning process, particularly for RNN and CopyRNN. This feedback is clear and actionable, as it directs the authors to provide additional information that can help readers understand how stable points in the probabilistic metric space are obtained. By addressing this point, the authors can enhance the clarity and reproducibility of their results. However, the comment could be more helpful if it provided specific suggestions on what aspects of the convergence process should be discussed or how these discussions could be integrated into the paper. Overall, the comment is 4 as it effectively guides the authors on a meaningful improvement to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides explicit actions to take, it does not offer concrete guidance on how to implement these suggestions. The authors are given a clear direction but lack detailed instructions on how to execute the actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"681\" and \"778,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the discussion of results for the task of inferring knowledge on objects and the inclusion of results for model (B). Additionally, it points out a terminology issue regarding the use of \"latent in verbs\" and suggests mentioning objects in this context. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also mentions that it would be better to use the same terminology for the model in Tables 1 and 2. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these changes are necessary or how they would improve the paper. The lack of detailed justification makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors discuss the results for the task of inferring knowledge on objects and include results for model (B). It also points out a terminology issue regarding the use of \"latent in verbs\" and suggests mentioning objects in this context. This feedback is clear and directs the authors to specific areas that need improvement, offering a concrete path for enhancing the draft. However, the comment could be more helpful if it provided additional context or examples of how these changes could enhance the paper. Overall, the comment is 4 as it identifies areas for improvement and offers actionable guidance, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific sentence in line 212 that is not correct and suggests a correction. It provides a clear and explicit action for the authors to make the sentence more accurate by suggesting that they should say they do a bidirectional encoder instead of a GRU. The comment also references Figure 2, which provides a concrete example of what the correct sentence should look like. This level of detail and specificity makes the action explicit and concrete, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the sentence, suggesting that it should be revised to accurately reflect the process. The comment provides a clear suggestion for correction, which is to use a bidirectional encoder instead of a GRU. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not correct, suggesting that it should be revised to reflect a bidirectional encoder instead of a GRU. The reviewer supports this claim by referencing Figure 2, which shows a bidirectional encoder. This provides a clear and specific example to support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or additional examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the sentence in line 212, noting that it is not strictly correct. It suggests a correction by proposing that the authors should say they do a bidirectional encoder instead of a GRU. This feedback is clear and actionable, as it provides a concrete suggestion for improving the accuracy of the sentence. Additionally, the comment references Figure 2, which could help the authors verify the correctness of the suggestion. However, the comment could be more helpful if it explained why the current sentence is incorrect or provided additional context on the significance of the correction. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment implies that the authors should consider including these baselines, it does not provide explicit instructions or detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include additional baselines but are not given specific steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, it does not specify which part of the paper this extension or the baselines should be added to, making it weakly grounded. The comment is specific in suggesting the inclusion of character embeddings as a baseline, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension is necessary or how character embeddings would enhance the work. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement these additional baselines or why they are necessary. The suggestion is 3 as it points out a potential area for enhancement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the baseline models: the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It explicitly instructs the authors to compare their work with Campos et al. and to include comparisons with other domain adaptation methods mentioned in Section 8. The comment provides concrete guidance on what needs to be added to the paper, making it 5. The authors know exactly what steps to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 277,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. While the comment highlights a potential issue with the baseline models, it does not provide specific examples or references to Campos et al. or other domain adaptation methods to substantiate the claim. This lack of detailed evidence or references makes the claim 3, as the authors would need to make a significant effort to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the weakness of the baseline models used. It points out that the authors have not compared their work with Campos et al. (2020), which also uses feedback in QA tasks, and have not included comparisons with other domain adaptation methods mentioned in Section 8. This feedback is clear and actionable, as it provides specific guidance on what the authors need to address to strengthen their work. By addressing these comparisons, the authors can significantly enhance the rigor and relevance of their study. However, the comment could be more helpful if it included suggestions on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific and leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the yaxis label in Figure 5, and suggests changing it to \"Exact Match ratio.\" This provides clear guidance on how to improve the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of Figure 5 by recommending that the yaxis label be changed to \"Exact Match ratio.\" This feedback is clear and direct, offering a straightforward way for the authors to enhance the accuracy and readability of their figure. By addressing this point, the authors can improve the clarity and comprehensibility of their visual presentation, which is valuable for enhancing the overall quality of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to consider. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains but does not provide any context or explanation for this preference. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains, but this is not directly related to the issue of societal biases. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. It does not provide any examples or data to demonstrate the presence of societal biases or how they might impact the issue at hand. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. While it identifies a relevant area for consideration, it lacks specific guidance or suggestions on how the authors might address this issue or what steps to take to ensure the knowledge bases are free from societal biases. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains, but this is not directly related to the main concern about societal biases. Overall, the comment provides some insight but lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while it is easier to show that something (e.g., attention in seq2seq MTL) is not working, the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the reasons for failure or how to modify the attention mechanism. The action is implied, as the authors are expected to infer that they need to investigate the reasons for failure and make changes to the attention mechanism. However, without concrete steps or examples, the authors may find it challenging to apply this feedback effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the discussion of attention mechanisms, but this inference is not direct. The comment is specific in its suggestion to investigate and modify the attention mechanism, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a common issue in research, where it is easier to show that something is not working but more challenging to identify the reasons for failure and make changes to improve it. It suggests that the true value lies in finding out why the attention mechanism in seq2seq MTL is not working and changing it to make it work. While the comment identifies a relevant point, it lacks specific guidance or suggestions on how to investigate and modify the attention mechanism. The authors are left with a general idea of what needs to be done but without actionable steps or detailed advice. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Table 3 should include many strong baselines that are not currently compared in the paper. It explicitly asks the authors to justify the reason for not including these baselines. This feedback provides a clear and direct action for the authors to take, which is to include additional baselines and explain the rationale behind their exclusion. The comment is specific and provides concrete guidance on what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MCNC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that Table 3 should include many strong baselines that are not currently compared in the paper, and it asks for a justification of the reason for their exclusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 3 should include many strong baselines that are not currently compared in the paper. However, it does not provide any specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to justify why these baselines should be included or how they would enhance the analysis. Without specific examples or references, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the inclusion of strong baselines in Table 3. It suggests that the MCNC should have many strong baselines that are not currently compared, such as those mentioned in reference [1]. This feedback is clear and actionable, as it prompts the authors to consider including additional baselines and justifying their exclusion. By addressing this point, the authors can enhance the comprehensiveness and robustness of their analysis. However, the comment could be more helpful if it provided specific examples of the baselines that should be included or explained why they were excluded. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It specifically mentions the reference to Supplementary Figure 6 in S3.1 and the model comparison and other details of the span vs. sentence investigation as examples of this reliance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the independence of the paper. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to independence but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as S3.1 and the model comparison, allowing the authors to accurately identify the parts being addressed. It also specifies the issue of reliance on supplemental space and the lack of independence in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It supports this claim by referencing specific sections, such as S3.1 and the model comparison, where the paper references supplementary figures and details of the span vs. sentence investigation. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it relies on supplemental space to contain the paper, which makes it not truly independent. It provides specific examples, such as the reference to Supplementary Figure 6 in S3.1 and the model comparison, to illustrate this reliance. This feedback is valuable as it highlights a critical weakness in the paper\"s independence, which the authors can address to improve the credibility and standalone nature of their work. However, the comment could be more helpful if it offered suggestions on how to mitigate this issue or what specific changes could be made to enhance the paper\"s independence. Overall, the comment is 4 as it provides clear and actionable feedback on a critical aspect of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also asks about the KNs in source language or English in Figure 3, noting that the mentions have been translated to English. The authors are instructed to correct the figure. While the comment provides explicit actions, it does not specify how to implement these changes or what specific details should be added to the input or figure. The action is clear but lacks concrete guidance on execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as adding information about the input being word embeddings and clarifying the KNs in source language or English in Figure 3. The comment provides clear guidance on what needs to be corrected, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also questions the KNs in source language or English in Figure 3, noting that the mentions have been translated to English. The comment is 3 as it provides a logical suggestion for clarifying the input and figure, but it lacks specific examples or references to support the claim. The authors are prompted to make a correction, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also questions the KNs in source language or English in Figure 3, noting that the mentions have been translated to English. This feedback is clear and directs the authors to make a specific correction that could improve the clarity and accuracy of their work. By addressing these points, the authors can enhance the transparency and comprehensibility of their methodology. Therefore, the comment is 5, as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the experiments. The feedback is vague and lacks concrete steps for the authors to take, leaving them without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the potential of the proposed augmentation method, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are the main weakness of the paper, as they are limited to an extremely lowresource regime and sentence classification, which is not the only case for using data augmentation in realworld applications. The reviewer also suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. While the comment identifies specific limitations and potential areas for improvement, it lacks detailed reasoning or references to support the claim that the experiments are weak. The suggestion for expanding the scope of the experiments is logical but could be strengthened with more specific examples or references. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. This feedback is 3 as it points out specific areas for improvement, such as expanding the scope of the experiments to include more NLP tasks. However, the comment could be more helpful if it provided specific suggestions on how to address these weaknesses or examples of other tasks that could be considered. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task. It acknowledges that generic summarization systems build similar knowledge graphs and generate summaries accordingly, but also notes that with an increase in node numbers, concept maps become harder to distinguish. The comment suggests that general summaries should be more readable. While the comment implies that the authors should consider whether to treat concept map extraction as a separate task, it does not provide explicit guidance on how to address this issue or what specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their approach to concept map extraction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether concept map extraction should be treated as a separate task. It acknowledges that generic summarization systems build similar knowledge graphs and generate summaries accordingly, but also notes that with an increase in node numbers, concept maps become harder to distinguish. The comment suggests that general summaries should be more readable. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results section where concept map extraction is discussed. The authors can infer that this comment pertains to the methodology or results section. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions whether concept map extraction should be treated as a separate task. It provides a logical reasoning by comparing it to generic summarization systems that build knowledge graphs and generate summaries. The comment also acknowledges the difficulty in distinguishing concept maps with an increasing number of nodes. However, it lacks specific examples or references to support the claim that general summaries should be more readable. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about whether concept map extraction should be treated as a separate task. It acknowledges that generic summarization systems build similar knowledge graphs and generate summaries accordingly, but also notes that with an increase in node numbers, concept maps become harder to distinguish. The comment suggests that general summaries should be more readable. While the comment identifies a potential issue with the current approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve the readability of their summaries. The feedback is 3 as it prompts the authors to consider the tradeoffs between concept map extraction and general summaries, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more information about the traits of the experts and to justify why annotation must be carried out by them, outside of its commercial value. It also asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions provide clear guidance on what the authors need to address to improve their draft. The action is explicit and concrete, as it specifies exactly what information is missing and how to incorporate it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. The comment also raises questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This level of detail provides clear guidance on what the authors need to address to improve their draft, making the comment 5.", "verifiability_rationale": "The review point raises questions about the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. It asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions imply a need for clarification or evidence to support the claim. However, the comment does not provide any supporting evidence or references to substantiate these claims. Therefore, the comment is considered 2, as it raises important questions but lacks the necessary evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the authors about the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. It raises important questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This feedback is clear and encourages the authors to provide more detailed information about the expertise and process involved in the annotation. By addressing these questions, the authors can enhance the clarity and robustness of their work. Therefore, the comment is 4, as it offers a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that lines 102106 are misleading, as they refer to a \"such distribution\" that cannot be related to the discussion in the previous section. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific changes or clarifications to be made to the text. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the misleading statement regarding \"such distribution\" and its relation to the discussion in the previous section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading, specifically mentioning that \"such distribution\" cannot refer to the discussion in the previous section. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is misleading or how it affects the clarity of the paper. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper, pointing out that lines 102106 are misleading due to the use of the term \"such distribution.\" It highlights that this phrase cannot refer to the discussion in the previous section, which is a critical observation that could lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might clarify or correct this issue, leaving them without actionable feedback. While it identifies a potential problem, it lacks depth and does not offer a path for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. While the action is implied, it is clear and concrete, as it specifies the type of examples that should be included and the context in which they should be presented. This provides the authors with a direct and specific action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where examples could be included. Without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. This feedback is 3 as it identifies a potential area for improvement in the paper, which could enhance the reader\"s understanding of the system\"s capabilities. However, the comment lacks specific guidance on how to implement this suggestion or what specific examples would be most effective. While it points out a potential improvement, it does not provide detailed instructions or examples to help the authors fully address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper\"s claims would benefit from more indepth analysis. However, it does not provide specific examples of which claims need more analysis or what aspects of the claims should be explored further. The comment lacks concrete guidance on how to improve the analysis or what specific aspects to focus on. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a number of claims from the paper would benefit from more indepth analysis, but it does not specify which claims or parts of the paper are being referred to. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts of the paper need further analysis. Additionally, the comment lacks specificity regarding what aspects of the claims should be analyzed more deeply. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not provide any specific examples or reasoning to support why these claims need further analysis or what aspects of the claims are insufficiently explored. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not specify which claims or aspects of the paper need this additional analysis. Without specific guidance or examples, the authors are left without clear direction on how to improve their draft. The comment lacks actionable feedback and does not provide the authors with a concrete path to enhance the depth and rigor of their analysis. Therefore, it is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two specific areas where the presentation of the model needs improvement: the pooling method used for embedding features (line 397) and the clarity of Equation (7) in line 472. It provides explicit questions about the pooling method and the definition of E_i in Equation (7), asking whether it represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability. This feedback is clear and provides concrete actions for the authors to take, such as clarifying the pooling method and the definition of E_i. The explicit nature of the questions and suggestions makes this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the pooling method used for embedding features and the definition of E_i in Equation (7). The comment provides detailed guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of the pooling method used for embedding features (line 397) and the definition of E_i in Equation (7) in line 472. It suggests that the LHS of Equation (7) should be a conditional probability. The comment provides logical reasoning by pointing out that the pooling method and the definition of E_i are unclear, and it questions whether they represent the type or identity of AC i. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the context and details to fully understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the presentation of the model needs improvement, providing clear and actionable feedback. It points out that the pooling method used for embedding features is not clearly defined and that Equation (7) in line 472 is not clear enough, questioning whether E_i represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability, which is a valuable suggestion for clarifying the model presentation. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and understanding of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not actually study them or discuss them further. It suggests that the hypotheses could be tested as given and that the paper should delve deeper into these topics. While the comment identifies a specific issue with the paper, it does not provide explicit instructions on how to address it or what specific aspects of the hypotheses should be explored. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the hypotheses and discuss them in more depth. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper raises two hypotheses but does not study them or discuss them further, nor are they mentioned or discussed again. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not study or discuss them further. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into these topics. However, the comment lacks specific examples or references to support the claim that the hypotheses are not studied or discussed adequately. While the reviewer provides some reasoning, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/languagespecific bias but does not study or discuss them further. This is considered misleading, as the hypotheses are not followed up on or even mentioned again in the paper. The comment suggests that the paper should delve deeper into these topics, at least to some extent, to provide a more comprehensive analysis. While it points out a critical gap in the paper, it does not offer specific suggestions on how to address this issue or what aspects of the hypotheses should be explored. This limits the comment\"s helpfulness, as it provides insight but lacks actionable guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. While the comment implies that the authors should explore this approach, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the same feature set from the cited work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. However, the comment does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the use of a particular feature set, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using feature engineering could improve the performance of the paper, citing an example from Uto et al. (2020) where a QWK of 0.801 was achieved using a set of handcrafted features. This provides a logical basis for the claim, as it suggests that using similar features could potentially enhance the results of the current work. However, the comment lacks specific details on how the feature engineering approach was implemented in Uto et al. (2020) or how it could be applied to the current work. This makes the claim 3, as it provides a reasonable basis but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement this suggestion or what specific features from Uto et al. (2020) could be used. The feedback is 3 as it points out a potential direction for improvement, but it could be more beneficial with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and seeks clarification on its role in the evaluation process. It implies that the authors should provide more information about how the CS is used, whether it is used for augmenting the training material, and the data split used. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the CS. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Challenge Set\" (CS), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the CS is used, whether it is used for augmenting the training material, and the data split used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically inquiring about its role in evaluation and whether it is used for augmenting the training material. It also asks for clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the paper\"s claim of generalization to different knowledge, suggesting that the substructure needs to be represented as a sequence of words. It also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to clarify the terminology. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the use of \"knowledge\" and the generalization of the model, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim of generalization to different knowledge and questions the use of constituent parse as knowledge. It also raises concerns about the term \"knowledge\" being misleading in the context of the paper. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the use of \"knowledge\" and the generalization of the model, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim of generalization to different knowledge, suggesting that the substructure needs to be represented as a sequence of words. The reviewer also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. The comment provides a logical reasoning for the critique, noting that the term \"knowledge\" is usually associated with external entities or a knowledge base, not syntax or semantics. However, the comment lacks specific examples or references to support the claim that the use of \"knowledge\" is misleading. This makes the claim 3, as the authors would need to further explore and address the issue to fully understand and resolve the concern.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim of generalization to different knowledge, suggesting that the substructure needs to be represented as a sequence of words. It also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. This feedback is 3 as it highlights a potential misunderstanding or misuse of terminology, which could impact the clarity and accuracy of the paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify the terminology or address the issue of generalization. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should investigate the gap between the oracle GAP for PPDBClus and the performance of the clustering approach, but it lacks specific instructions on how to conduct this investigation or what specific aspects to focus on. Additionally, it does not offer suggestions on how to improve the uniformity of the performance across all parts of speech. As a result, the comment is 3, as it identifies areas for concern but lacks concrete guidance on how to address them.", "grounding_specificity_rationale": "The comment addresses the performance of the TWSI model on nouns and the contradiction with the claim of generalizability to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is not uniform, which directly contradicts the claim. However, the comment does not specify which part of the paper discusses the performance on nouns or the claim about generalizability, making it weakly grounded. The comment is specific in detailing the issues with the performance and the contradiction, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is not uniform, which directly contradicts the claim that the clustering approach is generalizable. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration for the authors to fully understand and address the issues raised.", "helpfulness_rationale": "The review comment identifies a concern about the performance of the TWSI model on nouns, which is a specific area of interest. It also questions the generalizability of the clustering approach to all parts of speech, given the performance on nouns and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. This feedback is valuable as it highlights a potential weakness in the paper that the authors should address. However, the comment could be more helpful if it provided specific suggestions on how to investigate or improve the performance on nouns or how to address the contradiction with the claim of generalizability. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It explicitly requests examples of spurious structures to help clarify the discussion. This feedback is clear and provides a specific action for the authors to take, which is to provide examples of spurious structures to support their claims. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is that it is too abstract and does not provide insights into why the new model is better than MH. The comment also requests examples of spurious structures to help clarify the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. However, the comment lacks specific examples or references to support the claim that the discussion is abstract or lacks clarity. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstractness of the discussion in Section 5.2, noting that it does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. While the comment highlights a clear area for improvement, it lacks depth and does not provide specific guidance on how to address the issue or what kind of examples would be helpful. This limits the comment\"s usefulness, as it points out a problem but does not offer detailed suggestions for improvement. Therefore, the comment is 3, as it provides some direction but could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is an explicit action that the authors can directly implement by adding a statement to their paper. The comment is clear and provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a statement about the maximum number of tasks done by any annotator. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. Without explicit references, the authors cannot confidently determine the exact location of the suggested addition. The comment is specific in its request for a particular piece of information, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is a specific and actionable piece of feedback that can help improve the transparency and reproducibility of the study. By including this information, the authors can provide more detailed insights into the variability of task completion across annotators, which could be valuable for understanding the robustness of their results. However, the comment could be more helpful if it explained why this information is important or how it might impact the interpretation of the findings. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested. However, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not specify which parts of the paper are particularly challenging to understand or where the authors should focus their efforts to improve clarity. Without explicit references to sections or specific analyses, the authors may struggle to identify the areas that need attention. Therefore, the comment is weakly grounded because it does not specify which parts of the paper are being addressed, and it is not specific in detailing what needs to be clarified. This aligns with a score of 2.", "verifiability_rationale": "The review point expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant challenge in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different pieces of the puzzle fit together. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors\" attention to a crucial aspect of their work, but it could be more beneficial with actionable advice or examples. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and direct action for the authors to take, as it provides a specific request for inclusion in the table. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to show the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including the hard prompt baseline in Table 1 would provide insight into the increase in performance of each method. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and actionable suggestion that could help the authors better present their results and provide a more comprehensive analysis. By including the hard prompt baseline, the authors can demonstrate the effectiveness of their methods and highlight the improvements achieved. However, the comment could be more helpful if it provided additional context or explanation on why this inclusion is important or how it would enhance the analysis. Overall, the comment is 4 as it offers a specific and actionable suggestion for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. While it implies that the authors should include numerical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the application to popular algorithms should be discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for numerical results and application to popular algorithms, but it is 1 as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of numerical results in the paper. It expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. This feedback is 3 as it highlights a gap in the paper that could be addressed to enhance its comprehensiveness and rigor. However, the comment lacks specific guidance on how to implement these improvements or what specific numerical results should be included. To be more helpful, the comment could provide examples of what kind of numerical results would be relevant or suggest how to integrate these findings into the existing work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The comment is specific in detailing what additional comparisons are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental comparisons and suggests testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional comparisons are needed and why they are important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional comparisons are necessary or how they would impact the results. Without such justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental comparisons, specifically noting that the proposed InvP method is not tested with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback is valuable as it suggests a potential area for improvement in the experimental design, which could enhance the robustness and generalizability of the results. However, the comment could be more helpful if it provided specific guidance on how to implement these additional comparisons or why they are important. Overall, the comment is 4 as it points out a relevant area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection is not welldrawn and recommends either formalizing it more or adjusting the language to clarify the connection. This provides a clear and explicit action for the authors to take, either by strengthening the formal basis of the connection or by rephrasing the language to enhance clarity. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that the probabilistic connection is not welldrawn and recommends either formalizing it more or adjusting the language to clarify the connection. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors can infer that it relates to the discussion of the probabilistic connection, but this inference is not direct. The comment is specific in suggesting how to address the issue, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not welldrawn and suggests that it should be formalized more or clarified in the language. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific sections of the paper where the connection is unclear or inadequately formalized. As a result, the claim is 3, as it points out a potential issue but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the probabilistic connection is not welldrawn and lacks formalization. It suggests that the authors either formalize this connection more or adjust the language to clarify it. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. However, the comment could be more helpful if it offered specific examples or guidance on how to formalize the connection or clarify the language. Overall, the comment is 4 as it points out a critical area for improvement and provides a clear direction for the authors to enhance the clarity and rigor of their work."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is explicit in its request for additional evidence, providing a clear action for the authors to take. However, it does not specify what kind of evidence would be sufficient or how to present it, leaving some room for interpretation. Therefore, the comment is 4, as it identifies a specific area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests providing empirical evidence to support the claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of evidence would be sufficient. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this claim is made, the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to provide concrete evidence to substantiate their claims. However, the comment could be more helpful if it specified what kind of empirical evidence would be most effective or provided examples of similar studies that have successfully demonstrated this kind of improvement. Despite this, the comment still offers valuable guidance for enhancing the paper\"s credibility and rigor. Therefore, it is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for modifications to improve the scalability of the robust training scheme. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the robust training scheme, specifically questioning its scalability to practical datasets, particularly those with highdimensional domains. However, it does not specify which part of the paper this concern is based on, such as a specific section or figure where the robust training scheme is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issue with the scalability of the robust training scheme, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those with highdimensional domains. The comment provides a logical reasoning by suggesting that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to fully understand and address the concern without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. It points out that the accuracy might unfavorably scale unless the size of V scales exponentially with the dimension. This feedback is 3 as it highlights a potential limitation of the robust training scheme, which the authors should consider when designing their experiments or evaluating its applicability. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how it might be overcome. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without understanding the type of style shifts that occur during this period, it is difficult to appreciate what the model is capturing. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or specific actions for the authors to take, such as recommending additional datasets or discussing the type of style shifts that occur during the fouryear period. As a result, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without understanding the type of style shifts that occur during this period, it is difficult to appreciate what the model is capturing. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its question about the duration and type of style shifts, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of datasets and the duration of four years for studying style shifts, suggesting that it is insufficient to understand the type of style shifts that occur during this period. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why four years might not be sufficient for studying style shifts. As a result, the claim is 3, as it raises a valid question but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the duration of four years for studying style shifts. It questions whether four years is sufficient to understand the type of style shifts that occur during this period, which is an important consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or discussing the type of style shifts that occur during the fouryear period. While it identifies a potential weakness, the feedback does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the callout to Table 5 should be changed to Table 3 and provides the correct page and section number. Additionally, it points out that the figure 6 callout is not directing properly. This feedback is clear and provides specific actions for the authors to take, ensuring that they know exactly what needs to be corrected. The explicit nature of the instructions and the concrete details on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the callout to Table 5 and the figure 6 callout, providing detailed guidance on how to correct these issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the callout to Table 5 should be changed to Table 3 and that the figure 6 callout is not directing properly. However, the comment does not provide any supporting evidence, reasoning, or examples to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a mistake in the callout to Table 5, which should be changed to Table 3, and noting that the figure 6 callout is not directing properly. This feedback is clear and directs the authors to correct specific errors in their paper, ensuring that the references are accurate and easy to follow. By addressing these issues, the authors can improve the clarity and accuracy of their work. Therefore, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant concern with the experiments, specifically the lack of comparisons with other models, such as SketchRNN. It explicitly states that the paper should include comparisons with other models to provide a more comprehensive understanding of its results. The comment is clear and provides a concrete action for the authors to take, which is to include comparisons with other models. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of comparisons with other models, and suggests including comparisons with SketchRNN. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparisons with other models, specifically mentioning SketchRNN, and that this lack of comparisons contributes to the poor motivation problem. The comment provides a logical reasoning by suggesting that comparisons with other models would enhance the paper\"s comprehensiveness and credibility. However, it does not provide specific examples or references to support the claim that SketchRNN is a relevant comparison, nor does it explain why this comparison is necessary. While the claim is 3, it could be strengthened with additional justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s experiments, specifically the lack of comparisons with other models. It points out that the paper only includes selfcomparisons, which contributes to the poor motivation problem. The comment suggests that comparisons with SketchRNN could be beneficial. While the comment highlights an important area for improvement, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. This limits the comment\"s helpfulness, as it offers a direction for improvement but lacks detailed instructions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment recommends conducting more analysis and providing comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint regarding the benefits of increased model capacity for both CNNs and ViTs. The comment provides specific observations about the performance of DeiTB models compared to DeiTT and DeiTS, noting that DeiTB does not outperform DeiTS in certain datasets. However, it does not provide explicit guidance on how to conduct the analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. The comment provides specific observations about the performance of DeiTB models compared to DeiTT and DeiTS, noting that DeiTB does not outperform DeiTS in certain datasets. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim that the authors\" viewpoint is incorrect regarding the benefits of increased model capacity for both CNNs and ViTs. The reviewer provides specific observations from Figure 3, noting that DeiTB models do not outperform DeiTT or DeiTS in certain datasets. This claim is supported by the data and observations presented, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that support the authors\" viewpoint. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint regarding the benefits of increased model capacity for both CNNs and ViTs, noting that the DeiTB models do not outperform DeiTT or DeiTS in certain datasets. This feedback is valuable as it encourages the authors to reconsider their conclusions and potentially revise their analysis to better support their claims. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct the analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear direction for enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges that the paper is not difficult to follow but points out specific areas that may cause confusion. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve clarity or what specific changes should be made to avoid confusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not specify which sections or parts of the paper these areas are located in, making it difficult for the authors to pinpoint the exact issues. The comment is specific in identifying potential areas of confusion but lacks grounding as it does not specify where these issues are located in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the identified areas of confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any detailed guidance or suggestions on how to address these areas of confusion. Without actionable feedback or specific examples, the authors are left without a clear path to improve the clarity of their draft. Therefore, the comment is 2, as it points out an issue but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the claim of \"no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This feedback is clear and directs the authors to review the references mentioned to understand the tools available in the reinforcement learning setting. The action is explicit and concrete, as the authors know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the lack of corresponding tools for the reinforcement learning setting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides references to support the claim, which helps the authors understand the context and substantiate the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. However, the comment does not specify which references are being referred to or how they support the claim. This lack of detailed explanation or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some support but lacks the necessary detail to be 5.", "helpfulness_rationale": "The review comment challenges a claim made in the paper regarding the availability of tools for the reinforcement learning setting. It provides a specific rebuttal by referencing external sources, which is a valuable contribution to the discussion. However, the comment could be more helpful if it explained why these references are relevant or how they address the claim. While the feedback is clear and actionable, it lacks depth and could be improved with additional context or explanation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or how to improve the technical competency required to understand them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not specify which part of the paper this issue pertains to, such as the results section or a particular technique. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in its critique of the technical competency required to understand the results, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, suggesting that they are not immediately obvious and require a certain level of technical competency. This is a valuable observation that could prompt the authors to reconsider the accessibility and clarity of their results. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending ways to simplify the techniques or improve the presentation of results. While it points out a potential weakness, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. While the comment implies that the authors should make this distinction, it does not provide explicit instructions or concrete steps on how to implement this distinction. The authors are left to infer that they should make this distinction, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this distinction is necessary or how it would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This feedback is 3 as it identifies a potential area for clarification and differentiation in the paper. However, the comment lacks specific guidance on how to implement this distinction or why it is important for the paper. While it points out a potential issue, it does not provide detailed suggestions or examples on how to address it, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the discrepancy in data usage and the conclusion, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the conclusion that the direct model is clearly better based on the difference in data usage between the direct and endtoend systems. However, it does not provide specific data or references to support this claim, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed evidence or reasoning to substantiate the claim, making it 3. The authors would need to further explore the data usage and performance differences to fully address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion drawn about the superiority of the direct model compared to the endtoend system. It points out that the difference between the two systems is only a few percentage points, which raises questions about the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment highlights specific areas that need improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to provide more detailed explanations and evidence for GaRare\"s advantages over GaLore, as well as clarify the process of updating parameters. However, the comment lacks specific guidance on how to achieve these improvements, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GaRare\" and \"GaLore\" algorithms, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and provides a specific example of the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment suggests that this lack of detail hinders understanding. However, the comment does not provide specific examples or references to support the claim that GaRare has advantages over GaLore or that the current presentation is insufficient. While the claim is logical, the lack of detailed evidence or examples makes it 3, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors enhance their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing examples or references to similar works that have successfully motivated their algorithms or presented detailed algorithmic explanations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides explicit actions, it does not offer detailed guidance on how to conduct the ablation study or the specific experiment. The authors are left to infer the details of how to implement these suggestions, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left\" and \"visDial dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely conducting an ablation study on the visDial dataset and conducting an experiment on the performance of ATT(+H) in figure 4 left. The comment provides detailed guidance on what aspects to explore and how to support the proposed model in real datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides a logical request for additional experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the experiment and the potential impact of the suggested change. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. This feedback is clear and offers a concrete direction for the authors to improve their draft by conducting additional experiments and providing more evidence for the effectiveness of their model. However, the comment could be more helpful if it included suggestions on how to design and conduct the ablation study or the specific aspects of the ATT(+H) experiment to focus on. Overall, the comment is 4 as it guides the authors toward meaningful enhancements to their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of a reference to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of references to similar work that shares a similar structure and inference capabilities with the CRF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the relevance or significance of these references. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. This feedback is 3 as it points out a gap in the literature review that could enhance the authors\" understanding and comparison of their work. However, the comment could be more helpful if it provided specific examples or references to these similar works, which would guide the authors in incorporating them into their analysis. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. It also questions whether any input serves as white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the authors spend a lot of time showing WPA improves the test performance of the original model but do not provide insights into how WPA works. This feedback highlights a gap in the paper that needs to be addressed, suggesting that the authors should provide a deeper understanding of WPA to spark future research directions. The comment is explicit in its request for an explanation and provides concrete guidance on what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"np.ones input,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of why WPA works and the implications of the results shown in Figure 2. The comment provides a clear direction for the authors to improve their draft by explaining the model\"s predictions and the limitations of Gaussian noise input. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the effectiveness of WPA and suggests that the authors should provide an explanation of why it works. It references Figure 2, which appears to suggest that Gaussian noise input does not work as well as WPA. The reviewer also points out that the paper spends a lot of time showing WPA improves test performance but lacks insights into how it works. This claim is 3 as it provides a logical basis for the suggestion to explain WPA, but it lacks specific examples or references to support the claim about Figure 2. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a comprehensive critique of the paper, highlighting several areas that need improvement. It suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. This feedback is valuable as it encourages the authors to provide a deeper understanding of WPA, which could lead to new research directions. Additionally, the comment questions why Gaussian noise input does not work as well as WPA, based on Figure 2, and points out that the paper spends a lot of time showing WPA improves test performance but lacks insights into how it works. This feedback is clear and actionable, as it directs the authors to address specific gaps in their explanation and analysis. Overall, the comment is 5 as it guides the authors toward improving the clarity and depth of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method part of the paper is similar to a related work mentioned, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification on this similarity. While the comment implies that the authors should provide more information or explanation regarding the similarities, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification, but it is concrete in that it specifies the need for more information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"method part\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the similarity to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and requests clarification on this similarity. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the method part of the paper is similar to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the method part of the paper, suggesting that it is similar to a related work mentioned in the paper, \"Generating Adversarial Disturbances for Controller Verification.\" It asks for clarification on this similarity, which is a relevant point for the authors to address. However, the comment does not provide specific guidance on how to clarify this similarity or what aspects of the method need to be differentiated from the related work. While it points out a potential weakness, it lacks detailed suggestions or examples to help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for clarification but does not fully support the authors in making the necessary improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison with other methods and consider promoting existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed method, such as the use of a proposal generator pretrained on MSCOCO and its potential impact on existing class incremental semantic segmentation methods. It also mentions the authors\" adequate addressing of limitations and potential negative societal impact. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its inquiry about the fairness of comparison and the potential promotion of existing methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about fairness or the potential impact on existing methods. This makes the claim 3, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas for consideration, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a critical issue regarding the absence of discussion on how the important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include a discussion on parameter sensitivity, but the comment lacks concrete details on what aspects of this discussion should be included or how to conduct the analysis. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"End of Sec.2\" and the specific parameters/thresholds being discussed, namely the minimum cluster size and conductance threshold. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the absence of discussion on how these parameters are set and how sensitive the performance is to them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental section (Sec. 3) does not discuss or mention how the important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue in the paper, specifically the absence of discussion on how important parameters (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This is a significant oversight that could impact the validity and reproducibility of the experimental results. The comment provides a clear and actionable suggestion for the authors to include a discussion on parameter sensitivity, which is crucial for ensuring the robustness and generalizability of their findings. However, the comment could be more helpful if it offered specific guidance on how to conduct this analysis or what aspects of the parameter sensitivity should be discussed. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 could benefit from a slower development to improve readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need more development. The comment lacks concrete details on how to implement this suggestion, such as recommending additional content or a different structure. As a result, the authors are left without clear instructions on how to enhance the readability of the section. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the section is \"very tersely written\" and could benefit from a slower development for easier readability. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 4 is \"very tersely written\" and could benefit from a slower development to improve readability. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style of Section 4, noting that it is \"very tersely written\" and could benefit from a slower development to improve readability. While the comment highlights a potential problem, it lacks specific suggestions or guidance on how to achieve this improvement. It does not provide actionable steps or examples of how to enhance the readability of the section, leaving the authors without clear direction on how to address the issue. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific changes could be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the use of reinforcement learning, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance on how the authors might address this concern or improve their approach. Without detailed suggestions or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not offer enough detail for the authors to effectively address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, making it 5. The comment is specific about what needs to be included and explained, giving the authors a clear path to improve their draft. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the distribution of videos of different lengths within the benchmark and the explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide relevant explanations regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This claim is 3 as it logically points out a gap in the paper\"s explanation and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or references to support the importance of this explanation or the impact of the distribution on the assessment of reasoning ability and robustness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of explanation regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and actionable, providing the authors with a specific and concrete step to improve their draft. By addressing this issue, the authors can enhance the transparency and comprehensiveness of their work, making the comment 5. Therefore, it is rated as 5 on the helpfulness scale."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify how the implemented billinear layer differs from other approaches that perform billinear pooling. It raises questions about the dimensionality of embeddings and how the billinear layer is swapped out with other approaches. Additionally, it asks about the compression of representations using Equation (3) in this case. While the comment provides specific questions that need to be addressed, it does not offer explicit guidance on how to implement these clarifications or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, the differences between the billinear layer and other approaches that perform billinear pooling. The comment raises questions about the dimensionality of embeddings, how the billinear layer is swapped out with other approaches, and whether the compression of representations using Equation (3) is still done in this case. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the differences between the billinear layer and other approaches that perform billinear pooling. It suggests that the major difference might be the dimensionality of embeddings, but it does not provide any evidence or reasoning to support this claim. The comment also asks about the compression of representations using Equation (3) and how the billinear layer is swapped out with other approaches. While it identifies areas for clarification, the lack of supporting evidence or detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area where the authors need to clarify the differences between the billinear layer and other approaches that perform billinear pooling. It raises important questions about the dimensionality of embeddings and how the billinear layer is swapped out with other approaches, such as the hadarmard product and MCB approaches. Additionally, it questions whether the compression of representations using Equation (3) is still done in this case. This feedback is clear and actionable, providing the authors with specific areas to address in order to improve the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to clarify these points or provided examples of how other approaches handle these issues. Overall, the comment is 4 as it directs the authors to important areas for clarification and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to ensure the dataset is made available. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to take a cautious approach until the dataset is accessible, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not yet been made publicly available, suggesting that a cautious approach should be taken regarding the contribution until the dataset is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. This is a relevant point that could impact the credibility and impact of the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure the dataset is made available. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is 3, as it identifies a potential issue but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the limited novelty of the proposed method and its similarity to other attentional modules in previous works. It specifically mentions that the group attention design is related to ResNeSt but not discussed in the paper. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should discuss the similarities and differences between their work and previous works, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"group attention design\" and \"ResNeSt,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the similarity to other attentional modules in previous works, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works, such as ResNeSt, and noting that the group attention design is related to these works but not discussed in the paper. However, the comment lacks detailed comparisons or specific examples from these works to fully substantiate the claim. While the references provide some context, the comment could be strengthened by offering more specific examples or comparisons to fully support the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules in previous works. It specifically mentions the group attention design and its relation to ResNeSt, which is not discussed in the paper. This feedback is valuable as it highlights a potential weakness in the originality of the work, prompting the authors to address this issue. However, the comment could be more helpful if it provided suggestions on how to differentiate the method or discuss its unique aspects. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. This feedback provides a clear and explicit action for the authors to take, which is to include the illustration of the results in the paper. The comment is specific and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e.\" and \"Eqn 13,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the illustration of the results of the latter loss term of Eqn 13. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results of the latter loss term of Eqn 13 should be illustrated directly, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this illustration is necessary or how it would enhance the understanding of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, specifically suggesting that the authors should illustrate the results of the latter loss term of Eqn 13 directly. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and comprehensiveness of the paper. By addressing this point, the authors can enhance the understanding and interpretation of their results, which is valuable for improving the draft. However, the comment could be more helpful if it explained why this illustration is important or how it would benefit the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning [AB]. It suggests that a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of robustness in video action recognition and the lack of comparison with testtime adaptation (TTA) methods, such as [AB]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a comparison with TTA methods to prove the superiority of data processing over model parameter adjustment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with testtime adaptation (TTA) methods, specifically mentioning [AB]. The reviewer suggests that such a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. However, the comment does not provide specific examples or references to support the claim that TTA methods are relevant or how they could be applied to the paper. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of comparison with testtime adaptation (TTA) methods, such as [AB]. This is a critical observation as TTA methods aim to adapt to outofdistribution data when the input data is disturbed by noise. The reviewer suggests that a comparison with TTA methods could provide valuable insights into the effectiveness of data processing versus model parameter adjustment. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct such a comparison or what specific aspects to focus on. This limits the comment\"s helpfulness, as it points out a significant weakness but does not provide actionable steps for the authors to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a mistake in the first expression for J (\u03b8) and suggests it should be Q (s t 0, \u03c0\u03b8(s t 0)). This provides a clear and direct action for the authors to take, specifying the correct expression to use. The comment is specific and actionable, giving the authors a precise correction to make in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J (\u03b8), suggesting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J (\u03b8) is incorrect and should be Q (s t 0, \u03c0\u03b8(s t 0)). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific mistake in the first expression for J (\u03b8) in Section 3.2.1, noting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This is a clear and actionable piece of feedback that the authors can easily address to correct their draft. However, the comment could be more helpful if it provided additional context or explanation on why this mistake occurred or how it affects the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area needing correction. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with capitalization in the paper, including specific references that need capitalization. It also mentions that various words in the references need capitalization. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues. The authors are left to infer that they should review and correct the capitalization in the references and in the text. The action is implicit and somewhat vague, as it lacks detailed guidance on how to apply the corrections. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p. 8\" and \"Various words in many of the references need capitalization,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the capitalization issues in the references and provides examples of specific words that need capitalization, such as \"ai\" and \"Advances in neural information processing systems.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about capitalization issues in the paper and references. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several capitalization errors in the paper and references, which is a clear and actionable piece of feedback. It provides specific examples of words that need capitalization, such as \"ai\" and \"Advances in neural information processing systems,\" and points out capitalization inconsistencies in the references. This level of detail and specificity is valuable for the authors, as it allows them to easily correct these errors and improve the presentation of their work. However, the comment could be more helpful if it included suggestions on how to ensure consistent capitalization throughout the paper. Overall, the comment is 4 as it effectively guides the authors on a specific area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the missing parameter values for task 1 and the Boltzmann policy, specifically asking about the model parameters and the method used to choose them. While it does not explicitly instruct the authors to provide these details, the questions are clear and specific, indicating what information is missing and what the authors should include in their draft. The action is implicit but concrete, as the authors can infer that they need to provide the missing information. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific tasks, such as \"task 1\" and the Boltzmann policy, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on the model parameters and the method used to choose them, as well as how the parameters were chosen (e.g., maximum likelihood estimates). This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification on specific parameters and methods used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific missing information regarding the model parameters and the method used to choose them, particularly for task 1 and the Boltzmann policy. It raises important questions about the clarity and completeness of the paper, prompting the authors to provide necessary details that could enhance the understanding and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar information has been presented in other works. Despite this, the feedback is 4 as it directs the authors to important areas for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors claim to achieve stateoftheart results on challenging scene text recognition tasks, but the reviewer finds this claim unconvincing. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. While the comment implies that the authors should conduct such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct comparisons experiments to validate their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It also mentions the need for comparisons experiments with existing detection methods. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or claims presented in the paper. The comment is specific in its critique of the claim and the suggestion for comparisons, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks are unconvincing. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the basis of the claim and the need for comparisons experiments, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks. It suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. This feedback is 3 as it points out a potential weakness in the authors\" claims and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why they believe applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 deteriorates performance compared to only applying it to layers 3 and 4. It provides a clear and direct action for the authors to take, which is to provide an explanation or rationale for this observation. The comment is specific and actionable, as it guides the authors on how to address the issue by offering a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the deterioration in performance when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4 compared to only layers 3 and 4. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2 deteriorates performance compared to only applying it to layers 3 and 4. However, the comment lacks specific details or evidence to support this claim, such as data or analysis that demonstrates the performance difference. Without such supporting information, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2, noting that this deteriorates performance compared to only applying it to layers 3 and 4. It prompts the authors to provide an explanation or rationale for this observation, which is a clear and actionable suggestion. By addressing this issue, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it included specific suggestions on how to investigate or explain the performance difference. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the lack of comparison with a highly relevant method, specifically mentioning [1] and its proposed approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. The reviewer clearly states that the authors should include a comparison of their method with the one proposed in [1]. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, specifically mentioning [1] and its proposed approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with the method proposed in [1]. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning [1] and its approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of comparison with a highly relevant method, [1], which proposes a method for utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. By highlighting this omission, the comment provides the authors with a clear and actionable suggestion to include a comparison with the method proposed in [1]. This feedback is valuable as it directs the authors to a potential enhancement that could strengthen their work. However, the comment could be more helpful if it included specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it effectively points out a gap in the paper and offers a concrete suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or suggesting a specific approach to improve the clarity. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the Witness oracle is confusing or how it could be clarified, making the comment weakly grounded but specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the confusion caused by the implicit call to the Witness oracle. This feedback is clear and actionable, as it points out a specific area that needs clarification or explanation. However, the comment could be more helpful if it provided suggestions on how to clarify or improve the explanation of this concept. Despite this, the feedback is 3 as it directs the authors to a critical area that requires attention. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the proposed method\"s inability to handle headpose and questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The comment implies that the authors should consider incorporating headpose control into their method, but it lacks concrete steps or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"headpose,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the method cannot handle headpose and why it cannot be conditioned like a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that a previous work (e.g., Gafni et al. ICCV 2021) is able to control both facial expression and headpose. The reviewer questions why the NeRF method cannot condition the headpose parameters beyond facial expression, similar to the previous work. This claim is 3 as it references a specific work, providing some basis for the comparison. However, the comment lacks detailed explanation or examples of how the NeRF method could be adapted to handle headpose, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed method, noting that it cannot handle headpose while a previous work (e.g., Gafni et al. ICCV 2021) is able to control both facial expression and headpose. The comment questions why the NeRF method cannot condition the headpose parameters beyond facial expression, similar to the previous work. This feedback is valuable as it highlights a potential area for improvement and encourages the authors to consider incorporating headpose control into their method. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how similar approaches have been implemented. Overall, the comment is 4 as it points out a critical weakness and prompts the authors to consider a potential solution, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns that appear only a few times in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to mitigate the impact of these spurious features. While the authors can infer that they need to consider the potential impact of these features, the lack of concrete suggestions or detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the spurious features, comparing them to backdoor triggers and referencing specific examples from Chen et al. (2017) and Gu et al. (2019). This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns that appear only a few times in the training set. The reviewer supports this claim by referencing specific examples from Chen et al. (2017) and Gu et al. (2019), which are wellknown studies on backdoor triggers. This provides a strong foundation for the claim, making it 4. However, the comment could be further strengthened by providing more detailed examples or additional references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers. It provides a clear and specific comparison to wellknown examples from Chen et al. (2017) and Gu et al. (2019), which helps the authors understand the implications of this similarity. The comment highlights the potential impact of these spurious features on the trained model, suggesting that a few training examples with such triggers could significantly affect the model\"s performance. This feedback is valuable as it points out a specific area that the authors need to address, providing a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to mitigate the impact of these spurious features or how to address the issue in the paper. Overall, the comment is 4 as it identifies a critical area for improvement and provides a solid foundation for the authors to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a main component and that the optimization algorithm seems to be directly borrowed from previous works, which could be confusing and reduce the contribution. However, it does not provide explicit guidance on how the authors should address this issue or suggest improvements. The comment lacks concrete steps or suggestions for enhancing the contribution or clarifying the optimization algorithm. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of structural optimization being a main component and the use of an optimization algorithm that seems to be directly borrowed from previous works. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the confusion caused by the direct borrowing and the potential reduction in contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization is a main component and that the optimization algorithm seems to be directly borrowed from previous works, which could be confusing and reduce the contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the use of a structural optimization component that seems to be directly borrowed from previous works. This observation highlights a potential confusion in the contribution of the paper, as the optimization algorithm may not be seen as original. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the contribution of their work. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of poor baseline model introduction or how to improve the pipeline style method. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the pipeline style method, which includes two models, and notes that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses the pipeline style method or the baseline models, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of average results and baseline models, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some indication of an issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the pipeline style method, which includes two models, not yielding better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. While the comment highlights a potential problem, it lacks actionable suggestions or guidance on how the authors might address this issue or improve the pipeline style method. Without specific recommendations or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 3, as it points out a weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. However, it does not specify which part of the paper this observation is made in, making it weakly grounded. The comment is specific in detailing the issue with the authors\" methodology, questioning why this observation needs to be made using the \"coarse\" methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have reproduced a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that this observation is unnecessary. The authors may need to further substantiate the claim by providing evidence or references to similar works that have already addressed this issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. This feedback highlights a potential redundancy in the authors\" approach and suggests that they might need to reconsider their methodology or provide a more novel contribution. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their work. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing a specific work ([A]). This direct suggestion provides a clear and concrete action for the authors to take, ensuring that they are aware of the relevant literature and can incorporate it into their introduction. The comment is 5 as it clearly specifies what needs to be added to the paper, making it easy for the authors to implement the suggested change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of related work on modular networks for VQA, such as [A]. This provides clear guidance on how to improve the introduction by adding relevant references. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is crucial to mention related work on modular networks for VQA, specifically referencing work [A]. This claim is 3 as it logically suggests that including this work would provide a more comprehensive overview of the related literature. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as explaining why [A] is particularly relevant or how it relates to the current work. Providing more detailed justification would strengthen the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction section of the paper, noting that it seems to imply that no one does modular architectures for VQA. It suggests that the authors should mention related work on modular networks for VQA, such as [A], to provide a more comprehensive overview of the literature. This feedback is clear and actionable, as it directly instructs the authors on how to enhance their introduction by including relevant references. By addressing this point, the authors can improve the clarity and completeness of their introduction, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not compare their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should contrast their method with these other methods. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with other methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on SSC and the need to contrast the method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact nature of the comparison being suggested. Without detailed comparisons or references, the claim is not fully substantiated, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. This feedback is 3 as it points out a gap in the paper\"s comparison with other methods, which could enhance its comprehensiveness and relevance. However, the comment lacks specific suggestions on how to address this issue, such as which methods to include or how to structure the comparison. While it highlights an area for improvement, the lack of detailed guidance limits its utility for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the authors should clarify the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. The reviewer provides specific guidance by suggesting that the authors rename the column in Table 1 to \"Fully supervised\" and propose a better idea of specifying the data used to train each part of the model. This feedback is clear and actionable, giving the authors a direct path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semisupervised training and the suggestion to rename the column in Table 1. The comment provides detailed guidance on how to clarify this distinction and improve the clarity of the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between weak supervision and semisupervised training, specifically in Table 1. The reviewer provides a specific example of renaming the column to \"Fully supervised\" and proposes a better idea of specifying the data used to train each part of the model. This feedback is based on logical reasoning and specific suggestions, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim about the importance of clarifying these distinctions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors clarify the distinction between weak supervision and semisupervised training, particularly in Table 1. It offers a specific suggestion to rename the column to \"Fully supervised\" and proposes a more comprehensive approach by suggesting the addition of two columns for \"Mixture training data\" and \"Single source data.\" This feedback is valuable as it guides the authors on how to improve the clarity and comprehensiveness of their table, which can enhance the overall understanding and interpretation of their work. By addressing these points, the authors can significantly improve the clarity and accessibility of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment implies that the authors should consider how to differentiate their work from previous methods, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should focus on differentiating their work from previous methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. However, the comment does not specify which part of the paper discusses these contributions or how they are evaluated. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, the comment does not provide specific examples or detailed reasoning to support these claims. It mentions that it is difficult to differentiate the paper from its predecessors, but it does not explain why this is the case or how the paper could be improved in this regard. The lack of specific evidence or detailed reasoning makes the claim 3, as the authors would need to infer the basis of the critique and potentially make improvements based on intuition rather than clear guidance.", "helpfulness_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment identifies a potential weakness in the paper\"s differentiation from previous work, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove the statement about semantic segmentation being a lowlevel cue, as it is not accurate given that categories are specified for each pixel. This feedback is clear and concrete, providing a direct action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the term \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the statement about semantic segmentation being a lowlevel cue is incorrect, given that categories are specified for each pixel. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about semantic segmentation being a lowlevel cue is incorrect, as categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the use of the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, making the statement about semantic segmentation being a lowlevel cue inaccurate. This feedback is clear and actionable, as it directs the authors to remove or clarify this statement to avoid misleading readers. However, the comment could be more helpful if it provided additional context or suggestions on how to rephrase the statement or address the issue. Overall, the comment is 4 as it guides the authors toward improving the accuracy and clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the tables. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or correct the results, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy in performance without reinforcement learning (RL) dropping lower than without dependency tree and highlights the missing cases in the tables where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning (RL) dropped lower than without dependency tree in the ablation experiment. However, it does not provide any supporting evidence, such as data or comparisons, to substantiate this claim. Additionally, the comment mentions that the two tables do not list the cases where dependency tree and RL are not used, but it does not explain why this is a concern or how it affects the results. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the results of the ablation experiment, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is 3 as it highlights an area where the authors need to clarify or correct their results. However, the comment lacks specific suggestions on how to address the discrepancy or what additional information should be included in the tables. While it provides some direction, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies the main weakness of the paper as the experiments section, specifically noting that the results are presented only on the CIFAR10 dataset and do not consider other datasets from the Federated learning benchmarks. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback provides explicit actions for the authors to take, such as expanding their experimental evaluation to include additional datasets and models. The comment is clear and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of consideration of other datasets from Federated learning benchmarks and the need to consider relevant works like FedProx and FedMAX. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main weakness of the paper is the experiments section, specifically the lack of consideration of other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX to expand their evaluation. While the comment identifies a potential issue, it lacks specific examples or references to the relevant works that could be considered. This makes the claim 3, as the authors would need to make an effort to find and integrate these references themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of consideration of other datasets from Federated learning benchmarks in the experiments section. It suggests that the authors should consider relevant works like FedProx and FedMAX to expand their evaluation. This feedback is clear and actionable, as it provides specific guidance on how to enhance the comprehensiveness and relevance of the experiments. By addressing this issue, the authors can significantly improve the quality and impact of their work. However, the comment could be more helpful if it provided examples of how these additional datasets could be integrated or what specific aspects of the experiments should be considered. Overall, the comment is 4 as it effectively directs the authors to a meaningful area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the validity of the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to verify the claim. The comment implies that the authors should consider using another dataset, but it lacks concrete instructions or detailed suggestions on how to implement this change. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the table and the claim about accuracy and completeness, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the claim and suggests using another dataset for the ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. This is a constructive suggestion that could help the authors strengthen their argument by providing additional evidence or comparisons. However, the comment lacks specific guidance on which dataset to use or how to conduct the ablation study, which would make it more actionable. Overall, the comment is 3 as it points out a potential weakness in the paper but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and questions the ecological validity of such a study. The reviewer also mentions that previous work has considered multiple vulnerabilities or weaknesses simultaneously and asks if the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment concludes by stating that the results are difficult to interpret or may only show marginal improvements. While the comment identifies a potential issue with the methodology, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider multiple vulnerabilities and provide a rationale for their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vulnerability discovery methodology\" and the \"single vulnerability\" approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the ecological validity of the study and the interpretation of results, which are not marginal improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. The reviewer acknowledges the data imbalance issue and questions the ecological validity of such a study. The comment references previous work that considered multiple vulnerabilities or weaknesses simultaneously and asks if the authors are arguing that identifying one vulnerability at a time is an intended use case. The reviewer also notes that the results are difficult to interpret or may only show marginal improvements. While the comment provides a logical basis for the critique, it lacks specific references to external works or detailed examples to fully substantiate the claim. This makes the comment 3, as it provides a reasonable basis for the critique but requires more detailed evidence or references to fully support the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the methodology used for vulnerability discovery, specifically questioning the authors\" approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and raises concerns about the ecological validity of such a study. The reviewer also references previous work that considered multiple vulnerabilities or weaknesses simultaneously and questions whether the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment highlights that the results may be difficult to interpret or may only show marginal improvements. While the comment provides a clear critique of the methodology, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. This limits the comment\"s helpfulness, as it points out a potential issue but does not offer actionable advice for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It suggests that additional explanations are needed to address this issue. However, the comment does not provide specific guidance on how to provide these explanations or what aspects of the relationship should be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more explanations but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by the theorems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2 is not intuitive enough. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It points out that while the theorems prove conformity to a clearer community structure, the relationship with degree bias is not intuitive. This feedback is valuable as it highlights a potential gap in the paper\"s explanation, which the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this relationship or examples of how it might be explained more effectively. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this question. The authors are left to infer that they need to clarify this aspect of their work, but without specific instructions on how to do so, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 182183,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the construction of clean exemplar manifolds for a nonstochastic network and how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. The comment is 3 as it highlights a potential inconsistency in the paper, but it lacks specific examples or references to support the claim that the construction of clean exemplar manifolds is unclear. The authors might need to provide additional context or clarification to fully address the issue, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the construction of clean exemplar manifolds for a nonstochastic network. It raises a specific question about how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks, which is a critical aspect of the methodology. By pointing out this discrepancy, the comment provides the authors with a clear and actionable step to address a potential weakness in their work. However, the comment could be more helpful if it offered suggestions on how to clarify this issue or provided examples of how similar questions have been addressed in related literature. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, it does not provide explicit guidance on what additional information is needed or how to clarify this notation. The comment implies that the authors should provide more information, but it lacks concrete steps or suggestions on how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it is confusing. However, it does not specify which part of the paper this notation is used in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does provide some specificity by indicating that more information is required, such as what S and Xt represent. However, without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, the comment does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for how the authors might clarify the notation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the notation used to separate \"static\" and temporal features into two variables. It points out that this notation is initially confusing and requires more information to be fully understood. While the comment highlights a potential issue, it lacks specific suggestions or guidance on how the authors might clarify this notation or provide additional information. The feedback is 3 as it directs the authors to a specific area that needs clarification, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be more detailed, particularly in the definitions of the resistance distance and explanations of Algorithm 1. While it implies that more details should be provided, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper deals with many graph notions and is somewhat challenging to understand, but the writing is generally good. It provides specific feedback by mentioning the need for more detailed explanations, particularly in the definition of the resistance distance and the explanations of Algorithm 1. The authors can infer that these are areas that need attention, but the comment does not explicitly mention which sections or parts of the paper these issues pertain to. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in identifying the need for more detailed explanations. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper is challenging to understand due to its focus on graph notions, but it also acknowledges that the writing is generally good. The comment provides a specific suggestion for improvement by recommending more detailed explanations, particularly in the definition of the resistance distance and the explanations of Algorithm 1. This feedback is 3 as it identifies areas where the paper could be more comprehensive, but it lacks detailed examples or references to support the claim that these explanations are necessary. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it deals with many graph notions and is somewhat challenging to understand. However, it acknowledges that the writing is generally good. The comment provides some helpful suggestions for improvement by recommending the inclusion of more detailed explanations, particularly in the definition of the resistance distance and the explanations of Algorithm 1. While the feedback is clear and actionable, it could be more comprehensive by offering specific examples or guidance on how to enhance the explanations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more detailed to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the originality of their work. There is no guidance on potential ways to enhance the novelty or creativity of the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of originality, specifically mentioning that the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered unoriginal, but without explicit references to sections or figures, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the originality of the paper, specifically noting that the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the evaluation of shape model invariance, specifically asking if there are any quantitative results on testing images. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide quantitative results on testing images. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the evaluation on transformations of training images and asks for quantitative results on testing images. This provides clear guidance on what additional information is needed to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the evaluation on transformations of training images for the shape model invariance study. It suggests that quantitative results on testing images might be needed to fully prove the point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the evaluation of shape model invariance, specifically questioning the use of transformations of training images to prove the point. It suggests that quantitative results on testing images might be necessary to fully substantiate the claim. This feedback is 3 as it identifies a potential gap in the evaluation process and prompts the authors to consider additional evidence. However, the comment could be more helpful if it provided specific suggestions on how to conduct the testing or what types of quantitative results might be relevant. Overall, the comment offers a constructive direction for improvement, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the omission of a related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. The action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of this related work and its potential impact on the understanding of the stateoftheart. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared with the current work. The reviewer provides a logical reasoning by suggesting that the AAAI15 paper deals with hypergraph data with tensors, which is relevant to the current work. However, the comment lacks specific examples or references to the content of the AAAI15 paper, making it 3. The authors would need to conduct additional research to fully understand the relevance and potential contributions of the AAAI15 paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is relevant to the current work but has been overlooked. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a relevant reference that could enhance their understanding and analysis. However, the comment could be more helpful if it provided specific insights or suggestions on how to integrate this reference into the paper. Overall, the comment is 4 as it guides the authors to a valuable addition that could strengthen their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it would be beneficial to test its scalability on normal machines with a few cores. It also questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific tests should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should test scalability and provide more details on the computation of optimal transport. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Approach\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions how the authors compute the optimal transport distance, particularly in relation to the Sinkhorn method. The comment provides clear guidance on what needs to be addressed, such as testing scalability on normal machines and explaining the computation of optimal transport. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it is not clear how scalable the method is. The reviewer questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the method is not scalable or how it could be improved. The lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of the method and its computation of optimal transport distance. It raises questions about how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. This feedback is valuable as it prompts the authors to consider the scalability of their method on normal machines with a few cores, which is an important aspect for practical applications. Additionally, the comment highlights the need for a more detailed explanation of the computation process. While it does not provide specific suggestions on how to address these issues, it does guide the authors toward important areas for improvement. Therefore, the comment is 4, as it offers actionable insights that can significantly enhance the paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is difficult to follow, indicating that the authors need to improve the clarity and accessibility of their experimental procedures and evaluations. However, it does not provide specific guidance on how to achieve this improvement, such as recommending changes to the structure, language, or presentation of the paper. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning the experimental procedures and evaluations. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without explicit references to sections or details, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"extremely hard to follow,\" indicating that the reviewer had trouble understanding the experimental procedures and evaluations. However, the comment does not provide specific examples or details about what was difficult to follow, nor does it offer suggestions for improvement. Without these details, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is \"extremely hard to follow.\" This feedback highlights a critical weakness in the clarity and accessibility of the experimental procedures and evaluations, which is crucial for readers to understand and replicate the work. However, the comment lacks specificity and does not provide actionable guidance on how the authors might improve the clarity or structure of their paper. Without detailed suggestions or examples, the authors are left without a clear path to enhance the readability and comprehensibility of their draft. Therefore, the comment is 3, as it points out a significant problem but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide specific guidance on what aspect of the claim is questionable or how it could be improved. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. The reviewer points out that a model that can only handle a single time series data is almost useless. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this concern or what aspects of the claim might be misleading or inaccurate. As a result, the comment is not helpful, as it does not assist the authors in improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to consider introducing specific aspects of their model that are relevant to the example model. It provides a clear example of what needs to be addressed, such as the fact that the model is not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is concrete and provides specific guidance on how to improve the draft by introducing these aspects. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of specific aspects of the model that are relevant to the example model, such as the fact that the model is not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should introduce specific aspects of their model that are relevant to the example model, such as the fact that the model is not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This claim is 3 as it provides a logical reasoning for why these aspects should be introduced, but it lacks specific examples or references to support the claim fully. The authors might need to infer the exact aspects to include and how they would be introduced, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce specific aspects of their model that are relevant to the example model. It highlights the importance of clarifying that the model is not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is clear and directs the authors to enhance the clarity and completeness of their model description. By addressing these points, the authors can improve the understanding and applicability of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. Additionally, it recommends including more analysis and discussion for GPT2, specifically asking for the results of Figure 2 for GPT2. The comment provides explicit actions for the authors to take, such as expanding the experiments to include more models and including additional analysis for GPT2. The suggestions are concrete and provide clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to investigate whether the results can be generalized to other models and to include more analysis and discussion for GPT2. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. The reviewer provides a logical reasoning by pointing out that the experiments should be expanded to include more models, such as GPT2, and that additional analysis and discussion should be included for GPT2. However, the comment lacks specific examples or references to support the claim that the results cannot be generalized. Therefore, the comment is 3, as it provides a reasonable argument but could benefit from more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, and recommends including more analysis and discussion for GPT2. The comment provides clear and actionable feedback by suggesting specific areas for improvement, such as expanding the experiments to include more models and including additional analysis for GPT2. This guidance is valuable for the authors to enhance the generalizability and robustness of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. While the comment implies that the authors should explore these applications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their work to include these other areas. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the model and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. However, the comment lacks specific examples or references to support the claim that the model and experiments are limited to image data and ViT. Without such evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. This feedback is valuable as it prompts the authors to consider expanding their work beyond the specific focus on transformers in vision, which could enhance the method\"s versatility and broader applicability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might explore these other areas. Overall, the comment is 4 as it encourages the authors to consider a broader scope for their work, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should evaluate TTA methods on more conditions of natural distribution shift, like WILDS [9], to strengthen the paper. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA methods on more conditions of natural distribution shift, like WILDS, to strengthen the paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using nonstandard benchmarks breaks popular TTA methods and recommends evaluating TTA on more conditions of natural distribution shift, like WILDS. However, the comment does not provide specific examples or references to support this claim, nor does it explain why using nonstandard benchmarks is significant or how it affects the performance of TTA methods. Without additional context or evidence, the claim remains 3, as it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies an interesting observation about the performance of TTA methods under nonstandard benchmarks, suggesting that evaluating these methods on more conditions of natural distribution shift could strengthen the paper. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to implement this evaluation or what specific conditions of natural distribution shift should be considered. The feedback is 3 as it points out a potential enhancement but does not provide detailed instructions or examples for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. The reviewer suggests that this condition is not realistic and may lead to unreasonably large learning rates when learning on largescale datasets. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on whether the authors should modify the condition, provide a rationale for its use, or explore alternative approaches. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. It provides a clear rationale for why this condition is not realistic and may lead to unreasonably large learning rates when learning on largescale datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the learning rate condition and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the condition on the learning rate is not scalable, as it does not grow with the number of samples in practice. The reviewer provides a logical reasoning by explaining that this condition leads to unreasonably large learning rates when learning on largescale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not realistic. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. This is a critical observation, as it highlights a potential flaw in the methodology that could lead to unreasonably large learning rates when learning on largescale datasets. The reviewer provides a logical reasoning for why this condition is not realistic and suggests that the authors need a way to precisely characterize the benefit of large learning rates. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or explore alternative approaches. Overall, the comment is 3 as it points out a critical weakness but lacks detailed guidance on how to resolve it. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the paper need clarification. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of tensor networks to represent PMF of discrete variables and questions the significance of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of clarity regarding the utility of tensor networks and the significance of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. It highlights a potential weakness in the paper\"s contribution, which could impact its impact and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper\"s significance. While it points out a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use a more convincing setting for training, similar to that used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. It provides a specific reference to the paper by He et al. (EMNLP 2018) as an example of a convincing setting. This feedback is explicit and provides a clear action for the authors to take, which is to adopt a more convincing training approach. The suggestion is concrete and provides a specific method to implement the change, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)\" and suggests that this is impractical in realworld applications. It also references a specific paper, \"Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018,\" which provides a more convincing setting for training. This allows the authors to identify the exact part of the paper being addressed, making the comment fully grounded. The comment is also specific because it details the issue with the unbalanced data and suggests a specific approach to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in realworld applications. The reviewer suggests that the authors should use a more convincing setting, like the one described in the paper \"Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018,\" which directly samples unlabeled data from millions of reviews. The comment provides a specific reference to a relevant paper, which supports the claim by offering a practical example of a more convincing setting. This makes the claim 4, as it provides a clear rationale and evidence for the suggestion.", "helpfulness_rationale": "The review comment identifies a specific issue with the unlabeled data from the preprocessed Amazon review dataset, noting that it is perfectly balanced, which is impractical in realworld applications. The reviewer suggests that the authors should use a more convincing setting, like the one described in the paper \"Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018,\" which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a specific approach to address the issue of unbalanced data. By suggesting a more practical and convincing setting, the comment offers valuable guidance for improving the draft. However, it could be more helpful if it explained why the current setting is impractical or how the suggested approach might be beneficial. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity regarding how to sample from the DPP if the eigenfunctions e_n are inaccessible, referencing a specific line in the paper (line 130). It also mentions a similar issue with sampling from the leverage score in a previous work. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the clarity of their explanation. The action is implicit and vague, as the authors are left to infer that they need to clarify their sampling process, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 130\" and \"Eq (10),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar problem in a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a specific line in the paper (line 130) and a previous work. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that sampling from the DPP is easier than sampling from the leverage score. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper regarding the sampling process from the DPP when the eigenfunctions e_n are inaccessible. It references a specific line in the paper (line 130) and compares it to a similar issue in a previous work. This feedback is clear and actionable, as it points out a gap in the explanation that the authors need to address to improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the sampling process or offered examples of how similar issues have been addressed in other works. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the evaluation of the generalizability of observations to fewshot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the submission\"s contributions regarding understanding the properties of episodic training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation to include other fewshot learners, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation on the generalizability of observations to fewshot learners beyond Prototypical Networks. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the evaluation section. However, the comment is not specific as it does not detail what specific aspects of the evaluation are missing or how the authors could address this issue. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the observations presented do not evaluate the generalizability to fewshot learners beyond Prototypical Networks, which may limit the scope of the paper\"s contributions regarding understanding the properties of episodic training. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the lack of evaluation on the generalizability of observations to fewshot learners beyond Prototypical Networks. This feedback highlights a potential limitation in the scope of the paper\"s contributions regarding understanding the properties of episodic training. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or what specific aspects of the evaluation should be expanded. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address this issue, specifically asking for guidance on how to deal with the problem. However, the comment does not provide explicit instructions or concrete suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the contribution of different modalities and address the problem, but the comment lacks detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the contribution of different modalities of different instances, specifically mentioning modalities A and B and their performance in different instances. It raises a question about how to deal with the problem of removing the modal subset of all instances, as stated in Equation 3. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the discussion of modalities and their contribution. The comment is also specific because it details the issue of removing the modal subset and asks for guidance on how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address the problem, suggesting that Equation 3 directly removes the modal subset of all instances. However, the comment lacks specific examples or detailed reasoning to support the claim that the contribution of different modalities is different. Without additional context or evidence, the claim remains 3, as it provides a logical basis but lacks detailed justification or references. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the contribution of different modalities of different instances. It highlights that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address the problem, specifically mentioning Equation 3, which directly removes the modal subset of all instances. This feedback is 3 as it points out a potential issue that the authors need to consider and address. However, the comment lacks specific suggestions or guidance on how to address the problem, such as proposing alternative methods or discussing potential implications. While it identifies a relevant area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback provides clear and concrete actions for the authors to take, such as adding a description of the evaluation process and addressing language issues. The comment is specific and direct, giving the authors a clear understanding of what needs to be added or improved. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues on page, providing specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving their draft by adding a description of the evaluation process and addressing language issues. However, the comment could be more helpful if it offered suggestions on how to structure the evaluation section or provided examples of what such a description might look like. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the absence of experiments on a specific setting. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. While the comment identifies a specific issue with the experimental section, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should include experiments on these settings, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it points out an area for improvement but does not offer detailed instructions on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific setting of the POMDP problem with nonconvex value functions. It also specifies the issue with the experiments section, noting the absence of experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the experimental results, specifically the absence of experiments on specific settings. It references the examples of surveillance in museums with thresholded rewards and privacypreserving data collection as motivating cases for the paper. However, the comment lacks specific evidence or detailed reasoning to support why these examples are insufficient or why the experiments are not useful. The claim is 3, as it highlights a potential issue but does not provide sufficient justification or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, questioning the relevance and usefulness of the examples used to motivate the paper\"s solution. It points out the absence of experiments on specific settings, such as surveillance in museums with thresholded rewards and privacypreserving data collection. This feedback is valuable as it highlights a critical gap in the experimental section, which could impact the paper\"s credibility and impact. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific experiments or modifications to the existing ones. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment implies that the authors should clarify this confusion by providing more detailed explanations or examples. However, it does not explicitly instruct the authors to make these changes or suggest specific ways to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the notation and provide more context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the notation for target domain \u03c4 and the use of sparse labels. The comment further questions the use of unlabeled data in source domains and references the original MFDA paper by Yue et al. (2021a) for clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. The reviewer questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper by Yue et al. (2021a). The comment is 3 as it provides a logical basis for the confusion, referencing the original paper for clarification. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for target domain \u03c4 is unlabeled and questions the use of sparse labels, which is not consistent with the original MFDA paper by Yue et al. (2021a). The comment also highlights the confusion regarding the unlabeled data in source domains and suggests that the authors should clarify this issue. This feedback is clear and actionable, as it directs the authors to address the confusion in their description and potentially provide more detailed explanations or examples. However, the comment could be more helpful if it offered specific suggestions on how to improve the clarity or provided examples of how the original paper handled these issues. Overall, the comment is 4 as it effectively identifies a critical area for improvement and offers a clear direction for the authors to enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear rationale for why epochwise analysis could be valuable, it does not explicitly instruct the authors on how to implement this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The suggestion is specific, as it clearly outlines the potential benefits of epochwise analysis and how it could be applied to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms. The comment also suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the suggestion is logical and provides a clear rationale, it lacks specific examples or references to support the claim fully. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It suggests that epochwise analysis, particularly in finite sum settings, could be beneficial for understanding the behavior of optimization algorithms. The comment highlights how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms and aid in comparative analysis of deterministic and stochastic methods. This feedback is clear and provides a concrete direction for the authors to enhance their analysis and improve the paper. By offering a specific and actionable suggestion, the comment is 5 in guiding the authors towards a more comprehensive and insightful analysis. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific details to include. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the code and details in the article, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issues with the workload being immense and the contribution being incremental, as well as the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the absence of essential RAG algorithms like MedRetriever and KGRAG. The reviewer also mentions that the paper focuses on RAG for EHR, which should include these algorithms. The claim is 3 as it provides a logical reasoning based on the combination of existing methods and the focus on RAG for EHR. However, it lacks specific references to MedRetriever and KGRAG, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the immense workload and the incremental contribution. It points out that the paper essentially combines GraphRAG and GraphCare, which is not a significant contribution. Additionally, the comment highlights the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG, which are relevant to the focus on RAG for EHR. The feedback is 3 as it provides specific suggestions for improvement, such as introducing these algorithms and citing relevant works. However, it could be more helpful if it offered more detailed guidance on how to address these issues or provided examples of how these algorithms could be integrated into the paper. Overall, the comment provides some actionable feedback but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. The reviewer implies that the authors should provide more detailed explanations or examples to clarify this distinction. While the comment does not explicitly instruct the authors to make changes, it implies a clear action for the authors to take, such as providing additional context or examples to clarify the distinction. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the \"sample data file,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the distinction between derogatory and exclusionary extreme speech, and it provides a specific example from the sample data file to illustrate the confusion. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the distinction between the three classes of extreme speech, specifically questioning the classification of a specific instance as exclusionary extreme speech. The reviewer provides a specific example from the sample data file to illustrate the confusion, asking for clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. This request for clarification is a logical step in the evaluation process, as it seeks to understand the basis of the classification. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It provides a detailed example from the sample data file to illustrate the confusion, questioning why a particular instance is classified as exclusionary extreme speech. The comment also raises a question about the local regulation over speech and its impact on zeroshot crosscountry classification, prompting the authors to clarify their methodology. This feedback is clear and actionable, as it guides the authors to provide more detailed explanations or examples to improve the clarity of their classification. However, it could be more helpful if it offered suggestions on how to address the issue or improve the clarity of the distinction. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be included in the graph and why it is important. The comment also offers a rationale for why this graph is necessary, helping the authors understand the potential sources of performance improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included in the graph and why it is important to understand the sources of performance improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This claim is 3 as it logically suggests that such a graph would help clarify whether the performance improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This is a specific and detailed piece of feedback that can help the authors better understand the performance improvement and its potential sources. By including this graph, the authors can provide a more comprehensive analysis of their results, which could enhance the clarity and robustness of their paper. However, the comment could be more helpful if it explained why this graph is important or how it might influence the interpretation of the results. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper needs to be mathematically correct and provides a specific example by questioning the notation \"L_l\" instead of just \"L.\" It also suggests that the notation should be introduced beforehand. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make these changes or what specific changes should be made. The authors are left to infer that they need to make these corrections, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l instead of just L,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the notation \"L_l\" and the need for mathematical correctness. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper needs to be mathematically correct and questions the notation \"L_l\" instead of \"L.\" It provides a specific example of the notation issue and suggests that it should be introduced beforehand. However, the comment lacks detailed reasoning or references to support why this change is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is 3, as it provides a specific example but lacks comprehensive justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, specifically the use of \"L_l\" instead of \"L.\" It provides a clear and actionable suggestion to correct this issue, which could improve the mathematical correctness of the paper. Additionally, it points out that the notation should be introduced beforehand, which is a valuable piece of feedback for the authors to consider. However, the comment could be more helpful if it provided additional context or examples of how this correction might impact the overall presentation or understanding of the paper. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also notes that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to study the effect of noise accumulation. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sequential ensembling\" and \"homomorphic encryption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of noise accumulation in the context of homomorphic encryption, which prevents the use of even single deep neural networks on homomorphically encrypted data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that noise accumulation in the context of homomorphic encryption is a critical issue for sequential ensembling, as it prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the study of sequential ensembling in the context of homomorphic encryption. It points out that the accumulation of noise in this setting prevents the use of even single deep neural networks on homomorphically encrypted data. This is a valuable observation that could significantly impact the applicability and effectiveness of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or what specific experiments could be conducted to explore the impact of noise accumulation. While it highlights an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should consider different timesteps for training and evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the relevance of different timesteps and how they might impact the effectiveness of the proposed methods. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of the proposed methods, noting that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep. This observation raises questions about the novelty and impact of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or explore different timesteps. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of clarity regarding the disentanglement aspect of the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed. The reviewer suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Broader Impacts and Limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how disentanglement is achieved and guaranteed without certain bias types. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that disentanglement is not clearly explained and questions how it is achieved and guaranteed without certain bias types. While the comment references the \"Broader Impacts and Limitations\" section, it does not provide specific examples or detailed reasoning to support the claim that disentanglement is unclear. The reference to the \"Broader Impacts and Limitations\" section suggests that the authors have acknowledged the limitation, but the comment lacks further elaboration or evidence to substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the disentanglement aspect in the paper. It points out that while the \"Broader Impacts and Limitations\" section acknowledges a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed without certain bias types. The comment suggests that the authors should clarify this aspect to enhance the clarity and comprehensiveness of their work. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their paper that could impact its understanding and impact. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case, the authors should use a standard regularization trick. While the comment implies that the authors should apply this standard technique, it does not provide explicit instructions on how to implement it or which specific regularization trick to use. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the use of a standard regularization trick, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this standard technique is necessary or how it would improve the comparison. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance on which standard regularization trick to use or how it would impact the comparison. The feedback is 3 as it points out a potential issue but does not offer detailed instructions or examples to help the authors address it effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be included in the left graph in Figure 3. The suggestion is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the left graph in fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is a learning curve for a model without mean teacher or pi regularization. This provides clear guidance on what the authors should include to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a request for additional data or analysis, which is a factual observation rather than an opinion or claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It recommends adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This suggestion is clear and offers a concrete way to enhance the analysis by providing a baseline for understanding the impact of mean teacher on learning. By including this additional information, the authors can better demonstrate the effectiveness of their approach. Therefore, the comment is 5 as it directly guides the authors on how to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the need to discuss how to handle different types of inputs and the disorganization of the citation. While the first point suggests that the authors should discuss their solutions for handling different input types, it does not provide specific guidance on how to structure this discussion or what aspects to cover. The second point mentions that the citation seems disorganized but does not offer suggestions for improvement. Both points are implicit, as the authors need to infer what actions to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss \"different types of inputs\" and the disorganization of the citation, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to discuss how to handle different input types and the disorganization of the citation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the need to discuss different types of inputs and the disorganization of the citation. The first claim is 3 as it suggests that the paper should address how to handle various input types, but it lacks specific guidance on how to structure this discussion or what aspects to cover. The second claim about the citation being disorganized is 3, as it points out a potential issue but does not provide detailed examples or suggestions for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement: discussing different types of inputs and addressing the disorganization of the citation. While it highlights these issues, it does not provide specific guidance or suggestions on how to address them. The comment lacks depth and actionable advice, leaving the authors with a general understanding of the problem but without clear steps to improve their draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the implications of Eq. 4 and potentially improve the results in Table 5, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the implications of Eq. 4 and noting the lack of significant improvement in the designed solutions in Table 5, particularly on the OfficeHome dataset. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This claim is 3 as it provides some logical reasoning and specific examples to support the observation. However, it could be strengthened by providing more detailed analysis or references to substantiate the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This feedback is 3 as it points out a potential issue with the results and suggests that the authors might need to reconsider their approach. However, it lacks specific suggestions or guidance on how to address the issue or improve the results. To be more helpful, the comment could provide suggestions on how to improve the design solutions or clarify the implications of Eq. 4. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of specific stateoftheart references in the face recognition experiment, particularly mentioning \"Baidu\"s work\" and its reported results. It also highlights the use of the triplet loss and the similarity to the Webface dataset. The comment provides a clear and specific action for the authors to include these references in their work. Additionally, it suggests that the VRF achieved a better result than reported in Table 3, which could be a valuable comparison for the authors to make. The action is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the specific references that are missing, such as \"Baidu\"s work\" and \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" It also provides specific details about the triplet loss and the reported results, which allows the authors to identify the exact parts of the paper that need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the face recognition experiment, specifically mentioning \"Baidu\"s work\" and its reported results. The reviewer provides a specific reference to the work, which is a clear and verifiable claim. Additionally, the comment provides details about the triplet loss and the reported results, which further strengthens the claim. This level of detail and specificity makes the claim 4, as it provides a clear rationale for the claim and supports it with relevant information. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup in the paper, noting the absence of certain stateoftheart references, such as \"Baidu\"s work\" and its reported results. It provides a clear and actionable suggestion by recommending the inclusion of these references, which could enhance the paper\"s credibility and comprehensiveness. Additionally, the comment highlights the use of the triplet loss and the reported results, which could be valuable comparisons for the authors to make. However, the comment could be more helpful if it offered additional insights or suggestions on how to incorporate these references or what specific aspects of the work could be improved. Overall, the comment is 4 as it identifies a clear area for improvement and provides actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their question answering method, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the question answering process, particularly the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with the question answering process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process, which involves template mapping to transform questions into masked statements, might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without concrete evidence or detailed reasoning, the claim is not 5, as it relies on a general observation without clear justification. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. While the comment highlights a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve their question answering process. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VolumeDeform [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the issue is: the use of a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform [1]. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, the comment does not provide specific details or references to VolumeDeform to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered 2, as it lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any constructive feedback or suggestions for improvement. It lacks depth and actionable guidance, leaving the authors without a clear understanding of how to address the issue or enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. The reviewer suggests that this issue should be discussed or at least acknowledged in the main text in more detail. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss or acknowledge the issue in more detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLHAR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ICLHAR, noting that it improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This claim is 3 as it provides a specific numerical example (70.4 to 55.6) to support the assertion of a significant impact on accuracy scores. However, the comment lacks detailed reasoning or explanation of why this impact occurs or how it could be addressed. Additionally, it does not provide references to external works or studies that might substantiate the claim further. Therefore, the comment is rated as 3, as it provides some support but lacks depth and detailed justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the ICLHAR, noting that while it improves consistency and verifiability, it significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This is a critical observation that the authors should address, as it affects the overall quality and reliability of their results. The comment suggests that this issue should be discussed or at least acknowledged in the main text in more detail, providing clear guidance on how the authors can improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what aspects of the ICLHAR might be contributing to the accuracy drop. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to take action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by previous work. This is a direct and concrete action, as it specifies the exact source that needs to be cited. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to cite the source of the example. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by previous work and suggests that the source should be cited appropriately. However, the comment does not provide specific examples or references to the previous work that inspired the example, making it difficult for the authors to verify the claim. Without additional context or evidence, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by previous work and should be appropriately cited. This is a clear and actionable piece of feedback, as it directs the authors to provide proper attribution to the source of the example. By addressing this point, the authors can ensure that their work is properly credited and that their contribution is transparent. Therefore, the comment is 5, as it provides a clear and specific direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the innovations or how to mitigate the constraints. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or where the constraint embedding is mentioned. The authors cannot confidently determine which sections or parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the innovations or constraints are considered limited or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable feedback or detailed insights into potential improvements, leaving the authors without a clear path forward. Therefore, the comment is 2, as it points out a weakness but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that comparing the performance of a model pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors instead. It further suggests that the authors should provide the performance of the model pretrained on synthetic data but finetuned on realworld datasets with different losses. While the comment provides a clear action to take, it lacks specific guidance on how to implement this suggestion or what specific metrics or analyses should be included. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of comparing the performance of a model pretrained on synthetic data, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need to demonstrate the importance of the proposed three projection errors and suggests providing performance metrics for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that comparing the performance of a model pretrained on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors instead. The comment provides a logical reasoning by suggesting that finetuning on realworld datasets with different losses is necessary to showcase the model\"s performance. However, the comment lacks specific examples or references to support the claim that pretraining on synthetic data is unfair. This makes the claim 3, as the authors would need to infer the reasoning behind the claim and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the issue of comparing the performance of a model pretrained on synthetic data, which is considered unfair, and recommends demonstrating the importance of the proposed three projection errors instead. The comment suggests that the authors should provide performance metrics for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is valuable as it guides the authors on how to present their results in a more comprehensive and fair manner, which could significantly impact the paper\"s impact and credibility. However, the comment could be more helpful if it provided specific examples or guidance on how to implement this suggestion. Overall, the comment is 4 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, it does not explicitly instruct the authors to average over the subword representations or provide guidance on how to implement this suggestion. The action is implied and somewhat vague, as the authors need to infer that they should consider averaging over subword representations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, as done by Hewitt and Manning (2019, footnote 4). This feedback is actionable and provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, the comment does not provide specific examples or detailed reasoning to support why this is a common practice or how it would benefit the current work. While it references a specific work, the lack of detailed explanation or justification makes the claim 3. The authors would need to infer the importance of this suggestion and might find it challenging to understand the full implications without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in the paper, noting that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). This feedback is 3 as it points out a potential improvement in the clarity and accuracy of the language used in the paper. However, the comment lacks depth and does not provide specific suggestions or examples on how to implement this improvement or why it is important. While it highlights an area for improvement, it does not fully guide the authors on how to address it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear action to take, it lacks specific guidance on how to conduct the calibration curves or what aspects of the traditional method should be discussed. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model AUC and its ability to assess model discriminant ability, as well as the consistency between predicted scores and actual risks. It suggests conducting calibration curves to demonstrate this consistency, which is crucial for the clinical scoring system. The comment also mentions the difference between the traditional method and the authors\" method, which could be discussed in the paper. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as conducting calibration curves and discussing the difference between traditional and novel methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model AUC can assess the model discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It suggests that this consistency is crucial for the clinical scoring system and recommends conducting calibration curves to show the agreement. The comment also mentions the importance of discussing the difference between the traditional method and the authors\" method. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim about the importance of calibration curves. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of demonstrating consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. The comment suggests conducting calibration curves to show this consistency, offering a specific and concrete step for the authors to take. Additionally, it encourages the authors to discuss the difference between their method and traditional methods, providing a direction for further exploration and comparison. While the comment could be more helpful by offering examples of how to conduct calibration curves or suggesting specific aspects of the traditional method to discuss, it still provides valuable guidance for improving the draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to discuss these conditions and consider how sparsification affects them, but the comment lacks detailed guidance on how to implement these improvements. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out the lack of discussion on how to ensure DICE meets certain conditions, such as the range of ID and OOD not changing much with sparsification and the need for identical mean in Lemma 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These claims are 3 as they are based on observations from Figure 4 and the text, respectively. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claims. Providing more detailed evidence or references could strengthen the verifiability of the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, noting that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These observations highlight areas where the paper could be improved by discussing how to ensure that the conditions for DICE are met. However, the comment does not provide detailed guidance or suggestions on how to address these issues, such as suggesting specific methods or analyses that could be used to ensure the conditions are met. While it points out important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment implies that the authors should consider these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these changes to improve the readability and clarity of their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. However, it does not specify which part of the paper these sections are located in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these sections are, the comment lacks full grounding. It is specific about the need for breaking out the sections and improving readability, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the integration of updates across all possible environments and suggests that it might be for space reasons. The reviewer also notes that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment provides a logical reasoning for the suggestion to break out the sections, it lacks specific examples or references to support the claim about the integration of updates. The feedback is 3, as it provides a clear rationale for the suggested changes but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the integration of updates across all possible environments, suggesting that it might be for space reasons. It also points out that the bolded sections in page 6 are currently a huge wall of text and should be broken out into paragraphs for better readability. While the comment highlights these areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a general direction but are not provided with detailed steps or examples on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not offer comprehensive guidance for the authors to make those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses several issues related to the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the strength and fairness of the experiments, questioning the use of position kernels and the absence of certain baselines. It also suggests that the paper lacks discussion on limitations and societal impacts. While the comment identifies specific issues, it does not provide detailed reasoning or evidence to support these claims. The authors would need to infer the basis of these concerns and determine how to address them. Therefore, the comment is 3, as it provides some direction but lacks sufficient justification or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. It provides specific suggestions for addressing these issues, such as using default settings of baselines in the literature and comparing the proposed approach with other baselines. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how similar studies have addressed these concerns. Overall, the comment is 4 as it provides actionable feedback that can help the authors improve their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or improve their draft. There is no guidance on whether this drop is a concern, what factors might be contributing to it, or how the authors might mitigate it. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper needs attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the correlation drop need to be addressed or how it might be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation about the correlation drop after a short period of training, which increases with more training iterations. This is a clear and actionable insight that could prompt the authors to investigate the reasons behind this phenomenon and consider ways to address it. However, the comment lacks depth and does not provide suggestions on how to investigate or mitigate the issue. While it points out a potential area for improvement, it could be more helpful with additional guidance or context. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that all sparsity patterns seem to perform equally well and questions whether this is unique to the sparsity detection problem or applies to GNNs in general. It also notes a discrepancy in the presentation of \"bits\" in Section 4.3. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more insight into the results and clarify the presentation of \"bits.\" The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the uniqueness of the results and suggesting that the authors provide more insight into the sparsity patterns. The comment is specific because it clearly identifies what needs to be addressed, namely the lack of insight into the results and the discrepancy in the presentation of \"bits.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the uniqueness of the results and suggests that all sparsity patterns perform equally well. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or data to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, noting that all sparsity patterns seem to perform equally well and questioning whether this is unique to the sparsity detection problem or applies to GNNs in general. It also points out a discrepancy in the presentation of \"bits\" in Section 4.3. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or provide more insight into the results. The feedback is 3 as it prompts the authors to consider the generalizability of their findings and the presentation of their work, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. This provides a clear and direct action for the authors to take, ensuring that they either include the temperature or acknowledge its absence in the paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing temperature parameter, \u03c4, and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on how to improve the derivation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. The reviewer suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the temperature should be included or why its absence is problematic. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation from Equation 3 to Equation 4, noting that the temperature parameter, \u03c4, is missing. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this issue, the authors can enhance the rigor and clarity of their derivation, which is valuable for the overall quality of the paper. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add a citation on differential privacy, specifically mentioning a standard work like [2]. This is a clear and direct action for the authors to take, as it provides a specific reference to include in the paper. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, such as a standard work like [2]. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a factual suggestion that does not involve an opinion, judgment, or claim that requires verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by suggesting the addition of a citation on differential privacy. By mentioning a standard work like [2], the reviewer provides a clear and actionable suggestion that can enhance the paper\"s credibility and comprehensiveness. However, the comment could be more helpful if it explained why differential privacy is relevant to the paper or how it could be integrated into the existing content. Despite this, the feedback is valuable as it directs the authors to a specific area for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim made in the first paragraph of Section 3.2 that \"this methodology requires significant additional assumptions.\" It suggests that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The reviewer also points out a mistake in the inequality on line 310, suggesting that it has the wrong sign. While the comment identifies specific issues with the claim and the inequality, it does not provide explicit guidance on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and correct the inequality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of Section 3.2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The comment also points out a mistake in the inequality on line 310, providing specific guidance on how to correct it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The reviewer provides a logical reasoning by pointing out that this assumption is natural and not extreme. However, the comment lacks specific examples or references to support the claim that this assumption is not significant. Additionally, the mention of the incorrect sign in the inequality on line 310 is a factual observation that does not require verification. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a specific critique of the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme by implying that the methodology requires significant additional assumptions. The reviewer points out that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. This feedback is valuable as it challenges the authors to reconsider their claim and potentially revise it to be more accurate and less extreme. Additionally, the comment identifies a mistake in the inequality on line 310, which is a helpful detail for the authors to correct. However, the comment could be more helpful if it provided suggestions on how to address the claim or the inequality issue more effectively. Overall, the comment is 3 as it offers valuable insights and actionable feedback, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. Additionally, it recommends including a discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. While the comment provides explicit actions, it lacks concrete details on how to conduct these comparisons or what specific aspects of the methods should be discussed. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of Shapely values over other methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for experimental comparisons with other methods and a discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. It also recommends a discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that Shapely values are superior to other methods. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the need for experimental comparisons with other methods, such as CaCE or raw gradients, to support the authors\" argument for using Shapely values over other methods. Additionally, it recommends a significant discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. This feedback is valuable as it guides the authors to strengthen their argument and provide a more comprehensive analysis of their method. However, the comment could be more helpful if it included specific examples or references to similar studies that have conducted such comparisons. Overall, the comment is 4 as it offers clear and actionable guidance for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 needs this comparison or what aspects of the prior efforts should be compared. This makes it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the prior efforts should be compared or how this comparison would enhance the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in Section 6, suggesting that the authors could benefit from comparing the perspective taken in their manuscript to the contributions of prior efforts. This feedback is clear and actionable, as it points out a gap in the paper that could enhance its comprehensiveness and originality. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this comparison, such as which prior efforts to consider or how to integrate the comparison into the existing structure of the paper. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact change needed (examining performance with different numbers of scenarios), but it is somewhat vague because it does not provide detailed guidance on how to conduct the experiment or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the training process or results, but this inference is not direct. The comment is specific in suggesting the need for an experiment with different scenario numbers, but it lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion or how it could be tested. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential relationship between the performance and the number of scenarios used for training, suggesting that examining performance with different numbers of scenarios could be interesting. This feedback is 3 as it points out a potential area for exploration, but it lacks specific guidance on how to conduct the experiment or what aspects of the performance to focus on. While it provides a direction for further investigation, it does not offer detailed suggestions or examples that would fully support the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or test their model under such disturbances. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s ability to generate the correct quality label. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue is discussed. The authors can infer that it relates to the model evaluation or training process, but this inference is not direct. The comment is specific in its inquiry about the model\"s ability to predict quality labels, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or test their model under disturbances. The feedback is 3 as it prompts the authors to consider the robustness of their model, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, additional experiments, or guidance on how to enhance the validation process. As a result, the authors are left without any clear direction on how to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the types of experiments conducted, but it lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that these experiments are comprehensive. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it lacks specificity and actionable feedback. It does not provide guidance on how the authors could improve or expand upon these experiments, nor does it offer suggestions for potential areas of further exploration or analysis. As a result, the comment is 3, as it identifies a strength but does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting described in the paper is only partially strategic or game theoretic, as the opponent does not behave strategically. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the strategic nature of the setting or what specific changes should be made to make it more game theoretic. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the setting described in the paper, suggesting that it is only partially strategic or game theoretic because the opponent does not behave strategically. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the setting, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the setting described in the paper is only partially strategic or game theoretic because the opponent does not behave strategically. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s setting, noting that it is only partially strategic or game theoretic because the opponent does not behave strategically. This is a relevant observation that could prompt the authors to reconsider the nature of their setting and explore ways to enhance its strategic depth. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional strategic elements or gametheoretic approaches. While it points out a potential weakness, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a direct and concrete action for the authors to take, which is to improve the clarity of the illustration in Appendix A.2. The comment is specific about what needs to be addressed, making it 5. Authors know exactly what needs to be done to enhance the clarity of their illustration.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. It points out that the illustration is not clear, which is a critical aspect of the paper\"s presentation. This feedback is actionable as it directs the authors to improve the clarity of their illustration, ensuring that readers can better understand the environment\"s state space. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or examples of how similar illustrations have been effectively presented. Despite this, the comment is 4 as it highlights an important area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors\" approach is only applicable to small or mediumscale problems, as it cannot handle truly large problems that would overwhelm current LPsolvers. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach to handle larger problems. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to address this issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the authors\" approach, noting that it is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the applicability of the approach to large problems, but without clear grounding, the authors may struggle to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without concrete evidence or detailed reasoning, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a limitation in the authors\" approach, noting that it is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. This feedback highlights an important area for improvement, as it points out a potential weakness in the applicability of the authors\" work. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their approach to handle larger problems. While it provides some insight into a potential issue, it does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the bounded noise assumption in the context of stochastic optimization literature, noting its restrictiveness and suggesting that it has been extended in recent works. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or incorporate these extensions into their work. The references to specific papers and authors are provided, but they do not directly instruct the authors on how to apply this information to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should explore these extensions and potentially incorporate them into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bounded noise assumption, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The references to specific papers, A. Khaled and P. Richt\"arik, R. Gower, O. Sebbouh, and N. Loizou, provide clear guidance on where the authors can find more information and how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The reviewer supports this claim by referencing specific works, such as A. Khaled and P. Richt\"arik, R. Gower, O. Sebbouh, and N. Loizou, which have explored sgd in the nonconvex world and provided theoretical foundations for stochastic optimization. These references provide a solid basis for the claim, making it 4. However, the comment could be strengthened by further elaborating on how these extensions have impacted the literature or how the authors might incorporate them into their work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the bounded noise assumption, which is common in stochastic optimization literature but somewhat restrictive. It suggests that there have been efforts to extend these noise conditions, as evidenced by references to specific works. This feedback is 3 as it points out a potential area for improvement and provides references to relevant literature. However, it could be more helpful if it offered specific suggestions on how the authors might incorporate these extensions into their work or how they might address the restrictiveness of the bounded noise assumption. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might clarify this motivation or what specific aspects of the motivation are unclear. There is no guidance on how to address this issue, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that the motivation for using characteristic function regularization is not clear, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a lack of clarity in the motivation for using characteristic function regularization, which is a critical aspect of the paper. However, it does not provide specific guidance or suggestions on how the authors might clarify this motivation or what aspects of the methodology are unclear. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the contribution is incremental because these techniques are not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this limitation or improve their draft. There is no guidance on how to differentiate their work from existing techniques or how to enhance the contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the paper, namely that the combination of these techniques is not novel and therefore the contribution is considered incremental. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. However, the comment lacks specific examples or references to these existing techniques, making it difficult for the authors to understand the basis of the claim. Additionally, the reasoning is not fully developed, as it does not explain why these techniques are considered incremental or how the authors could address this perception. Therefore, the comment is 3, as it provides some basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. While the comment highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance their contribution. The feedback lacks actionable advice or detailed critique, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and concrete, as it specifies exactly what needs to be added or clarified in the paper. The authors know exactly what information is missing and how to address it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"aggregation operation after \"Integration,\"\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the details of the aggregation operation and the acknowledgment of other architectures if they are referred to. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification and that if other architectures are referred to, their structure should be acknowledged properly. However, the comment does not provide specific examples or detailed reasoning to support why these clarifications are necessary or how they would improve the paper. Without additional context or examples, the claim is 3, as it requires the authors to infer the importance of the suggested clarifications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the aggregation operation after \"Integration.\" It suggests that the authors provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This feedback is clear and actionable, as it directs the authors to enhance the clarity and completeness of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on what additional details should be included. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to improve their writing quality, but without concrete steps or examples, they may struggle to know where to focus their efforts. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in detailing what exactly is unclear or needs improvement in the writing. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address them effectively. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies significant writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights these problems, it does not provide specific examples or guidance on how to address them. The comment lacks actionable advice or suggestions for improvement, leaving the authors without a clear path to enhance the quality of their draft. Therefore, the feedback is 3 as it points out areas for improvement but does not offer detailed guidance or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to run the corresponding experiments and add the results to the figures and Table 1, clarifying specific aspects of the data used in the experiments. The comment also asks for clarification on the nature of the data used, such as whether it is random or not, and suggests including examples of random data in the appendix. These actions are clear and specific, leaving no ambiguity about what the authors need to do to address the feedback. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3c\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as running the corresponding experiments and adding the results to the figures and Table 1. The comment also asks for clarification on the nature of the data used, which adds further detail to the specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification and additional experiments. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the paper could be improved, such as running the corresponding experiments and adding the results to the figures and Table 1. It also clarifies ambiguities in the current presentation, such as the nature of the data used and whether the dotted lines show networks trained on unaltered data, evaluated with random data. The comment provides clear and actionable feedback, guiding the authors on how to enhance the clarity and completeness of their work. However, it could be more helpful if it offered suggestions on how to present the additional results or examples in the appendix. Overall, the comment is valuable in directing the authors toward improvements that can strengthen their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or address this issue. Without guidance or direction, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on what \"100 steps\" means in the context of the search model comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically in section 5.1. This question highlights a potential area of confusion or ambiguity in the paper, which could be clarified to enhance the reader\"s understanding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the potential of exploring energy models for image generation and suggests that it is less explored compared to GANs and VAEs. However, it also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. While the comment implies that the authors should consider this similarity and potentially address it in their work, it does not provide explicit guidance on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should address the similarity to the prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it acknowledges that the motivation and goals of the model are similar to a prior VAE paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the comparison to the prior work. The lack of specific examples or detailed justification makes the claim 3, as the authors would need to infer the basis of the comparison and potentially conduct additional research to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the potential of exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This feedback is 3 as it highlights an area of potential interest and a similarity to prior work, providing the authors with a direction for further exploration or clarification. However, the comment could be more helpful if it offered specific suggestions on how to address the similarity or how to differentiate the model from prior work. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. This feedback is explicit and provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is also concrete, as it specifies the need for statistical analysis and the need to repeat the experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the improvement over previous methods, specifically mentioning the results in Table 1 and Fig. 5. It also suggests repeating the experiments and conducting statistical significance analysis on the numbers. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for statistical analysis and the need to repeat the experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation. It also suggests repeating the experiments and conducting statistical significance analysis to determine whether the results are statistically significant. The comment provides some logical reasoning by pointing out the limited novelty and marginal improvement, which supports the suggestion to reject the paper. However, it lacks specific examples or references to statistical methods or previous studies that could strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the limited improvement over previous methods and the lack of statistical significance analysis. It suggests repeating the experiments and conducting statistical significance analysis to determine whether the results are statistically significant. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, the comment could be more helpful if it offered guidance on how to conduct the statistical analysis or provided examples of similar studies that have successfully demonstrated statistical significance. Despite this, the feedback is 4 as it highlights a critical area for improvement and provides a concrete suggestion for enhancing the paper\"s rigor and impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends conducting experiments on a different benchmark, such as Atari, to verify the generalizability of the method. This suggestion is clear and provides a specific action for the authors to take. Additionally, it highlights the importance of evaluating the method on a diverse set of domains to ensure its applicability beyond the current domain. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation on a single domain, Meta World, and suggests running experiments on a different benchmark, such as Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for generalizability testing and the importance of evaluating the method on a diverse set of domains. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is evaluated only on the tasks from Meta World, a robotic manipulation domain, which makes it difficult to judge whether the results will generalize to other domains. The reviewer suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is based on the need to verify whether the method works with discrete action spaces and highdimensional observations. The claim is 3 as it provides a logical reasoning for the need to test generalizability, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is evaluated only on the tasks from Meta World, a robotic manipulation domain. This observation highlights the need for generalizability testing to ensure that the results can be applied to other domains. The comment provides a specific recommendation to conduct experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is actionable and offers a clear path for the authors to improve their draft by expanding the evaluation to a more diverse set of domains. However, the comment could be more helpful if it included examples of how the Atari benchmark could be used or why it is particularly relevant for the method under consideration. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The comment implies that the authors should add more depth to the explanation of the model, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what aspects of the model should be analyzed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is specific in suggesting the need for an analysis but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that while the method is presented well and the experiments are thorough, there is a lack of analysis on what the model does. This feedback highlights an area for improvement, suggesting that the authors should include an analysis of the model\"s functionality, which could be interesting. However, the comment does not provide specific guidance or examples on how to conduct this analysis or what aspects to focus on. While it points out a potential area for enhancement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify these aspects, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date are not clearly described. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the task setup, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that these aspects are unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the task setup, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This feedback is clear and actionable, as it points out areas where the authors need to provide more detailed information to ensure that their task setup is understandable. However, the comment could be more helpful if it offered suggestions on how to clarify these aspects or provided examples of how similar tasks have been described in the literature. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of the approach section in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the approach section. The comment implies that the authors should include the approach section in the main paper, but it lacks concrete details on how to integrate it or what specific content should be included. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" and the \"supplementary material,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the approach section in the main paper and the use of supplementary material as additional information rather than an extension to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the approach section should be included or how the supplementary material should be used. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the approach section is missing in the main paper. It suggests that the supplementary material should be used as additional information rather than an extension to the paper. While the comment highlights an important oversight, it lacks specific guidance on how to address this issue or what content should be included in the approach section. The feedback is 3 as it points out a critical gap in the paper, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the statement regarding the biological plausibility of backpropagation in the introduction may be too weak and points out that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to strengthen the statement. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the statement and provide more robust evidence or reasoning to support it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the weakness of the statement and the need to provide more robust evidence or reasoning to support it. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation in the introduction is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation. It points out that the statement may be too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is 3 as it highlights an area where the authors may need to provide more robust evidence or reasoning to support their claims. However, the comment could be more helpful if it suggested specific ways to strengthen the statement or provided examples of alternative perspectives or evidence that could be considered. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the modulator is heuristically designed and questions the scalability issue, suggesting that there might be a need for tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of scalability in the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the scalability issue and the potential need for hyperparameter tuning, but without clear grounding, the authors cannot confidently determine which part of the paper this pertains to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the modulator is heuristically designed and questions the scalability issue, suggesting that there might be a need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. This is a relevant concern that could impact the practicality and efficiency of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of the modulator. Without actionable advice or detailed feedback, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail for the authors to effectively address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that f_R and f_P can be adapted over time but highlights the incorporation of domain knowledge into their structure. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to consider. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of domain knowledge being incorporated into the structure of the experiments, specifically mentioning f_R and f_P. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the impractical amount of data required for a less informed f_R/f_P. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments performed here incorporate a great deal of domain knowledge into their structure, which could require an impractical amount of data to learn for a less informed f_R/f_P. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that f_R and f_P can be adapted over time but highlights the incorporation of domain knowledge into their structure. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. While the comment identifies a potential issue with the experiments, it lacks specific suggestions or guidance on how the authors might address this concern. The feedback is 3 as it points out a potential limitation, but it does not provide actionable advice or detailed insights for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit instructions or suggestions on how the authors should conduct these experiments or what specific aspects to focus on. The action is implicit and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these aspects are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that obtaining labeled data for imitation learning is necessary and that there are no experiments on the difficulties in obtaining such data or how performance changes with data size. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the difficulties in obtaining labeled data for imitation learning and the impact of data size on performance. It highlights the need for experiments to address these issues, which is a crucial aspect of the methodology. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what aspects to focus on. While it points out an important area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it directs the authors to a critical area for enhancement but does not fully support them in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection between the necessary conditions and generalization bounds, suggesting that the constructions of ReLU networks for robust memorization may not lead to robust generalization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the connection between necessary conditions and generalization bounds, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of overparameterization and its implications on generalization bounds, suggesting that the necessary conditions may have stronger implications if they are connected to generalization. It mentions the constructions of ReLU networks for robust memorization and questions whether this leads to robust generalization. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the connection between necessary conditions and generalization bounds, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connection between necessary conditions and generalization bounds, suggesting that overparameterization can lead to powerful memorization and good generalization performance. The reviewer acknowledges that the authors acknowledge this in the conclusion but considers it a serious question. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the constructions of ReLU networks for robust memorization may not lead to robust generalization. Without such evidence or examples, the claim remains 3, as it provides a logical basis but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the connection between necessary conditions and generalization bounds, suggesting that overparameterization can lead to powerful memorization and good generalization performance. It acknowledges that the authors acknowledge this in the conclusion but considers it a serious question. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the paper. While it highlights an important area for consideration, it does not provide actionable feedback or detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. However, it does not provide specific guidance on how the authors should address this issue or what additional exploration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the generalizability of their results. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s exploration of the implications of the proposed method for other NLP tasks, suggesting that the paper\"s generalizability is somewhat limited due to this lack of exploration. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which somewhat limits its generalizability. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. This observation highlights a potential weakness in the generalizability of the results, which could limit the impact of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional exploration could be conducted. While it points out an area for improvement, the lack of actionable advice makes the comment 3, as it provides insight but not a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the terminology \"certificate\" in the paper, as it has a strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to avoid misinterpretation. The action is implicit and vague, as the authors are left to infer that they need to reconsider the use of this terminology and possibly provide clarification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the terminology \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the terminology \"certificate\" in some contexts could be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of terminology in the paper, specifically the term \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This is a clear and actionable point that the authors can address to avoid confusion and ensure their terminology is appropriately understood. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the terminology in question. Overall, the feedback is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems in imaging, specifically mentioning the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with these methods. While the comment provides a clear action\u2014mentioning the relevant work and potentially comparing the current method\u2014it does not specify how to integrate this information into the paper or what specific aspects of the comparison should be highlighted. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" for inverse problems in imaging, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work by Ulyanov et al. (CVPR 2018) and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. This provides clear guidance on how to enhance the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the current work is interesting because the trained network can provide strong OOD generalization. However, it also mentions that untrained NNs, like those used in the Ulyanov et al. (CVPR 2018) paper, can be used for inverse problems across a wide range of images. The reviewer suggests that the current work should be placed in context by mentioning these existing methods and potentially comparing them. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to the Ulyanov et al. paper or other relevant works that could strengthen the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a constructive suggestion by pointing out that the current work on OOD experiments is interesting due to the strong generalization capabilities of the trained network. However, it also highlights a potential limitation by mentioning that untrained NNs, like those used in the Ulyanov et al. (CVPR 2018) paper, can be used for inverse problems across a wide range of images. The comment suggests that the current work should be placed in context by mentioning these existing methods and potentially comparing them. This feedback is valuable as it encourages the authors to consider the broader context of their work and potentially enhance its impact by integrating these comparisons. However, the comment could be more helpful if it provided specific guidance on how to integrate these comparisons or what aspects to focus on. Overall, the comment is 4 as it offers actionable suggestions for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments are limited to toy data and recommends expanding the analysis to include real data. While the comment implies that the authors should consider using real data, it does not provide specific guidance on how to implement this suggestion or what aspects of real data should be considered. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to toy data and recommends expanding the analysis to include real data. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should consider using real data to demonstrate the performance of the method in various settings. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and recommends expanding the analysis to include real data. However, the comment does not provide specific examples or references to support the claim that real data would be beneficial or how it would impact the results. The suggestion is based on a logical assumption, but without detailed evidence or reasoning, it lacks verifiability. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are currently limited to toy data. It suggests expanding the analysis to include real data, which could provide a more comprehensive understanding of the method\"s performance in various settings. This feedback is 3 as it points out a potential area for improvement, but it lacks specific guidance on how to implement this suggestion or what aspects of real data should be considered. The authors are given a general direction but may need to infer the details themselves, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment implies that additional experiments are necessary, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions on how to implement the suggested experiments. The action is implicit and somewhat vague, as the authors need to infer the specific details of how to proceed with the additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. The references provided are relevant but do not directly address the comment. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. The comment provides references to relevant works, which supports the claim that these experiments could enhance the paper. However, the comment lacks detailed reasoning or specific examples of how these additional experiments would benefit the paper. While the references provide some context, the claim could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides some support but lacks full justification.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions or suggestions for the authors. Therefore, the comment is 3 as it points out a potential area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sample selection mechanism is not clearly explained in terms of how it preserves the label distribution. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific ways to clarify the mechanism or suggesting alternative explanations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed sample selection mechanism, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding how the mechanism preserves the label distribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the proposed sample selection mechanism in preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the proposed sample selection mechanism, noting that it is not clear how it preserves the label distribution. This feedback is 3 as it points out a potential weakness in the paper that the authors should address to improve clarity and understanding. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the mechanism or what aspects of the explanation are unclear. While it highlights an area for improvement, it does not fully guide the authors on how to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any explicit or implicit suggestions for improvement or additional models to consider. The authors are left without guidance on how to enhance the scope or relevance of their evaluation. As a result, the comment lacks actionable advice, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the results and analysis, noting that they are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not specify which part of the paper this critique pertains to, such as the results or analysis sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the evaluation are lacking or how the authors could expand their analysis. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of the results and analysis, noting that only two relatively old and small models are considered. This feedback highlights an area where the authors could potentially expand the scope and relevance of their evaluation by including more diverse or contemporary models. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional models or methods to consider. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer implies that this makes the motivation for Algorithm 1 unclear. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. It lacks actionable details, such as suggesting how to clarify the motivation or how to incorporate this insight into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making the motivation unclear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is 3 as it provides a logical reasoning based on the conjugate function, which is a wellknown mathematical concept. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation could lead to a clearer understanding of the problem and its solution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the motivation for Algorithm 1. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS, particularly when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take based on this observation. There is no guidance on how to incorporate this understanding into the paper or what specific aspects of the paper should be revised to reflect this view. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion that LS and KD are equivalent under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD can be considered a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without additional context or evidence, the claim remains 1, as it does not provide sufficient justification for the authors to address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. It provides a specific example of when this equivalence occurs, which is when the teacher network is uniformly distributed and the temperature is set at 1. This feedback is 3 as it offers a potential insight into the relationship between KD and LS, which could be useful for the authors to consider when discussing their method. However, the comment could be more helpful if it provided suggestions on how to incorporate this understanding into the paper or how to address any implications of this equivalence. Overall, the comment offers a valuable observation but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results on largescale datasets, such as ImageNet, to verify the effectiveness of their proposed method. This feedback is explicit and provides a clear action for the authors to take, which is to include results on larger datasets. The comment also mentions that competing dynamicpruning methods are outdated, implying that the authors should consider more recent works. However, it does not specify which recent works should be included or how to incorporate them into the paper. While the action is clear, the lack of detailed guidance on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamicpruning methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of results on largescale datasets, such as ImageNet, to verify the effectiveness of the proposed method. Additionally, it points out that competing dynamicpruning methods are outdated, suggesting that more recent works should be included. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that competing dynamicpruning methods are outdated and suggests that more recent works should be included. However, the comment does not provide specific examples of these outdated methods or recent works that should be considered. Without detailed references or specific examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include results on largescale datasets, such as ImageNet, to verify the effectiveness of their proposed method. It also points out that competing dynamicpruning methods are outdated, implying that more recent works should be considered. This feedback is specific and offers a concrete direction for improvement, making it 4 for the authors. However, it could be more helpful if it provided examples of recent works or detailed guidance on how to incorporate these changes into the paper. Overall, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to provide an explanation for why the performance degrades when using additional information about missing, wrong, or redundant data. This is a clear and direct request, giving the authors a specific action to take. The comment is specific in its request for an explanation, which provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the performance degrades when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance degradation when using additional information about missing, wrong, or redundant data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance degradation when using additional information about missing, wrong, or redundant data. It prompts the authors to provide an explanation for this phenomenon, which is a clear and actionable request. This feedback is valuable as it directs the authors to clarify an aspect of their results that may be confusing or misleading. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have handled similar challenges. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. The reviewer explicitly asks for clarification on these points, providing a clear direction for the authors to improve the clarity of their explanations. The action is explicit and concrete, as it specifies exactly what needs to be addressed to improve the readability of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail helps the authors understand what needs to be addressed to improve the clarity of their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are hard to read due to unclear explanations of previous approaches. It provides specific examples of unclear statements, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. These examples are detailed and provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to support the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity and readability of the first two sections of the paper. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96, and asks for clarification on these points. This feedback is clear and actionable, as it directs the authors to improve the clarity of their explanations and provide more detailed descriptions of their methods. By addressing these issues, the authors can significantly enhance the readability and comprehensibility of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the captions should be more descriptive and provides a specific example of the issue of having to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment provides a clear action to make the captions more descriptive and an explicit request for an explanation of the scramble network, it does not provide detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specifics of how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests making the captions more descriptive and provides an example of the issue of having to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the figures or captions in the paper. The comment is specific in its request for more descriptive captions and an explanation of the scramble network, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions are not descriptive and that it is annoying to have to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment identifies a specific issue with the captions, it lacks detailed reasoning or examples to support why this is a problem or how it could be improved. The suggestion to make the captions more descriptive is logical, but the lack of specific guidance or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the captions should be more descriptive, which would improve the clarity and accessibility of the figures in the paper. It also highlights the issue of having to search through the text for interpretations of figures, which are usually on a different page. This feedback is valuable as it directly addresses a common challenge in scientific writing and offers a clear solution to improve the draft. Additionally, the comment requests an explanation of the scramble network, which could further enhance the clarity and understanding of the paper. Overall, the comment is 5 as it provides clear and actionable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of using randomly sampled CIFAR images as backgrounds for the task, suggesting that the motivation for this choice is not wellexplained. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the motivation should be clarified. The comment lacks concrete suggestions or examples of how the authors might improve the explanation or justification for their choice. As a result, the authors are left without clear direction on how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the use of randomly sampled CIFAR images as backgrounds for the task, suggesting that the motivation for this choice is not wellexplained. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the motivation for the choice and asking for clarification, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds for the task, suggesting that the choice is not wellmotivated. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds for the task, suggesting that the choice is not wellmotivated. It highlights a potential weakness in the paper\"s explanation of the task difficulty, which could be a significant area for improvement. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the motivation should be clarified. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds flat minima, the analysis about flatness is missing. The reviewer suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is explicit and provides a clear action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (3)\" and \"the analysis about flatness,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the losses of the noiseinjected models after training to substantiate the claim about the flatness of the minima found by the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis about the flatness of the minima is missing, and it suggests that minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima. The reviewer provides a logical reasoning by explaining that the loss used for training the base model is the averaged loss for the noiseinjected models, and that the convergence analysis on this loss does not guarantee the flatness of the minima. However, the comment lacks specific examples or references to support the claim that the analysis on the losses of the noiseinjected models after training is necessary to substantiate the claim about the flatness of the minima. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds flat minima, the analysis about flatness is missing. The reviewer provides a logical explanation of why minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima, and suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is clear and actionable, guiding the authors to address a crucial aspect of their argument that could significantly impact the paper\"s credibility. Therefore, the comment is 4, as it provides a concrete direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to make the text inside the figure and labels roughly the same size as the manuscript text. This is a clear and direct action that the authors can take to improve the readability of their figures. The comment provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the size of the text compared to the manuscript text. This provides clear guidance on how to improve the readability of the figures. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and labels is too small to read without zooming, suggesting that it should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the readability of the figures. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the figures, noting that the text inside the figure and the labels are too small to read without zooming. It provides a clear and actionable suggestion to make the text roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a usability concern that could impact the accessibility and comprehension of the figures. However, the comment could be more helpful if it included examples or additional guidance on how to achieve this improvement. Overall, the comment is 4 as it effectively points out a specific issue and offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a direct and concrete action for the authors to take, which is to revise the introduction to clarify the motivation. The comment is specific in identifying the issue and offers a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the motivation. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of clarity in the motivation. It suggests that the introduction should be revised to make the paper easier to follow. While the comment highlights a critical area for improvement, it does not provide specific guidance on how to revise the introduction or what aspects of the motivation are unclear. This limits the comment\"s helpfulness, as it points out a problem but does not offer detailed suggestions for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its observation about the differences in features and positions across categories, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps to take to ensure its validity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the alignment of relabeled reward data with human annotator judgments, indicating that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficient validation of the alignment between relabeled reward data and human annotator judgments. This is a critical point that could impact the reliability and robustness of the results. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. Without specific recommendations or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model is somewhat complicated and recommends improving its presentation in Section 4, possibly by referring to the supplement. It also provides specific suggestions for enhancing the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These actions are explicit and concrete, providing clear guidance on how to improve the presentation of the model. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as suggesting the use of notation and breakout diagrams to enhance the presentation of the model. This level of detail provides the authors with a clear understanding of what changes are needed to improve the presentation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model is somewhat complicated and recommends improving its presentation in Section 4, possibly by referring to the supplement. It provides a specific suggestion to replace natural language descriptions with notation and adds breakout diagrams to illustrate the attention mechanisms. This claim is 3 as it offers a logical suggestion for improving the presentation, but it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It provides specific suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These suggestions are actionable and can help the authors enhance the clarity and accessibility of their presentation. However, the comment could be more helpful if it explained why these changes are necessary or provided examples of how they could be implemented. Overall, the comment is 4 as it offers clear and constructive feedback, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their work. The authors are left to infer that they need to consider expanding their experiments to more molecules or exploring ways to streamline the training process. While the comment highlights a potential limitation, it lacks concrete suggestions for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the limited scope of the experiments conducted in the paper, specifically mentioning that only a few molecules are tested and that indistribution testing is provided for these samples. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the method\"s potential limitations due to the need for individual training for each molecule. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments to include more molecules. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or how to make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the complexity of the symbols used in the paper, suggesting that they are difficult to understand. However, it does not specify which symbols or parts of the paper are causing this issue, making it difficult for the authors to pinpoint the exact areas that need attention. The comment lacks specificity regarding which symbols or sections are problematic, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the complexity of the symbols used in the paper, suggesting that they are difficult to understand and take a lot of time to comprehend. While this feedback identifies a potential weakness, it lacks specificity and does not provide actionable guidance on how to simplify the symbols or improve their clarity. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the source of the red line and the ground truth, but it lacks specific instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the red line in the figure and asks for clarification on the origin of the test data and the existence of a ground truth. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern. The comment lacks depth and does not offer actionable advice or insights into how the authors might clarify the origin of the red line or the ground truth. As a result, the feedback is not particularly helpful, as it does not guide the authors toward improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to take. It lacks actionable details, such as recommending specific modifications or experiments to address this concern. As a result, the authors are left without a clear path forward, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as specific experiments or sections where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the role of periodicity in the results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a logical basis for the question but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending experiments or modifications to the model. While it provides a thoughtprovoking insight, it could be more helpful with additional actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper is not wellwritten and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues, such as suggesting particular formatting changes or improvements to the figures and tables. The authors are left to infer that they need to improve the writing and formatting, but without concrete steps, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s writing quality, suggesting that it may be rushed and difficult to read. It mentions specific areas for improvement, such as presentation and formatting, particularly in figures and tables. However, the comment does not explicitly mention which sections or parts of the paper are problematic, making it weakly grounded. The authors can infer that it relates to the sections on presentation and formatting, but this inference is not direct. The comment is specific in detailing what needs to be improved, such as the figures and tables, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of specificity and detailed evidence or references makes the claim 2, as it provides some indication but not enough detail for the authors to fully understand and act upon the feedback.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s writing quality, suggesting that it may be rushed and difficult to read. It highlights specific areas for improvement, such as presentation and formatting, particularly in figures and tables. While the comment provides some insight into the areas needing attention, it lacks detailed guidance or specific suggestions on how to improve the writing and formatting. The authors are left with a general understanding of the issues but without actionable steps to address them. Therefore, the comment is 3, as it points out areas for improvement but does not provide comprehensive guidance for the authors to make significant improvements to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the introduction to orthogonality in Part 2 could be more detailed. This provides a clear and direct action for the authors to take, which is to expand or clarify the introduction to make it more comprehensive. The comment is specific in identifying the need for more detail, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Part 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction to orthogonality. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the introduction to orthogonality in Part 2. It suggests that the introduction could be more detailed, providing a clear direction for the authors to enhance their draft. However, the comment lacks specific guidance on what aspects of the introduction need more detail or how to achieve this improvement. While it points out a potential weakness, it does not offer actionable steps or examples to help the authors address it effectively. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should highlight the novelty of its result in relation to prior work, particularly regarding the removal of double descent in certain anisotropic settings. While the comment implies that the authors should clarify the novelty of their result, it does not provide specific guidance on how to do so or what aspects of the paper should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the novelty of their result. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical results of prior work that show samplewise multiple descent in linear regression, which provides a clear reference point for the authors to address. It also specifies the main contribution of the paper, which is the result that optimal regularization can remove double descent in certain anisotropic settings. The comment suggests that if this is not the case, the paper should better highlight the novelty of their result in relation to prior results. However, it does not provide specific guidance on how to achieve this or what aspects of the paper should be emphasized. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the paper\"s main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, which is based on prior work that theoretically shows samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper but suggests that the claims seem correct. This provides a logical basis for the claim but lacks specific references or detailed evidence to fully substantiate it. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed evidence or references to fully support it.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s contribution, noting that the main result about removing double descent in certain anisotropic settings is based on prior work that theoretically shows samplewise multiple descent in linear regression. The reviewer suggests that the paper should better highlight the novelty of its result in relation to prior results, as the theoretical basis is already established. While the comment provides a clear direction for improvement, it lacks specific guidance on how to effectively highlight the novelty or what aspects of the paper should be emphasized. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed suggestions for enhancing the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to integrate the methods or improve their connection. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically contrastive training objective and contrastive search, and notes that they are independent methods with little inner connection on both the intuition and the algorithm. However, it does not specify which part of the paper these methods are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of lack of connection between the methods, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods, contrastive training objective and contrastive search, noting that they are independent and lack a clear connection on both the intuition and the algorithm. This feedback is 3 as it points out a potential weakness in the paper\"s presentation and suggests that the authors should consider integrating these methods more effectively. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending ways to enhance the connection between the methods or explaining why this connection is important. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a concern regarding the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. While the comment implies that the authors should provide a comparison and justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. It suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or methodology sections. The comment is specific in detailing what needs to be addressed, such as the need for a comparison and justification. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. While the comment identifies a potential issue with the paper\"s goal and suggests improvements, it lacks specific examples or references to support the claim that the method is not comparable to existing DAS earthquake detectors. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. It suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. This feedback is clear and actionable, as it points out a critical gap in the paper that needs to be addressed to strengthen its claims. By suggesting a comparison with existing methods and a justification for the proposed method\"s benefits, the comment provides the authors with a concrete direction for improvement. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what about the ablation studies of MCT without the adaptive metrics. While these questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to clarify the discrepancy in the results and potentially include ablation studies, but the comment lacks specific details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the alignment of results and asking about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two questions that are relevant to the paper\"s content and methodology. First, it questions the alignment of results between Table 6 and Table 1 (MCTpair), which could indicate a discrepancy or inconsistency in the data. Second, it asks about the ablation studies of MCT without the adaptive metrics, suggesting that this could provide valuable insights into the model\"s performance. While the comment identifies areas for clarification and potential enhancement, it does not offer specific guidance or suggestions on how to address these issues. The authors are left with a general sense of what needs to be improved but without detailed instructions on how to do so. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR10 models on distribution shifts. It references specific works that have already studied this topic, such as RobustBench and [A, B]. The comment suggests that the current work may not provide novel insights or results, as the analyses are not particularly surprising. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes could be made to enhance the novelty or impact of their work. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the novelty and impact of their work based on the references provided. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific analyses and prior works, such as RobustBench and [A, B], which have already studied the robustness of CIFAR10 models on distribution shifts. This allows the authors to identify the exact parts of the paper being addressed. The comment is also specific because it clearly specifies what is problematic: the lack of novelty in the current work due to similar analyses in prior works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR10 models on distribution shifts. It references specific works, such as RobustBench and [A, B], which have already studied this topic. The comment also mentions that the current work does not provide novel insights or results, as the analyses are not particularly surprising. This claim is supported by the references to prior works, which provide a basis for the assertion that similar analyses have been conducted. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works to fully substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and impact of the current work, noting that similar analyses have been conducted in prior works. It specifically references specific works, such as RobustBench and [A, B], which have already studied the robustness of CIFAR10 models on distribution shifts. The comment suggests that the current work may not provide novel insights or results, as the analyses are not particularly surprising. However, it does not provide specific suggestions or guidance on how the authors could address this issue or enhance the novelty or impact of their work. While the comment highlights a potential weakness, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it points out a potential problem but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not provide any specific guidance on what kind of discussions are needed or how the authors should address this issue. The comment lacks actionable details, such as recommending additional analyses or discussions that could be included to enhance the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not specify which part of the paper these subtasks are discussed in or where the discussions are lacking. Without explicit references to sections or specific subtasks, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what kind of discussions are needed or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the 10 subtasks are simplistic for bAbi and suggests that more discussions are required. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of how the subtasks are simplistic or how they could be improved with additional discussions. Without such support, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the 10 subtasks presented in the paper, suggesting that they may be simplistic for bAbi and that more discussions are required. However, the comment lacks specificity and does not provide any guidance on what kind of discussions or analyses would be beneficial. Without detailed suggestions or examples, the authors are left without actionable steps to improve their draft. Therefore, the comment is 2, as it points out a potential weakness but does not offer concrete suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider this limitation and potentially explore alternatives, it does not provide explicit instructions or concrete suggestions on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider extending the approach to longer subsequences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether the limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It does not present an opinion, judgment, or suggestion that requires verification. It is a factual observation seeking clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a valid concern about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It questions whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. This feedback prompts the authors to consider whether their approach is limited by the specific windowing method or if it can be extended to accommodate longer sequences. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how to address this limitation or explore alternative approaches. Therefore, the comment is 3, as it points out an area for improvement but does not provide detailed guidance for the authors to act upon."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper and suggests that related work might be relevant but not necessarily detrimental to the novelty of the paper. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sequence of episodes\" and suggesting that related work might be relevant but not detrimental to the novelty of the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and observations about the definition of \"sequence of episodes\" and the relevance of related work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper, which is a relevant point for clarity. It also suggests that related work might be relevant but not detrimental to the novelty of the paper. While the comment identifies a potential area for improvement by suggesting the inclusion of related work, it lacks specific guidance or suggestions on how to address this issue or incorporate related work. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes should be made to the study. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the study\"s classification but lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. While it identifies a potential issue with the study\"s designation, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or reframe their study. The feedback is 3 as it points out a potential misclassification but does not offer actionable advice for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The authors are left without any direction on how to incorporate this suggestion into their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the inclusion of AccNet in a larger predictor. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, and suggests that it might make sense to learn AccNet in this context. However, the comment lacks depth and does not provide any specific guidance or suggestions on how the authors might incorporate this idea into their work. It does not offer actionable steps or detailed reasoning, leaving the authors without clear direction on how to address the question or improve their draft. Therefore, the comment is rated as 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any guidance on how the authors should address this issue or suggest ways to expand the testing to other datasets. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the proposed metric, noting that it is only tested on a single dataset. However, it does not specify which dataset or which part of the paper discusses this metric, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the testing of the metric, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed metric is only tested on a single dataset, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this limitation or how it affects the validity of the metric. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the paper, noting that the proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets for testing or discussing potential implications of this limitation. While it points out a relevant weakness, the feedback could be more helpful with additional context or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm architecture to similar architectural competitors like AutoDial and AdaBN. This feedback provides a clear and explicit action for the authors to take, which is to extend the evaluation to include these additional comparisons. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"comparing several base DA methods with and without the proposed TransferNorm architecture.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN. This provides clear guidance on what additional evaluations should be conducted to enhance the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN. However, the comment does not provide specific reasoning or evidence to support why these comparisons would enhance the evaluation or how they would impact the results. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand the exact benefits of including these comparisons. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the evaluation section by suggesting that the base DA methods should be evaluated with and without the proposed TransferNorm architecture, as well as with other architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation by including additional comparisons. By doing so, the authors can strengthen their evaluation and demonstrate the competitiveness of their proposed method. However, the comment could be more helpful if it explained why these additional comparisons are important or how they would impact the results. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6. It also mentions that the lack of definitions hindered understanding in an initial read. The reviewer provides specific references to similar works that have defined these terms, which offers a clear direction for the authors to address these issues. By explicitly mentioning the undefined terms and providing examples of how they have been defined in other works, the comment offers concrete guidance on how to improve the clarity and accessibility of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"L73\" and \"L166,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue of undefined abbreviations and the lack of definition for superscript notation in Equation 6, which hindered understanding. Additionally, it provides examples of similar works that have defined these terms, offering clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. The reviewer provides references to similar works that have defined these terms, offering a logical basis for the claim. However, the comment could be strengthened by providing more detailed explanations or examples of how these terms are defined in the referenced works. As it stands, the claim is 4, as it is supported by references but lacks comprehensive justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. It provides examples of similar works that have defined these terms, offering clear guidance on how to improve the clarity and accessibility of the paper. By pointing out these specific issues and providing references to similar works, the comment offers actionable feedback that can help the authors enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it included suggestions on how to address these issues, such as recommending specific definitions or approaches. Overall, the comment is 4 as it identifies important areas for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue. There is no guidance on what specific changes or improvements could be made to the evaluation or baselines. Without actionable advice or concrete steps, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the evaluation and the baselines used in the paper, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the evaluation being weak and the baselines not being designed for fair classification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, noting that the baselines used in the paper are not designed for fair classification. This is a critical observation that highlights a potential weakness in the paper\"s methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the evaluation. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the setting but may not be entirely sure of the exact details to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting needs to be spelled out more clearly and suggesting that the authors may be trying to present something in greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. The reviewer suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to understand the exact issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors may be presenting something in greater generality than what is actually shown, which muddles the exposition. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their work to improve the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the setting or what specific aspects need to be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the convincing nature of the experiments and questions the choice of the old baseline, R3D and C3D. It suggests that the authors should consider whether their proposed method works on other 3D CNNs, such as X3D, SlowFast, etc., and compare its advantages to those approaches. While the comment implies that the authors should conduct additional experiments or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or comparisons to address the concerns raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the old baseline and suggesting that the proposed method should be evaluated against other 3D CNNs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the convincing nature of the experiments and suggests that the authors should consider whether their proposed method works on other 3D CNNs, such as X3D, SlowFast, etc. The comment also raises a logical question about the advantage of the proposed method compared to these approaches. However, the comment lacks specific examples or references to support the claim that the baseline is outdated or that the proposed method is not convincing. This makes the claim 3, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experiments, questioning the choice of the old baseline and suggesting that the proposed method should be evaluated against other 3D CNNs. It also raises a logical question about the advantage of the proposed method compared to existing approaches. While the comment provides a clear direction for improvement by suggesting additional experiments or comparisons, it lacks specific guidance on how to conduct these experiments or what specific aspects to focus on. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed instructions on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the attention module is attached to the backbone ResNet20 architecture, including the number of attention modules used, their placement (after each block or stage), and how they are integrated into the overall architecture. This feedback provides clear and specific guidance on what the authors need to address to improve the clarity of their draft. The action is concrete, as it details the exact information that needs to be clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module attached to the backbone ResNet20 architecture\" and the need to clarify how many attention modules are used, where they are placed, and after which stages. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules, their placement, and the integration into the overall architecture. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how the attention module is attached to the backbone ResNet20 architecture, specifically asking about the number of attention modules, their placement, and how they are integrated into the overall architecture. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the integration of the attention module with the backbone ResNet20 architecture. It asks for clarification on the number of attention modules used, their placement, and how they are integrated into the overall architecture. This feedback is clear and actionable, as it provides the authors with specific questions to address in order to improve the clarity of their draft. By addressing these points, the authors can enhance the understandability and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information in the paper. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. It also asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. While the comment provides explicit actions\u2014asking for clarification and suggesting a related work for discussion\u2014it does not offer specific guidance on how to implement the contentadaptive algorithm or what aspects of the method need improvement. The authors are given clear directions but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BDrate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the method\"s performance at low bitrates and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. The reviewer asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. While the comment identifies a potential issue with the method\"s performance, it lacks specific examples or detailed reasoning to support the claim. The suggestion to discuss a related work is helpful but does not fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it performs stronger at high bitrates but is close to the baselines at low bitrates. This is a valuable observation that prompts the authors to reconsider the method\"s performance range and potentially adjust their claims. Additionally, the comment suggests discussing a related work about implementing contentadaptive algorithms in learned video compression, which could provide a valuable context for the authors to consider. While the comment does not offer specific suggestions on how to address the issue or implement the contentadaptive algorithm, it provides clear and actionable feedback that can guide the authors in improving their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should make this distinction, it does not provide explicit instructions on how to do so or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they need to make a distinction but are not given specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide detailed guidance on how to make this distinction. The authors can infer that it relates to the discussion or analysis of results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making the suggested distinction. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While this feedback identifies a potential area for clarification and differentiation, it lacks specific guidance on how to achieve this distinction or what aspects of the paper need to be revised. The comment highlights a potential issue but does not provide actionable steps for the authors to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what additional analysis should be conducted. The comment lacks concrete details or specific actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not specify which tasks, previous works, or selfimplemented baselines are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what additional analysis should be conducted or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide specific examples or details on what aspects of the analysis are lacking or how the authors could improve it. The comment lacks actionable guidance or suggestions for enhancing the analysis, leaving the authors without clear direction on how to address the critique. As a result, the feedback is not helpful, as it does not provide the authors with a path to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the proof or relocate Theorem 8 to a more accessible location, but it lacks specific instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the proof more accessible. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the linear convergence rates relying on Theorem 8, which is buried in the appendix and whose proof is unclear. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This claim is 3 as it provides a specific reference to Theorem 8 and the appendix, allowing the authors to understand the issue. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the proof is unclear or how it affects the paper\"s conclusions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This is a clear and actionable point that the authors can address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the proof or relocate Theorem 8 to a more prominent location in the paper. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. The comment explicitly instructs the authors to correct the inaccuracy regarding the Walkman algorithm, specifying that it is solved by ADMM with two versions. It also points out the lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors clarify the intended reference. These actions are explicit and provide concrete guidance on what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about the Walkman algorithm, noting that it is solved by ADMM with two versions, and it points out the lack of clarity in the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed in these parts of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization.\" It does so by pointing out that the Walkman algorithm is solved by ADMM with two versions, which suggests that the claim is inaccurate. The reviewer provides a specific example of the Walkman algorithm, which is a clear and logical point. However, the comment could be strengthened by referencing the specific ADMM versions or providing more detailed information about the Walkman algorithm. Despite this, the claim is 4 due to the clear reasoning and specific example provided.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. By pointing out these issues, the comment provides clear and actionable feedback that empowers the authors to correct their work. The suggestion to clarify the reference to \"it\" in Section 3 is particularly helpful, as it ensures that the authors provide a clear and accurate description of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the statement about the Walkman algorithm or provided additional context on the significance of the ADMM versions. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the theoretical result, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the utility guarantees are only valid when the features and noise are Gaussian, which is a strong requirement on the data. Additionally, it suggests that the authors should compare their rates to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. The reviewer suggests that this requirement is problematic, as it limits the applicability of the algorithm to specific data types. Additionally, the comment recommends that the authors compare their rates to existing rates in the literature. While the comment identifies a potential issue with the assumption and suggests a comparison, it lacks specific examples or references to support the claim about existing algorithms not requiring this assumption. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical result of the paper, noting that the utility guarantees are only applicable when the features and noise are Gaussian, which is a strong requirement on the data. This is a critical observation that could impact the applicability and generalizability of the algorithm. Additionally, the comment suggests that the authors should compare their rates to existing rates in the literature, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific examples or references to existing algorithms that do not require this assumption, which would help the authors understand the scope of their work. Overall, the comment is 4 as it highlights a critical weakness and offers a constructive suggestion for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This implies that the authors should include such a comparison in their paper. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects to focus on. While the action is implied, it is not as concrete as it could be, as the authors are left to infer the details of the comparison themselves. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the need for a comparison, but without clear guidance on where to place it, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\"s credibility and rigor. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, such as which specific aspects of the original approach should be compared or how to interpret the results. While it provides a general direction for improvement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should include additional experiments, it does not specify which specific baselines or comparisons should be included. The action is clear but lacks concrete details on which additional experiments to conduct or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it references specific works that focus on similar questions, it does not provide detailed reasoning or evidence to support why these additional comparisons are necessary or how they would enhance the paper. The reference to specific works is a helpful starting point, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some support but requires more detailed explanation to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section, noting that the authors only compared their method with two baselines. It suggests that there are several other works that focus on similar questions, such as [1,2,3], and recommends adding more experimental comparisons to demonstrate the effectiveness of the proposed method. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can enhance the paper\"s rigor and comprehensiveness. However, it could be more helpful if it included specific examples of additional experiments or comparisons that could be included. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their experimental section."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This is a clear and explicit action for the authors to take, as it provides a specific direction for improving the presentation of results. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper\"s presentation of results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s results are not convincing because they are based on the best results on the development set with hyperparameter search and model selection on the development set. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it provides a logical reasoning for why the current presentation of results is insufficient, but it lacks specific examples or references to support the claim. The suggestion for presenting results on the test set is a reasonable one, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that the authors report the best results on the development set with hyperparameter search and model selection on the development set, which is not enough to be convincing. The comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, providing a concrete suggestion for improving the presentation of results. By addressing this issue, the authors can enhance the credibility and persuasiveness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are explicit, the comment lacks concrete guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the dataset, but the specific actions to take are not clearly stated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset and methodology sections. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are relevant and could guide the authors in improving their draft, the comment lacks specific suggestions or actionable advice on how to address these issues. The authors are left with a clear understanding of what needs to be clarified but without detailed guidance on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not provide comprehensive guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback implies that the authors should expand their analysis to include more comparisons and consider additional NAS approaches. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on which NAS approaches to include or how to conduct the analysis. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis on BRPNAS, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. However, the comment does not provide specific examples or references to these other NAS approaches, nor does it explain why these comparisons are necessary or how they would enhance the analysis. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the analysis section of the paper, specifically noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback highlights an area where the authors could expand their analysis to provide a more comprehensive understanding of the BRPNAS. However, the comment does not offer specific suggestions on how to address this issue or which NAS approaches to consider, leaving the authors with a general direction but without detailed guidance on how to implement the suggested improvements. While it points out a relevant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, stating that it distracts from the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, should be made to the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the distraction but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the zeroshot version and its connection to density estimation are distracting from the main point of the paper, which is about learning effective prototypes for fewshot learning. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the paper. Without actionable feedback or constructive criticism, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors need to provide more information on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for details on the translation and filtering methodology to assess the dataset quality. This feedback is clear and concrete, as it specifies exactly what information is missing and what needs to be added. Therefore, the comment is 5, as it provides a direct and specific action for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of details on the filtering process used to create the dataset and the need for more information on the translation and filtering methodology to assess dataset quality. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking.\" This is a factual observation about the paper, as it highlights a gap in the description of the dataset creation process. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this detail is important or how it affects the quality of the dataset. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the lack of details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results could be enriched by adding attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that these additions would improve the results, it does not provide specific guidance on how to implement these changes or what specific types of attacks or threshold analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or figures where these additions could be made. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these additions would improve the results. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 2, as it provides a general direction but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment results by suggesting the addition of attacks with different strengths and an exploration of how different thresholds influence detection performance. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific types of attacks or threshold analyses should be considered. Overall, the comment is 4 as it directs the authors toward meaningful enhancements to their experimental results, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer notes that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. While the comment provides a clear action\u2014to evaluate the claim by training a discriminator\u2014it does not offer specific guidance on how to implement this evaluation or what metrics to use. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the claim to reduce exposure bias and the need to train a discriminator on generations from the learned model. The comment provides a clear direction for the authors to follow, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer explains that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. This claim is 3 as it provides a logical reasoning for the need to evaluate the claim and explains the difference between Figure 1 and Figure 4. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of the paper, which is to train a discriminator on generations from the learned model to confirm if the paper successfully reduces exposure bias. The reviewer explains the difference between Figure 1 and Figure 4, noting that the former involves coadaptation between the discriminator and generator, while the latter is a static representation. This feedback is valuable as it guides the authors on how to test their claim and provides a specific method for evaluation. However, the comment could be more helpful if it offered additional insights or examples on how to implement this evaluation or what metrics to use. Overall, the comment is 4 as it provides a clear direction for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. While the action is implicit, it is clear and concrete, as it specifies what additional information is needed to be included in the paper. The authors know exactly what to do to address the comment, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance difference resulting from using different image sizes and variations of ResNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the impact of the experimental setup on performance. However, the comment lacks depth and does not provide specific guidance on how to present this information or what specific aspects of the performance should be highlighted. While it points out a potential gap, it does not offer detailed suggestions for addressing it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to present and describe the Algorithm in detail, which is helpful for understanding the proposed method. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to present and describe the algorithm in detail, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this suggestion, the authors can improve the reader\"s ability to understand and evaluate the proposed method. However, the comment could be more helpful if it included specific examples or guidance on how to present and describe the algorithm in detail. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper. While it implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a runtime comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the comparison could be included. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential addition. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific comparison that could enhance the paper\"s contribution. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. While it points out a potential improvement, it does not fully support the authors in making that enhancement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider the applicability of their method to natural images. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its question about the applicability of the method to natural images, but without explicit grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, the comment lacks any supporting evidence, reasoning, or references to justify why this limitation is a concern or how it affects the paper\"s contribution. Without such information, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. This is an important consideration for the broader applicability of the method in realworld scenarios. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or expand their work to include natural images. While it identifies a potential limitation, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the organization or presentation of the prompts, nor are there suggestions for alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in this area. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the prompts being poorly organized, with all sentences squeezed together. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a clear area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the organization. While it highlights a potential problem, it does not offer actionable guidance or detailed advice for the authors to enhance their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the clarity of the figures and label the modules, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"CMAF, L_BT, VoLTA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the clarity of the figures, particularly the confusion in Figure 2 regarding the relation between subfigures and the lack of labeling for certain modules. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning Figure 2 and the confusion regarding the relation between subfigures. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the basis of the confusion and the importance of labeling the modules. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This feedback is clear and actionable, as it directs the authors to improve the clarity of the figures by labeling the modules and ensuring the subfigures are properly labeled. By addressing these issues, the authors can enhance the readability and comprehension of their figures, which is crucial for effectively communicating their research. Therefore, the comment is 4, as it provides clear and actionable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that if FFNs are omitted due to a linear decomposition issue, the authors should consider whether there is existing work that offers a way around this limitation. If not, the comment recommends adding a line or two acknowledging the lack of a solution and describing it as an open (hard) problem. This feedback provides a clear and explicit action for the authors to take, ensuring they know exactly what steps to consider to improve their draft. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of FFNs being omitted due to a linear decomposition problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering existing work for a way around the issue and proposes adding a line or two to acknowledge the problem as an open (hard) problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that FFNs are omitted due to a linear decomposition issue and questions whether there is existing work that offers a way around this limitation. The comment suggests that if not, a line or two should be added acknowledging the problem as an open (hard) problem. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. The authors might need to conduct additional research to verify the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the omission of FFNs due to a linear decomposition problem. It suggests that the authors should consider whether there is existing work that offers a way around this limitation or if it is an open (hard) problem. The comment provides a clear and actionable suggestion for improving the paper by acknowledging the issue and offering a potential solution. This feedback is valuable as it guides the authors in enhancing the clarity and completeness of their work. However, it could be more helpful if it included specific references or examples of existing work that addresses this issue. Overall, the comment is 4 as it provides a constructive direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to control domain drift. The comment lacks actionable details, such as recommending specific methods or experiments to explore, making it difficult for the authors to know how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the use of perplexity and the need to control domain drift, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, the comment does not provide specific examples or references to support the claim that perplexity is an inappropriate measure or that domain drift is a significant issue. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. This is an important point that could impact the validity and reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or control domain drift. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. While these questions imply that the authors should investigate the effect of image number and provide an explanation for BYOL, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide an explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific questions about the cluster structure and its impact on model performance, as well as the first appearance of BYOL in the abstract. However, it does not explicitly mention which part of the paper these questions pertain to, such as specific sections or figures. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for an explanation of BYOL and the impact of the number of images on performance, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. These questions prompt the authors to investigate the effect of image number on model performance and provide a clear direction for further analysis. However, the comment lacks specific guidance on how to conduct this analysis or what aspects of the BYOL explanation should be emphasized. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to clarify the reasoning behind the method\"s effectiveness. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the rationale behind the observed effects, specifically regarding the L_pixel component. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that providing stronger arguments or intuitions to explain why the method works would be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind the method\"s effectiveness, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples or references to support the claim that the current explanation is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the rationale behind the observed effects, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions to explain why the method works would be beneficial. This feedback is 3 as it points out an area where the authors could enhance their explanation, but it lacks specific guidance on how to develop these arguments or intuitions. The comment highlights a potential weakness in the paper but does not provide detailed suggestions on how to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. The comment is clear and concrete, giving the authors specific details to include in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more comprehensive overview of existing methods and their limitations, including sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This provides clear guidance on what needs to be improved in the Related Work section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations. The reviewer provides a list of specific methods to consider, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This detailed list of examples and references provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these methods are relevant to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the Related Work section. It identifies a lack of comprehensive details and suggests that the authors should provide a more comprehensive overview of existing methods and their limitations, including specific examples such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This detailed guidance helps the authors understand what is expected of their Related Work section and how to improve it, making the comment highly beneficial for enhancing the draft. Therefore, it deserves a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It suggests that LLMs are typically trained on trillions of tokens and that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their dataset. The action is implicit and vague, as the authors are left to infer that they need to consider the size and diversity of their dataset. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It suggests that LLMs are typically trained on trillions of tokens and that the dataset needs to be massive to cover varied domains. However, the comment does not specify which part of the paper this concern is related to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the concern about the dataset size and its implications, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. The reviewer suggests that LLMs are typically trained on trillions of tokens and that the dataset needs to be massive to cover varied domains. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. Without detailed evidence or comparisons, the claim remains 3, as it provides a logical argument but lacks the necessary substantiation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It suggests that LLMs are typically trained on trillions of tokens and that the dataset needs to be massive to cover varied domains. While the comment identifies a potential weakness in the dataset size, it lacks specific suggestions or guidance on how the authors might address this issue or improve their dataset. The feedback is 3 as it points out a potential limitation but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what alternative metrics or approaches might be more suitable. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of binary classification as a baseline metric and expresses skepticism about its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the binary classification are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\" understanding of finegrained errors like technique errors. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to alternative metrics or methods that could be used instead. As a result, the claim is not 5, making it difficult for the authors to understand and address the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment questions the use of binary classification as a baseline metric, expressing skepticism about its ability to assess models\" understanding of finegrained errors like technique errors. While it acknowledges the importance of the TAL task, it does not provide specific reasoning or suggestions for alternative metrics or methods that could be used to better assess the models\" performance. The comment lacks actionable feedback or guidance, leaving the authors without clear direction on how to address the concern. As a result, it is not helpful in improving the draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work only uses binary features and questions whether the method is applicable to real and categorical features. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to consider real and categorical features. The comment lacks concrete details on how to incorporate these features or what specific modifications are needed. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of binary features in the work and questions whether the method is applicable to real and categorical features. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of binary features and suggesting that the method may not be applicable to real and categorical features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work only uses binary features, which is a factual observation. However, it questions whether the method is applicable to real and categorical features, suggesting that this limitation needs to be addressed. The comment does not provide specific examples or references to support this claim, making it 3. The authors may need to infer the importance of considering real and categorical features, but the lack of detailed evidence or reasoning makes the claim 3.", "helpfulness_rationale": "The review comment identifies a limitation in the work, noting that it only uses binary features while realworld data typically includes a mix of binary, real, and categorical features. This is a relevant observation that could impact the applicability and generalizability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate real and categorical features into their analysis. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. The comment lacks explicit guidance on how to address the issues, leaving the authors without a clear understanding of what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of what needs to be clarified. Without specific references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support why the writing is unclear or how it could be improved. Without specific references or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they could be improved. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of what changes to make to enhance the clarity and readability of their paper. Therefore, the comment is 2, as it identifies an area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback provides a clear and explicit action for the authors to take, which is to consider using additional metrics for evaluating their results. The suggestion is concrete, as it specifies a specific metric to use, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation of results, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the use of BERTScore as an alternative metric, providing some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why BERTScore is a better choice or how it would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback is 3 as it identifies a potential area for improvement by suggesting the use of a different metric for evaluating the results. However, the comment lacks depth and does not provide detailed guidance on why BERTScore might be a better choice or how it could be integrated into the evaluation process. Additionally, it does not address other potential metrics or discuss the implications of using a different metric. While the suggestion is a step in the right direction, it could be more helpful with additional context and explanation. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, specifically mentioning metrics like MMLU and Big Bench for language generation. While the comment does not explicitly instruct the authors to conduct this comparison, it provides a clear direction for how to enhance the evaluation of their metric. The action is implicit but concrete, as it specifies the metrics to compare and the conditions under which SynTextBench should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"large amount of work on LLM evaluation\" and references specific metrics like MMLU and Big Bench, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely comparing the SynTextBench metric to other metrics proposed in the literature and clarifying under what conditions SynTextBench should be used over other metrics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there has been a large amount of work on LLM evaluation and mentions specific metrics like MMLU and Big Bench. It also claims that some of the metrics in the literature do not satisfy the proposed desiderata, but it does not provide specific examples or detailed reasoning to support this claim. The comment suggests comparing the SynTextBench metric to other metrics proposed in the literature, but it lacks specific examples or detailed guidance on how to conduct this comparison. This makes the claim 3, as it provides a direction for improvement but lacks the necessary evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the evaluation of the SynTextBench metric compared to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. It suggests that the authors should clarify under what conditions SynTextBench should be used over other metrics. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a comparison that could enhance the paper\"s evaluation. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it provides a concrete suggestion for enhancing the paper\"s evaluation section."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, it does not provide any guidance on how the authors should address this issue or what specific changes could be made to enhance the novelty of their work. The comment lacks explicit or implicit actions, leaving the authors without direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"algorithm for construction of coresets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, stating that the algorithm is not novel because it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the algorithm for constructing coresets is not novel because it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the novelty of the paper, noting that the algorithm for constructing coresets is not novel as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This feedback is clear and actionable, as it points out a weakness in the paper\"s originality and suggests that the authors should consider how to enhance the novelty of their work. However, the comment could be more helpful if it provided suggestions on how to differentiate their approach or what aspects of the existing frameworks could be improved. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the writing and annotations are difficult to follow, but it does not provide any specific guidance on how to improve them. It lacks actionable advice or suggestions on how to make the writing and annotations clearer or more accessible. Without concrete steps or examples, the authors are left without a clear understanding of what changes to make to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing and annotations are difficult to follow. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are difficult to follow. However, it does not provide any specific examples or detailed reasoning to support this claim. Without such evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations being difficult to follow. However, it lacks specificity and does not provide any actionable suggestions or examples on how to improve the clarity or accessibility of the content. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their writing need attention or how to enhance it. Therefore, the comment is not helpful as it does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should provide an explanation or analysis to clarify this discrepancy. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. The comment does not present any claims or opinions but rather seeks clarification or explanation. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This is a relevant observation that could prompt the authors to investigate and clarify the discrepancy in their results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the results might be misleading. While it points out a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this methodology is discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the methodology but lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. This is an important point that could impact the validity and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what potential implications it might have on the study. While it points out a potential weakness, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a relevant area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to enhance the paper. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this acknowledgment pertains to, making it weakly grounded. The comment does provide a specific suggestion for improvement, which is to consider the relaxation proposed by Guzman et al. This provides some level of specificity, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a minor suggestion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. It identifies a minor suggestion, but without further elaboration or guidance, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on the scalability bounds of FedDES, specifically mentioning the need for a clear discussion on memory requirements and computational complexity. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include a discussion on scalability bounds, but the comment lacks concrete suggestions on what aspects to focus on or how to present this information. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper limits of FedDES\"s scalability\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the scalability bounds, memory requirements, and computational complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough exploration of the upper limits of FedDES\"s scalability and does not provide a clear discussion on memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a thorough exploration of the scalability bounds of FedDES. It points out that there is no clear discussion on memory requirements or computational complexity, which are crucial aspects of the system\"s performance. This feedback is valuable as it highlights an area where the authors can enhance their draft by providing a more comprehensive analysis of the system\"s scalability. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps or provided examples of how similar studies have approached this issue. Overall, the comment is 4 as it directs the authors\" attention to an important aspect of their work that needs further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should generate instances with more constraints and variables, as the paper currently has few instances with more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a clear and explicit action. The comment also raises a concern about LLMs\" ability to model problems with large instance sizes, providing a specific direction for improvement. However, it does not offer detailed guidance on how to implement this suggestion or what specific constraints and variables should be included. While the action is clear, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a specific suggestion for improvement. However, the comment does not explicitly mention which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for more variables and constraints, but without clear grounding, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks instances with more constraints and variables, as few instances have more than 7 variables. This claim is based on the observation that the paper currently has few instances with large instance sizes, which raises concerns about LLMs\" ability to model such problems. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the concern. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the limited number of instances with more than 7 variables, which raises concerns about LLMs\" ability to model problems with large instance sizes. This feedback is clear and actionable, as it suggests that the authors should consider generating instances with more constraints and variables to test the limits of their model. However, the comment could be more helpful if it provided specific guidance on how to implement this suggestion, such as recommending particular constraints or variables to include. Overall, the comment is 4 as it points out a critical area for improvement but lacks detailed guidance on execution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the presentation of results, such as labeling the yaxis in Figures 2 and 3 and using a scatter plot with x/y axes being runtime/performance. It also recommends highlighting the best results in tables. These explicit actions are clear and concrete, giving the authors a direct path to enhance their draft. The comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as the ambiguous labeling of the yaxis and the lack of runtime representation in the figures. The suggestion to use a scatter plot with runtime/performance axes is clear and provides a concrete action for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results presentation in Figures 2 and 3 could be improved by labeling the yaxis more clearly and including runtime information. The comment provides a specific suggestion to use a scatter plot with x/y axes being runtime/performance, which is a clear and actionable improvement. However, the comment lacks detailed reasoning or references to support why this change would enhance the clarity or interpretation of the results. While the suggestion is logical, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It points out that the yaxis in Figures 2 and 3 is ambiguous and suggests using a scatter plot with x/y axes being runtime/performance to clarify the results. Additionally, it recommends highlighting the best results in tables, which is a helpful suggestion for enhancing the clarity and interpretability of the results. The comment is clear and provides concrete steps for the authors to take, making it 4. However, it could be more helpful if it included additional suggestions or examples of how to highlight the best results in tables. Overall, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It seeks clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment implies that the authors should provide more information or clarification on this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implications of this statement, including whether the base node affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the implications of a statement regarding \"NodeSort differentially sorting nodes depending on the base node.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node,\" seeking clarification on whether the base node affects the ordering, key nodes for attention, and model performance. This is a relevant question that could help the authors better understand the potential impact of their method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. This question implies that the authors should clarify or correct the arrow direction to better align with the intended purpose of the figure. However, the comment does not explicitly instruct the authors to make this change, leaving it somewhat vague. While the action is implied, the authors can infer that they need to address this issue, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the direction of the arrow in the figure, which is a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer seems to question the logic of the figure, suggesting that the main purpose is to influence n^(i). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the direction of the arrow in Figure 2, specifically questioning why it goes from a Gaussian space into the latent space rather than the other way around. This feedback highlights a potential inconsistency in the figure, which could be confusing for readers. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the figure. While it identifies a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. It provides a clear and specific action for the authors to take, which is to define these abbreviations in the text or provide a glossary. This guidance is direct and concrete, leaving no ambiguity about what needs to be done to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviation \"AR\" in Table 5, noting that it stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definitions and cause confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This claim is 3 as it offers a concrete example of an abbreviation that needs clarification. However, it lacks detailed reasoning or references to support the general claim about the prevalence of unexplained abbreviations in the paper. Providing more examples or references could strengthen the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that many abbreviations lack definitions and cause confusion. It provides a clear example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is valuable as it highlights a potential source of confusion for readers and offers a concrete suggestion for improvement by recommending the inclusion of definitions or explanations for these abbreviations. However, the comment could be more helpful if it suggested ways to improve the clarity of the definitions or provided examples of how other abbreviations could be clarified. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific technical considerations should be addressed or how the authors might address them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what technical considerations are being questioned or how they might impact the analysis. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not present any claims, opinions, or suggestions that require verification. It is a request for clarification, which is not a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, which is a relevant point for the authors to address. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what technical considerations might be relevant. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting of Unsupervised Online Adaptation is strange, as it requires a training set, including documents, queries, and labels. The reviewer suggests that this is not \"Unsupervised\" because the training set also requires annotations. While the comment identifies a potential issue with the labeling of the adaptation process, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the clarity or accuracy of the description. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the nature of the training set and its annotation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The reviewer supports this claim by referencing Section 3.1, where the model\"s training requirements are described. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as explaining why the training set\"s requirements make it less unsupervised. While the reference to Section 3.1 provides some context, the comment could be strengthened with additional justification or examples. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set, including documents, queries, and labels. This observation highlights a contradiction in the description, as the training set seems to require annotations, which would make the adaptation process less \"unsupervised.\" However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify the nature of the training set and its annotation requirements. While it points out a potential problem, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an issue with the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This implies that the comparison is unfair and suggests that the authors should address this issue to ensure fairness in their evaluation. However, the comment does not provide explicit guidance on how to rectify this issue or what specific changes should be made to the evaluation process. While the action is implied, it is not detailed enough for the authors to know exactly how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights while most baselines use a uniform weight of 1. This claim is 3 as it provides a logical reasoning for the unfairness, but it lacks specific examples or references to support the assertion that this difference significantly impacts the comparison. The authors would need to make a concerted effort to understand and address the issue, which requires more detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This is a critical observation that could impact the fairness and validity of the comparison. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending a standardized weighting scheme or explaining the potential impact of this difference. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the time complexity of the system if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the time complexity or suggestions for adjusting the buffer size. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"reply buffer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of high time complexity if the buffer is too large, providing clear guidance on what needs to be addressed. However, the comment could be more specific by suggesting ways to mitigate the time complexity or providing examples of how other similar systems have handled this issue. Therefore, the comment is 4, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the system if the reply buffer is too large. This is a relevant concern that could impact the performance and scalability of the system. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue. It does not offer actionable advice or examples of how to mitigate the time complexity, leaving the authors without a clear path forward. Therefore, the comment is 3 as it points out a potential problem but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a specific direction for improvement, it does not offer concrete guidance on how to implement these changes or which specific baselines to consider. The authors are left to infer the necessary steps to take, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to consider, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these alternative approaches would be beneficial or how they would improve the paper. Without specific examples or detailed explanations, the claim remains 1, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a specific direction for improvement by suggesting alternative approaches to consider. However, the comment lacks detailed guidance on how to implement these changes or which specific baselines to use. To be more helpful, the comment could offer examples of how these alternative approaches have been applied in similar contexts or provide suggestions on how to effectively integrate them into the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a brief conclusion and a summary of the article\"s contributions are needed. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact content that needs to be included in the conclusion and summary. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a brief conclusion and a summary of the article\"s contributions, providing full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the need for a conclusion and a summary of the paper\"s contributions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the article\"s contributions are needed. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how they would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a brief conclusion and a summary of the paper\"s contributions. This feedback is clear and actionable, as it directly guides the authors on how to enhance the final section of their paper. By providing a concrete suggestion for improving the paper\"s conclusion, the comment offers valuable insight that can help the authors better communicate the significance and impact of their work. However, the comment could be more helpful if it included specific examples or suggestions on how to structure the conclusion and summary. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or modifications to the experiment, making it difficult for the authors to know how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the data distribution in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the synthetic experiment in a nonseparable case, specifically questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment lacks specific examples or references to support this claim or provide a detailed explanation of why the experiment might be problematic. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This is a valid point that could lead to a significant issue in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the experiment. It does not provide actionable feedback or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is 3, as it identifies a potential problem but does not offer detailed guidance for resolution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. This feedback implies that the authors should include this comparison in their paper to enhance the results\" meaningfulness. While the action is implicit, it is clear that the authors need to make this addition to improve their draft. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what specific aspects of the framework should be compared. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting a potential comparison, but without clear guidance on where to place it, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such a comparison would be beneficial. The absence of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the benefits of this comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending a comparison with a method designed to defend against multiple attacks. This feedback is actionable as it points out a specific area where the authors could enhance their study, which could lead to more meaningful results. However, the comment could be more helpful if it provided examples of such methods or detailed guidance on how to conduct the comparison. Overall, the comment is 4 as it identifies a clear area for improvement and offers a direction for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. However, it does not provide any guidance on how to address this issue or suggest improvements to the presentation. The comment lacks explicit instructions or concrete details on how to improve the presentation, leaving the authors uncertain about what changes to make. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and the \"first 1000 episodes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes and questioning the reason for presenting them in this way. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way, specifically mentioning the disregard of safety violations in the first 1000 episodes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this presentation is problematic or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. It highlights the unclear reason for presenting the results in this way, which is a critical observation that could impact the interpretation and understanding of the results. However, the comment lacks depth and does not provide suggestions or guidance on how to address this issue or improve the presentation. While it points out a potential problem, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \tau_i^l, which is important for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on what needs to be added, ensuring that the authors know exactly what is expected of them. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. However, the comment does not provide any supporting evidence or reasoning to justify why this definition is necessary or how it would impact the understanding of the function. Without additional context or explanation, the authors may find it challenging to fully understand the basis of the request. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area where the authors need to provide more detail. By pointing out the importance of defining the bounds for \tau_i^l, the reviewer highlights a critical aspect of the paper that could enhance the understanding of the timewarp function. This feedback is clear and actionable, giving the authors a direct path to improve their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to define these bounds or why they are important. Overall, the comment is 5 as it effectively guides the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment identifies these errors, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to revise these sections to correct the errors and add a title. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be corrected, namely the writing errors and the lack of a title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it points out specific areas that need correction to improve the clarity and professionalism of the paper. However, the comment could be more helpful if it provided suggestions on how to correct these errors or offered guidance on how to improve the overall writing quality. Despite this, the feedback is 4 as it directs the authors to specific areas for improvement, which can enhance the clarity and professionalism of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests elaborating on the reasoning behind the statement on line 134, which pertains to the theorem about the standard sigmoid function. It also mentions that elaborating on why this theorem holds would be useful, particularly in the context of the RNN and URNN convergence. While the comment provides a clear direction for the authors to expand on the explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detail, but it is concrete in that it specifies what needs to be elaborated. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the reasoning behind the statement regarding the standard sigmoid function and its relation to the RNN and URNN convergence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests elaborating on the reasoning behind a statement on line 134 and Theorem 4.1. It provides a logical basis for the suggestion by explaining that the RNN will converge to the nearest FP, unlike the URNN. However, the comment lacks specific examples or references to support the claim that elaboration is necessary. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors elaborate on the reasoning behind a statement on line 134 and Theorem 4.1. It highlights the importance of elaborating on why the theorem holds, particularly in the context of the RNN and URNN convergence. This feedback is clear and constructive, as it guides the authors to enhance the clarity and depth of their explanation. By addressing this suggestion, the authors can improve the understanding and comprehensibility of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their pairwise matching. There is no guidance on potential solutions, alternative approaches, or specific actions to take. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, specifically noting that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem with the efficiency of pairwise matching, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. This is a relevant observation that could impact the practicality and applicability of the work. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the efficiency of their pairwise matching. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks concrete details on how to address the issue, leaving the authors uncertain about how to apply the feedback. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions \"Figure 1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. However, the comment lacks specificity regarding what aspects of the figure are considered naive or how it could be improved. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support why the allocation is considered naive or how it could be improved. Without these elements, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or suggestions on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to address the issue. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the planbased method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to improve the generalizability of their method. The authors are left to infer that they need to consider this issue and find ways to improve their method, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it highlights an area for improvement but does not provide explicit instructions on how to implement it.", "grounding_specificity_rationale": "The comment addresses the planbased method, specifically mentioning the requirement for manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. However, the comment does not specify which part of the paper discusses the planbased method or where the comparison to Table 2 is made. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue with the planbased method and its limitations, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the planbased method is unrealistic in realworld scenarios due to the requirement for manually designing a plan based on the ground truth in advance. It also compares the learned plan methods to those with predefined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the planbased method is unrealistic or that the learned plan methods are not comparable to those with predefined plans. This makes the claim 3, as it provides some logical reasoning but requires further elaboration to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the planbased method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also highlights a limitation in the learned plan methods compared to those with predefined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. This feedback is 3 as it points out a critical issue that the authors need to address to improve the realworld applicability of their method. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to improve the generalizability of the method. Overall, the comment offers valuable insights but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the first sentence of the abstract needs to be rewritten. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and provides a concrete action, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. However, it does not provide specific details on what needs to be rewritten or why the current sentence is problematic. This lack of specificity makes the comment weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any reasoning, evidence, or examples to support why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the first sentence of the abstract, suggesting that it needs to be rewritten. While this feedback is clear and actionable, it lacks depth and does not provide any further explanation or guidance on what aspects of the sentence need improvement. The authors are given a specific task to address, but without additional context or suggestions, the comment may not fully support the authors in making the necessary changes. Therefore, it is 3, as it points out a specific area for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. While the comment implies that this is a necessary step, it does not explicitly instruct the authors to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup, but the comment lacks full grounding. It is specific in suggesting a change to the experimental methodology, but without explicit references to sections or figures, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without specific examples or detailed explanations, the claim remains 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup by suggesting that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. While the comment acknowledges the time constraints that may arise from using multiple splits, it still encourages the authors to make this improvement. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the experimental design. However, it could be more helpful if it included examples of how this change would impact the results or how it could be implemented. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the method or what specific aspects of the method are overly complex. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as specific sections, figures, or experiments. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in suggesting that the method might be overly complex and that there might be a simpler principle driving the quality gains. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide specific guidance or suggestions on how the authors might simplify the method or explore the underlying principle. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential issue but lacks depth and specificity in its critique."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to determine what constitutes a significant contribution or how to improve the transferability of the method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, method, or result. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what constitutes a significant contribution or how the authors might address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might improve the transferability of their method or what aspects of the contribution are lacking. Without actionable feedback or detailed reasoning, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a potential issue but lacks depth and specificity in its critique."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the motivation or clarify the architecture. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not specify which part of the paper discusses the hGRU architecture, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered adhoc or poorly motivated, leaving the authors without clear guidance on how to address these concerns. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any specific reasoning or evidence to support this claim. There is no detailed explanation or examples given to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any specific examples or detailed reasoning to support this claim. Without further explanation or guidance, the authors are left without actionable feedback on how to address this concern or improve the motivation of the architecture. The lack of specificity and depth makes the comment 2, as it points out a potential issue but does not offer a clear path for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and suggests that the authors might want to use s_n instead. It also asks for the average return results with more env steps, potentially from a specific external source. While the comment implies that the authors should make a change, it does not explicitly instruct them to do so. The action is concrete, as it specifies the change to be made and the additional information to be provided, but it is somewhat vague because it does not provide detailed guidance on how to implement the change or what specific data to include. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 8 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of s_t instead of s_n and requests additional information on the asymptotic performance and average return results with more env steps. The reference to an external source, \"[1] https://github.com/watchernyu/REDQ,\" provides additional context and specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and a request for additional information on the asymptotic performance and average return results with more env steps. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the use of s_t instead of s_n on Line 8 of Algorithm 1, which is a clear and actionable point for the authors to address. It also suggests that the authors might want to use s_n instead, providing a concrete suggestion for improvement. Additionally, the comment requests additional information on the asymptotic performance and average return results with more env steps, which could help the authors better understand and present their method. However, the comment could be more helpful if it provided specific examples or references to similar studies that have addressed these questions. Overall, the comment is 4 as it identifies a specific area for improvement and offers actionable suggestions for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain the challenges and the differences between this analysis and that of Zhang et al. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Adam under the (L0,L1)smoothness condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the challenges and differences between this analysis and that of Zhang et al. This provides clear guidance on what the authors need to clarify or improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of Adam under the (L0,L1)smoothness condition is unclear and suggests that the authors should explain the challenges and differences with Zhang et al. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the analysis of Adam under the (L0,L1)smoothness condition. It points out that the challenges in this analysis are not clearly explained and suggests that the authors should clarify these challenges, especially in comparison to Zhang et al. This feedback is 3 as it highlights a potential gap in the paper that the authors can address to improve clarity and understanding. However, the comment could be more helpful if it provided specific suggestions on how to clarify these challenges or what aspects of the analysis are unclear. Overall, the comment offers some guidance but lacks depth and actionable details, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as it is not accurate according to the reviewer\"s understanding. Additionally, it advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, focusing on plurals and articles. These are clear and specific actions that the authors can take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests compressing the method section, particularly on essential definitions. Additionally, it points out grammatical errors and provides specific examples, such as \"l.\" This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the claim about the neural network memorizing critical points is inaccurate, based on the reviewer\"s understanding of TopoNet. However, the comment does not provide any specific references or detailed reasoning to support this claim, nor does it offer alternative perspectives or evidence. The suggestion to tone down the statement is somewhat vague, as it lacks specific guidance on how to rephrase it. Additionally, the comment mentions grammatical errors and suggests compressing the method section, but it does not provide detailed examples or explanations. Overall, the claim is 3, as it points out a potential issue but lacks sufficient evidence or guidance for the authors to address it effectively.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on multiple aspects of the paper. It identifies a potential inaccuracy in the statement about the neural network memorizing critical points, suggesting that the authors should tone down this claim. This is a clear and constructive suggestion that can help the authors improve the accuracy and clarity of their claims. Additionally, the comment advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, particularly with plurals and articles. This feedback is detailed and actionable, empowering the authors to make significant improvements to their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or what specific aspects of the paper need to be revised based on this knowledge. As a result, the comment lacks actionability and is not helpful for the authors in improving their draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not specify which part of the paper this information pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the paper should be addressed or improved based on this information. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. This is a descriptive statement that does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not offer any insights, suggestions, or guidance on how this information could be used to improve the paper. Without actionable feedback or a connection to the paper\"s content, the comment lacks utility for the authors. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce what the section is about, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests adding a first sentence to introduce what Section 3.2 is about. However, it does not provide any reasoning, evidence, or examples to support why this addition is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their paper. By providing a specific and direct recommendation, the comment offers a straightforward way for the authors to enhance the organization and structure of their work. However, the comment could be more helpful if it explained why this introduction is important or how it would benefit the reader. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide explicit guidance on what the authors should do to address this issue or how to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of the term, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this statement is problematic or unclear. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback highlights a potential inconsistency or confusion in the paper, which could be clarified to improve the clarity and coherence of the text. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative phrasing might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. The reviewer provides a clear and specific suggestion for how to rephrase the statement to improve clarity. This feedback is explicit and concrete, as it directly instructs the authors on how to revise their draft to better convey the concept of uncertainty. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper where the uncertainty is defined, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion for clarifying the definition of uncertainty by suggesting that the epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. This provides a clear direction for the authors to improve the clarity of their explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. The reviewer provides a logical explanation of how this process works, which is based on common knowledge in the field of uncertainty modeling. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further develop the explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This feedback is clear and constructive, as it offers a precise way to enhance the explanation of the concept of uncertainty. By following this suggestion, the authors can significantly improve the clarity and accessibility of their draft, making it more understandable to readers. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors experimented with using domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for clarification on the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide more information about their experimental setup, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about their experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are important or how they relate to the paper\"s content. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the usage of domain ontologies to avoid placeholder generation in the evaluated responses, which is a relevant and potentially valuable aspect to explore. It also seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy, which could provide valuable insights into the robustness and performance of the system. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for potential enhancement, it does not provide actionable feedback or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and provides concrete actions for the authors to take, including identifying and including relevant citations to enhance the context of their work. The explicit nature of the suggestion and the specific references make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for citations to set the paper in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly outlines what needs to be addressed by including relevant citations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. The reviewer provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This provides a clear and concrete basis for the claim, as it offers specific references that can help the authors understand the broader context of their work. Therefore, the claim is 5, as it is supported by explicit and relevant references.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper lacks citations to set it in the context of other MARL work, particularly selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and actionable, as it directs the authors to include relevant citations to enhance the context and relevance of their work. By addressing this point, the authors can significantly improve the comprehensiveness and impact of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. While the suggestion is clear, it lacks specific guidance on which methods to compare with or how to conduct the comparison. The authors are left to infer that they should explore other methods, but without detailed instructions on how to do so, the action remains vague. Therefore, the comment is 3, as it provides a direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be made. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with other methods, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or beneficial. Without such details, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. This is a valuable suggestion as it could help the authors broaden the scope of their work and demonstrate the applicability of their method in a wider context. However, the comment lacks specificity and does not provide guidance on which methods to compare with or how to conduct the comparison. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. While the comment implies that the authors should provide a clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the two processes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the abstention process differs from a decision threshold used by the models, and it suggests that the authors clarify this distinction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the abstention process, asking for clarification on how it differs from a decision threshold used by the models. This is a clear and actionable request for the authors to provide additional explanation or clarification in their draft. By addressing this question, the authors can improve the clarity and understanding of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the comparison with Megatron, suggesting that it is overrated and points out that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer also raises a question about the authors\" claim of parameter efficiency, suggesting that if this claim is valid, it could apply to these other works as well. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the comparison with Megatron and clarify their claims about parameter efficiency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with Megatron, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the overrating of the comparison and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also raises a question about the authors\" experimental setup, specifically the change in BPE vocabulary, and whether this change affects performance. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer provides a logical reasoning by comparing the performance of these models, which supports the claim that the comparison with Megatron is overrated. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the similarities in performance. Despite this, the claim is 4 due to the logical reasoning provided.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between COCOLM and Megatron, suggesting that the performance of these models is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This feedback is valuable as it challenges the authors to reconsider the significance of their comparison and potentially adjust their conclusions accordingly. Additionally, the comment raises a question about the authors\" experimental setup, specifically the change in BPE vocabulary, and whether this change affects performance. While the comment does not provide specific suggestions on how to address these issues, it does prompt the authors to consider these aspects of their work more closely. Overall, the feedback is 3 as it highlights areas for improvement and encourages the authors to reevaluate their claims."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis from lines 128 to 149 is not convincing and suggests that the GSP50 model has smaller class selectivity score, which means it shares more features with ResNet50. The reviewer also hypothesizes that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the analysis. The reference to external works, while helpful, does not offer detailed instructions on how to apply this information. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their analysis and potentially explore additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 128 to 149,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the analysis, noting that the GSP50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet50. The comment further hypothesizes that additional context may allow the network to reduce its dependency. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis from lines 128 to 149 is not convincing enough, based on the histogram in Figure 3, which shows that the GSP50 model has a smaller class selectivity score compared to ResNet50. The reviewer references external works [1] and [2] to support the claim that the GSP50 model shares more features with ResNet50, suggesting that additional context may allow the network to reduce its dependency. However, the comment does not provide detailed reasoning or examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment could be strengthened by explaining how the external works relate to the analysis in the paper. Therefore, the claim is 3, as it requires further elaboration to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from lines 128 to 149 is not convincing enough. It points out that the GSP50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet50. The reviewer hypothesizes that additional context may allow the network to reduce its dependency. While the comment provides a clear direction for improvement by suggesting that the authors should reconsider their analysis and potentially explore additional context, it lacks specific guidance on how to address this issue or what specific changes should be made. The reference to external works is helpful but does not fully substantiate the claim. Therefore, the comment is 3, as it identifies a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of convincing evidence in the paper\"s conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be due to limited exploration of combination methods and points to recent works that have shown the potential of feature replay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data and the potential for feature replay methods to improve performance. It also references specific works, such as [R1], [R2], and [R3], which provides clear guidance on what aspects of the paper are being addressed. The comment is specific in detailing the issue with the conclusions, suggesting that the results might be due to limited exploration of combination methods and pointing to recent works that have shown the potential of feature replay methods in continual learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works that have shown the potential of feature replay methods in continual learning, such as [R1], [R2], and [R3]. These references provide a basis for the claim, but the comment could be strengthened by further explaining why these works are relevant or how they support the critique. Overall, the claim is 4, as it is based on logical reasoning and references to relevant literature, but it could be more fully substantiated with additional details or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s conclusions, noting that some of them are not convincing. It provides a detailed critique by suggesting that the results might be due to limited exploration of combination methods, and it references recent works that have shown the potential of feature replay methods in continual learning. This feedback is clear and actionable, as it points out a specific area for improvement and suggests potential solutions. By suggesting the exploration of combination methods and referencing relevant literature, the comment provides the authors with a concrete direction for enhancing the credibility and robustness of their conclusions. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare their work with a chainofthought prompting approach, which is a specific and concrete suggestion for improvement. This feedback provides clear guidance on what the authors need to do to enhance their comparisons and make their work more robust. The explicit nature of the suggestion and the concrete example of a potential baseline make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of meaningful baselines and the suggestion to compare with a chainofthought prompting approach. This provides clear guidance on what the authors need to improve in their comparisons. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors should compare their work with a chainofthought prompting approach. While the comment identifies a potential issue with the baselines, it does not provide specific examples or detailed reasoning to support why the current baselines are insufficient. The suggestion to compare with a chainofthought prompting approach is a logical one, but the comment lacks the necessary evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the comparisons are limited to simple naive baselines despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare their work with a chainofthought prompting approach, which could provide a more meaningful baseline. This feedback is clear and actionable, as it points out a specific area for improvement and offers a concrete suggestion for enhancing the comparisons. By addressing this issue, the authors can significantly enhance the robustness and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the model is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its inquiry about the pretraining process and its generalizability. This aligns with a score of 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the pretraining process of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. This feedback is 3 as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and generalizability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present this information in the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to ensure that the observations and design decisions are not dependent on specific hardware or software. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine which sections or elements of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are dependent on hardware or software. Without clear guidance on what needs to be addressed or improved, the authors cannot effectively address the comment. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While it identifies a potential weakness, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the paper might be affected. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to investigate the accuracy of the ground truth and the noticeability/measurability of the difference, but the comment lacks specific guidance on how to conduct this investigation or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table. The authors can infer that it relates to the results or analysis sections, but this inference is not direct. The comment is specific in its inquiry about the accuracy and noticeability of the differences, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the accuracy and reliability of the results presented in the paper. It questions whether the small differences observed are actually noticeable or due to noise or randomness in the training process. Additionally, it points out a lack of difference between the results reported in the ablation study in Table. While the comment identifies potential issues, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider the accuracy and reliability of their results, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of important experimental details in the main text and the lack of explanations or interpretations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8 as examples of missing information. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text and Appendix, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of explanations or interpretations for the PCA experiments in these figures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. The reviewer provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that highlight the importance of including explanations and interpretations in the main text. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it highlights specific areas where the authors need to improve the clarity and completeness of their experimental details. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending a specific structure or approach for presenting the experimental details in the main text. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of new evaluation metrics and the limited exploration of existing metrics in the experimental analysis section. It explicitly states that there needs to be an indepth exploration of the reasons for the experimental results. This provides a clear and concrete action for the authors to take, as they are directed to conduct a more thorough analysis of the experimental results. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of new evaluation metrics and the limited exploration of existing metrics. The comment provides guidance on what needs to be explored indepth, such as the reasons for the experimental results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are combined linearly. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. However, the comment does not provide specific examples or references to support the claim that existing metrics are combined linearly or that there is a lack of new metrics. Without detailed evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of new evaluation metrics and the limited exploration of existing metrics. It highlights the need for an indepth exploration of the reasons behind the experimental results. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive analysis of their experimental findings. However, the comment could be more helpful if it offered specific suggestions on how to conduct this exploration or what aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, it does not provide explicit guidance on how to resolve this issue or suggest alternative notations. The action is implicit and vague, as the authors are left to infer that they need to clarify or change the notation to avoid confusion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L166\" and \"L176,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"K,\" which is being used for both a known kernel function and the number of layers, causing confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" noting that it is being used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176), which can cause confusion. This feedback is clear and actionable, as it points out a potential source of confusion in the paper and suggests a way to clarify the notation. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a different notation or explaining the context in which \"K\" is used. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern about the practical impact or suggestions for improving the paper to better demonstrate its relevance. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the theoretical interest and the potential practical impact, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the weak recovery problem studied is primarily of theoretical interest and questioning the practical impact of the AMP algorithm for nonGaussian problems. This feedback highlights a potential limitation in the paper\"s relevance and applicability, which could impact its impact on the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or demonstrate the practical relevance of their work. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection to human cognition, questioning the relevance of the authors\" suggestion that cognitively basic adaptation mechanisms might have a significant impact on selforganization. It suggests that the authors should provide more evidence or references to support their claim. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on how to present this evidence or what kind of references would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should provide more evidence or references to support their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the connection to human cognition and questions the relevance of the authors\" suggestion that cognitively basic adaptation mechanisms might have a significant impact on selforganization. It references the authors\" statement about the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation, which are typically associated with human cognition. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the authors\" suggestion and the need for more evidence or references to support it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of the authors\" suggestion that cognitively basic adaptation mechanisms might have a significant impact on selforganization, given the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation. The reviewer suggests that it would be surprising for a behavioral economist to ignore these factors and implies that more evidence or references are needed to support the claim. However, the comment lacks specific examples or references to substantiate the claim, making it 3. The authors would need to provide additional evidence or reasoning to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the relevance of the authors\" suggestion that cognitively basic adaptation mechanisms might have a significant impact on selforganization, given the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation that humans use. It questions the authors\" claim and suggests that more evidence or references are needed to support it. While the comment identifies a potential weakness in the argument, it does not provide specific guidance or suggestions on how the authors might address this issue or what kind of evidence would be appropriate. The feedback is 3 as it points out a potential gap in the argument, but it could be more beneficial with additional guidance on how to strengthen the paper. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, it does not provide specific guidance on how to tone down the language or suggest alternative phrasing. The comment lacks explicit instructions or concrete examples of what constitutes overly exaggerated or flamboyant language, making it difficult for the authors to know exactly how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, describing it as overly exaggerated and flamboyant. This provides clear guidance on what needs to be addressed in the conclusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or references to overly exaggerated or flamboyant language, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant in multiple places. This feedback is 3 as it points out a potential problem with the language used in the paper, which could be revised to be more appropriate and professional. However, the comment lacks specific examples or suggestions on how to tone down the language or what alternative phrasing might be more appropriate. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR. This provides full grounding as it clearly identifies the part of the paper that needs attention, allowing the authors to accurately pinpoint the section that requires revision. The comment is also specific because it specifies the aspects to be compared, such as the number of learnable parameters and GFLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR. This claim is 3 as it logically suggests that such an experiment would provide valuable insights into the performance of the proposed method. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as how these comparisons would impact the paper\"s conclusions or contributions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including these comparisons. By doing so, the authors can demonstrate the effectiveness of their method in a more comprehensive and rigorous manner. However, the comment could be more helpful if it included suggestions on how to design and conduct these experiments, such as which metrics to use or how to interpret the results. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to compare against or detailing the expected utility measure. The comment lacks concrete steps for the authors to take, leaving them uncertain about how to improve their draft. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for comparison to baselines. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility or some other measure, which is a significant weakness. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure to prove the effectiveness of the proposed approach. This is a critical oversight that could impact the credibility and impact of the paper. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting which baselines to compare against or how to implement the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it does not provide explicit instructions or concrete actions for the authors to take. The comment mentions that Figure 5a seems strange and asks for more explanations, but it does not specify what aspects of the figure are problematic or how to address them. Similarly, it mentions the handling of DVS input when the input is in AER format but does not offer guidance on how to improve this aspect. The comment also suggests analyzing energy consumption as in reference [15], but it does not provide specific steps or examples on how to implement this analysis. Overall, the comment lacks explicit instructions and is vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a\" and \"11,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with \"Fig. 5a\" and suggests providing more explanations, as well as addressing the handling of DVS input when the input is in AER format. Additionally, it suggests analyzing energy consumption as in reference [15] to make the paper more solid. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of several questions and suggestions for improvement, rather than making subjective claims or opinions. It does not contain any claims or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several pieces of feedback that can help the authors improve their draft. It points out that Figure 5a seems strange and suggests that more explanations are needed. It also questions how the authors handled DVS input when the input is in AER format, which could be a critical aspect to address. Additionally, the comment suggests analyzing energy consumption as in reference [15] to make the paper more solid. While the comment identifies areas for improvement, it lacks specific guidance or examples on how to address these issues. The authors are given direction but may need to infer the exact steps to take. Therefore, the comment is 3, as it provides a starting point for the authors to enhance their draft but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifically mentions the use of separate embeddings and positional encoding, but it does not provide explicit guidance on how the embeddings are combined or how they are fed into the CSCM. The comment implies that the authors should provide more detailed explanations or clarifications, but it does not specify exactly what needs to be clarified or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text\" and \"CSCM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, how historical observations are combined with inputs known over all time given differences in sequence lengths. The comment provides a clear direction for the authors to address the issue by asking for clarifications on how the embeddings are combined and fed into the CSCM. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It mentions the use of separate embeddings and positional encoding, but it does not provide any supporting evidence, reasoning, or references to justify the claim that clarifications are needed. The comment lacks specific examples or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embeddings and positional encoding but lacks clarity on how these are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or clarifications in these areas. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects should be clarified. Overall, the comment is 4 as it effectively guides the authors toward improving the clarity and comprehensibility of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not provide any explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how to improve the innovation or how to differentiate the approach from existing methods. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what is considered a common approach and what is lacking in the paper\"s contribution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks, and that merely migrating this approach to the field of MLMs is not innovative. The reviewer supports this claim by referencing the article itself, which implies that the authors should have known this. However, the comment lacks specific examples or references to support the claim that merely migrating this approach is not innovative. This makes the claim 3, as it provides some evidence but could be strengthened with more detailed examples or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might address this issue or differentiate their approach from existing methods. The feedback is 3 as it highlights a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to address the concerns raised. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the transfer performance of the model. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the concerns about the model\"s generalization and suggesting additional experiments, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment is 3 as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments to validate the claim, making the comment 3. Therefore, the score is 3.", "helpfulness_rationale": "The review comment raises important concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these additional experiments or what specific downstream tasks should be considered. The feedback is 3 as it points out a potential issue but does not provide detailed guidance on how to resolve it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to provide more discussion on the power of different architectures but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the architectures should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that fast SMP is less expressive than SMP. Without such evidence or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the architectures should be discussed. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. This feedback provides a clear and explicit action for the authors to take, which is to consider using different splits of the training, validation, and testing datasets to test the robustness of their methods. The comment is specific in detailing what needs to be done to improve the robustness of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the evaluation or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would be more robust than simply using different initialisation seeds. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be more robust. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the robustness of their results. By suggesting a more comprehensive evaluation approach, the comment offers a concrete way to enhance the quality and reliability of the paper. However, it could be more helpful if it provided additional guidance on how to implement this change or what specific metrics to use for the evaluation. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear path for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction should be combined together. This is an explicit action that the authors can directly implement to simplify the introduction. The comment provides a clear and concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests combining the first two bullets about contributions at the end of the introduction. However, it does not specify which part of the introduction these bullets are located in, making it weakly grounded. The comment is specific in suggesting a potential simplification of the introduction by combining these two bullets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any supporting evidence, reasoning, or examples to justify why this combination would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction could be combined together. This is a specific and actionable suggestion that could simplify the introduction and improve the clarity of the paper\"s contributions. However, the comment does not provide further explanation or guidance on why this combination is beneficial or how it might impact the overall structure or content of the paper. While it identifies a potential improvement, the lack of detailed justification or examples limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or what specific changes should be made to improve the clarity. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of unclear definitions, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the paper, noting that the types of situations and social norms, such as physical and psychological safety, are not clearly defined. This feedback is 3 as it points out a potential area for improvement, but it lacks depth and does not provide specific suggestions on how to clarify these concepts or what aspects of the paper need further explanation. While it highlights an important issue, the comment could be more helpful with additional guidance or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. However, it points out the need to demonstrate the algorithm\"s improvement over existing solutions by addressing robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment implies that the authors should provide more evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence to substantiate their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s focus on a specific problem and its potential benefits to the neuroscience community. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The comment suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where the algorithm\"s performance is discussed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment identifies a critical area for improvement, it lacks specific examples or references to support the claim about the algorithm\"s improvement over existing solutions. This makes the claim 3, as the authors would need to make a concerted effort to address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem in the neuroscience community. It identifies a critical area for improvement, namely the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on how to address the issue of demonstrating improvement. This limits the comment\"s helpfulness, as it points out a critical area for improvement but does not fully guide the authors on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more baselines should be compared and more domains should be tested. It also mentions that the choices of weighting and learning density functions are not strongly motivated, and that stronger empirical results are needed. However, the comment does not provide specific guidance on which baselines to compare or how to test the additional domains. The authors are left to infer that they need to expand their experimental setup, but without concrete suggestions on which baselines or domains to include, the action remains vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that more baselines should be compared and more domains should be tested, and it mentions the choices of weighting and learning density functions as areas for improvement. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments where these improvements could be made. Additionally, it lacks specific guidance on which baselines or domains should be included. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that more baselines should be compared and more domains should be tested, and it critiques the choices of weighting and learning density functions as not being strongly motivated. However, the comment lacks specific examples or references to support the claim that these choices are not wellmotivated. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the limited comparison of baselines and the lack of testing in multiple domains. It suggests that the choices of weighting and learning density functions are not strongly motivated and that stronger empirical results are needed. While the comment highlights areas for improvement, it does not provide specific guidance on which baselines or domains should be included or how to address the motivation issue. This limits the comment\"s helpfulness, as it points out a need for improvement but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete request, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB\" and \"fig. 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification about the dashed lines in figures 2AB and 4B. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it directly addresses a specific issue by requesting clarification on the definition of the dashed lines in figures 2AB and 4B. This feedback is clear and actionable, as it guides the authors to provide a necessary explanation for their figures, which could enhance the clarity and understanding of their work. By addressing this point, the authors can improve the readability and comprehensibility of their figures, making the paper more accessible to readers. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the comparability of the results or what specific aspects need to be improved. As a result, the authors are left without any clear direction on how to enhance the significance of their work. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, which suggests that the significance of the proposed methods is questionable. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods may be questionable. However, it does not provide any specific examples or guidance on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment implies that the authors should provide more insights into these challenges, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of overcorrelation, but the comment does not provide specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DeCorr [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems, despite being a straightforward application of existing literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer supports this claim by mentioning that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also acknowledges that modifications like different penalty coefficients for users and items are proposed. While the claim is 3 due to the mention of DeCorr and the transposition of insights, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to understand and address the critique, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically DeCorr. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment provides some insight into the paper\"s limitations, it does not offer specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their work. The feedback is 3 as it identifies a critical area for improvement, but it lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the clarity of the symbols or the explanation of the process. The authors are left to infer that they need to clarify the symbols and provide more information on the process, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed in the figure and the process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support the claim of ambiguity or the need for clarification. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This feedback is 3 as it points out a potential area for improvement in the clarity and comprehensibility of the figure. However, it lacks depth and does not provide specific suggestions or guidance on how to address the ambiguity or improve the explanation of the symbols. While it highlights an issue, the comment could be more helpful with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, noting that this assumption excludes popular classes of kernels like Matern kernels. The reviewer suggests that the results could be restrictive due to this assumption. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to broaden the scope of the results. The action is implicit and somewhat vague, as the authors need to infer that they should consider including other classes of kernels in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption regarding the spectrum of a kernel being subgaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the assumption excludes popular classes of kernels like Matern kernels, which could limit the scope of the results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the assumption of the spectrum of a kernel being subgaussian is a limitation, as it excludes popular classes of kernels like Matern kernels. The reviewer supports this claim by noting that Matern kernels have polynomially decaying spectra, which could restrict the applicability of the results. However, the comment lacks specific examples or references to Matern kernels or other classes of kernels to fully substantiate the claim. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, which excludes popular classes of kernels like Matern kernels. This is a relevant point as it highlights a potential restriction in the applicability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or broaden the scope of their analysis to include other classes of kernels. While it points out a potential issue, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain. While the comment explicitly states the need for more discussion on the unsupervised pretraining, it does not provide specific guidance on how to integrate this discussion into the main paper. The authors are left to infer that they should add more details about the pretraining method, but the comment lacks concrete steps or examples on how to do so. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"unsupervised pretraining,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on the unsupervised pretraining in the main paper, despite its importance in performance gain. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, based on data from Table 4. However, it does not provide specific evidence or detailed reasoning to support this claim, such as data analysis or comparisons with other methods. The comment suggests that the unsupervised pretraining should be discussed more in the main paper, but it lacks the necessary justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed evidence or reasoning to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the unsupervised pretraining is a key factor in performance gain but is not discussed in detail in the main paper. It suggests that the authors should focus more on the pretraining method, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific guidance on how to integrate this discussion into the main paper or offered examples of how other papers have effectively discussed similar topics. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they might need to consider this aspect in their methodology or experimental design, but the comment lacks concrete steps or detailed advice on how to implement this change. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors might have an idea of where this discussion might occur, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its critique of the methodology, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment lacks specific examples or references to support the claim that this is a drawback or how it affects the methodology. The reasoning is somewhat logical, but without detailed evidence or examples, the claim is 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is 3 as it highlights a potential issue with the methodology that the authors may not have considered. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to incorporate gender detection models into the pipeline. Overall, the comment identifies a relevant concern but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the writing is difficult to follow in many places and suggests simplifying it. However, it does not provide specific examples or guidance on how to achieve this simplification. The authors are left to infer that they need to make their writing more accessible, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is 3, as it identifies an issue but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and suggests simplifying it. However, it does not specify which parts of the paper are particularly challenging or where the simplification is needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests simplifying it. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or examples, the authors may find it challenging to understand where the writing is difficult to follow and how to simplify it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a significant issue with the writing, noting that it is difficult to follow in many places and suggests simplifying it. While it highlights a clear area for improvement, the comment lacks specificity and does not provide guidance on how to achieve this simplification. Without detailed suggestions or examples, the authors are left with a general direction but without actionable steps to improve their draft. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the paper is incremental and lacks technical substance, suggesting that it only adds a new loss to an existing work. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical substance or what specific aspects of the paper need to be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to an existing work. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or lacking in technical substance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, suggesting that it only adds a new loss to an existing work. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to an existing work. However, it does not provide any specific examples or detailed feedback on what aspects of the paper are considered incremental or lacking in technical substance. Without actionable suggestions or guidance on how to improve the paper, the authors are left without a clear path forward. The comment identifies a potential issue but lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. While the comment implies that the authors should provide more detailed explanations or examples, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more information or examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"the invertible function $f^*$,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the proof of Theorem 1 and the dependence of $f^*$ on the fixed $P^*$. The comment suggests providing intuition for the proof and inquires about the impact of different distributions on determining $f^*$. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. The comment does not contain subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. These questions are relevant and could guide the authors in improving the clarity and depth of their explanation. However, the comment does not provide specific suggestions or examples on how to address these issues, which limits its helpfulness. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending a specific notation change or explaining why the current notation is problematic. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of notation, expecting them to be analogous but noting a discrepancy. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, the comment does not provide any reasoning or explanation for why the notation should be the same or why the current notation is problematic. Without additional context or justification, the claim is not verifiable, as it lacks the necessary support to be understood or addressed by the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. This feedback highlights a potential issue in the clarity and consistency of the notation used in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their notation. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to demonstrate the applicability of their model to realworld diffusion processes. While the comment implies that the authors should conduct experiments or provide examples to support their claims, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide empirical evidence but may not be entirely sure of the specifics of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the applicability of the model to realworld diffusion processes is a concern, and it provides a logical reasoning by stating that the authors should provide empirical evidence to demonstrate its effectiveness. However, the comment lacks specific examples or references to support the claim that the model captures diffusion phenomena in realworld scenarios. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the model to realworld diffusion processes. It acknowledges the elegance of the proposed solutions but suggests that empirical evidence is needed to demonstrate the model\"s effectiveness in realworld scenarios. This feedback is clear and actionable, as it provides a specific direction for the authors to address the applicability issue by providing empirical evidence. However, the comment could be more helpful if it offered suggestions on how to conduct such experiments or what specific aspects of the diffusion process should be examined. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is implicit, it is clear that the authors need to expand their testing to include more datasets. The comment provides a specific suggestion for improvement, which is to test on additional datasets. However, it does not offer detailed guidance on which datasets to use or how to conduct the additional testing. Therefore, the action is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the testing and evaluation of the method, but this inference is not direct. The comment is specific in suggesting the need for additional testing, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any supporting evidence, reasoning, or references to justify why testing on more datasets would be beneficial or necessary. The claim is based on a logical assumption, but without additional context or examples, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. This is a reasonable suggestion that could improve the robustness and generalizability of the results. However, the comment lacks specificity and does not provide guidance on which datasets to use or how to conduct the additional testing. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, and that alternatives already exist, as noted in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes could be made to improve the novelty or contribution of the work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the main contribution, which is the combination of attention with other linear mechanisms. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the contribution are not novel or how the alternatives are addressed in the paper. Without clear guidance on where to focus improvements, the authors may struggle to effectively address the critique. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, the comment does not provide specific examples or references to these alternatives, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. This is a valid observation that could prompt the authors to reconsider the originality of their work. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their contribution. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and concrete action that the authors can take to improve their draft. The comment provides a specific suggestion for visualizing the results, which is a direct and actionable point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the method being applied on each layer, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the plot of relative weight change after unlearning to see which layers are affected the most. This provides clear guidance on what the authors should include in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a plot of how different weights of the model move after unlearning to see which layers are affected the most. This is a request for additional analysis and visualization, which is a logical suggestion for improving the paper. However, the comment does not provide specific examples or references to similar studies that have already demonstrated the importance of such an analysis. While the suggestion is logical, the lack of detailed justification or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors plot the relative weight change after unlearning to see which layers are affected the most. This is a clear and concrete suggestion that can help the authors better understand and communicate the impact of their method. By addressing this feedback, the authors can enhance the clarity and comprehensiveness of their results, which is highly beneficial for improving the draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide more novelty or depth in their methodology section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"methodology aspect\" and \"ENCODE part,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The reviewer further suggests that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific references or detailed reasoning to support the claim that the ENCODE part is already proposed. The suggestion about the decomposition part is somewhat vague, as it does not provide a clear explanation of what the authors should do to address this issue. Therefore, the claim is 3, as it requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which involves factoring M_v into factor D and slicing Phi_v. While the comment highlights a potential weakness in the paper\"s novelty, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice or detailed insights to fully support the authors in improving their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. While the comment identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the domain of the inputs, but it is vague because it lacks specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the inputs are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed regarding the domain of the inputs. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\"s validity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the domain of the inputs. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare the performance of their proposed CLN (region proposal generation algorithm) with that of another work. While the comment implies that the authors should conduct a performance comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not specify which part of the paper discusses the CLN or where the performance comparison should be included. The authors cannot confidently determine which section or part of the paper is being addressed, making this comment 1. Additionally, the comment lacks specificity regarding what aspects of the performance comparison should be considered or how it should be conducted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work, which could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks specificity and does not offer guidance on how to conduct this comparison or what aspects to focus on. Without detailed instructions or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also recommends the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment provides a clear action\u2014adding an illustrative figure\u2014it does not specify which concepts should be illustrated or how the figure should be designed. The authors are given a clear direction to add an illustrative figure but are left to determine the specifics of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation, specifically mentioning that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also suggests the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the presentation and notation in chapter 3. The suggestion to include an illustrative figure is specific, providing a clear action for the authors to take. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. While the comment identifies specific issues with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for an illustrative figure is a logical point, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation by adding an illustrative figure. However, the comment could be more helpful if it offered specific guidance on what elements should be illustrated or how the figure should be designed to enhance comprehension. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and the independence of x and y given W. The reviewer suggests that taking Z\u00e2\u0080\u0099 to be the empty set would lead to a contradiction with Eq. (7), which states otherwise. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to resolve the conflict. While the action is implied, it is not detailed enough for the authors to know exactly how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, particularly regarding the definition of Z\u00e2\u0080\u0099 and its implications for the independence of x and y given W. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and its implications for the independence of x and y given W. The reviewer provides a logical reasoning by taking Z\u00e2\u0080\u0099 to be the empty set and demonstrating the contradiction. This logical reasoning and the specific reference to the definition of Z\u00e2\u0080\u0099 and Eq. (7) make the claim 4, as it provides a clear explanation of the issue and its implications. However, the comment could be strengthened by providing more detailed examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and its implications for the independence of x and y given W. By pointing out this contradiction, the reviewer highlights an area where the paper may be inconsistent or incorrect. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or resolve the conflict. While it alerts the authors to a potential problem, it lacks actionable advice or detailed feedback to fully assist in improving the draft. Therefore, the comment is 3, as it identifies a weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out that the visual presentation, specifically the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide explicit guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the subscripts, but without specific suggestions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual presentation of the subscripts, for better readability and aesthetic appeal. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the comprehensive nature of the data presented in Figure 3 but suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide specific examples or detailed reasoning to support why the subscripts are problematic or how they could be improved. Without such examples or references, the claim is not 5, as it lacks the necessary evidence or justification to substantiate the suggestion. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out a specific area for improvement. It suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. While the comment identifies a clear area for improvement, it lacks detailed guidance or suggestions on how to achieve this enhancement. The authors are left to infer that they should make changes to the subscripts, but without specific guidance, the feedback is 3. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify their explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the problem of gradient bias in Batch Normalization and the potential of Online Normalization. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the difference between Online Normalization and Batch Normalization, asking why Online Normalization is unbiased while Batch Normalization is biased. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that Online Normalization is unbiased and Batch Normalization is biased, suggesting that the authors have not adequately explained this difference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. This is a relevant point that could help the authors clarify their explanation or provide additional context to readers. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in cramped equations and captions too close to the figures. This is seen as a violation of the 9page paper limit. The comment provides a clear and direct action for the authors to take, which is to address the issue by adjusting the spacing and layout of the paper to comply with the page limit. The action is concrete, as it specifies the problem and provides a clear solution, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of whitespace throughout the paper, specifically mentioning the cramped equations and captions too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9page paper limit due to the reduced whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper violates the 9page limit due to the reduced whitespace, specifically mentioning cramped equations and captions too close to the figures. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s acceptability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the layout and spacing of the paper, noting that equations are cramped together and captions are too close to the figures. This is seen as a violation of the 9page paper limit. While the comment highlights a clear problem, it does not provide actionable suggestions or guidance on how the authors might address this issue, such as recommending adjustments to the spacing or layout. Without such specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical details or formulations, nor are there suggestions for how to better highlight the novelty of the scheme or procedure. As a result, the authors are left without any clear direction on how to enhance their draft based on this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are lacking or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any specific guidance or suggestions on how the authors might improve the technical details or formulations to better highlight the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path for enhancing their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the concept of local interactions, asking whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area for clarification, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the concept of local interactions in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its questioning of the concept, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the concept of local interactions, specifically asking whether it refers to interactions within a time window or within the same modality. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the confusion. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is 3 as it identifies a potential area for improvement in the paper, namely the need to clarify the concept of local interactions. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending a specific definition or example to clarify the concept. While it points out a potential weakness, the lack of actionable advice limits its usefulness for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper claims better results in the Molecule generation experiment but notes that adding the proposed constrained method actually yields lower validity and diversity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims regarding the Molecule generation experiment. It points out that the addition of the proposed constrained method actually yields lower validity and diversity, which is a critical observation that could impact the paper\"s conclusions. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or what changes could be made to improve the results. Without actionable advice or suggestions, the authors are left with a general observation that does not fully support their draft. Therefore, the comment is 3, as it highlights a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the archetype positions are updated after initialisation in Algorithm 2. It explicitly asks the authors to clarify this aspect, providing a clear action for the authors to take. The comment is specific in its request for clarification, making it 5. The authors know exactly what needs to be addressed and how to implement the action, as they are prompted to provide a comment on this aspect. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"the query Q consists of the archetypes z_1, \u00e2\u0080\u00a6, z_k,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on how the archetype positions are updated after initialisation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of how the archetype positions are updated after initialisation in Algorithm 2. It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the initialisation and updating of archetype positions in Algorithm 2. It asks the authors to clarify this aspect, which is important for understanding the methodology. This feedback is clear and actionable, as it prompts the authors to provide additional explanation or clarification in their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These are all clear and concrete actions that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details what information is missing, such as recording parameters, preprocessing steps, and the condition under which the restingstate was recorded. Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point makes several claims about the missing information in the empirical study, such as recording parameters, preprocessing steps, and the condition under which the restingstate was recorded. It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These claims are 3 as they are based on logical reasoning and common knowledge about empirical studies. However, the comment could be strengthened by providing specific references or examples to support the claims or by offering more detailed explanations of the missing information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the transparency and completeness of their empirical study. By addressing these points, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can differ across datasets. It suggests that the paper lacks crossdataset experiments, which would be a good way to test the generalization of the work. While the comment implies that the authors should conduct crossdataset experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for crossdataset experiments and determine how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of crossdataset experiments, which is a critical aspect of testing the generalization of the work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods that exploit relationships between action units can suffer from differences in cooccurrences across datasets, as seen in Figure 1. The reviewer suggests that crossdataset experiments are necessary to test the generalization of such work. While the comment provides a logical reasoning for the need to test generalization, it lacks specific examples or references to datasets or studies that demonstrate these differences. This makes the claim 3, as the authors would need to infer the significance of the issue and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a specific example of this issue by pointing out the cooccurrence of AU1 and AU12 in Figure 1, which illustrates the difference in correlation across datasets. The comment suggests that crossdataset experiments are necessary to test the generalization of the work. While it provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to conduct crossdataset experiments or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so or provide specific guidance on what details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about the environment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what aspects of the environment should be described. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not provide any reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without such justification, the claim is 1, as it lacks the necessary evidence or explanation to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the environment should be described or how this additional information would enhance the paper. The feedback is 3 as it points out a potential gap in the paper, but it does not offer actionable steps for the authors to address this issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should reconsider their statement about overparameterization, which is currently perceived as a negative aspect. The reviewer provides a rationale by pointing out that overparameterization can be beneficial for supervised learning of deep neural networks in practice, and references a theoretical work that supports this claim. However, the comment does not explicitly instruct the authors to change their stance or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their position. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the authors\" assertion about overparameterization and provides a rationale by pointing out its benefits in practice and referencing theoretical work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point challenges the authors\" assertion about overparameterization, suggesting that it can be beneficial for supervised learning of deep neural networks in practice. The reviewer provides a rationale by referencing a theoretical work that supports this claim, which adds credibility to the argument. However, the comment lacks specific examples or detailed explanations from the referenced work, making it 3. The authors would need to further explore the theoretical work to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment challenges the authors\" assertion about overparameterization, suggesting that it can be beneficial for supervised learning of deep neural networks in practice. The reviewer provides a rationale by referencing a theoretical work that supports this claim, which adds credibility to the argument. However, the comment could be more helpful if it provided specific examples or detailed explanations from the referenced work to further substantiate the claim. While it offers a valuable perspective, the lack of detailed guidance limits its utility for the authors. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects of the training and testing process should be described. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed description and comparison with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of training the shape model and the complexity of the parsing model, suggesting that the processing efficiency of training and testing should be described and compared with existing work. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the training and testing process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its training in pixel level (though sparsity by landmark) and the model being trained independently on all font images and characters. Additionally, it suggests that the parsing model is a highorder factor graph with four types of factors, which affects processing efficiency. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. However, the comment lacks specific examples or references to existing work that could substantiate the claim about the efficiency of the models. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or references to fully support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what aspects of the training and testing process should be described and compared. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional details or suggestions on how to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. While the comment implies that the authors should explore other domain adaptation methods, it does not provide specific guidance on which methods to use or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore other domain adaptation methods to enhance their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. However, the comment does not specify which parts of the paper these critiques pertain to, such as sections, figures, or specific techniques. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the use of more recent domain adaptation methods, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors combine two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. The reviewer suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. The comment provides a logical reasoning by pointing out the age of the domain adaptation method and the existence of more recent methods. However, it lacks specific examples or references to recent domain adaptation methods that could be considered, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on which domain adaptation methods to consider or how to implement them. The feedback is 3 as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on what to discuss. The comment is specific and leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the discussion. The comment is specific in suggesting what needs to be addressed, but without explicit grounding, it is difficult for the authors to pinpoint the exact part of the paper that requires revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. This feedback is 3 as it identifies a specific area that could enhance the paper by providing more context and detail about the dataset creation process. However, the comment lacks depth and does not offer suggestions on how to structure or present this discussion, nor does it provide examples of what could be included. While it points out a potential gap in the paper, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from incremental engineering papers. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is problematic or where the motivation is unclear. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation or the paper are unclear or how they could be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or originality of their work. Without actionable feedback or detailed insights into what aspects of the paper are unclear or lacking, the authors are left without a clear path for improvement. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be beneficial to see how it affects the performance of the method in a scenario where the game has repetitive background sounds. The reviewer provides a clear rationale for why this ablation is important, noting that the weighting might have helped remedy the underperformance in such scenarios. However, the comment does not explicitly instruct the authors to conduct this ablation or provide detailed guidance on how to implement it. While the action is implicit, it is concrete because it specifies the type of analysis that should be conducted. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning the scenario where the game has repetitive background sounds. This provides a clear reference to the section where the authors discuss the performance of their method in such scenarios. However, the comment does not explicitly mention which part of the paper this ablation should be added to, making it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, namely the weighting method of the crossentropy loss. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation on the weighting method of the crossentropy loss, specifically mentioning that it might help remedy the underperformance of the method in a scenario with repetitive background sounds. This claim is 3 as it is based on a logical reasoning that the weighting might improve performance in such scenarios. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it might help remedy the underperformance of the method in a scenario with repetitive background sounds. This is a clear and actionable suggestion that could improve the paper by providing additional insights into the performance of the method in different contexts. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation or what specific aspects of the weighting method should be explored. Overall, the comment is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to demonstrate novelty and incremental improvements, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of the lack of novelty and incremental nature of the work, as well as the problem of column operations in designing semantic parsers for TexttoSQL. It also mentions the design of a new dataset, which is a different train/test split of an existing dataset, SQUALL. Additionally, it points out a synthetic benchmark paper based on a single question template. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be improved, such as demonstrating novelty and incremental improvements, and providing suggestions for addressing the issue of column operations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically addressing a problem of column operations in designing semantic parsers for TexttoSQL. The reviewer provides some justification by mentioning that the proposed dataset is a different train/test split of an existing dataset, SQUALL, and that the synthetic benchmark paper is based on a single question template. However, the comment could be strengthened by providing more detailed examples or references to support the claim of lack of novelty. As it stands, the comment is 3, as it provides some evidence but lacks comprehensive justification. Therefore, the score is 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template, which further highlights the lack of novelty. This feedback is clear and actionable, as it directs the authors to address the issue of novelty and incremental nature in their work. However, the comment could be more helpful if it provided suggestions on how to demonstrate novelty or incremental improvements, such as by suggesting alternative approaches or datasets. Overall, the comment is 4 as it effectively identifies a critical weakness and offers direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the experiments are limited to one game environment and suggests that more experiments are necessary. This provides a clear and direct action for the authors to take, which is to expand their experimental scope to include additional game environments. The comment is specific in its request for additional experiments, making it 5.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to conduct more experiments, but without clear references to specific sections or experiments, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are conducted on only one game environment. It suggests that more experiments are necessary to provide a broader perspective. While this feedback highlights an area for improvement, it lacks specific guidance on which additional environments should be considered or how to conduct these experiments. The comment is 3 as it points out a potential weakness but does not offer detailed suggestions for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This is a clear and direct action for the authors to take, as it specifies the need for a detailed explanation with examples. The comment provides a concrete direction for improvement, ensuring that the authors know exactly what needs to be done to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a detailed explanation with examples. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are important or how removing them would contribute to the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more detail and explanation. It points out that the removal of certain assumptions like bounded variance and bounded gradients is an important contribution, but it does not provide examples or further explanation of why these assumptions are important. This feedback is 3 as it highlights a gap in the paper that the authors need to address, but it lacks depth and specificity. The comment could be more helpful if it offered suggestions on how to present the examples or examples themselves, which would guide the authors in making the necessary improvements. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific information about the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This explicit comparison and concrete data provide the authors with a clear action to take: they need to address the issue of slow speed and low accuracy by improving their implementation. The comment is explicit and provides concrete details on how to apply the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the implementation of ImageNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of slow speed and low accuracy, providing specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, citing specific examples of time and accuracy. However, the comment does not provide any supporting evidence or references to substantiate these claims. Without additional context or detailed analysis, the authors may find it challenging to understand the basis of these claims and address them effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This feedback is clear and actionable, as it highlights a critical issue that the authors need to address to improve the credibility and effectiveness of their work. By addressing these points, the authors can enhance the robustness and reliability of their implementation. However, the comment could be more helpful if it offered suggestions on how to improve the speed and accuracy, such as potential optimizations or alternative approaches. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning, and it explicitly asks for an explanation of the correspondence between the learning curves and MPHATE in Figure 3. The reviewer also questions the rationale behind the learning curves and the accuracy numbers, providing specific questions that the authors should address. These actions are clear and detailed, giving the authors a clear path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the need for an explanation of the experimental setting for continual learning, the correspondence between the learning curves and MPHATE, and the accuracy numbers. The comment provides detailed questions that guide the authors on what aspects of the paper need clarification or expansion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add a few more sentences to explain the experimental setting for continual learning. It also requests an explanation of the correspondence between the learning curves and MPHATE in Figure 3, questioning the rationale behind the learning curves and the accuracy numbers. This feedback is clear and constructive, as it guides the authors on how to enhance the clarity and understanding of their experimental setup. By addressing these points, the authors can improve the comprehensibility and rigor of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer any explicit guidance or actionable steps for the authors to take. The comment lacks specific instructions or suggestions on how to incorporate this idea into their work. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that labeled data might provide effective information for consistency training and provides examples of relevant works, such as \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation.\" Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. The reviewer supports this suggestion by referencing two external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which demonstrate the effectiveness of using labeled data for this purpose. However, the comment lacks detailed reasoning or specific examples from the works to fully substantiate the claim. While the references provide some support, the comment could be strengthened by further elaboration on why labeled data might be beneficial and how it could be integrated into the current work. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer specific guidance or actionable steps for the authors to explore this idea further. The comment references two external works, which could be useful for the authors to consider, but the lack of detailed suggestions or examples limits its helpfulness. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific suggestions for how to do so. It suggests that the experimental content listed in the main text should highlight the superiority of the method, and it provides a list of experimental suggestions that should be included in the main text. These suggestions are concrete and provide clear guidance on what changes the authors should make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental part\" and the \"experimental section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the reorganization and highlighting of the experimental content to showcase the superiority of the method. The suggestions for reorganization and the inclusion of specific experimental content are detailed, providing clear guidance for the authors to make improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part needs to be reorganized and improved, suggesting that the experimental content listed in the main text does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to specific sections of the paper where the issue is apparent, making it difficult for the authors to understand and address the critique. As a result, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental part of the paper, noting that the experimental content listed in the main text does not effectively highlight the superiority of the method. It provides a clear and actionable suggestion to reorganize the experimental section and includes specific experimental suggestions that should be included in the main text. This feedback is valuable as it guides the authors on how to improve the presentation and clarity of their experimental results, which is crucial for the paper\"s credibility and impact. However, the comment could be more helpful if it included examples of how the experimental content should be reorganized or if it provided more detailed guidance on the specific experimental suggestions. Overall, the comment is 4 as it offers clear and actionable feedback, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. It also requests theoretical justifications, if possible. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should report the classification accuracy and provide theoretical justifications. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed classification network, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. Additionally, it requests theoretical justifications, which provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. The reviewer suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. However, the comment lacks specific examples or references to support the claim about the classification error or the need for theoretical justifications. This makes the claim 3, as the authors would need to make a significant effort to understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. It suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. This feedback is actionable as it prompts the authors to address the classification accuracy and potentially provide theoretical justifications. However, the comment could be more helpful if it offered specific suggestions on how to improve the classification accuracy or provided examples of theoretical justifications. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific changes could be made to improve the argument or simulations. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific argument related to the practicality of the recognition process, particularly in the context of old vs. new judgments. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the exhaustive list of items and how it relates to concrete predictions through simulations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. The reviewer points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. This claim is 3 as it provides a logical reasoning for the difficulty in implementing the argument, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the argument presented regarding the recall of recognition lists based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their argument. The feedback is 3 as it prompts the authors to consider the practicality of their argument, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pretrained model as the compared methods. It points out that if not, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly rerun experiments with different initialization methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the initialization of the proposed method before the finetuning stage. The comment suggests that if the compared methods were not initialized with the same pretrained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pretrained model as the compared methods. The reviewer supports this claim by referencing Table 1, which shows the inferior performance of the proposed method without SSL compared to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential issue in the experimental setup that could affect the results. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have addressed this issue. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method before the finetuning stage. It points out that if the compared methods were not initialized with the same pretrained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This feedback is 3 as it highlights a potential weakness in the experimental setup that the authors should address to ensure fairness and validity. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a specific initialization method or suggesting ways to standardize the initialization process across methods. Overall, the comment identifies a critical area for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion to use better metadata embeddings and provides a specific reference to a related work. However, it does not provide detailed guidance on how to implement this suggestion or what specific steps to take. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. The comment provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the authors should consider this approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The reviewer provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" This reference provides a clear rationale for the suggestion, as it demonstrates that better metadata embeddings can lead to improved performance. However, the comment could be strengthened by providing more detailed analysis or specific examples of how the proposed method could benefit from these embeddings. Overall, the claim is 4, as it is supported by a specific example and logical reasoning, but it could be further substantiated with additional evidence or detailed explanation.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by recommending the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. It references a specific example from a related work, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which demonstrates the potential for better performance using better metadata embeddings. This feedback is clear and actionable, as it guides the authors on how to enhance their results and potentially improve their paper\"s impact. However, the comment could be more helpful if it provided additional context or detailed guidance on how to implement this suggestion. Overall, the comment is 4 as it offers a concrete direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This explicit action provides a clear and concrete step for the authors to take, as it specifies the exact visualization needed to demonstrate the practical benefits of SGC. The comment is 5 because it directly instructs the authors on how to enhance their draft with a specific visualization, ensuring that the authors know exactly what to do to improve their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the limited applicability of SGC and the need for a plot to compare its flexibility with LoRA. It specifies the issue by suggesting a visualization with sparsity on the xaxis and performance on the yaxis. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff but is limited in practicality due to the need for extra tuning. The reviewer suggests including a plot to demonstrate the flexibility of SGC compared to LoRA. This claim is 3 as it provides a logical reasoning for the need to visualize the tradeoff, but it lacks specific examples or references to support the claim about the limitations of SGC. The suggestion for a plot is a helpful direction, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s claim about the flexibility and performance of SGC, specifically in scenarios where compute constraints are present. It suggests a specific action for the authors to take, which is to include a plot demonstrating the flexibility of SGC compared to LoRA. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by adding a visualization that could help clarify the practical benefits of SGC. By addressing this point, the authors can enhance the clarity and persuasiveness of their argument. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, and suggests that the code should be published to demonstrate the computation time advantage. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or publish the code to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasonableness of the shorter training time for Gerrymandering compared to Independent, and suggests that the code should be published to demonstrate the computation time advantage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might not be reasonable. It also mentions that the code should be published to demonstrate the computation time advantage. However, the comment lacks specific evidence or references to support the claim about the training time or the need for code publication. The reasoning is based on logical reasoning and common sense, but it does not provide detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might not be reasonable. It also suggests that the code should be published to demonstrate the computation time advantage, which could be beneficial for the authors. While the comment identifies a potential issue and provides a suggestion for improvement, it lacks depth and does not offer specific guidance or examples on how to address the issue or improve the code. The feedback is 3 as it points out a potential weakness but does not provide detailed guidance for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information that CD captures on top of Predictive Uncertainty. It also questions the use of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" and requests clarification on line 113. While the comment provides explicit actions for the authors to take, such as describing alternate formulations and clarifying the additional information captured by CD, it does not specify how to implement these actions or provide detailed guidance on what specific formulations should be considered. The action is concrete but could be more detailed, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the possible alternate formulations for Confidence Diversity (CD) and the clarification of the additional information captured by CD on top of Predictive Uncertainty. The comment also questions the use of entropy as a measure and requests clarification on line 113. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the possible alternate formulations for Confidence Diversity (CD) and the additional information captured by CD on top of Predictive Uncertainty. It also questions the use of entropy as a measure and requests clarification on line 113. While the comment identifies areas of uncertainty and seeks clarification, it does not provide specific examples or references to support the claims or questions. This makes the comment 3, as it requires the authors to provide additional context or evidence to fully address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarify the additional information captured by CD on top of Predictive Uncertainty. It also questions the use of entropy as a measure and requests clarification on line 113. This feedback is clear and directs the authors to specific areas that need improvement, offering a concrete path for enhancing the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided examples of alternate formulations or detailed guidance on how to clarify the additional information captured by CD. Overall, the comment is 4 as it identifies important areas for improvement and offers actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. It also points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited human data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the human baseline. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of the human baseline being weaker, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the human baseline, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. Additionally, the comment points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited human data. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is considerably weaker than the model baseline due to the limited amount of speech recordings followed by the human. The comment supports this claim by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, while the model baseline is evaluated on the full 15 hours. Additionally, the comment notes that the abstract statement about beating a human who learned Kalamang is misleading due to the limited human data. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific data or studies that demonstrate the impact of limited human data on baseline performance. Therefore, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. This is a critical observation that could impact the validity and applicability of the human baseline. The comment also points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited human data. This feedback is valuable as it highlights a potential misrepresentation in the paper, which the authors should address to ensure the accuracy and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific changes could be made to improve the human baseline. Overall, the comment is 3 as it identifies a critical weakness and offers a direction for improvement, but it lacks detailed guidance on how to address it fully."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the assumption for termination states of instructions is quite strong, particularly when it comes to labeling a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, particularly in the context of labeling a large number of data manually. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue of the assumption being too strong, but it lacks detailed guidance on how to address this issue or what specific changes could be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is \"quite strong,\" particularly when it comes to labeling a large number of data manually. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the assumption for termination states of instructions, particularly when it comes to labeling a large number of data manually. This is a relevant point that could impact the feasibility and costeffectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the nature of the contribution with respect to ECE_sweep. It explicitly states that the contribution is not clearly described and suggests that the authors should be more upfront about it. The reviewer provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate, and notes that this is not fundamentally different from the contribution. The comment is explicit in its request for clarification and provides a specific example of what needs to be addressed. Therefore, the comment is 5, as it clearly guides the authors on how to improve the clarity of their contribution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ECE_sweep\" and the issue with the contribution being unclearly described. It specifies the problem by pointing out that the contribution is not clearly described, and it provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate. This level of detail allows the authors to understand exactly what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the contribution with respect to ECE_sweep is not clearly described in the text. It provides a specific example of the issue, which is the autotuning of a hyperparameter in the estimate, and notes that this is not fundamentally different from the contribution. The reviewer acknowledges being confused about the paper\"s point until they realized this. This provides a clear and specific example of the issue, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar works that might have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the contribution regarding ECE_sweep. It points out that the contribution is not clearly described in the text, and provides a concrete example of what is missing: the autotuning of a hyperparameter in the estimate. This feedback is 5 as it guides the authors to clarify the contribution and its significance. Additionally, the reviewer acknowledges that they were confused about the paper\"s point until they realized this, which highlights the importance of the clarification. Therefore, the comment is 5 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, it does not provide explicit guidance on which methods should be used as a baseline or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to consider using these methods as a baseline but are not given specific instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the related work section, noting that it discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This feedback is 3 as it points out a potential gap in the paper\"s evaluation, which could be addressed by including these methods as baselines. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these methods or why they are important. Additionally, it does not address other aspects of the paper, such as its originality or contributions. Therefore, the comment is 3, as it highlights an area for improvement but does not fully guide the authors on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a confusion regarding whether the authors are referring to a particular efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" might be a misnomer, as there is no specific proxy called \"Efficient Proxy.\" However, the comment does not provide explicit guidance on how the authors should clarify this confusion or what specific changes should be made to the text. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terminology and possibly revise the text to avoid confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"Efficient Proxy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology, suggesting that the authors might be referring to a family of efficient proxies rather than a single proxy. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of whether the authors are referring to a particular efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" might be misleading, as there is no specific proxy called \"Efficient Proxy.\" The comment provides a logical reasoning by pointing out the potential confusion caused by the term \"is,\" which could suggest a particular proxy, but the lack of a specific proxy called \"Efficient Proxy\" suggests a broader reference. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, particularly the term \"Efficient Proxy.\" It points out that the term might be misleading, as there is no specific proxy called \"Efficient Proxy,\" suggesting that it might refer to a family of efficient proxies. This feedback is clear and actionable, as it provides the authors with a specific area to clarify and potentially revise their terminology to avoid confusion. By addressing this issue, the authors can improve the clarity and precision of their work, making the comment 4. However, it could be more helpful if it offered suggestions on how to clarify the terminology or provided examples of how other similar terms have been used effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the authors stacking methods from Mirzasoleiman et al., 2020 and using a grouplearning setting, followed by a classical method like DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the grouplearning setting, followed by the use of a classical method like DBSCAN for clustering. However, it does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the methodology, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors stack methods from Mirzasoleiman et al., 2020 and use a grouplearning setting, followed by a classical method like DBSCAN for clustering. However, the comment lacks any supporting evidence, reasoning, or references to justify why this approach is problematic or inappropriate. Without additional context or explanation, the claim remains 1, as it does not provide sufficient justification for the authors to understand or address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the methodology used by the authors, noting that they stack methods from Mirzasoleiman et al., 2020 and use a grouplearning setting, followed by a classical method like DBSCAN for clustering. While the comment highlights a potential problem with the approach, it does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not guide the authors on how to address this issue or what alternative methods might be more appropriate. As a result, the comment is 2, as it points out a weakness but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. It also mentions that the authors might have missed this in the appendix. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the resilience of the metric to the choice of random projection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the chosen random projection matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. The comment also mentions that the authors might have missed this in the appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. However, the comment lacks specific examples or references to support the claim that such pathological projection matrices are unlikely with random projections. While it highlights a potential concern, the lack of detailed evidence or examples makes the claim 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results obtained using the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. It also points out that the authors might have missed this in the appendix. While the comment highlights an important area for investigation, it lacks specific guidance or suggestions on how to address this issue or what specific tests could be conducted to verify the resilience of the metric. The feedback is 3 as it prompts the authors to consider this aspect, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests that the authors explicitly state the model used in the paper, suggesting that this information could be added to the appendix. While the comment provides some guidance on what the authors should include, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide examples and model details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"support data\" and \"predicted training count data\" in Figure 1, as well as requests that the model used be explicitly stated in the appendix. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific terms and data used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests that the authors explicitly state the model used in the paper, suggesting that this information could be added to the appendix. While the comment identifies areas for clarification and potential enhancement, it does not provide specific guidance on how to address these issues or what specific changes would be beneficial. The feedback is 3 as it points out areas that need clarification, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. While the comment implies that the authors should expand the evaluation to include additional comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden the evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited use of FGT for evaluating the performance of the proposed method and comparative methods. This provides clear guidance on how to improve the evaluation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of FGT is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the paper\"s conclusions. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of FGT, noting that it is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for expanding the evaluation to include additional comparisons. By addressing this point, the authors can enhance the robustness and comprehensiveness of their evaluation, which is valuable for improving the draft. However, the comment could be more helpful if it provided specific examples of comparative methods or detailed guidance on how to conduct these additional evaluations. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to enhance the model\"s complexity or complexity analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as the model description, results, or analysis. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the model seems overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model\"s complexity. Without actionable feedback or detailed analysis, the comment lacks depth and does not assist the authors in enhancing their draft. Therefore, it is rated as 2, as it identifies a potential weakness but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the scope of the work or how to demonstrate its broader impact. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of narrow focus and its potential impact on the broader impact of the work, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and how it affects the broader impact of the work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential limitation of the work, noting that its focus on a narrow task (climate change QA) in a specific language (Arabic) could limit its broader impact. While this observation highlights a potential issue, it does not provide specific guidance or suggestions on how the authors might address this limitation or broaden the scope of their work. The comment lacks actionable feedback or detailed advice on how to enhance the paper\"s impact, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not contribute novelly to the understanding of the winnertakeall property, as it uses extremely simplified settings and reports findings that have been previously reported in other works. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or how to present the findings in a novel way. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"winnertakeall property\" and \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not contribute novelly to the understanding of this behavior due to the use of extremely simplified settings and the repetition of findings from previous works. This provides clear guidance on what needs to be addressed to improve the originality of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. However, the comment lacks specific references to these previous works or detailed examples of how the findings have been reported elsewhere. Without such references or detailed justification, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides some basis but lacks sufficient evidence or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. This is a critical observation that could impact the paper\"s originality and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from previous studies. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to improve the paper. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the action is explicit, it is somewhat vague as it does not specify which part of the main paper should include the mention or how to present the runtimes. However, the authors can infer that they need to add a brief mention and provide examples, making the comment 4.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and providing a rough example of runtimes in the experiments. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the computational cost is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of a brief mention and examples, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests mentioning the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim about the computational cost. The mention of a rough example is 3, but the overall claim could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a reasonable suggestion but lacks full justification.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends mentioning the negligible computational cost of CHR in the main paper, which could help motivate the method. Additionally, it suggests providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. This feedback is specific and offers concrete steps for the authors to enhance the clarity and applicability of their work. By addressing these points, the authors can improve the comprehensiveness and accessibility of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors elucidate the EEG token quantization process in greater detail, specifically addressing the ambiguity in interpretation. It suggests that the authors should clarify whether the spatial arrangement of the EEG sensors played a role in this process. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity in the interpretation of the EEG topography plots and the need to clarify the role of the spatial arrangement of the EEG sensors in the EEG token quantization process. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents ambiguity in interpretation due to the EEG topography plots for both the input and output during the EEG token quantization process. The reviewer suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role. While the comment identifies a potential issue with interpretation, it lacks specific examples or references to support the claim that the spatial arrangement of the sensors is relevant. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and understanding of the figure. By addressing this point, the authors can enhance the clarity and comprehensibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes could be made to improve the directness of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" approach to addressing the problem, specifically mentioning the use of the Witness oracle and its complexity. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspect of the complexity issue is problematic or how it could be addressed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not address the problem directly by leveraging the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach, specifically the use of the Witness oracle and its complexity. It suggests that the authors may not be addressing the problem directly, as the oracle is described as \"polynomial time\" in the tabular case. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their approach. Without detailed guidance or examples, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning the paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This provides a clear and direct action for the authors to take, as they are instructed to include this discussion in their paper. The comment is specific and provides concrete guidance on how to enhance the literature review section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph (lines 2230) and discusses the use of moment matching in distributional RL. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on moment matching and its relevance to distributional RL. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL. The reviewer supports this claim by referencing a specific paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This reference provides a clear and specific example of relevant literature that could be included in the paper. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be beneficial in the context of distributional RL. Despite this, the claim is 4 due to the reference to a specific work that supports the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks relevant literature, specifically on the use of moment matching instead of quantile regression for distributional RL. It provides a clear and actionable suggestion by referencing a specific paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This feedback is valuable as it directs the authors to include a discussion on this topic, which could enhance the paper's literature review and depth of analysis. However, the comment could be more helpful if it explained why moment matching is a relevant approach or how it could benefit the paper. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their work with existing code completion commercial applications, such as Copilot, as a baseline. It provides a specific suggestion for testing on a smaller subset of RepoEval and highlights the importance of comparing with stateoftheart code completion systems. This feedback is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. It specifies that this comparison should be tested on a smaller subset of RepoEval and is essential for comparing with stateoftheart code completion systems. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. This claim is 3 as it provides a logical reasoning for the suggestion, which is to test the performance of the proposed system against stateoftheart code completion systems. However, the comment lacks specific examples or references to these existing applications, making it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of baselines, specifically comparing the proposed work with existing code completion commercial applications like Copilot. This is a valuable piece of feedback as it highlights the importance of benchmarking against stateoftheart systems to validate the performance of the proposed work. By including this comparison, the authors can strengthen the robustness and generalizability of their findings. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or suggested specific aspects of the existing code completion systems to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. While the comment implies that the authors should consider expanding their evaluation to include more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that understanding the criteria behind the selection and exploring other tasks or datasets might yield different insights. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. However, the comment does not provide specific examples, references, or detailed reasoning to support why this choice might impact the generalizability of the results. While it highlights a potential issue, the lack of detailed justification makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. This feedback is 3 as it prompts the authors to consider the broader implications of their evaluation approach and how it might impact the generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional tasks or datasets might be relevant to include. Overall, the comment offers a valuable direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled, presumably tumour growth. While the comment identifies a potential issue with the clarity of the introduction, it does not provide explicit guidance on how to improve it. The authors are left to infer that they should clarify the modelled curves and their relation to tumour growth, but the comment lacks concrete suggestions on how to achieve this clarity. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of not being immediately obvious what is being modelled, which is a clear and actionable concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph in the introduction discussing modelling curves is not immediately obvious what is being modelled, presumably tumour growth. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue in the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. It points out that the mention of modelling curves is not immediately obvious, and it suggests that the authors should clarify this aspect to enhance the clarity of their work. While the comment highlights an important area for improvement, it does not provide specific guidance or suggestions on how to address this issue. The authors are left to infer that they need to clarify the modelled curves and their relation to tumour growth, which could be more helpful with additional direction. Therefore, the comment is 3, as it identifies a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the performance of the shiftedMNIST dataset and suggests that it would be useful to show the model and baselines on test samples from the observational (in) distribution. While the comment implies that the authors should provide additional data or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance difference between shift=0 and shift~N (0, \u03c3 2) and suggests showing performance on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of the shiftedMNIST dataset. It suggests that both cases incorporate a domain shift, implying that the performance difference is not as significant as claimed. However, the comment does not provide specific reasoning or evidence to support this claim, nor does it offer alternative explanations or comparisons. This lack of detailed justification makes the claim 3, as the authors would need to further explore the issue themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of the shiftedMNIST dataset. It suggests that both cases incorporate a domain shift, implying that the performance difference might not be as significant as claimed. The comment also recommends showing the performance of the model and baselines on test samples from the observational (in) distribution, which could provide valuable insights into the robustness of the results. While the comment identifies a potential weakness in the analysis and offers a constructive suggestion for improvement, it could be more helpful if it provided specific examples or guidance on how to conduct the additional analysis. Overall, the comment is 3 as it points out a potential issue and suggests an actionable step for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the experimental description, suggesting that increased clarity would be beneficial. It explicitly states that the current description is insufficient and points to a specific section (\"Questions\") for further details. This provides a clear and direct action for the authors to take, which is to enhance the clarity of the experimental details. The comment also offers a reference point for additional information, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental details\" and the \"Questions\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the experimental details and the need for increased clarity to better judge the results. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental description lacks detail and clarity, which hinders the reader\"s ability to judge the results. It suggests that increased clarity would be beneficial. However, the comment does not provide specific examples or detailed reasoning to support this claim, nor does it reference external sources or examples to substantiate the need for increased clarity. This makes the claim 3, as the authors would need to infer the specific details and examples needed to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, namely the lack of detail in the experimental description. It suggests that increased clarity in this area would significantly benefit the reader\"s ability to understand and evaluate the results. The comment points to a specific section (\"Questions\") for further details, providing a clear direction for the authors to enhance the clarity of their experimental description. This feedback is actionable and offers a concrete way for the authors to improve their draft, making it 4. However, it could be more helpful if it provided specific examples or suggestions on how to improve the clarity of the experimental details. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more explanation to clarify the main contributions of the paper, specifically regarding the optimization strategies and their corresponding results. It suggests discussing different scenarios, such as minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is clear and concrete, as it specifies exactly what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more explanation regarding the optimization strategies and their corresponding results. The comment provides a clear direction for the authors to improve the clarity of their paper by discussing different scenarios and their implications. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks explanation regarding the optimization strategies and their corresponding results, specifically mentioning the contribution of the CBR. The reviewer provides a specific example of what could be discussed, such as the consequences of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This claim is 3 as it provides a logical reasoning for the need of additional explanation, but it lacks detailed justification or references to support the importance of these discussions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding the optimization strategies and their corresponding results. It suggests that the paper should provide more clarity on the contributions of the CBR, particularly by discussing different scenarios such as minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is clear and actionable, as it directs the authors to expand on their discussion to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to present these discussions. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is an explicit action, as it clearly specifies what the authors need to do to improve their draft. The comment provides a clear and concrete direction for the authors to add a definition, making it 5.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the proofs, but this inference is not direct. The comment is specific in suggesting the inclusion of a definition, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including a definition. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their work. By including a definition, the authors can ensure that readers understand the concept and its importance in the context of the paper. However, the comment could be more helpful if it provided additional guidance on how to present the definition or examples of how it has been used in the proofs. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. This feedback provides a clear and explicit action for the authors to take, which is to include an analysis of the quality of the local minima. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Algorithm 1 and the local minima, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of these local minima, such as the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors analyze the quality of the local minima, particularly the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and improve the paper. By addressing this suggestion, the authors can strengthen their work by providing more detailed insights into the behavior of the algorithm under various conditions. However, the comment could be more helpful if it included specific examples or references to similar analyses in the literature, which would guide the authors in implementing this suggestion effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper is not selfcontained and points out that the supplementary material is necessary to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment identifies a specific issue with the selfcontainment and suggests a solution by requesting the release of the source code, it does not provide explicit instructions on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should release the source code and improve the selfcontainment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplementary\" material, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper is not selfcontained and that the supplementary material is necessary for understanding and reproducibility. Additionally, it requests the release of the source code, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and requires the supplementary material for understanding and reproducibility. It also requests the release of the source code to allow reproduction of the results. While the comment identifies a potential issue with the selfcontainment, it lacks specific examples or detailed reasoning to support the claim. The suggestion to release the source code is logical, but the justification for the claim is not fully articulated. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed evidence or explanation.", "helpfulness_rationale": "The review comment identifies a significant issue with the selfcontainment of the paper, noting that the supplementary material is necessary to understand large parts of the main paper and ensure reproducibility. It also requests the authors to release the source code of their experiments, which is a clear and actionable suggestion. This feedback is valuable as it highlights a critical aspect of the paper that needs improvement and provides a concrete step for the authors to enhance the selfcontainment and reproducibility of their work. However, the comment could be more helpful if it offered specific suggestions on how to improve the selfcontainment or provided examples of how other papers have addressed this issue. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear actionable step."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, and references a specific sentence regarding the performance of the secret model with or without fusion. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms should be clarified or how the authors might address the issue of information redundancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and the specific sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it asks for clarification on how information redundancy is built into the algorithms and how it affects the performance of the secret model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how information redundancy is built into the Fill, Propagate, Decode algorithms. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms, specifically asking for clarification on how this redundancy is built into the algorithms. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their explanation. The feedback is 3 as it points out a potential weakness in the paper, but it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of using multiple INs at different speeds in the dynamics predictor, suggesting that this design choice is not ablated. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider ablating this feature to determine its impact, but it lacks concrete instructions on how to do so or what specific aspects to focus on. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and suggesting that one IN might suffice. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of using multiple INs at different speeds in the dynamics predictor, suggesting that this design choice is not ablated. However, it does not provide any supporting evidence, reasoning, or references to justify why this design choice is important or not. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of using multiple INs at different speeds in the dynamics predictor, suggesting that this design choice is not ablated. It prompts the authors to consider whether one IN would suffice, which is a valuable point for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or what potential implications this design choice might have. While it identifies a relevant area for consideration, the feedback could be more helpful with additional context or suggestions for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is a surprise. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their experimental design. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the opponent does not aim to maximize the multiagent payoff proposed by the authors, which is a clear and specific critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is a surprise. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the experimental setup, noting that the opponent does not aim to maximize the multiagent payoff proposed by the authors. This observation highlights a potential weakness in the experimental design, as it suggests that the opponent may not be fully representative of the system being evaluated. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their experimental setup. While it identifies a potential problem, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. It implies that the authors should clarify the reasoning behind these choices, specifically mentioning the attention model paper that the algorithm iterates on. While the comment does not explicitly instruct the authors to provide this rationale, it clearly indicates what needs to be added to the paper. The action is concrete, as it specifies the need for clarification and provides a direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"REINFORCE algorithm\" and \"PPO,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors provide a rationale for why certain choices were made, such as the use of REINFORCE versus PPO. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. The reviewer implies that this choice might be related to the attention model paper that the algorithm iterates on, but does not provide specific evidence or references to support this claim. While the suggestion is logical, it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a rationale for the choices made in their work, such as the use of the REINFORCE algorithm versus PPO. It implies that this choice might be related to the attention model paper that the algorithm iterates on, but does not provide detailed guidance on how to clarify this rationale. While the comment highlights an important aspect of the paper that could be clarified, it lacks specific suggestions or examples on how to present this rationale effectively. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully guide the authors on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, specifically regarding the potential disadvantage of MMD DRO compared to the variance regularized problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this confusion or clarify the statement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement in the theorem, which could indicate a disadvantage of MMD DRO compared to the variance regularized problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO compared to the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO compared to the variance regularized problem. This is a relevant observation that could lead to a deeper understanding of the paper\"s results and conclusions. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the statement. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more information on how to use morphologic segmentation across domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains and points out that the paper lacks insight into this aspect. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on morphologic segmentation across domains. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"morphologic segmentation\" and \"domain adaptation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of morphologic segmentation across domains and how it should be conducted differently for different domains. The comment also questions the assumption of morphologic segmentation invariance across domains, which adds further clarity to the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks insight into how to use morphologic segmentation across domains and how it should be conducted differently for different domains. It questions whether morphologic segmentation is invariant across domains and suggests that the paper assumes this invariance without providing evidence or justification. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to infer the need for additional information and address the questions raised, but the lack of detailed evidence or reasoning makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the use of morphologic segmentation across domains and how it should be conducted differently for different domains. It questions the assumption of morphologic segmentation invariance across domains and highlights the importance of addressing this issue for task domain adaptation. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or examples on how to conduct morphologic segmentation differently across domains. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique used in LUMP. This is a clear and direct action, as it specifies exactly what needs to be done to improve the draft. The authors know exactly what additional experiments are needed and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results demonstrating the pure contribution of the proposed method without the mixup technique used in LUMP. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mixup technique used in LUMP should be excluded from the proposed method to demonstrate its pure contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the mixup technique used in LUMP is also adopted for the proposed method in the experiments on SplitCIFAR100 and SplitTinyImageNet. It suggests that the authors should include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by including additional experiments. However, the comment could be more helpful if it explained why the mixup technique is important or how its exclusion might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention being performed on the image or on some convolutional feature map. It suggests clarifying this point and potentially rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the object detectionbased attention, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on whether the attention is performed on the image or on some convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be clarified, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the object detectionbased attention and its application. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention, specifically asking whether it is performed on the image or on some convolutional feature map. It also suggests that clarification is needed regarding any rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment identifies a potential area for clarification, it lacks specific guidance or suggestions on how to address this issue. The authors are given a direction to clarify but are not provided with actionable steps or detailed advice on how to improve their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a discussion about Set Transformer and other related works that use summary tokens. This provides a clear and direct action for the authors to take, which is to include a discussion on these topics. The comment is specific in identifying the missing content and provides a concrete action for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and \"other related works that also use summary tokens,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the use of summary tokens and related works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there is a missing discussion about Set Transformer and other related works that use summary tokens. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a discussion about Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to expand their literature review to include relevant works that could enhance their understanding and analysis. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the paper. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide explicit guidance on how to address this issue or what specific analysis should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical support but are not given clear steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure where this analysis is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. This feedback is valuable as it prompts the authors to consider a potential gap in their analysis and provides a clear direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or what kind of analysis should be conducted to support the theoretical foundation. Overall, the comment is 4 as it identifies a critical area for improvement and provides a direction for the authors to explore further."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the lack of details regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information about the network\"s training process, but it lacks concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of detail regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking details regarding the network\"s training process, but without clear grounding, the authors cannot confidently determine which section or part of the paper needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of details regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this is a significant issue or a problem that needs to be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of details on how the network fits the residual instead of directly learning the inputoutput mapping. This is a relevant point that could impact the understanding and interpretation of the network\"s training process. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details might be needed. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. While the comment implies that the authors should provide more details about these aspects, it does not explicitly instruct them to do so. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides some context but does not offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for details on the experiment setup, such as data augmentation methods and learning rate, and provides a reference to a related paper for context. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is helpful in providing context but does not offer actionable advice. Overall, the comment is 3 as it points out a potential area for improvement but lacks depth and specificity in its guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider an error in the initial calibration steps (steps 1 and 2) as a possible explanation for the speed disparities observed between the RSPs and FDs. However, it does not provide explicit instructions or concrete guidance on how to investigate or address this potential error. The authors are left to infer that they should look into the initial calibration steps, but without specific details or suggestions on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the suggestion, making it difficult for the authors to understand or address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the initial calibration steps, suggesting that an error might explain the speed disparities observed between the RSPs and FDs. While it highlights an area for further investigation, it lacks specific guidance or suggestions on how the authors might address this issue or verify the potential error. The comment is 3 as it points out a potential source of discrepancy, but it could be more beneficial if it provided more detailed advice on how to investigate and resolve the issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of artificial networks trained using ASAP (and similar methods) not necessarily resembling biological networks, except for the weight transport problem. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the resemblance of artificial and biological networks, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any constructive feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. Without actionable advice or insights, the comment does not assist the authors in enhancing their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors conducted statistical significance tests for the numbers presented in the paper. While it implies that the authors should consider conducting such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is presented in, making it weakly grounded. The comment is specific in its request for statistical significance tests, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is relevant or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. This is a valuable point as it highlights a potential area for improvement in the paper, which could enhance the credibility and robustness of the results. However, the comment lacks specific guidance on how to conduct statistical significance tests or what aspects of the comparison should be analyzed. While it identifies a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is 3, as it points out an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the paper\"s focus on learning HMMs with nonparametric emission distributions but questions how these distributions affect inference. It specifically asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the inference tasks should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the impact of emission distributions on inference tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on learning HMMs with nonparametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how these emission distributions affect inference and asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It asks which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that these tasks are affected by the emission distributions. This makes the claim 3, as the authors would need to make a logical deduction to understand the implications of the emission distributions on inference tasks. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically questions which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This feedback is valuable as it prompts the authors to clarify and expand on the implications of their model for inference tasks. However, the comment could be more helpful if it provided specific suggestions on how to address this gap or examples of how the emission distributions affect inference tasks. Overall, the comment is 4 as it directs the authors to a critical area needing further exploration and explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results, including identifying the factors contributing to the poor performance. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, leaving some ambiguity about the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for a more detailed analysis themselves, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the results. By pointing out the lack of analysis, the comment empowers the authors to enhance their draft by including a more detailed explanation of the factors contributing to the poor performance. However, the comment could be more helpful if it suggested specific areas to explore or provided examples of how to conduct a deeper analysis. Overall, the comment is 4 as it directs the authors to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. While the comment implies that the authors should expand their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section where the authors discuss the datasets considered, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why only 10 out of 120 datasets are considered and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This feedback is 3 as it identifies a potential area for improvement in the paper\"s analysis. However, the comment lacks depth and does not provide specific guidance on how to conduct the additional analysis or what aspects of the batch and greedy algorithms should be compared. While it points out a potential gap in the analysis, it does not offer detailed suggestions for enhancing the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. It also implies that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of the lowrank factorization in the context of the main result. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"lowrank factorization\" in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary nature of the lowrank factorization and the potential implications for lowrank matrix factorization. This provides clear guidance on what the authors should consider and discuss in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. The reviewer suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the need for discussing lowrank matrix factorization based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation in the introduction, specifically the lowrank factorization, which may not be necessary given the main result about polytopes. It suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. This feedback is 3 as it points out a potential area for improvement in the paper\"s motivation and alignment with the main results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the lowrank factorization should be discussed in the context of the main result. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. While the comment implies that the authors should clarify these labels, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the labels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the labels for each dataset, including the datasets \"caspealr1\" and \"mugshot,\" and questions where these labels are coming from. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the labels for each dataset in 4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. This is a relevant inquiry that could help the authors clarify their methodology and provide more transparency about their dataset selection process. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address this issue. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their work or what specific aspects of the paper are lacking. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not specify which part of the paper this assessment is based on, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the authors could improve their work. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any specific details or references to support this claim, such as how the paper is incremental or how the adaptation affects the results. Without additional context or evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their work or address the issue of incrementality. Without actionable feedback or detailed analysis, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to the \u03bb parameters, and questions how \u03bb is calculated. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but does not fully understand the implications. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to improve the explanation or calculations. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the process of calculating \u03bb and improve the explanation of the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines on pages 8 and 9, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters, questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific examples or detailed reasoning to support the claim that performance and sample efficiency are sensitive to \u03bb parameters. The references are provided as a means of context, but they do not fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the sensitivity of performance and sample efficiency to \u03bb parameters, which is a critical aspect of the paper\"s results. It raises questions about how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment, which are important areas for clarification. The reviewer also provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the explanation. While it points out areas for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. However, it does not provide any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete details on what the authors should do to clarify or expand on this aspect of their work. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve the minmin problem, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding this method, making it underspecific. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking for clarification about the specific method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve the explanation. The comment lacks depth and actionable feedback, leaving the authors with only a vague idea of what needs to be clarified. Therefore, the comment is 2, as it points out a potential weakness but does not offer concrete steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in other environments. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these concerns or improve the draft. The authors are left without any clear direction on how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure2\" and \"MsPacman,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of lower bound double qlearning, particularly in the context of convergence and overestimation of true maximum values. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, based on observations from Figure 2 and specific environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. The reviewer provides some evidence by mentioning the slight performance decrease in MsPacman and the convergence of algorithms in other environments. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some support, the authors would need more detailed evidence or examples to fully understand and address the critique. Therefore, the comment is 3, as it provides some evidence but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of lower bound double qlearning, specifically questioning its performance in certain environments and its tendency to overestimate true maximum values. It provides specific examples from Figure 2 and other environments, which helps the authors understand the basis of the critique. However, the comment could be more helpful if it offered suggestions on how to address these concerns or improve the algorithm. While it highlights a relevant area for improvement, it lacks actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or suggest alternative approaches to explore. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the novelty, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. This feedback highlights a potential weakness in the paper\"s contribution, which could be addressed by providing more novel or innovative approaches to model interpretation. However, the comment does not offer specific suggestions or guidance on how the authors might enhance the novelty or address this limitation. While it points out an area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or explain the performance behavior in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and suggests that it should approach vanilla methods from above but from below. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. This feedback identifies a potential discrepancy in the results that the authors may need to address or clarify. However, the comment lacks specific guidance or suggestions on how to resolve this issue or improve the explanation in the paper. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a gap in the paper, noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not doing so in the author response, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback provides a clear and explicit action for the authors to take, which is to include comparisons with these systems. The comment is specific and provides concrete guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors have explained their reasons for not comparing their results with some earlier research work from 2020. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the comparison with earlier systems with worse performances, such as Taghipour and Ng (2016). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer suggests that the authors should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). However, the comment lacks specific examples or references to the earlier works that the authors have overlooked, making it 3. The authors would need to infer which systems are being referred to and potentially conduct additional research to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that it does not compare its results with some earlier research work from 2020. While the authors have explained their reasons for not doing so, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison with existing work. By addressing this point, the authors can strengthen the validity and relevance of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of significance testing method used in the paper, suggesting that a paired test setting like the Wilcoxon signedranked test might be more appropriate. While the comment implies that the authors should consider using a different test, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of significance testing method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of significance testing method used in the paper, specifically questioning the appropriateness of the current method. However, it does not specify which part of the paper discusses this choice, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in suggesting an alternative test, the Wilcoxon signedranked test, but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of why the current test might be inappropriate or how the suggested test would be more suitable. As a result, the claim is not 5, as it relies on a vague suggestion without sufficient justification or evidence. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. While it identifies a potential issue with the current choice, it does not provide specific guidance or examples of alternative tests that could be used. The comment lacks depth and does not offer actionable steps for the authors to address the concern, making it 3 but incomplete. The authors are given a direction to consider, but the feedback does not fully support them in making improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not provide specific guidance on how to expand the experiments or what additional aspects to consider. The action is implicit and somewhat vague, as the authors can infer that they need to broaden the scope of their experiments but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The suggestion to expand the experiments is specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It highlights the limitation of the model size and the restrictive baselines, which constrain the scope of the experiments. However, the comment does not provide specific examples or references to support why these limitations are problematic or how they impact the results. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some justification but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. While the comment identifies a potential weakness in the experiments, it lacks specific guidance on how to expand the scope or what additional aspects to consider. The authors are given a general direction to improve their experiments but are not provided with actionable steps or detailed suggestions on how to achieve this. Therefore, the comment is 3, as it provides insight into a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. It provides a clear and specific action for the authors to take, which is to elaborate on the topic. The comment is explicit and provides concrete guidance on what needs to be added to the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the Hoeffding\"s bound and its implications for stochastic algorithms. This provides clear guidance on what the authors need to address in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Hoeffding\"s bound holds true for any w as long as samples are drawn independently, and that stochastic algorithms impose conditioning on the previous iterate to guarantee the inequality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (Line 124125) and suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. This feedback is clear and actionable, as it directs the authors to provide more detailed information on a topic that is likely important for the paper\"s understanding and credibility. By addressing this suggestion, the authors can enhance the clarity and depth of their explanation, which could improve the overall quality of their draft. However, the comment could be more helpful if it provided additional context or examples to guide the authors in their elaboration. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. While the comment implies that the authors should consider adding this information, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is clear but lacks concrete details on how to integrate the metalearning approach into the table. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, it does not specify which part of the table this addition should be made, making it weakly grounded. The comment is specific in suggesting the addition of these approaches, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. This is a specific and actionable suggestion that could potentially enhance the paper by providing additional context and depth to the table. However, the comment lacks detailed guidance on how to integrate these approaches or why they are relevant to the table. While it points out a potential area for improvement, the authors would need more detailed instructions or justification to fully understand and implement the suggestion. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This feedback provides a clear and direct action for the authors to take, which is to include an ablation study to address this issue. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for an ablation study, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of an explanation for why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This provides clear guidance on what the authors need to include in their paper to address the reviewer\"s concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting the inclusion of an ablation study to explain why the prompt was chosen in a particular way, such as using fewshot examples for CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by addressing a gap in the experimental design. However, the comment could be more helpful if it included examples or detailed guidance on how to conduct such an ablation study. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to be careful with the terms \"causal mechanisms\" and \"temporal relationship,\" as they are not interchangeable. This feedback is clear and provides a specific action for the authors to take, ensuring that they use the terms correctly. The comment is concrete, as it specifies the exact issue and offers a direct way to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms like \"causal mechanisms\" and \"temporal relationship,\" providing guidance on how to avoid confusion and ensure clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the use of terms \"causal mechanisms\" and \"temporal relationship,\" suggesting that they are not interchangeable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it points out a specific issue with the use of terms like \"causal mechanisms\" and \"temporal relationship\" in the paper. It provides a clear and actionable suggestion to avoid confusion by using these terms carefully. However, the comment could be more helpful if it offered additional guidance on how to effectively use these terms or provided examples of how they might be misused. Overall, the feedback is valuable but could be more comprehensive to fully support the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what alternative demonstrations could be used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific statement from the paper, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what aspect of the demonstration is questionable or how it could be improved. It suggests that \"better than random\" may not be a strong demonstration of capability, but without further explanation or examples, the authors are left without clear guidance on how to address this concern. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why \"better than random\" might not be a strong demonstration. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any specific reasoning or examples to support this claim or offer alternative demonstrations that could be used. The comment lacks depth and actionable guidance, leaving the authors without clear direction on how to address the concern or improve their demonstration. As a result, the feedback is not helpful, as it does not provide the authors with meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a desire for a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" While it implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results need to be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, it is not specific, as it lacks detailed guidance on what aspects of the results need to be discussed or how they relate to the lower bounds. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for further exploration and discussion. However, it lacks specific guidance on how to integrate this discussion into the paper or what aspects of the results need to be addressed. While it points out a relevant reference, it does not provide detailed suggestions on how to effectively incorporate this discussion into the paper. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to clarify the assumptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and the significance of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. The reviewer provides a reference to a related work by Dombrowski et al. (2022) to support their claim about the use of PCA. However, the comment lacks detailed explanation or analysis of why the assumptions are unclear or how they impact the paper\"s significance. While the reference provides some context, it does not fully substantiate the claim, making the comment 3. The authors would need to further explore and address the assumptions and their implications to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the novelty and significance of the paper, suggesting that the use of PCA to reduce interaction count is intuitive and that the assumptions made are unclear. It provides a reference to a related work by Dombrowski et al. (2022) to support its claim. While the comment identifies a potential weakness in the paper\"s novelty and significance, it lacks specific guidance on how the authors might address these concerns or what aspects of the assumptions need clarification. The reference to the external work is helpful, but the comment could be more actionable by offering suggestions on how to improve the clarity and significance of the paper. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It asks a question about how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the fewshot RC models considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of these models compared to relation extraction/generation models in fewshot settings. This provides clear guidance on what aspect of the paper needs further exploration or discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim that the fewshot RC models considered in the paper are not stateoftheart models. However, it does not provide any specific references or examples to support this claim, nor does it compare the performance of these models to other models in the field. Without such evidence or comparisons, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the fewshot RC models considered are not stateoftheart models. It raises a relevant question about how the performance of these models compares to relation extraction/generation models in fewshot settings. This feedback is 3 as it prompts the authors to consider a potential limitation in their work and to address it by providing a comparison. However, the comment could be more helpful if it offered specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. However, it does not provide any guidance on how the authors should address this limitation or suggest ways to expand the results to include other network architectures. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results only apply to shallow fullyconnected ReLU networks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the results section, specifically noting that the results only apply to shallow fullyconnected ReLU networks. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand their results to include other network architectures. While it points out an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the background knowledge and literature description. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, such as providing more background knowledge and literature description. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the paper. Without concrete evidence or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s organization, suggesting that it could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and does not provide detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specific steps to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it identifies a potential gap in the comparison, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific models, \"PanopticFPN\" and \"Mask2Former,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these models in the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these models should be included in the comparison. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is valuable as it highlights an area where the paper could be expanded to include more comprehensive comparisons, which could enhance its contribution and rigor. However, the comment lacks detailed guidance on how to address this issue, such as suggesting specific analyses or comparisons that could be conducted. While it points out a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it identifies a relevant area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide results or observations regarding the use of sequential MCB versus a single MCT layer for the decision head. This is a clear and direct request, as it specifies exactly what the authors need to include in their discussion. The action is concrete, as it specifies the exact information that should be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB versus a single MCT layer for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of results or observations regarding this discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the discussion of using sequential MCB versus a single MCT layer for the decision head was interesting but lacks results or observations. However, it does not provide any supporting evidence, reasoning, or examples to substantiate why this discussion is important or how it could be improved. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of interest in the paper, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It points out that while the discussion is interesting, no results or observations are shown, prompting the authors to provide more details. This feedback is 3 as it highlights a gap in the paper that could be addressed with additional information or analysis. However, it lacks specific suggestions on what kind of results or observations would be beneficial, leaving the authors with a general direction but not detailed guidance on how to proceed. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" and requests that the authors proofread the paper to fix all language problems. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should proofread the paper to fix language issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"the above of (7)\" and \"the above of Theorem 1,\" allowing the authors to accurately identify the parts being addressed. It also specifies the language issues, such as \"we typically considers\" and \"two permutation,\" providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of comments on language usage, such as \"we typically considers\" and \"two permutation,\" which are factual observations rather than claims or opinions. It does not contain any subjective judgments, suggestions, or critiques that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" which are minor but important corrections to improve the clarity and professionalism of the writing. Additionally, it encourages the authors to proofread the entire paper to fix all language problems. While the comment provides actionable feedback, it could be more helpful if it offered suggestions on how to improve the language usage or provided examples of better phrasing. Overall, the comment is 3 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address them. The authors can infer that they need to consider these questions, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of 20 distribution sets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the number of distribution sets for each class can be controlled and what the implications would be if only a few distribution sets are selected. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the choice of 20 distribution sets is problematic. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also inquires about the implications of selecting only a few distribution sets. This feedback is 3 as it prompts the authors to consider the potential limitations and consequences of their choice. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these issues. While it highlights an important area for consideration, the lack of detailed guidance limits its utility. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models, which raises concerns about its broader applicability. The reviewer suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation or expand the scope of their framework. The action is implicit and somewhat vague, as the authors need to infer that they should consider broadening the scope of their framework. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluative framework, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited scope of the framework, which is restricted to only three QuestionAnswering tasks and two language models, and raises concerns about its broader applicability. The comment suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, restricted to only three QuestionAnswering tasks and two language models, which raises concerns about its broader applicability. The comment suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. However, the comment lacks specific examples or references to substantiate these concerns, making it 3. The authors would need to infer the potential applicability issues and address them themselves, rather than having clear guidance on how to improve the framework. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. This observation raises concerns about the method\"s broader applicability, as it may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. While the comment highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their framework. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or detailed guidance for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also highlights the issue with using obsolete language models, which adds context and guidance for the authors. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the specific language models used, such as ngram HMM and RNN, which are considered obsolete. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are carried out on obsolete language models, specifically ngram HMM and RNN, which are not commonly used nowadays. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to align the paper with current NLP trends. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to current NLP trends or the relevance of transformerbased models. The authors would need to make an effort to understand and address the suggestion, which justifies a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are carried out on obsolete language models (ngram HMM, RNN) that are no longer commonly used in NLP. It suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the use of more uptodate models. However, the comment could be more helpful if it explained why transformerbased models are preferred or how they might enhance the paper\"s contribution. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments or referencing specific works to support their claims. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplified selfattention model\" and \"theoretical analysis,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also mentions the need to cite the result in Kaplan et al. 2020, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The reviewer references the result in Kaplan et al. 2020 as a potential source of validation. However, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient or how additional experiments would address the issue. The reference to Kaplan et al. 2020 provides some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental setup, noting that the experiments are insufficient to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that more empirical experiments or toy experiments are needed to address this gap. Additionally, it references the result in Kaplan et al. 2020 as a potential source of validation. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their experimental setup and substantiate their claims. By addressing these points, the authors can significantly improve the robustness and credibility of their work. However, the comment could be more helpful if it provided additional details on what specific aspects of the theoretical analysis need validation or how the additional experiments should be designed. Overall, the comment is 4 as it effectively directs the authors to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, making it unclear how it can be estimated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify this issue or what specific steps they should take to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion on the misestimation of mu, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the issue with the estimation of mu, as it is the proportion of missing observations, and how this affects the clarity of the discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the discussion is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated at all. This feedback highlights a gap in the clarity of the discussion, which could be improved by providing more detailed explanations or examples. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, leaving them with only a general direction for improvement. While it points out a relevant area for clarification, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This feedback is explicit and provides concrete guidance on how to implement the suggested approach. The authors know exactly what steps to take to address the issue of sensitivity to initialization. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sensitivity to initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, with a detailed explanation of how to implement this approach. This includes randomly sampling a matrix M^0 within a specific distance range and reporting performance accordingly. The comment is specific in detailing what needs to be addressed and how to implement the suggested approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion for how to implement this approach, including randomly sampling a matrix M^0 within a certain distance range and reporting performance accordingly. This claim is 4 as it logically follows the suggestion with a clear explanation of how to implement it. However, the comment could be strengthened by providing examples or references to similar approaches in the literature, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for addressing the issue of sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, which is a clear and concrete approach. The comment also provides a detailed explanation of how to implement this approach, including randomly sampling a matrix M^0 within a specific distance range and reporting performance accordingly. This feedback is 5 as it offers a clear and practical solution to improve the paper\"s presentation of results. By following this suggestion, the authors can enhance the clarity and robustness of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary use of the absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This is a factual observation about the mathematical definition of the Frobenius norm, which does not require an opinion or subjective judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the Frobenius norm in line 77, noting that the absolute value operation is unnecessary because tensor entries are real numbers. This is a clear and actionable point that can help the authors improve the clarity and accuracy of their draft. By pointing out this oversight, the comment provides the authors with a concrete step to take in revising their manuscript. However, the comment could be more helpful if it offered suggestions on how to better explain or justify the use of the absolute value operation in the context of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the use of ensemble methods and measures of robustness, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to ensemble methods or existing studies that have successfully used these methods. This makes the claim 3, as the authors would need to infer the specifics of how to implement these suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, as it provides a concrete direction for enhancing the paper\"s rigor and robustness. By suggesting specific methods to improve the analysis, the comment empowers the authors to make meaningful enhancements to their draft. However, it could be more helpful if it included examples or references to ensemble methods or similar studies that have successfully achieved highprobability bounds. Overall, the comment is 4 as it provides clear guidance for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation for the work is good but that the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so or provide specific guidance on how to implement these evaluations. The action is implicit and somewhat vague, as the authors need to infer the need for these additional evaluations and determine how to incorporate them into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation for the work is good but the results are less impressive, and it recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these aspects are discussed, the comment lacks full grounding. It is specific in suggesting additional aspects to consider, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation for the work is good but the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, the comment lacks specific examples or detailed reasoning to support why the results are less impressive or how these additional aspects should be evaluated. Without specific examples or references, the claim is 3, as it provides a general direction but lacks the necessary detail for the authors to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, suggesting that they are less impressive despite a good motivation. It recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these additional evaluations or what specific metrics should be considered. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed instructions on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might incorporate diversity into their model or what specific changes could be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s motivation for diversity, specifically mentioning that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the model\"s lack of diversity enforcement, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity in the model. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. This is a critical point as it undermines the paper\"s central argument. However, the comment lacks specificity and actionable suggestions on how the authors might address this issue or improve their model to enforce diversity. Without detailed guidance or examples, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is 3, as it points out a critical weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on how the authors should address this issue or what specific experiments should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence affects the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is 3 as it highlights a potential gap in the experimental setup, which the authors should address to provide a more comprehensive evaluation of their work. However, the comment lacks depth and does not offer suggestions on how to incorporate these experiments or what specific aspects of the paper would benefit from their inclusion. While it points out a potential area for improvement, it does not fully guide the authors on how to address it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion to use DinoV2 Frechet Distances is specific and provides a concrete detail for the authors to implement, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplistic Inception network\" and \"FIDs,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of DinoV2 Frechet Distances for comparisons in addition to the widely used FID metric. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are \"clear flaws associated with FIDs and the simplistic Inception network,\" but it does not provide specific examples or references to support this claim. The suggestion to use DinoV2 Frechet Distances is made without further explanation or justification, leaving the authors without a clear understanding of why this alternative metric is preferred or how it addresses the flaws mentioned. The lack of detailed reasoning or evidence makes the claim 1, as it does not provide sufficient support for the authors to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of FIDs and the simplistic Inception network, noting that there are clear flaws associated with these methods. It provides a clear and actionable suggestion by recommending the use of DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is valuable as it directs the authors to consider an alternative method that could potentially improve the robustness and accuracy of their evaluations. However, the comment could be more helpful if it explained why DinoV2 Frechet Distances are preferred over FIDs or provided examples of their use in similar contexts. Overall, the comment is 4 as it offers a concrete suggestion for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the novelty of the paper and asks for clarification on how it differs from a specific reference. While it implies that the authors should provide a comparison with the referenced work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed comparison or explanation of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not specify which part of the paper should be addressed or where the novelty is lacking. The authors can infer that it relates to the introduction or methodology sections, but this inference is not direct. The comment is specific in its request for a comparison with the reference, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the novelty is incremental. Without such information, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. While it identifies a potential issue with the paper\"s novelty, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the paper\"s originality. The comment lacks actionable feedback or detailed insights into what aspects of the paper could be improved or expanded upon. As a result, it offers limited value to the authors in terms of improving their draft. Therefore, the comment is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them without a clear path forward. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"CUB and SOP datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the reported ablation studies, where the complete loss function performed worse than those with missing terms. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. This observation raises a valid concern about the validity of the results and prompts the authors to question why this might be the case. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions that this would allow for inspection of the longrange inference capacity of the model. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. The action is explicit and concrete, as it clearly specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions the need to inspect the longrange inference capacity of the model. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for the experiment. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the longrange inference capacity of the model. The reviewer provides a logical reasoning for why this experiment would be beneficial, noting that it would simulate realworld scenarios where keypoint detection may fail. However, the comment lacks specific examples or references to similar experiments in the literature, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by suggesting an experiment where the image is occluded to simulate irregularity in neural/behavioral data. This experiment would allow the authors to inspect the longrange inference capacity of the model, which is a valuable addition to the study. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. This feedback is 5 as it offers a specific and meaningful enhancement to the paper, providing clear guidance for the authors to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer recommends using a second yaxis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not specify which alternative visualization should be used or how to implement the change. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests using a second yaxis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. However, the comment lacks specific reasoning or examples to support why Figure 6C is awkward or how it implies negative rates. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when it should represent positive rates. The reviewer suggests a solution by recommending the use of a second yaxis or another visualization that is more physically accurate. This feedback is clear and actionable, providing the authors with a concrete step to improve the accuracy and clarity of their figure. However, the comment could be more helpful if it included additional details on how to implement the suggested changes or examples of alternative visualizations. Overall, the comment is 4 as it effectively guides the authors on how to address a specific issue in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their approach. While the comment implies that the authors should conduct these tests, it does not explicitly instruct them to do so. The action is concrete, as it specifies a specific test that could be conducted, but it is somewhat vague because it does not provide detailed guidance on how to implement these tests or what specific models should be tested. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment is specific in suggesting a potential test, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be useful in other embedding models besides CP, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to other models where inverse triples could be applied, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors test inverse triples in other embedding models besides CP. This is a relevant point as it could provide additional insights into the effectiveness of their approach. However, the comment lacks specific guidance on which models should be tested or how to implement these tests. While it highlights a potential area for improvement, it does not offer detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. It also implies that technical details are not necessary for the abstract. While the comment provides a clear action\u2014to clarify the statement and simplify the abstract\u2014it does not offer specific guidance on how to achieve this clarity or what aspects of the statement are unclear. The authors are left to infer the necessary changes, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement regarding the lowrank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technical details are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. The reviewer provides a specific example of the unclear statement, \"with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions,\" which is highlighted as problematic. However, the comment lacks detailed reasoning or examples to support why this statement is unclear or how it could be clarified. Without additional context or explanation, the claim is 3, as it provides a specific example but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, pointing out that the statement regarding the lowrank feature subspace, a small number of attacked samples, and other mild assumptions is unclear. It suggests that the abstract should be more highlevel and that technical details are not necessary. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending a more concise and simplified abstract. However, the comment could be more helpful if it offered specific guidance on how to achieve this clarity or what aspects of the statement are confusing. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left to infer that they need to make changes to the algorithm, but without concrete instructions or examples, they may struggle to determine the exact steps to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper discusses Algorithm 2 or where it is located. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of Algorithm 2 need improvement or how to achieve this improvement. Without clear guidance or examples, the authors may struggle to understand and address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that there is room to improve the complexity of Algorithm 2, which is a valuable observation. However, it lacks specificity and does not provide any guidance on how to achieve this improvement or what aspects of Algorithm 2 need attention. Without actionable advice or examples, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, as it identifies an area for improvement but does not offer sufficient guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It also provides a rationale for why expected test loss might not be as meaningful for languagerelated tasks. However, the comment does not explicitly instruct the authors to include these results or provide guidance on how to incorporate them into the paper. While the suggestion is clear, the lack of concrete steps or detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, specifically mentioning languagerelated tasks. It also provides a rationale for why expected test loss might not be as meaningful for languagerelated tasks. However, the comment does not specify which part of the paper should include these results or how they should be integrated. While the authors might have an idea of where to include these results, the lack of explicit guidance makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. The comment provides a rationale for why expected test loss might not be as meaningful for languagerelated tasks, suggesting that people care more about OOD performance. However, the comment lacks specific examples or references to support the claim that expected test loss is not as relevant for languagerelated tasks. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It provides a rationale for why expected test loss might not be as meaningful for languagerelated tasks, suggesting that people care more about OOD performance. This feedback is 3 as it identifies a potential area for improvement and provides a logical basis for the suggestion. However, the comment could be more helpful if it offered specific guidance on how to incorporate these results or what aspects of OOD performance should be prioritized. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. It highlights the importance of considering how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment implies that the authors should provide more detailed justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot situation for graph link prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not consider how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. The reviewer suggests that the paper defines and creates a fewshot situation but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the method does not effectively use \"fewshot.\" This makes the claim 3, as the authors would need to further develop the reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the motivation of the work, specifically in the context of fewshot learning. It points out that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. This feedback is valuable as it highlights a gap in the paper that the authors need to address to strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to effectively use \"fewshot\" or how to ensure generalizability. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not provide explicit guidance on how the authors should address this critique or improve their approach. It lacks actionable details, such as recommending specific ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not specify which part of the paper discusses the use of GP, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where GP is discussed, the comment lacks full grounding. It is specific in detailing the critique of the approach, but without explicit references to the paper sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of Gaussian Processes (GP) is straightforward and naive, suggesting that the approach is not novel. The reviewer supports this claim by referencing the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. This reference provides a basis for the claim, but it does not offer detailed reasoning or examples to fully substantiate the critique. The authors might need to explore the literature further to understand the specific aspects of the critique. Therefore, the comment is 3, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific guidance on how the authors might address this critique or improve their approach. It does not provide actionable suggestions or examples of how to enhance the novelty or innovation of the work. As a result, the comment is 3, as it points out a potential issue but does not offer detailed feedback for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the statement in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. It points out that this claim is not supported by the authors\" experience, as evidenced by the training of 1500dimensional LSTMs on PTB. The reviewer also asks about the application of dropout to both embeddings and hidden states. While the comment identifies a specific issue with the statement, it does not provide explicit guidance on how to address it or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and provide evidence or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that smaller architectures are necessary for LM compared to GAN models, suggesting that the baseline models are not properly regularized. The reviewer also asks about the application of dropout to both embeddings and hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, suggesting that the baseline models are not properly regularized. This provides a logical and 3 argument against the claim, as it challenges the basis of the statement. However, the comment could be strengthened by providing more detailed evidence or references to support the counterexample. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim in the supplemental section D.4 that is questionable, suggesting that the statement about smaller architectures being necessary for LM compared to GAN models is not supported by the authors\" experience. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, which challenges the claim that baseline models are not properly regularized. Additionally, the comment asks about the application of dropout to both embeddings and hidden states, which could be a relevant consideration for the authors to address. While the comment identifies a potential weakness in the paper, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their analysis. Therefore, the comment is 3, as it points out a potential problem but does not provide comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to locate. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of the writing, but without concrete steps on how to achieve this. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"previous sections\" and \"the following contents,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ablations being difficult to locate in the writing, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without specific examples or references, the claim lacks verifiability, making it challenging for the authors to improve their draft based on this feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the writing, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback is valuable as it highlights an area where the authors can improve the readability and accessibility of their work. However, the comment could be more helpful if it provided specific examples of where the ablations are difficult to locate or suggested ways to improve the clarity of the writing. Despite this, the comment still offers actionable guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty of the online algorithm and robustness, which should be integrated into the main paper. However, the comment does not provide specific guidance on how to improve the differential privacy application or what aspects need more clarity. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to address the issues. As a result, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also mentions the online algorithm and robustness as being interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application, making it weakly grounded. The comment is specific in its critique of the differential privacy application and the suggestion to integrate the online algorithm and robustness into the main paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. However, the comment does not provide specific reasoning or examples to support this claim. It mentions the online algorithm and robustness as being interesting and novel, but this does not address the issue of the differential privacy application being \"halfbaked.\" The lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to understand and address the issue without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a general critique of the differential privacy application, suggesting that it is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which should be integrated into the main paper. However, the comment lacks specific suggestions or guidance on how to improve the differential privacy application or integrate the online algorithm and robustness into the main paper. While it identifies areas for improvement, the feedback is 3 as it points out potential weaknesses but does not provide actionable steps for the authors to address them. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their work. There is no explicit or implicit action for the authors to take, such as suggesting ways to enhance the contribution or providing examples of how to differentiate the two approaches. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, but it does not specify which part of the paper this comparison is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered incremental or how the authors might address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this comparison and how it affects the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, suggesting that the former is incremental. However, it does not provide any specific insights or suggestions on how the authors might address this issue or improve their work. Without actionable feedback or guidance, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the methodology need to be adjusted. The action is implied and somewhat vague, as the authors need to infer that they should consider using robotic manipulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to use robotic manipulation, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current methodology is insufficient or why robotic manipulation would be more appropriate. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the proposed methodology may not be specific to bimanual manipulation. It recommends using robotic manipulation instead, which could be more appropriate. This feedback is 3 as it points out a potential area for improvement, but it lacks specific guidance on how to implement this change or what aspects of the methodology need to be adjusted. The authors are given a direction to consider, but the comment could be more actionable with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to include the METEOR results, which are reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is specific and provides concrete guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the inclusion of METEOR results, which is a specific aspect of the paper. However, it does not specify which part of the paper should include these results, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the METEOR results in the paper. The comment is specific in its request for the inclusion of METEOR results, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include the METEOR results, which are reported in recent works. However, the comment does not provide any supporting evidence, references, or reasoning to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include the METEOR results, which are reported in recent works. This is a clear and actionable suggestion that can help improve the paper by providing additional evidence or comparison to other studies. However, the comment lacks depth and does not explain why the inclusion of these results is important or how they might enhance the paper. While it identifies a specific area for improvement, it could be more helpful if it provided more context or justification for the inclusion of these results. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the comparability of Geffect values or recommending specific analyses or comparisons to be made. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. It points out that studying Geffects of each learning objective in isolation raises questions about the validity of these comparisons. This feedback is 3 as it highlights an area that the authors should consider addressing, but it lacks specific suggestions or guidance on how to improve the comparability of Geffect values. The comment could be more helpful if it provided examples or additional context to help the authors understand and address the issue. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the results, specifically the advantage of UNIFORM over other procedures, which is not consistent across the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting. Additionally, the comment praises the clarity and welldesigned experiments, providing a clear direction for improvement. However, the comment does not specify which tables or sections need clarification, making it 3. The authors are given a general idea of what needs to be addressed, but the lack of specific guidance on how to implement the suggested clarification makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"tables\" and the \"1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the advantage of UNIFORM over other procedures, noting that the tables show that UNIFORM does not always offer a clear advantage. Additionally, it asks for clarification on why the method is not as effective in the 1shot setting and praises the clarity and welldesigned experiments. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables, and questions whether the authors have a theory to explain this. The comment also praises the clarity and welldesigned experiments, providing a 3 basis for the claim about the advantage of UNIFORM. However, the comment lacks specific examples or references to the tables or experiments that support the claim, making it 3. The authors would need to further investigate the tables and experiments to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the results, specifically the advantage of UNIFORM over other procedures, which is not consistent across the tables. It prompts the authors to clarify why the method is not as effective in the 1shot setting, providing a clear direction for improvement. Additionally, the comment praises the clarity and welldesigned experiments, offering positive feedback that can help guide the authors in enhancing their draft. However, the comment could be more helpful if it provided specific suggestions on how to address the discrepancy or how to improve the clarity of the results. Overall, the comment is 4 as it highlights a critical area for improvement and offers constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider the reason why information value is a stronger predictor for dialogue, and if there is any existing linguistic theory that could explain it. It also recommends adding this information to make the paper stronger. While the comment implies that the authors should explore this topic, it does not provide specific guidance on how to integrate this information into the paper or what specific linguistic theories to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This provides clear guidance on what the authors need to consider and explore in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. The comment implies that adding this information would strengthen the paper. However, it does not provide specific examples or references to existing linguistic theories or studies that could support this claim. Without such evidence or detailed reasoning, the claim is 3, as it requires the authors to make a significant effort to explore and substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a potential area for improvement by suggesting that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This feedback is clear and actionable, as it prompts the authors to explore a specific aspect of their work that could enhance its theoretical foundation and rigor. However, the comment could be more helpful if it provided specific suggestions on how to integrate this information or what linguistic theories to consider. Overall, the feedback is valuable in guiding the authors to strengthen their paper, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance, specifically mentioning the extraction of hints for future network architecture design. It implies that the authors should provide more detailed commentary on these aspects, such as the biggest takeaways from the found architecture. However, the comment does not explicitly instruct the authors to include this discussion or specify what aspects should be covered. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AutoML approaches and the potential benefits beyond raw performance, such as extracting hints for future network architecture design. It also specifies the lack of discussion on these aspects, providing clear guidance on what the authors should address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main reason for using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without concrete evidence or detailed reasoning, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance. It highlights the importance of extracting hints for future network architecture design and suggests that the authors should provide more detailed commentary on these aspects. While the comment points out a relevant issue, it does not offer specific suggestions or guidance on how to address this gap in the discussion. The authors are given a direction to consider but are left without actionable steps to improve their draft. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is an explicit observation that the authors can directly address by providing the definition in the appropriate section. The comment is clear and concrete, as it specifies the exact issue and suggests a straightforward action to resolve it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the use of T_a(t) in Section 3.1 but only being defined in Section 4. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation that does not require any subjective judgment or opinion. It is a statement of fact that can be verified by the authors themselves, as it is directly observable from the paper. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper regarding the use of T_a(t) in Section 3.1 but only being defined in Section 4. This is a clear and actionable observation that the authors can address to improve the consistency and clarity of their work. By pointing out this issue, the comment provides the authors with a specific area to focus on for revision, ensuring that the definition is in the appropriate section. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or completeness of the definition in Section 4. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While the action is implicit, it is clear that the authors need to condense the introduction and include empirical results to enhance the paper. The comment provides a specific direction for improvement, but it lacks detailed guidance on how to achieve this concision or which empirical results should be included. Therefore, the action is 3, as the authors know they need to make changes but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, it does not specify which part of the introduction is too long or where empirical results should be included. The authors can infer that the introduction and empirical results sections are being addressed, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, the comment does not provide any specific examples or reasoning to support why the current introduction is too long or how empirical results could enhance it. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While it identifies a potential area for improvement, it lacks specific guidance on how to achieve this concision or which empirical results would be most relevant. The comment provides a general direction for improvement but does not offer detailed suggestions or examples to help the authors effectively enhance their draft. As a result, the feedback is 3, as it points out an area for improvement but does not fully support the authors in making those changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the clarity of the empirical analysis in Figure 3 and requests additional clarification on the adjustments made to the input series and forecasting target based on the Frequency Stability score. It also asks for an explanation of why these adjustments enhance the model\"s performance. While the comment provides specific questions that the authors need to address, it does not offer concrete guidance on how to present this information or what specific details should be included. The action is explicit but somewhat vague, as the authors know they need to provide clarification but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the adjustments made to the input series and forecasting target based on the Frequency Stability score and the explanation of why these adjustments enhance the model\"s performance. The comment also points out the spacing issue in Equations (9) and (10), providing specific details for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the empirical analysis in Figure 3, specifically questioning the adjustments made to the input series and forecasting target based on the Frequency Stability score. The reviewer requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also references external work by Liu et al. (2022) to provide context. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the adjustments are confusing or unclear. While it raises valid points, the lack of detailed justification makes the claim 3, as the authors would need to provide more information to fully address the reviewer\"s concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific area of confusion in the empirical analysis, specifically the adjustments made to the input series and forecasting target based on the Frequency Stability score. It requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also points out that Equations (9) and (10) have large spacing from the preceding text, which is a minor but relevant observation. This feedback is 4 as it guides the authors to clarify and enhance the clarity of their analysis, which is crucial for effective communication of their results. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the recent related work, CoCoOp, should be compared in the experiments. It provides a clear and direct action for the authors to take, specifying that they should include a comparison with CoCoOp in their experiments. This guidance is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the related work \"CoCoOp\" and its comparison with CoCoOp in the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with CoCoOp in the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work, CoCoOp, should be compared in the experiments. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting that the recent related work CoCoOp, which is a CVPR\"22 work, is not compared in the experiments. This is a clear and actionable point, as it highlights a gap in the experimental analysis that could enhance the paper\"s comprehensiveness and relevance. By suggesting the inclusion of a comparison with CoCoOp, the comment provides the authors with a direct and constructive suggestion for improvement. However, the comment could be more helpful if it offered additional context or insights into why this comparison is important or how it might impact the paper\"s conclusions. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, automatic scoring, and where model training is used to optimize the selection modules. While the comment provides a clear direction for improvement, it does not specify how to enhance the figure or what specific elements should be added or changed. The authors are left to infer the details of how to implement these suggestions, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, including suggestions for enhancing the figure to show the processing pipeline more clearly. The comment details the elements that should be included, such as prompt generation, manual check, demonstration selection, ground truth scores, automatic scoring, and model training optimization. This level of detail provides a clear path for the authors to follow in making improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation, manual check, demonstration selection, ground truth scores, automatic scoring, and model training optimization. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these elements are necessary or how they would enhance the figure. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the clarity and comprehensiveness of Fig. 1. It suggests adding elements such as prompt generation, manual check, demonstration selection with ground truth scores, automatic scoring, and model training optimization to the processing pipeline. This detailed guidance helps the authors understand what aspects of the figure need improvement and how to enhance it to better convey the research. However, the comment could be more helpful if it included examples or references to similar figures or studies that effectively illustrate these elements. Overall, the comment is 4 as it provides clear and actionable suggestions for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for testing on more complex games, but it is somewhat vague in detailing how to implement this additional testing. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as testing on more complex games, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems, specifically mentioning the issue of input size for value and policy functions. However, the comment lacks specific examples or references to support the claim that these complex problems are necessary for testing ReBeL. Without detailed evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. This feedback is 3 as it points out a potential gap in the experimental setup and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples of complex games or detailed guidance on how to implement the additional testing. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove abbreviations like \"MoCo\" from section headers, as they might not be familiar to readers. This is a clear and direct action that the authors can take to improve the clarity of their draft. The comment provides concrete guidance on what to remove, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of abbreviations like \"MoCo\" in section headers. This provides clear guidance on what the authors need to change to improve the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the reader\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper. By pointing out that abbreviations like \"MoCo\" should not appear in section headers, the reviewer highlights a potential source of confusion for readers who might not be familiar with the term. This feedback is clear and direct, offering a straightforward way for the authors to enhance the accessibility of their work. However, the comment could be more helpful if it provided additional context or examples of how this change would improve the clarity of the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors could clarify the technical contribution or make the analysis more novel. There is no explicit or implicit action for the authors to take, such as suggesting new analyses or methods to differentiate their work. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are unclear or where the analysis is standard. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need clarification or improvement. The comment lacks both grounding and specificity, making it 1 at all. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide specific examples or detailed feedback on how the authors could clarify the technical contribution or make the analysis more novel. Without actionable suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors should present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence or arguments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not specify which part of the paper discusses this advancement or where the authors should provide additional evidence or arguments. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in suggesting that more substantial evidence or arguments are needed, but without clear guidance on where to apply this, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s contribution, suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. It acknowledges that this is a significant contribution but points out the need for more substantial evidence or arguments to establish it as such. While the comment highlights an area for improvement, it does not provide specific guidance on how the authors might present their evidence or arguments more effectively. The feedback is 3 as it directs the authors\" attention to a potential gap in their paper, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been extensively explored in previous works. It implies that adding topic entities is incremental and does not provide a clear direction for improvement. However, the comment lacks explicit guidance on how the authors could address these concerns or what specific changes could be made to enhance the novelty or impact of their work. Without concrete suggestions or actionable steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been extensively explored in previous works. However, it does not specify which datasets or aspects of the paper are being referred to, making it difficult for the authors to pinpoint the exact parts that need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the authors could address these concerns. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been extensively explored in previous works. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed evidence or reasoning, the claim is not verifiable, as it does not provide sufficient justification for the authors to improve their work. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been extensively explored in previous works. It implies that adding topic entities seems incremental and does not provide a clear direction for improvement. However, the comment lacks specific suggestions or actionable feedback on how the authors could address these concerns or enhance the novelty or impact of their work. Without detailed guidance or constructive feedback, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it does not specify what aspects of the discussion should be included or how it should be structured. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspects of the theoretical guarantee are missing or how the authors should address this issue. The comment is specific in identifying the lack of discussion but lacks detailed guidance on how to improve it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, specifically the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a relevant point that could enhance the paper\"s theoretical foundation and provide additional insights into the method\"s performance. However, the comment does not offer suggestions or guidance on how the authors might address this gap in the discussion. While it highlights an important area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate quantitative measures or what specific metrics should be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to include quantitative measures but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a quantitative measure to evaluate the generated VCEs, and notes that evaluation is mainly performed with visual inspection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by noting the lack of quantitative measures to evaluate the generated VCEs. It highlights that the evaluation is mainly performed with visual inspection, which is a relevant point for the authors to consider. However, the comment does not provide detailed guidance on how to incorporate quantitative measures or what specific metrics should be used. While it points out a weakness, it lacks actionable suggestions or examples that would help the authors address this issue effectively. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method only provides marginal improvements over baselines, with most improvements within the error bar range. It also notes that the authors claim the method performs better than the baselines, but the high error range suggests that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of their method. The action is implicit and vague, as the authors are left to infer that they need to improve the performance of their method, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, suggesting that the improvements are marginal and within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the high error range suggests otherwise. However, the comment does not specify which part of the paper discusses these claims or the baselines, making it weakly grounded. The comment is specific in its critique of the performance improvements and the high error range, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method provides only marginal improvements over baselines, with most improvements within the error bar range. The reviewer questions the authors\" claim that the method performs better than the baselines, noting the high error range. This claim is 3 as it provides a logical reasoning for questioning the authors\" claims, but it lacks specific examples or detailed evidence to fully substantiate the argument. The authors would need to further explore the data or provide additional analysis to fully address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It questions the authors\" claim that the method performs better than the baselines, given the high error range. This feedback is 3 as it points out a potential weakness in the paper\"s claims, but it lacks specific suggestions or guidance on how the authors might address this issue or improve the performance of their method. While it highlights an area for improvement, the comment could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights issues with the generated videos, specifically noting significant artifacts and questioning the action recognition performance compared to stateoftheart methods. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it guide the authors on how to address the issues raised. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the generated videos, specifically mentioning artifacts and the action recognition performance on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment does provide some specificity by questioning the action recognition performance compared to stateoftheart methods, which suggests that the authors should address this aspect. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and questions the action recognition performance compared to stateoftheart methods. However, it does not provide specific examples or detailed reasoning to support these claims. The mention of artifacts and action recognition performance is vague, and the comparison to stateoftheart methods is not substantiated with specific references or detailed analysis. This lack of supporting evidence or detailed reasoning makes the claim 2, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the generated videos, noting significant artifacts and questioning the action recognition performance compared to stateoftheart methods. However, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. The comment highlights a problem but does not offer constructive feedback or specific steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the proposed evaluation set more diverse and representative than the previous method and how to select representative images. However, it does not provide any explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more details or examples, but it does not specify what those details or examples should be. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of diversity and representation in the proposed evaluation set, specifically mentioning the need for more diverse and representative images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as how to make the evaluation set more diverse and representative, and how to select representative images. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed evaluation set is unclear in terms of diversity and representation, and that the authors need to provide more details on how to select representative images. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without concrete evidence or reasoning, the claim is not verifiable, as it does not provide a clear path for improvement. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed evaluation set, specifically the lack of clarity on how to make it more diverse and representative than the previous method and how to select representative images. This feedback is valuable as it highlights a key area where the authors need to provide more detailed explanations or examples to ensure their evaluation is comprehensive and accurate. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues, such as recommending specific criteria or methods for selecting representative images. Overall, the comment is 3 as it points out a significant gap in the paper but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. These actions are clear and concrete, as they specify exactly what needs to be added to the paper. The authors know exactly how to apply these suggestions to improve the clarity and understanding of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, and suggests providing a brief overview of the original DPO algorithm. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included to improve the clarity and understanding of the RL context and the modifications proposed in the methods section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This claim is 3 as it logically suggests that a background section would enhance the clarity and understanding of the paper. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting the inclusion of a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is valuable as it directly addresses the need for a more comprehensive introduction to the RL context, which can significantly improve the clarity and accessibility of the paper. By addressing these points, the authors can enhance the reader\"s understanding of the work and its contributions. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method to accommodate continuous language addition. The comment lacks actionable guidance or specific steps for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a potential limitation of the proposed method, specifically the issue of handling continuous addition of new languages due to the limited model capacity. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the method, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may encounter a limitation due to the limited model capacity when users continuously add new languages. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. This is a relevant point that could impact the scalability and applicability of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or improve the method to accommodate continuous language addition. Without actionable advice or detailed feedback, the comment offers some insight but does not fully support the authors in improving their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). While it does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it implies that the authors should consider the relevance of the term in the context of their work. The action is implicit but clear, as the authors can infer that they need to evaluate the relevance of the term and potentially revise their work accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), providing a clear direction for the authors to consider the context and implications of this term in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), which is cited in the paper. This question prompts the authors to consider the context and implications of the term in their work, potentially leading to a deeper understanding and clarification of their ideas. However, the comment does not provide specific guidance or suggestions on how to address this issue, nor does it offer actionable advice on how to incorporate the reference or clarify the relevance of the term. While it points out a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, it does not provide specific guidance on which datasets to include or how to conduct the additional experiments. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, but it does not specify which part of the paper this limitation is discussed in. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying the issue of limited datasets being used for experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the validity or applicability of the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment points out a limitation in the experiments, specifically that they are limited to MNIST and a single realworld dataset. This feedback highlights an area where the authors could potentially expand their experiments to include a more diverse set of datasets, which could enhance the generalizability and applicability of their results. However, the comment does not provide specific suggestions on which datasets to include or how to conduct the additional experiments. While it identifies a potential weakness, it lacks actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should provide more information about the parameters and their impact on efficiency, but it lacks concrete steps or examples to follow. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the number of parameters does not change when the kernel height/width remains the same, and it suggests that more details are expected regarding the efficiency improvements. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. The reviewer provides a logical reasoning by explaining that if the kernel height/width remains the same, the depth will increase, resulting in more parameters. However, the comment lacks specific examples or references to support the claim about the number of parameters or the efficiency improvements. While the reasoning is somewhat clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure regarding the number of parameters and suggests that more details are expected regarding the efficiency improvements. It provides a logical explanation of how the depth of the structure could increase with the same kernel height/width, resulting in more parameters. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional details should be included. While it points out a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or differentiate their method from [10]. The comment lacks actionable details, such as recommending specific modifications or discussions to be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"approach in [10],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the approach in [10] cannot use the additional information, such as scoring causal predictions and interventional data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. It questions why [10] cannot use these side information. While the comment identifies a potential issue with the originality of the proposed method, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from [10]. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results from the Atari game are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the interpretability of their results. There is no guidance on whether they should expand the experiment to include more games or baselines, or how they might present their findings more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the interpretation of the Atari game results, specifically noting that the results are limited to a single game and a single baseline. This feedback highlights an area where the authors could improve the clarity and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional experiments or analyses. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This implies that the model may not be incentivized to use fewer factors, leading to an increase in the number of factors and increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they need to consider adding a sparsity constraint, but without concrete instructions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"factorized model with an IBP prior,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which leads to increased computation with more tasks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which leads to increased computation with more tasks. The comment provides a logical reasoning by explaining the potential consequences of this lack of constraint, namely that the model will not be incentivized to use fewer factors. However, the comment does not provide specific examples or references to support this claim, such as data or studies that demonstrate the impact of sparsity constraints on computational efficiency. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation highlights a potential limitation of the model, which could lead to increased computation with more tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate its impact. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be addressed in the paper. The comment is 5 as it offers a specific guidance on how to improve the draft by clarifying the rationale behind the simulation results.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comment, which is that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). The comment suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study does not provide a clear explanation for why the GPC (benchmark) is performing better than BPC (the authors\" method). The reviewer suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. While the comment identifies a specific issue with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion is 3 as it points out a potential gap in the explanation but requires more detailed evidence or examples to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. This feedback is clear and actionable, as it provides a concrete suggestion for how the authors can improve their draft by addressing the lack of explanation regarding the simulation results. By addressing this point, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered additional context or examples to support the claim. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. It provides a historical context by mentioning the use of ReLUs in the AlexNet paper, which was considered deep at the time. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim. While it implies that the authors should provide more detailed information or examples, the action is not directly stated. The comment is 3, as it provides a direction for improvement but lacks concrete guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks.\" It provides a historical context by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling. However, the comment does not specify which part of the paper this claim is made in, nor does it provide detailed guidance on how to quantify or clarify the claim. While the authors might have an idea of where this claim is made, the lack of explicit grounding makes it difficult to pinpoint the exact section. The comment is specific in suggesting a potential improvement but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. The reviewer provides a historical context by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling. This reference provides some support for the claim, as it suggests that ReLUs were used in a deep network, but it does not fully substantiate the claim itself. The comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or specific examples to fully support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. It provides a historical context by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling. This feedback is 3 as it identifies a potential area for improvement by suggesting a quantification or clarification of the claim. However, the comment lacks specific guidance on how to quantify or clarify the claim, which would make it more actionable. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It implies that the authors should provide more information about the calculation method or clarify the discrepancy between the reported perplexities and the better BLEU scores. While the comment does not explicitly instruct the authors to provide this information, it clearly points out a potential issue that needs to be addressed. Therefore, the comment is 4, as it provides a clear direction for the authors to improve their draft by explaining the perplexity calculation method or addressing the discrepancy.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexities, which are over 30, and suggests that this high perplexity contradicts better BLEU scores. The comment further asks how the perplexity was calculated, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reported perplexities in Figure 1, suggesting that they are high and contradict better BLEU scores. However, it does not provide any evidence or reasoning to support this claim, such as specific examples or references to similar studies. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It suggests that this high perplexity contradicts better BLEU scores, which is an important observation that could impact the interpretation of the results. By questioning the methodology, the comment prompts the authors to clarify their approach and potentially improve the accuracy or interpretation of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or what aspects of the calculation might be problematic. Overall, the comment is 4 as it identifies a potential weakness and prompts the authors to consider a critical aspect of their methodology."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the evaluation should include experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, specifying exactly what additional experiments are needed to improve the draft. The comment is specific and concrete, giving the authors a clear path to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for additional experiments, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or examples to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is 3 as it identifies a potential area for improvement in the evaluation section. However, it lacks specific guidance on how to implement these experiments or what aspects of the evaluation would be enhanced by including them. The comment could be more helpful if it provided suggestions on how to design and conduct these experiments, or how they would impact the overall evaluation. As it stands, the comment offers a direction for improvement but does not fully support the authors in making those changes. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors need to elaborate on the importance of rooted patterns and how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback provides clear and concrete actions for the authors to take, such as elaborating on the importance of rooted patterns or discussing nonrooted patterns in the supplementary material. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concept of \"rooted patterns\" and how they are defined, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of elaboration on why rooted patterns are important and how they are chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not elaborate on the importance of rooted patterns or how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, that the discussion should be moved to the supplementary material. The comment provides a logical reasoning for the need to clarify these aspects, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more detail or clarification. It points out that the concept of rooted patterns is defined in a similar way to orbit counting in GSN, but it does not elaborate on why rooted patterns are important or how they are chosen. The comment suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and completeness of their explanation. However, it could be more helpful if it provided specific suggestions on how to elaborate on the importance of rooted patterns or how to choose the roots. Overall, the comment is 4 as it directs the authors to a critical area needing further explanation and provides a path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more explanations on the consistency between training and inference, specifically mentioning lines 9597 and 308310. While the comment implies that the authors should elaborate on the smoothness of neural models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanations. However, the comment does provide a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the lack of explanation regarding the consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks explanations regarding the consistency between training and inference due to the smoothness of neural models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it claims consistency between training and inference due to the smoothness of neural models but lacks adequate explanations. It suggests that the authors should provide more detailed explanations on this topic. While the comment highlights an area for improvement, it does not offer specific guidance or examples on how to enhance the explanation. This limits its helpfulness, as the authors are given a direction but not detailed steps to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It asks for clarification on whether the proposed model improves with larger word embedding and LSTM parameters. While the comment implies that the authors should provide evidence or experiments to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional experiments or evidence to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about superior performance with fewer parameters, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have tested the model with standard parameter settings in the baseline model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. The reviewer requests evidence or experiments to support the claim, indicating a need for further clarification. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional information or experiments to fully substantiate the claim, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It questions whether the proposed model improves with larger word embedding and LSTM parameters, which is a relevant and important point for the authors to address. The comment provides a clear direction for the authors to provide evidence or experiments to support their claim, which could significantly impact the paper\"s credibility and impact. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the availability of the environment or a good OPE method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these hyperparameters are introduced, the comment lacks full grounding. It is specific about the issue of finetuning and the dependence on the environment or OPE method, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains 1, as it does not provide sufficient justification for the authors to make improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. This feedback is 3 as it points out a potential problem that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to ensure the availability of the environment or a good OPE method. Without actionable advice or detailed explanation, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the application of regularization between the LN model and GLMs. It suggests that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al., to ensure a fair comparison. While the comment implies that the authors should make an effort to replicate the previous model, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the LN model and the GLMs, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the application of regularization between the LN model and GLMs, and suggests that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors apply regularization to both LN models and GLMs, which is not consistent with the GLM presented by Pillow et al. The reviewer suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment lacks specific examples or references to the GLM by Pillow et al. to fully substantiate the claim. While the reviewer provides a logical reasoning, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the application of regularization between the LN model and GLMs, suggesting that the authors should try to reproduce the main features of previous models, particularly the GLM presented by Pillow et al. This feedback is 3 as it points out a potential issue in the comparison between models and provides a direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to reproduce the main features of the previous model or what aspects of the comparison should be emphasized. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the paper should include failure cases and related discussions. While it implies that the authors should add this content, it does not provide specific guidance on how to structure or present these cases or discussions. The action is implicit and somewhat vague, as the authors need to infer that they should include these elements but are not given detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include failure cases and related discussions. However, it does not specify which part of the paper should include these elements, such as specific sections or figures. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting the inclusion of failure cases and discussions, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including failure cases and related discussions would be beneficial. However, it does not provide any reasoning, examples, or references to support why this addition would be valuable or necessary. Without specific justification or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the paper should include failure cases and related discussions, which could provide valuable insights into the limitations and robustness of the work. However, the comment lacks specificity and does not offer guidance on how to structure or present these cases or discussions. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that an ablation study on the necessity of the base layer GNN encoding would be helpful. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to understand the role of the base layer GNN encoding in the proposed method. The comment is specific in its request, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the necessity of the base layer GNN encoding and the need for an ablation study. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to understand its role. However, the comment does not provide specific reasoning or evidence to support why the base layer GNN encoding is unnecessary or how an ablation study would benefit the paper. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the suggestion without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to understand the role of this layer and its impact on the overall performance. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to improve their draft by conducting an ablation study. By addressing this point, the authors can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a discrepancy in the use of \u03b4 in equations (10) and (11) and suggests introducing \u03b4 when (11) is discussed. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"equation (11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent use of \u03b4 in equations (10) and (11) and suggests introducing \u03b4 when (11) is discussed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \u03b4 is not used in equation (10) but is used in equation (11). It suggests introducing \u03b4 when (11) is discussed. This claim is 3 as it provides a specific observation about the inconsistent use of \u03b4 in equations, which could be a source of confusion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of \u03b4 in equations (10) and (11), noting that \u03b4 is not used in equation (10) but is used in equation (11). It suggests introducing \u03b4 when (11) is discussed, which could improve clarity. This feedback is clear and actionable, as it provides a concrete suggestion for how the authors can improve the consistency and clarity of their equations. However, it could be more helpful if it included a rationale or explanation for why this inconsistency is problematic or how it affects the overall understanding of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or reasoning."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also suggests that the authors should elaborate on empirical runtimes, which adds another actionable point. Therefore, the comment is 5, as it provides clear guidance on how to enhance the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the computational complexity of counting homomorphisms, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for explicit bounds of counting and potential elaboration on empirical runtimes. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms. The reviewer provides a specific example of a brief statement made by the authors, which is \"Better still, homomorphism counts of small graph patterns can be efficiently computed even on large datasets\" (L 145). The reviewer suggests that adding explicit bounds of counting and potentially elaborating on empirical runtimes would be beneficial for the paper. However, the comment lacks specific examples or references to support the claim that these additions would improve the paper. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper, namely the discussion of computational complexity in counting homomorphisms. It points out that the authors make brief statements without providing explicit bounds or elaborating on empirical runtimes, which are crucial for understanding the practical implications of their work. The comment suggests that adding these details would enhance the paper\"s clarity and depth. While it highlights an important area for improvement, it could be more helpful by providing specific examples or guidance on how to present these details. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific errors in the text: the first \"f\" should be \"g\" in \"we fixed the form of\" and an extra \".\" in the middle of a sentence in line 115. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network has converged to reasonable results. The comment provides explicit actions for the authors to correct the errors and a specific question about the methodology. The actions are clear and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"line 108\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the errors in the text, such as the incorrect \"f\" to \"g\" and the extra \".\" in the middle of a sentence. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network has converged to reasonable results. This question provides clear guidance on what aspect of the methodology needs clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual corrections and a request for clarification. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific errors in the text, such as the incorrect \"f\" to \"g\" in \"we fixed the form of\" and an extra \".\" in the middle of a sentence. This level of detail provides clear guidance for the authors to correct these errors, ensuring the accuracy and professionalism of their work. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network has converged to reasonable results. This question is relevant and could prompt the authors to provide more detailed explanations or evidence in their methodology section. However, the comment could be more helpful if it offered suggestions on how to address the issue of early learning cutoff, which could significantly affect ensemble performance. Overall, the comment is 4 as it identifies specific errors and raises a relevant question for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. While the comment implies that the authors should conduct this study, it does not provide explicit instructions or concrete steps on how to conduct the study or what specific aspects to focus on. The action is clear but lacks detailed guidance, making it 3.", "grounding_specificity_rationale": "The comment suggests studying the inference time of the pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not specify which part of the paper should include this analysis or where the inference time is currently discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific about the need for an inference time comparison but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a study of inference time for the pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer provides a logical reasoning by stating that since the method is direct, it should be compared to previous topdown and bottomup pose estimation methods in terms of inference speed. This claim is 3 as it provides a logical basis for the suggestion, but it could be strengthened with specific references or examples to support the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by including a study of inference time. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it provides a valuable direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the proof in Theorem A.3, specifically regarding the input x and its indices. It also points out a potential error in the equation involving the sum of k(Wk(2))^2. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the input x and correct the equation, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the input x having two indices, as it is a vector, not a matrix, and points out a potential error in the equation involving the sum of k(Wk(2))^2. This provides clear guidance on what needs to be addressed in the proof. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual observations and questions about the proof in Theorem A.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the proof in Theorem A.3, pointing out that the input x is a vector, not a matrix, and questioning the equation involving the sum of k(Wk(2))^2. This feedback is clear and actionable, as it directs the authors to correct the input type and the equation. However, the comment could be more helpful if it provided additional context or explanation on why this correction is necessary or how it affects the overall proof. Despite this, the feedback is 4 as it guides the authors to make a significant improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in section 4.3 and 4.4, questioning the effectiveness of beam search in ensuring the correctness of the results. It suggests that the reviewer is concerned about the reliability of the results, particularly when relationships and entities are replaced. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve the reliability of their results. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies an area of concern but does not offer specific steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. The comment further raises concerns about the reliability of the results and suggests that the reviewer is concerned about the pluggedin entities/relationships being the correct ones. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. It questions the reliability of the results and suggests that the reviewer is concerned about the pluggedin entities/relationships being the correct ones. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the reviewer\"s concerns. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. It questions the reliability of the results and suggests that the reviewer is concerned about the pluggedin entities/relationships being the correct ones. This feedback is valuable as it highlights a potential weakness in the paper\"s methodology and suggests a direction for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these concerns or improve the reliability of their results. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding batch normalization. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or what aspects should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding batch normalization. However, the comment does not specify which part of the paper discusses the claim about evolutional dropout, making it weakly grounded. The authors can infer that it relates to the discussion of dropout methods, but this inference is not direct. The comment is specific in detailing the limitations of evolutional dropout and batch normalization, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer suggests that batch normalization standardizes the variance and centers the activation, which is a different approach. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the limitations and make a logical connection themselves, which may be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the claim about evolutional dropout addressing internal covariate shift. It suggests that the method can only increase the variance of some lowvariance units, while batch normalization standardizes the variance and centers the activation. This feedback is valuable as it points out a specific weakness in the claim and provides a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to discuss these limitations or what aspects of batch normalization should be emphasized. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the limitations of FedPCL due to its reliance on pretrained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pretrained models. However, the comment does not provide explicit guidance on how the authors should further improve their work or what specific aspects of the framework should be refined. It lacks actionable details, such as suggestions for additional experiments or modifications to the framework. As a result, the authors are left without clear direction on how to enhance their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the sensitivity of the model accuracy to pretrained models and how the authors addressed this limitation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of FedPCL heavily relies on the selection of different pretrained models, which limits its applications to more wide areas. The reviewer supports this claim by referencing Table 4, which shows the model accuracy is sensitive to pretrained models. However, the comment does not provide further explanation or examples of how this limitation affects the applicability of FedPCL. While the reference to Table 4 provides some support, the comment could be strengthened by offering more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment acknowledges the limitations of FedPCL due to its reliance on pretrained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pretrained models for prototyping. However, the comment lacks specific suggestions or guidance on how the authors could further improve their work or address the limitations more effectively. It does not provide actionable feedback or detailed insights into potential enhancements or alternative approaches. As a result, the comment is 3, as it identifies a limitation but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include tentative attention maps in the qualitative figures to provide a more comprehensive understanding of the attention mechanism. While the comment implies that the authors should add these maps, it does not explicitly instruct them to do so. The action is concrete, as it specifies what additional information should be included, but it is somewhat vague because it does not provide detailed guidance on how to present these maps. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, which implies that it relates to the visualization or discussion of the attention mechanism. However, it does not explicitly mention a specific section or figure where these maps should be included, making it weakly grounded. The comment is specific in suggesting what additional information should be included, such as the retrieved and final attentions, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including tentative attention maps in the qualitative figures would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the understanding of the attention mechanism. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that including tentative attention maps in the qualitative figures would enhance the understanding of the attention mechanism. This feedback is 3 as it identifies a potential area for improvement by recommending the inclusion of additional visual information. However, the comment lacks depth and does not provide specific guidance on how to present these maps or why they are important. Without further explanation or examples, the authors may find it challenging to fully understand and implement the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the author to add more description about the contribution of the paper. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment provides a specific suggestion for enhancing the paper\"s contribution section, making it 5. The authors know exactly what is expected of them, and the feedback is concrete, making it easy to implement the suggested changes. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the author should add more description about the contribution of the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, results, or discussion sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to make these additions. Additionally, the comment lacks specificity regarding what kind of additional description is needed or how it should be presented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper lacks a detailed description of its contribution. However, it does not provide any specific examples or reasoning to support why this is an issue or how it could be improved. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper lacks a detailed description of its contribution, which is a valid point. However, it does not provide specific guidance on what aspects of the contribution should be elaborated on or how the authors might enhance the description. While it identifies a potential area for improvement, the comment lacks depth and actionable suggestions, making it 3. The authors are given a general direction but are not provided with detailed steps to follow, which limits the comment\"s utility. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit suggestions for improving the paper. First, it recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models. This action is clear and concrete, as it specifies where the information should be placed and how it should be organized. Second, it suggests referencing tricks like normalization or feature scaling in a separate section, which is also a clear and concrete action. Finally, it mentions that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, providing a specific area for improvement. Overall, the comment is 5 as it provides clear and concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"2.3\" and \"2.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the two types of attention for deep VAEs in a separate section and referencing tricks like normalization or feature scaling in a separate section. The comment also suggests reorganizing the description of the layerwise attention mechanism to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides several suggestions for improvement, including describing the two types of attention for deep VAEs in a separate section, referencing tricks like normalization or feature scaling, and reorganizing the description of the layerwise attention mechanism. These suggestions are based on logical reasoning and common practices in the field, but they do not include specific examples or references to support the claims. While the suggestions are clear, they lack detailed justification or evidence to fully substantiate the claims. Therefore, the comment is 3, as it provides a direction for improvement but lacks the depth and evidence needed for full verifiability.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models, which can help clarify the contributions of the paper. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section, which can improve the organization and accessibility of the paper. Finally, it points out that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, suggesting a reorganization to improve clarity. These suggestions are clear and actionable, providing the authors with specific steps to enhance the clarity and organization of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the understanding of Figure 5 or the labels being incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific steps to take to improve the figure or labels. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper, such as Figure 5, is being addressed. It lacks specificity because it does not provide details on what is unclear or incorrect about the figure or labels. Without explicit references or detailed feedback, the authors cannot effectively identify the issues or make improvements. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment claims that either the reviewer does not understand Figure 5 or the labels are incorrect. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the clarity or accuracy of Figure 5 or the labels used in the figure. However, it does not provide any specific guidance or suggestions on how to address this issue, such as suggesting alternative labels or clarifying the figure\"s purpose. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of supervised baselines in the paper and suggests that it is reasonable to assume that full annotation is available for datasets of scale ~100k images. It also notes that even if this is not the case, having an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. While the comment implies that the authors should include supervised baselines, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of supervised baselines in the paper, specifically mentioning that most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. It suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results sections. The comment is specific in its suggestion to include supervised baselines, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a significant issue, as most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. The reviewer suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This claim is 3 as it provides a logical reasoning for the inclusion of supervised baselines, but it lacks specific examples or references to support the assertion that full annotation is typically available for datasets of this scale. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which are crucial for understanding the performance of selfsupervised methods. It logically argues that since most experiments are conducted on datasets of scale ~100k images, it is reasonable to assume that full annotation is available. The comment suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it included examples of suitable supervised baselines or detailed guidance on how to implement them. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. It also notes that the benchmarks used are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or how to update the benchmarks. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of minimal performance differences between methods across evaluations, noting that the differences are typically less than 1 percentage point. It also mentions that the benchmarks used are outdated and likely saturated, referencing specific works. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the issue of minimal performance differences and the need to update the benchmarks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point, which may be due to random variation. The reviewer supports this claim by referencing the outdated and likely saturated benchmarks used. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, it could be strengthened with more detailed analysis or references to specific experiments or studies that support the claim. Therefore, the comment is 3, as it provides some evidence but could be more fully substantiated with additional details or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. This observation suggests that the methods may be overfitting or that the benchmarks are saturated. The comment also points out that the benchmarks used are outdated, which could impact the relevance and applicability of the results. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples on how to update the benchmarks or improve the performance evaluation would make the comment more actionable. Therefore, the comment is 3, as it identifies a significant weakness but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the method and its applicability, suggesting that it may not be beneficial in certain domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and asks for evaluation on other domains. While the comment identifies areas for improvement and questions that need answers, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should evaluate the method on other domains and consider including BEAR in their baselines. The feedback is 3 as it points out areas for improvement but lacks detailed guidance on how to implement these changes.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests including it. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the method\"s applicability and the need for evaluation on other domains. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests including it. However, the comment lacks specific examples or references to support these claims or questions. The reasoning is based on logical assumptions and observations, but without detailed evidence or references, it is difficult for the authors to fully understand and address the critique. Therefore, the comment is categorized as 2, as it provides some basis for the claims but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises several questions and suggestions that could help the authors improve their draft. It questions the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics to assess its empirical efficacy. This feedback is valuable as it prompts the authors to consider the method\"s applicability in a broader context. Additionally, the comment questions the absence of BEAR from baselines and suggests including it, which could enhance the method\"s evaluation. However, the comment could be more helpful if it provided specific guidance on how to evaluate the method on other domains or how to incorporate BEAR into the baselines. Overall, the comment is 4 as it identifies areas for improvement and provides a direction for the authors to explore, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. While the action is explicit, it lacks concrete details on how to present this justification or what specific aspects should be addressed. The authors are given a clear direction to provide theoretical justification, but without specific guidance on how to do so, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this justification should be provided in, nor does it provide details on what aspects of the results need justification. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its request for theoretical justification but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. This is a valid point as these techniques are important for performance, and theoretical justification can help strengthen the paper\"s claims. However, the comment lacks specific guidance on what aspects of the results or theoretical justification are most crucial or how the authors might present this information effectively. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. While the comment provides a clear and explicit action\u2014changing \"X\" to a multiset\u2014it does not offer detailed guidance on how to implement this change or what specific considerations should be taken into account. The action is concrete, but the lack of additional context or explanation makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the change from a set to a multiset in the context of representing graphs with repeated vertex or edge labels. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning based on the need to include multiplicities to ensure an honest representation of the graph. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and potential implications to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the representation of graphs in Section 4, suggesting that \"X\" should be a multiset instead of a set. This feedback is clear and actionable, as it provides a concrete suggestion for improving the accuracy of the graph representation. By pointing out the need to include multiplicities of labels, the comment offers a straightforward way for the authors to enhance the clarity and validity of their work. However, the comment could be more helpful if it included additional context or explanation on why this change is necessary or how it affects the overall analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors\" derivation is based on classical learning theorybased bounds, which are not realistic without Bayesian considerations. It suggests that the authors should consider BayesianPACbased bounds to make their derivation more realistic. While the comment implies that the authors should incorporate Bayesian considerations, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to understand the implications of the suggestion and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors\" derivation, specifically mentioning that it is based on classical learning theorybased bounds. However, it does not specify which part of the paper this critique pertains to, such as a particular section or equation. The authors can infer that it relates to the derivation or theoretical sections, but this inference is not direct. The comment also suggests that Bayesian considerations should be taken into account, but it does not provide specific examples or guidance on how to incorporate these considerations. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is underspecific in terms of what needs to be addressed.", "verifiability_rationale": "The review point claims that the authors\" derivation is based on classical learning theorybased bounds, which are not realistic without Bayesian considerations. The reviewer supports this claim by suggesting that BayesianPACbased bounds are more realistic. However, the comment lacks specific examples or references to classical learning theorybased bounds or BayesianPACbased bounds, making it 3. The authors would need to infer the relevance of these concepts and explore them further to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" derivation, noting that it is based on classical learning theorybased bounds that are not realistic without Bayesian considerations. The reviewer suggests that the authors should consider BayesianPACbased bounds to make their derivation more realistic. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a particular approach to enhance the validity of the derivation. However, the comment could be more helpful if it included examples or references to BayesianPACbased bounds or explained why these are more realistic. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or offer specific guidance on what details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but may not be entirely sure of the exact content or structure of these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be included in, nor does it provide specific guidance on what aspects of the method should be elaborated on. While the authors might have an idea of where these details could be added, the comment lacks full grounding as it does not explicitly mention sections or elements of the paper. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact location for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that more details about the proposed method should be presented, particularly regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their explanation of the methodology. However, the comment could be more helpful if it offered specific examples or guidance on how to present these details, such as suggesting particular sections or aspects of the methodology that should be elaborated on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer suggests that the method might struggle to detect hallucinations due to the potential for different responses pertaining to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the method. The action is implicit and somewhat vague, as the authors can infer that they need to consider this potential challenge but are not given detailed instructions on how to address it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific example of a prompt like \"introduce a sports celebrity to me,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed method, namely that it might struggle to detect hallucinations in openended responses due to the potential for different responses pertaining to different individuals. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The comment provides a logical reasoning by suggesting that the method could face challenges in identifying shared information for consistency checking due to the potential for different responses pertaining to different individuals. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, specifically its ability to detect hallucinations in openended responses. It provides a specific example of a prompt like \"introduce a sports celebrity to me\" and suggests that the method might struggle to detect hallucinations due to the potential for different responses pertaining to different individuals. This feedback is valuable as it highlights a specific area where the method could be improved, allowing the authors to consider and address this issue in their draft. However, the comment could be more helpful if it provided suggestions on how to improve the method\"s ability to detect hallucinations or examples of how this might be done. Overall, the comment is 4 as it directs the authors to a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for action. The authors know that they need to verify the conclusion, but the comment could be more explicit in suggesting specific experiments or methods to conduct these tests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests verifying the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need to verify the conclusion, but without explicit references to sections or experiments, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical findings are unclear in their relation to realworld deep learning models. It provides a specific suggestion to verify the conclusion about label noise and model size on MNIST and CNN. This claim is 3 as it logically suggests that verification is necessary to clarify the theoretical findings. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical findings and their relation to realworld deep learning models. It suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which could provide valuable insights into the practical implications of their theoretical findings. This feedback is clear and actionable, as it directs the authors to conduct additional experiments that could strengthen the paper\"s contribution. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on the paper\"s organization, writing, and content clarity. It suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. While the comment provides some guidance on potential areas for improvement, it does not offer concrete steps or examples on how to implement these improvements. The authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"writing\" and \"content clarity,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the weaknesses, such as the need for a table to compare different CoT prompting methods and the questionable assumption about the frequenterror cluster. Additionally, it raises questions about the selection criteria in section 4.2, providing specific feedback on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is wellorganized and the writing is good, but it also identifies areas for improvement. The reviewer suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, the reviewer questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. These points are supported by logical reasoning and specific questions, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides both positive and negative feedback. On the positive side, it acknowledges that the paper is wellorganized and the writing is good, which is a valuable observation. However, it also identifies areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods across different dimensions. This feedback is actionable and can help the authors enhance the clarity and comprehensiveness of their paper. Additionally, the comment questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, which are important areas for clarification and potential improvement. Overall, the comment is 4 as it provides clear and actionable suggestions for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the probability distribution p(y|Hf(tn)) should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. It also mentions that this assumption is made in the ELBOs later in the paper. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to address the issue. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the probability distribution \"p(y|Hf(tn))\" and the assumption that it should be Gaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the need to choose a Gaussian distribution for Kalman Filtering and Smoothing, and the assumption made in the ELBOs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. The comment provides a logical reasoning by stating that this assumption is made in the ELBOs later in the paper. However, it lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. It also points out that this assumption is made in the ELBOs later in the paper. This feedback is clear and actionable, as it directs the authors to make a specific choice in their modeling that is crucial for the methodology. By addressing this issue, the authors can improve the clarity and robustness of their work. However, the comment could be more helpful if it provided additional context or examples to further explain the importance of this choice. Overall, the comment is 4 as it effectively guides the authors on a critical aspect of their modeling."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal cosine similarities for large weight decay parameters. The reviewer notes that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the results. The action is implicit and somewhat vague, as the authors need to infer that they should report cosine similarities for larger weight decay strengths and possibly adjust the plotting range. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application of weight decay to all layers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that cosine similarities for large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of weight decay across all layers leads to suboptimal cosine similarities for large weight decay parameters. The reviewer supports this claim by noting that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that cosine similarities are suboptimal. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay across all layers, suggesting that this could lead to suboptimal cosine similarities for large weight decay parameters. It points out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is 3 as it highlights a specific area for improvement, namely the reporting of cosine similarities for larger weight decay strengths. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific experiments or analyses to be conducted. Overall, the comment offers some guidance but lacks detailed actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. It suggests that this omission could lead to incorrect conclusions by casual readers. The reviewer implies that the authors should fix this issue, but does not provide specific guidance on how to do so. The comment is explicit in identifying the problem but lacks concrete details on how to address it. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of explaining that the results are for unsupervised random forests. This provides clear guidance on what the authors need to correct to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This omission could lead to incorrect conclusions by casual readers. The reviewer suggests that this is a serious oversight and implies that it should be corrected for publication. However, the comment does not provide specific examples or references to support the claim that this omission is a significant issue. While the claim is logical and somewhat supported by the suggestion to correct the oversight, the lack of detailed evidence or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a serious omission in the paper, specifically the lack of explanation that the results are for unsupervised random forests. This is a critical issue that could lead to incorrect conclusions by casual readers. The comment suggests that the authors should fix this oversight, which is a clear and actionable piece of feedback. However, it does not provide detailed guidance on how to address this issue or suggest alternative ways to present the information. While the feedback is valuable, it could be more helpful with additional suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. It also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. The comment provides specific actions for the authors to take, such as providing visualization results or schematic diagrams to aid understanding. These suggestions are explicit and concrete, giving the authors clear guidance on how to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of qualitative experiments to demonstrate the validity of the conditional independence model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD, as well as the need for a correctness test and comparative experiments with other metrics. The suggestion to use a toy dataset to demonstrate the separability of inlier and outlier features is also clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. The reviewer also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. The comment is 4 as it provides logical reasoning and specific suggestions for improvement. However, it could be strengthened by referencing existing literature or studies that demonstrate the importance of these qualitative experiments. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, namely the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. The reviewer also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. These suggestions are clear and actionable, offering the authors a concrete path to enhance their draft. By addressing these points, the authors can significantly improve the rigor and comprehensiveness of their experimental evaluation. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to compare the computational complexity of their proposed method with other methods. This request is clear and provides a specific action for the authors to take, which is to conduct a comparison. However, it does not specify which methods to compare with or how to conduct the comparison, leaving some room for interpretation. The action is explicit but somewhat vague in terms of execution, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"online version of the algorithm\" and the issue of training multiple iterations/epochs with large models and datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for a comparison of the computational complexity with other methods, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the proposed method requires more computational complexity than other methods. It suggests comparing the computational complexity with other methods, implying that the authors should provide evidence or examples to support their claim. However, the comment does not provide specific references or examples to substantiate the claim, making it 3. The authors would need to make a significant effort to verify the claim themselves, as the comment lacks detailed evidence or reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the computational complexity of the proposed method compared to other methods. It suggests that the authors should provide a comparison of computational complexity to substantiate their claim. This feedback is 3 as it identifies a potential weakness in the paper and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific methods or examples for conducting the comparison, which would guide the authors more effectively. Overall, the comment is 3 as it points out a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides a clear direction for further analysis, it does not explicitly instruct the authors to conduct this study. The action is implicit but concrete, as it specifies what aspects of the analysis should be explored. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. However, it does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The comment is specific in detailing what aspects of the analysis should be explored, such as the roles between \"winners\" and \"cooperators\" and the potential impact of cost on collective return. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides logical reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a systematic analysis of the impact of the cost of incentivization on performance. It offers a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The comment also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. This feedback is highly valuable as it guides the authors to a specific area for further exploration and analysis, which could significantly enhance the paper. However, the comment could be more helpful if it provided additional details or examples on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 5 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It points out a specific example from line 486 where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment provides a clear and explicit action for the authors to take, which is to conduct significance testing to support their claims. This guidance is concrete and leaves no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of significance testing to support claims about method differences. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about method differences without conducting significance testing. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment is 4 as it provides a clear example of the issue and references specific lines in the paper, allowing the authors to understand the basis of the claim. However, it could be strengthened by providing more detailed reasoning or references to support the claim about the significance of the differences. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about method differences. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between the methods is minimal and that proper testing is needed to determine whether it is significant. This feedback is 5 as it directs the authors to a specific area where their claims are not supported by evidence, providing them with a clear and actionable step to improve their draft. By addressing this issue, the authors can strengthen the credibility and robustness of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the approach description in Section 3 is difficult to follow and recommends revising it. It also suggests using the additional page of the cameraready version to extend the approach description rather than adding more experiments. This provides clear and concrete guidance on what needs to be done to improve the draft. The authors know exactly what changes to make and how to structure their approach description for clarity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the approach description being difficult to follow and suggests revising it. The comment also provides a clear suggestion to extend the approach description using the additional page of the cameraready version, rather than adding more experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the approach description in Section 3 is difficult to follow and suggests revising it. However, the comment does not provide specific examples or detailed reasoning to support why the approach description is challenging or how it could be improved. Without additional context or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It suggests revising the description to make it clearer and more accessible. Additionally, it provides a concrete suggestion to extend the approach description using the additional page of the cameraready version, rather than adding more experiments. This feedback is actionable and offers a clear direction for improvement, making it 4. However, it could be more helpful if it included specific examples or suggestions on how to revise the approach description to enhance clarity. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. While the comment highlights these gaps, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to include more interpretive insights and comparisons with other methods. The action is implicit and somewhat vague, as it lacks concrete details on how to implement these improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of interpretive insights into the outperformance of the proposed gyrostructures and the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. This provides clear guidance on what needs to be improved in the experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and that the paper lacks comparison with other stateoftheart methods that do not rely on gyrostructures. The comment suggests that this omission makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifoldbased learning. While the comment identifies specific gaps in the discussion, it does not provide detailed reasoning or examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issue, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the experimental section of the paper. First, it points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. This feedback is valuable as it highlights an area where the authors need to provide more detailed analysis and explanation to support their claims. Second, it notes the absence of comparison with other stateoftheart methods that do not rely on gyrostructures, which makes it unclear whether the proposed approach actually outperforms simpler or more commonly used techniques in manifoldbased learning. This feedback is also valuable as it prompts the authors to broaden their comparisons and provide a more comprehensive evaluation of their method. However, the comment could be more helpful if it suggested specific methods or approaches to include in the comparisons. Overall, the comment is 4 as it identifies important areas for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. While the comment implies that additional analysis is needed, it does not specify what kind of evidence or analysis is required or how it should be presented. The authors are left to infer that they need to provide more detailed information, but the comment lacks concrete guidance on what exactly is needed. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or figure. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. The comment is specific in its request for additional evidence or analysis, but it lacks full grounding as it does not explicitly mention the sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of evidence or analysis supporting the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide more detailed evidence or analysis to strengthen their claims. However, the comment could be more helpful if it suggested specific types of evidence or analysis that would be beneficial, such as comparisons with other datasets or detailed performance metrics. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. While the comment provides a clear action for the authors to take, it does not specify which details should be added or how to extend CATER to other languages. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more details about the two baselines presented in Figure 5 and the suggestion to extend CATER to other languages. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support why these improvements are necessary or how they would enhance the paper. The suggestion to extend CATER to other languages is logical but could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks comprehensive evidence or reasoning.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and comprehensiveness of the figure and the study\"s scope. By addressing these points, the authors can enhance the readability and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the literature review, specifically regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment implies that the authors should make these improvements, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added (an explicit and comparative analysis of related work), but it is somewhat vague in terms of how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and \"GFlowNet for sequence generation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved: the clarity of the main contribution and the distinction from existing work. The comment provides a clear direction for the authors to enhance the literature review by suggesting a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear, particularly regarding the main contribution of the proposed method and its distinction from existing work. The reviewer suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment identifies a potential issue, it lacks specific examples or references to existing work that could clarify the distinction. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the literature review, specifically the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work, which is crucial for effectively communicating the novelty and significance of the proposed method. This feedback is clear and actionable, as it directs the authors to enhance the literature review section to better support their claims. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct a more comprehensive analysis of related work. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any explicit guidance on how to implement this suggestion or what specific changes should be made to the section. The action is implicit and vague, as the authors are left to infer that they should remove the section without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not specify which part of section 3.2 is problematic or how it relates to the distribution. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or how it affects the paper\"s content or clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any reasoning or explanation for why this section is unnecessary or how it might detract from the paper\"s overall clarity or contribution. Without additional context or suggestions for improvement, the comment lacks depth and does not offer actionable guidance for the authors to enhance their draft. Therefore, it is rated as 2, as it provides some insight but not enough to be fully beneficial."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It highlights the need for proper ablation studies to verify this claim. While the comment identifies a specific concern and suggests a potential solution (ablation studies), it does not provide explicit instructions on how to conduct these studies or what specific aspects to focus on. The action is clear but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It points out the need for proper ablation studies to verify this claim. However, the comment does not specify which part of the paper discusses the distillation process or the claim about its effectiveness. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claim and the need for ablation studies, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. The reviewer provides a logical reasoning by pointing out that the finetuning without earlystopping could lead to high variances, which would affect the validity of the claim. However, the comment lacks specific examples or references to support the argument, such as data or studies that demonstrate the impact of regularization on teacher performance. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that the improvements in teacher performance are due to distillation. It suggests that the improvements might be due to regularization effects instead, given the lack of earlystopping and the high variances in finetuning. This is a valuable observation that prompts the authors to reconsider their claim and potentially revise their experimental setup to include earlystopping and validation. However, the comment could be more helpful if it provided specific suggestions on how to conduct the ablation studies or what aspects of the finetuning process should be examined. Overall, the comment is 4 as it highlights a critical area for improvement and encourages the authors to reevaluate their claims, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests two specific actions for the authors to take: (i) to include performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework, and (ii) to include morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These are explicit actions that the authors can directly implement to improve their draft. The second point is a minor suggestion, but it is still clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of performance on word similarity and sentence translation tasks and the inclusion of morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. This provides clear guidance on how to enhance the robustness and effectiveness of the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that adding performance on word similarity and sentence translation tasks would enhance the credibility of the framework, similar to the MUSE paper and others. It also recommends including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These suggestions are based on common practices in the field and are logical, but the comment lacks specific examples or references to support the claim fully. The authors might need to infer the benefits of these additions themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the experiments section of the paper. First, it recommends adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, which would enhance the credibility and effectiveness of the framework. This is a clear and concrete suggestion that the authors can easily implement to strengthen their work. Second, it suggests including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments, which would further diversify the evaluation and provide more comprehensive results. While the second point is a minor suggestion, it is still actionable and could help the authors expand their experiments. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes should be made to include the 1shot setting. The comment lacks actionable details, such as recommending specific experiments or modifications to the paper, making it 1.", "grounding_specificity_rationale": "The comment addresses the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its critique of the absence of the 1shot setting in the experiment part, but it lacks grounding as it does not pinpoint the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\"s conclusions. The claim is based on a logical observation but lacks detailed justification or examples, making it 3. The authors would need to infer the importance of addressing this issue themselves, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid point about the absence of the 1shot setting in the experiment part of the paper, noting that related works like RALE have included this setting. This feedback highlights a potential gap in the paper\"s experimental evaluation, which could impact the authors\" conclusions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to fully explore the 1shot setting. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. While the comment implies that additional discussions are needed, it does not provide specific guidance on what aspects of these discussions should be included or how to structure them. The authors are left to infer that they need to expand on the existing discussions, but without concrete instructions on what to focus on or how to implement these changes, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. The authors can infer that it relates to the discussion of LLMs, but this inference is not direct. The comment is specific in its suggestion to include more discussions, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the limitations and challenges of LLMs. However, the comment lacks specific guidance or suggestions on what aspects of these discussions should be included or how to structure them. While it points out a gap in the paper, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of insight into the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more detailed explanations or justifications for this approach. However, the comment does not explicitly instruct the authors to add this information or specify what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but may not be entirely sure of the exact details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results and suggests that while the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio, it lacks insights into why this approach is needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of insight into the rationale behind the need for selfsupervised learning on this kind of data. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results suggest the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio but lacks insights into why this approach is needed. The comment provides a logical reasoning by pointing out the absence of detailed explanations for the rationale behind the approach. However, it does not provide specific examples or references to support the claim, making it 3. The authors may need to infer the need for more detailed explanations themselves, which could lead to some confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It highlights that while the experimental results suggest the approach\"s value, the paper lacks insights into why this approach is necessary. This feedback is 3 as it points out an area where the authors could provide more context or explanation to enhance the paper\"s clarity and depth. However, the comment does not offer specific suggestions or guidance on how to address this issue, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the link between IP and the terms/equations should be explained more explicitly and prominently. It also requests that labels be included for subfigures in Figures 3 and 4, rather than just being mentioned in the captions. While the comment provides a clear action for the authors to take, it does not specify how to implement this improvement or what specific changes are needed to make the link more explicit. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for labels on subfigures and the clarification of the link between IP and the terms/equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. However, it does not provide any specific examples or reasoning to support this claim. The comment also requests the inclusion of labels for subfigures in Figures 3 and 4, but it does not explain why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the link between IP and the terms/equations could be explained more explicitly and prominently. It also provides a clear and actionable suggestion to include labels for subfigures in Figures 3 and 4, rather than just mentioning them in the captions. This feedback is valuable as it directs the authors to enhance the clarity and accessibility of their work, which can significantly impact the reader\"s understanding. However, the comment could be more helpful if it explained why the current explanation is insufficient or how the suggested changes would improve the paper. Overall, the comment is 4 as it provides actionable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on how to enhance the robustness and reliability of their results, making it 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results over multiple runs, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their results. By suggesting a specific method for evaluating statistical significance, the comment provides a concrete step for the authors to take in enhancing the quality of their work. However, the comment could be more helpful if it explained why averaging over multiple runs is necessary or how it would impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with the paper, noting that it only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, it does not provide explicit guidance on what specific analysis should be conducted or how to address this gap. The authors are left to infer that they need to include analysis on the projection head, but without concrete instructions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the \"projection head,\" which is a critical component of the SimCLR approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why the projection head is crucial or how it relates to the SimCLR case. Without this additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, noting that it only covers the SimCLR case and lacks analysis on the projection head, which is considered important. This feedback is valuable as it highlights a gap in the paper that could be addressed to enhance its comprehensiveness and relevance. However, the comment does not provide specific suggestions or guidance on how to incorporate analysis on the projection head or what aspects of this analysis would be most beneficial. While it points out an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the observations and conclusions should be highlighted in the paper, particularly in the experimental section. This implies that the authors should make a conscious effort to emphasize these aspects in their draft. However, the comment does not provide specific guidance on how to highlight these observations or what aspects should be emphasized. While the action is implied, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section, which implies that the authors should highlight these aspects in the paper. However, it does not specify which observations or conclusions are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is specific in suggesting that highlighting these observations and conclusions would be beneficial, but it lacks grounding as it does not identify the exact sections or elements being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section, implying that the paper could be improved by highlighting these aspects. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it effectively. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these aspects would be beneficial for understanding the tradeoffs of annotation effort and corresponding training performance. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by directing the authors to emphasize the observations and conclusions in the experimental section. However, the comment could be more helpful if it offered specific guidance on how to highlight these sections or what aspects should be emphasized. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is explicit and provides a clear action for the authors to take, which is to conduct ablation experiments. However, it does not specify which modifications should be tested or how to conduct the experiments, leaving some details to be inferred. While the action is clear, the lack of concrete guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. However, it does not provide any specific examples or references to support the claim that these modifications are necessary or beneficial. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is 3 as it identifies a potential area for improvement by suggesting an additional validation method. However, the comment lacks specific guidance on which modifications to test or how to conduct the ablation experiments. While it points out a potential area for enhancement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1\" and \"Zhang et. al.\" (presumably references to specific sections or figures in the paper), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed: a comparison of performance on datasets with a decision space beyond binary. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary, referencing Zhang et al. as an example. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary, which could provide valuable insights into the robustness of the approach. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what specific datasets should be considered. While it identifies a potential area for improvement, the feedback is somewhat vague and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions imply that the authors should investigate these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explore the impact of capacity on FID and consider potential artifacts in the pipeline, but the comment lacks specific details or suggestions on how to conduct these investigations. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, such as a particular section or experiment. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for information about the impact of capacity and artifacts, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions themselves are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could be valuable for the authors to address. First, it asks how the capacity of the SR model affects the FID, which could provide insight into the relationship between these two aspects. Second, it mentions unexpected artifacts due to the proposed method being pipelined, which could be a potential issue that needs to be addressed. While the comment identifies areas for further exploration and consideration, it lacks specific guidance or suggestions on how to investigate or address these issues. The authors are given a direction to pursue but would benefit from more detailed feedback to fully understand and address the concerns. Therefore, the comment is 3, as it points out areas for improvement but does not provide comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out that the authors\" \"proof\" is missing. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the purpose of Proposition B.1 and include a proof, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the content in these sections, such as the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. The comment also points out the missing \"proof\" and suggests that the purpose might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the purpose might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out that the authors\" \"proof\" is missing. This claim is 3 as it provides a logical reasoning for the purpose of Proposition B.1 and references a wellknown concept in machine learning. However, the comment could be strengthened by providing specific examples or references to support the claim about the missing proof. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out that the authors\" \"proof\" is missing. This feedback is 3 as it highlights areas where the paper could be improved, but it lacks detailed guidance on how to address these issues. For example, it does not provide suggestions on how to clarify the purpose of Proposition B.1 or how to include a proof. Therefore, the comment is 3, as it directs the authors\" attention to specific areas needing improvement but does not fully support them in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments. The comment is specific about the types of experiments that are missing, giving the authors a concrete understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing the types of experiments that are missing, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would enhance the paper. Without such evidence or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of additional necessary experiments such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly points out areas where the paper could be strengthened by including these experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a concern about the use of approximations in the paper, specifically mentioning lines 107110. It suggests that the authors should expand on the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what additional information should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should expand on the possible vulnerability of the approximations, particularly regarding the assumption of attacks being in the feasible set only in those lines. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of approximations in the paper leaves \"loose ends\" and suggests that the possible vulnerability of these approximations needs to be expanded to reassure readers. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the concern about the vulnerability of the approximations. As a result, the claim is 3, as it requires further elaboration to be fully understood and actionable by the authors. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of approximations in the paper, specifically mentioning lines 107110. It points out that while approximations are necessary, the paper does not adequately address the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. The comment suggests that the authors should expand on this issue to reassure readers that it is not a real concern. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address it. However, it could be more helpful if it included suggestions on how to present this information or what additional details should be included. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses a subjective opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors might address this perception or improve the contribution of their work. There is no explicit or implicit action for the authors to take, such as suggesting alternative approaches or improvements to the model. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution of the paper and the approach of the proposed model, but it does not specify which part of the paper this perception is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution or approach are considered incremental or limited. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed explanations, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses a subjective opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific reasoning or examples to support this claim or offer suggestions for improvement. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their work need attention or how to enhance its impact. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct a more careful analysis of the model\"s performance, especially on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis, it does not specify exactly how to do so or what additional details should be included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. However, the comment does not specify which part of the paper discusses the model\"s performance or the evaluation procedures, making it weakly grounded. The suggestion to provide more details is specific, but without clear grounding, the authors cannot confidently determine which sections need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. The comment suggests that more careful analysis is needed, particularly for these \"old\" benchmarks. However, the comment lacks specific examples or references to support the claim that the model\"s performance on these benchmarks is problematic. Without detailed evidence or reasoning, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It suggests that more careful analysis is needed, particularly for these benchmarks. Additionally, it recommends providing more details about the evaluation procedures, which could help the authors improve the transparency and robustness of their results. While the comment highlights important areas for consideration, it lacks specific suggestions or guidance on how to conduct the additional analysis or what details to include in the evaluation procedures. This limits the comment\"s helpfulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a discrepancy in the experimental part of the paper, specifically noting that the different metrics used for different OPE methods are not consistent across the figures. It explicitly requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The comment is concrete, as it specifies the issue and provides a clear direction for addressing it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the evaluation methods across different OPE methods and requests an explanation of the differences between the two sets of evaluation methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part of the paper verifies different metrics for different OPE methods but notes a discrepancy in the evaluation methods across different OPE methods in Figures 4 and 5. The reviewer suggests that the authors should provide comments on the differences between the two sets of evaluation methods. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental part of the paper, noting that the different metrics used for different OPE methods are inconsistent across the figures. It explicitly requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and actionable, as it directs the authors to clarify and address the inconsistency in their experimental results. By providing a specific area for improvement, the comment offers valuable guidance for enhancing the clarity and accuracy of the paper. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the experimental results, noting that the proposed method does not show any advantage without prior information, but only when using prior knowledge. It suggests that this comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. While the comment identifies an issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider the extra complexity and cost of using prior knowledge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not show any advantage without prior information but only when using prior knowledge. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison and the additional complexity and cost of using prior knowledge. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not show any advantage without prior information but only when using prior knowledge. The reviewer supports this claim by explaining that the comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. This reasoning is logical and provides a clear explanation for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not show any advantage without prior information but only when using prior knowledge. It highlights that this comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. This feedback is valuable as it points out a potential weakness in the experimental setup and suggests that the authors should consider the impact of prior knowledge on the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or how to design a more fair comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include collaborative games in their experiments to explore how the evaluated methods behave in both collaborative and competitive settings. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to implement this suggestion or what specific collaborative games should be included. The authors are left to infer the details of how to incorporate collaborative games into their experiments, which could be improved with more concrete instructions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper this issue pertains to, such as the sections where the experiments are described or discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of collaborative games, but without grounding, it is difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of collaborative games in the experiments. It suggests that including such games would be beneficial to explore the behavior of the evaluated methods in both collaborative and competitive settings. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in their experiments. However, the comment could be more helpful if it offered examples of collaborative games or provided guidance on how to incorporate them into the existing experimental setup. Overall, the comment is 4 as it points out a meaningful area for improvement and provides a clear suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific settings to include or suggesting ways to improve the figures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of experimental settings for these figures, making them difficult to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the absence of experimental settings for figures 1 to 9. This is a critical observation that could impact the credibility and persuasiveness of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the figures. While it points out a problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment identifies a specific area for clarification, it does not provide explicit instructions on how to address this issue or what specific details should be included in the clarification. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the proposed method and its potential impact on task knowledge acquisition. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rationale behind the work is based on the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment highlights an important area for clarification, it does not provide specific guidance on how the authors should address this issue or what aspects of the rationale need clarification. The feedback is 3 as it points out a potential gap in the explanation, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the lack of theoretical support is a weakness. It also points out that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. The reviewer provides a specific example of the median as a potential replacement. While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to implement these changes or provide detailed guidance on how to adapt the median or other statistics. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the regularization term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the adhoc nature of the regularization term and suggests that the lack of theoretical support is a weakness. The comment provides a specific example of the median as a potential replacement for the mean and standard deviation in the regularization. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the adhoc nature of the regularization term and suggests that the lack of theoretical support is a weakness. The reviewer provides a specific example of using the median instead of the mean and standard deviation in the regularization, which is a logical suggestion. However, the comment lacks detailed reasoning or references to support the claim that the median is a superior choice. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the adhoc nature of the regularization term and the lack of theoretical support. It suggests that the authors have provided an intuitive explanation but that more theoretical justification would be beneficial. The reviewer provides a specific example of using the median instead of the mean and standard deviation in the regularization, which could strengthen the theoretical foundation of the work. This feedback is clear and actionable, as it points out a specific area for improvement and offers a concrete suggestion for enhancing the paper. However, it could be more helpful if it included additional examples or detailed guidance on how to adapt the median or other statistics. Overall, the comment is 4 as it provides a clear direction for the authors to enhance the theoretical foundation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It clearly states the action needed, which is to integrate benchmark comparisons against stateoftheart fairness algorithms. This provides a concrete and specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of comparisons with existing fairness algorithms. The comment provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would significantly enhance the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that integrating benchmark comparisons against stateoftheart fairness algorithms would enhance the paper by providing tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This claim is 3 as it logically suggests that comparisons with existing fairness algorithms would strengthen the paper, but it lacks specific examples or references to existing work that could be used for comparison. The authors would need to infer the specific fairness algorithms to include and how they would enhance the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section, noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper by offering tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This feedback is 5 as it guides the authors on how to strengthen their experimental section and improve the overall quality of their work. By addressing this suggestion, the authors can significantly enhance the credibility and impact of their paper. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of their proposed method and to include the iteration cost of all related methods, including baseline methods. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and direct, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the iteration cost should be discussed, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and the iteration cost of all related methods, including baseline methods. This provides clear guidance on what the authors need to include in their discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the iteration cost is a critical aspect to discuss. The authors are left to infer the importance of this discussion themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a detailed discussion on computational efficiency. By addressing this point, the authors can improve the comprehensiveness and clarity of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It explicitly instructs them to report average results over multiple runs, which is a clear and actionable step. It also suggests discussing the decision boundaries in the toy dataset, which is another actionable point. Additionally, it asks for clarification on what information is in Fig. 9, which is a specific request for more detail. Each of these points is clearly stated and provides concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section\" and specific sections within it, such as \"Sec. 3.1\" and \"Sec. 3.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what needs to be addressed, such as reporting average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes several claims regarding the experimental section, including the need to report average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these suggestions. Therefore, the claims are considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental section, particularly regarding the need to report average results over multiple runs to clarify the results. It also suggests discussing the decision boundaries in the toy dataset and clarifying the information in Fig. 9. These points are clear and offer concrete suggestions for improvement, which can help the authors enhance the clarity and robustness of their experimental results. However, the comment could be more helpful if it provided additional context or examples of how these improvements could be achieved. Overall, the feedback is 4 as it directs the authors toward specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the dimensionality problem or suggestions for potential solutions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed model, specifically that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\"s dimensionality, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a relevant observation that could impact the practicality and applicability of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate its impact on the model. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail for the authors to effectively address it."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homolumo gap, suggesting that it may lead to negative transfer. It provides an example of TransformerM performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. However, the comment does not offer explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prediction of homolumo gap\" and the \"QM9 in downstream experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the TransformerM model performs poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, as evidenced by TransformerM\"s poor performance on most tasks except for homo, lumo, and gap. The reviewer provides an example from QM9 in downstream experiments, which supports the claim. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have observed similar negative transfer effects. As it stands, the claim is 4 due to the example provided, but it could be further substantiated with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homolumo gap, suggesting that it may lead to negative transfer. It provides an example of TransformerM performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. This feedback is 3 as it highlights a potential weakness in the paper\"s claims and suggests a direction for improvement. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or improve their claims. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" statement regarding the center correlation being uninsightful for discriminating model defenses, as it is used in Figure 4 A&B. The reviewer questions why the metric is considered useful in one place but not another, and seeks clarification on the authors\" intent. While the comment implies that the authors should clarify their reasoning, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 8082\" and \"figure 4 A&B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" statement about the center correlation being uninsightful for discriminating model defenses, and it seeks clarification on why it is considered useful in one place but not another. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" statement about the center correlation being uninsightful for discriminating model defenses, as it is used in Figure 4 A&B. The reviewer is seeking clarification on why the metric is considered useful in one place but not another, and what the authors meant by their statement. This is a request for clarification rather than a claim or opinion, as it does not express an opinion or judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in the authors\" statement regarding the center correlation being uninsightful for discriminating model defenses, as it is used in Figure 4 A&B. This is a clear and actionable observation that prompts the authors to clarify their reasoning or intent behind this statement. By questioning the usefulness of the metric in one context versus another, the comment encourages the authors to provide a more comprehensive explanation or justification for their choice. However, the comment could be more helpful if it offered suggestions on how to address this issue or what additional context might be needed. Overall, the comment is 4 as it directs the authors to clarify an important aspect of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" may be too strong to accurately represent the empirical phenomenon presented. It points out that the total variation between the test and train distributions of the network\"s outputs might not be zero, and that this conclusion is difficult to draw from a few test functions where the outputs match. However, the comment does not provide explicit guidance on what term or phrasing would be more appropriate or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative terms or phrasing to better represent the phenomenon. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it may be too strong to accurately represent the empirical phenomenon presented. The comment provides a clear rationale for why the term might not be appropriate and suggests an alternative approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the appropriateness of the term \"distributional generalization\" to describe the phenomenon presented, suggesting that it may be too strong. The reviewer provides a logical reasoning by explaining that the term implies a complete vanishing of the total variation between the test and train distributions, which might not be the case. This reasoning is based on the observation that the outputs match in a few test functions, suggesting that the phenomenon is not as idealized as the term implies. However, the comment lacks specific examples or references to support the claim that the term is inappropriate. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"distributional generalization\" used to describe the phenomenon presented in the paper. It points out that the term might be too strong, as it implies a complete vanishing of the total variation between the test and train distributions, which might not be the case. The reviewer provides a logical reasoning by explaining that the outputs might not match in all test functions, suggesting that the phenomenon is not as idealized as the term implies. This feedback is 3 as it highlights a potential misrepresentation of the empirical phenomenon, but it could be more beneficial if it offered suggestions for alternative terms or phrasing to better represent the phenomenon. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the theoretical contribution as \"ok but not particularly strong\" and points out that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It does not suggest specific ways to strengthen the theoretical contribution or offer guidance on how to make the proof more novel. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the theoretical contribution of the paper, specifically mentioning that it is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the weaknesses of the theoretical contribution and the proof, but without grounding, it lacks actionable guidance for the authors to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical contribution is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the theoretical contribution as \"ok but not particularly strong,\" which is a subjective assessment. It also points out that the theoretical result is a weak, unpractical bound and that the proof lacks mathematical novelty. While the comment identifies some weaknesses in the paper, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the theoretical contribution. The feedback is 3 as it highlights areas for improvement, but it lacks actionable advice or detailed critique to fully support the authors in enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper. While the comment provides explicit actions to take, such as including ablation and using the same setup as in the DEN paper, it does not specify how to implement these actions. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental evaluation, such as the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. Additionally, it points out the need for a more comprehensive comparison with the DEN paper, including using the same setup. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks ablation for the \"picking\" step and that the comparison on CIFAR is not convincing. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper. The comment provides some logical reasoning by pointing out the need for ablation and a more comprehensive comparison, but it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a basis for the critique but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper to ensure fairness and correctness. This feedback is clear and actionable, as it provides specific guidance on how to improve the experimental evaluation section. By addressing these points, the authors can significantly enhance the credibility and robustness of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" to make the plot easier to interpret. While the comment provides a specific suggestion for clarity, it does not offer detailed guidance on how to implement this change or why it is necessary. The action is explicit but somewhat vague, as the authors know they need to make the change but may not be entirely sure of the exact implementation or rationale behind it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plot\" and suggests a specific change to \"above/below diagonal\" instead of \"above/below 45 degree.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the clarity of the plot labels. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer provides a logical reasoning that \"above/below diagonal\" is clearer because it refers to a visual aspect, while \"above/below 45 degree\" is more ambiguous. However, the comment lacks specific examples or references to support the claim that \"above/below diagonal\" is more interpretable. This makes the claim 3, as the authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to improve the clarity of the plot by using \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear and concise way for the authors to enhance the interpretability of their plot, which is a valuable contribution. However, the comment could be more helpful if it explained why \"above/below diagonal\" is more intuitive or provided examples of how this change might improve the plot. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear suggestion for enhancing the clarity of the plot."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer implies that the authors might be trying to convey that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide explicit guidance on how to clarify this point or what specific changes should be made to improve the clarity. While the action is implied, it is not directly stated, and the authors are left to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the phrasing of \"is sufficient\" and suggests that the authors might be trying to convey that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment lacks specific examples or references to support this interpretation, making it 3. The authors would need to infer the intended meaning and potentially revise the phrasing themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the phrasing in lines L240 and L428, questioning what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is 3 as it points out a potential area for clarification, but it lacks depth and does not offer specific suggestions on how to improve the clarity or rephrase the phrasing. The authors are given a direction to consider, but the comment could be more actionable with additional guidance or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism over prior taskoptimized approaches. It points out that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which makes it unclear how these nonlinear models attain solutions purely through optimization on a task. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the clarity of their work. The feedback is 3 as it identifies a potential gap in the explanation but lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. The comment highlights the lack of clarity regarding the model\"s relationship to nonlinear RNN models and how these models attain solutions purely through optimization on a task. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the scientific insight provided by the model and formalism over prior taskoptimized approaches. It claims that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which makes it unclear how these nonlinear models attain solutions purely through optimization on a task. The comment provides a logical reasoning by pointing out the lack of clarity in the explanation, but it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a reasonable basis for the critique but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. It points out that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which makes it unclear how these nonlinear models attain solutions purely through optimization on a task. This feedback is valuable as it highlights a critical gap in the paper that the authors need to address to provide a clearer explanation of their work. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what additional evidence or examples could be included to support the scientific insight. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the texts in legends and axis labels larger, similar to the text size. It also clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. These actions are direct and concrete, providing clear guidance on how to improve the draft. The authors know exactly what changes to make, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the legends and axis labels, and the beginning of page 6, where Proposition (1) is mentioned. It also provides specific suggestions, such as increasing the font size of captions and legends in Figures 2 and 3, and clarifying the confusion between Proposition (1) and Equation 1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the texts in legends and axis labels should be larger, similar to the text size, and clarifies the confusion between Proposition (1) and Equation 1. It also provides specific suggestions for improving the font size of captions and legends in Figures 2 and 3. These suggestions are based on logical reasoning and common practices, making the claim 4. However, the comment could be strengthened by providing examples or references to similar practices in the literature. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the readability of the paper. It points out that the texts in legends and axis labels should be larger, similar to the text size, to enhance clarity. Additionally, it clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. These suggestions are clear and provide the authors with a direct path to improve the readability and comprehensibility of their draft. The comment is 5 as it offers concrete steps for enhancing the presentation of the paper, making it easy for the authors to implement the suggested changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments. It specifies that this comparison should be made at a particular step of the sampling trajectory, referring to Figure 2 in Journey TRAK. This provides a clear and concrete action for the authors to take, as they are given specific steps to follow in order to enhance their experimental analysis. The comment is 5 because it provides a direct and specific request for improvement, ensuring that the authors know exactly what needs to be done to address the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the counterfactual experiments and suggests a comparison against Journey TRAK, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, specifically a comparison against Journey TRAK at a particular step of the sampling trajectory, as shown in Figure 2. This provides clear guidance on what the authors should include in their experiments to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison against Journey TRAK should be included in the counterfactual experiments, specifically at a particular step of the sampling trajectory. The reviewer provides a reference to Figure 2 in Journey TRAK, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This provides a logical basis for the claim, as it suggests that including this comparison could enhance the understanding of the results. However, the comment could be strengthened by providing more detailed reasoning or examples from the Journey TRAK work to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments in the paper. It suggests including a comparison against Journey TRAK, which is a relevant work in the field, at a particular step of the sampling trajectory. This feedback is valuable as it offers a clear direction for the authors to enhance their experimental analysis and potentially strengthen their results. By incorporating this comparison, the authors can demonstrate a more comprehensive understanding of their method\"s performance and its implications. However, the comment could be more helpful if it provided additional context or rationale for why this comparison is important or how it might impact the results. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It points out that Table 3 shows ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). The reviewer suggests that the placement of adaptive convolutions is important, but no analysis or comments are provided on this aspect of the technique. While the comment identifies a potential issue, it does not offer specific guidance on how the authors should address this issue or what kind of analysis or comments would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should include analysis or comments on the placement of adaptive convolutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3\" and \"ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of adaptive convolutions and suggests that the placement of adaptive convolutions is important, but it does not provide further details or suggestions on how to address this issue. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions does not always lead to better performance, based on the experimental results in Table 3. The reviewer provides a specific example, noting that ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This provides a clear and concrete basis for the claim, making it 4. However, the comment could be strengthened by providing additional analysis or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It provides a specific example by comparing ACNNv3 (all adaptive convolutions) to ACNNv2 (adaptive convolutions only in the last layer), where ACNNv3 performed worse. This observation highlights the importance of the placement of adaptive convolutions, which is a valuable insight for the authors. However, the comment lacks detailed analysis or suggestions on how the authors might address this issue or what aspects of the technique should be analyzed further. While it points out a critical area for improvement, it does not provide actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of the tradeoff and possibly explore ways to mitigate it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"ancestral graphs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. The comment further raises a question about the information encoded in the ancestral graph compared to the DAGs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the reduction in search space results in a loss of information. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a relevant consideration for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important aspect of the paper, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. While the comment implies that the authors should include such results, it does not provide explicit instructions or concrete steps on how to achieve this. The authors are left to infer that they should include these results, but the comment lacks detailed guidance on what specific aspects to focus on or how to present them. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not specify which part of the theoretical discussions needs improvement or which specific results should be included. The authors can infer that it relates to the theoretical sections, but the comment lacks full grounding as it does not explicitly mention the sections or elements being addressed. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on how to implement these changes. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. The reviewer provides a specific expectation, such as \"given confidence levels, what is the sufficient amount of training data points that would not return NSF.\" This suggestion is based on a logical expectation of what should be included in the theoretical discussions, but it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems should include sample complexitytype results related to not returning NSF. The reviewer provides a clear expectation by mentioning the need for results based on confidence levels and the sufficient amount of training data points that would not return NSF. This feedback is actionable and constructive, as it guides the authors on how to enhance their theoretical discussions and provide more depth to their analysis. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully addressed this issue. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the description of the VAD is puzzling and suggests that the authors should clarify what they mean by \"discarding TF bins with a magnitude of less than epsilon.\" It also highlights that this approach is not consistent with a VAD, which is supposed to look for speech presence and is unlikely to be defined over frequency. The comment implies that the authors should reconsider their definition and approach to VAD. While the action is implicit, it is clear and provides a direction for the authors to take, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the VAD description, pointing out that the current approach discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The comment further explains that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that the authors are discarding TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer argues that a VAD should look for speech presence and is unlikely to be defined over frequency, which is a common understanding in the field. The comment provides a logical reasoning and references common knowledge about VADs, making it 4. However, it could be strengthened by providing specific references or examples to support the claim about VADs and their definition. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the description of the VAD, noting that the current approach discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. It points out that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear understanding of what a VAD should entail. The comment also suggests that the authors should reconsider their definition and approach to VAD, offering a constructive suggestion for improvement. This feedback is 5 as it guides the authors to clarify and refine their description of the VAD, ensuring that their work aligns with common understanding and standards in the field. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. It provides a specific example of what could be discussed, namely the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is explicit and provides concrete guidance on what the authors should add to their discussion. The action is clear and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" and \"Section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the empirical motivation for a timevarying Q ^ t and S t , and provides an example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This suggestion is based on logical reasoning and provides a clear direction for improvement. However, the comment could be strengthened by referencing specific studies or examples to support the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the draft. It highlights the need for a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer offers a specific example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is valuable as it guides the authors to include a relevant and potentially insightful discussion in their paper. However, the comment could be more helpful if it provided additional context or references to similar studies that have explored this topic. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It also mentions that the literature has shown that regression methods do not significantly influence the results. The reviewer suggests that the authors clarify this issue and provides a potential solution by suggesting that direct regression to the center point is sufficient. However, the comment does not explicitly instruct the authors to clarify this point or provide specific guidance on how to address the issue. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer provides a detailed explanation of the potential confusion regarding the methods and suggests that the authors clarify this issue. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer cites the literature to support their claim that regression methods do not significantly influence the results. However, the comment lacks specific references to the literature or detailed explanations of the differences between the methods. This makes the claim 3, as the authors would need to conduct further research or analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It references the literature to support the claim that regression methods do not significantly influence the results. The reviewer suggests that the authors clarify this issue, which is a clear and actionable piece of feedback. By addressing this concern, the authors can improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific examples or references to the literature that support the claim. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments lack something to hang on to. However, it does not provide specific guidance on how to improve the clarity or intuition of the paper. The authors are left without actionable steps to take to address these issues. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of intuition is most apparent. Without specific references to sections, figures, or experiments, the authors cannot confidently determine which parts need attention. Additionally, the comment does not provide specific guidance on how to improve the clarity or intuition of the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that the experiments lack something to hang on to, but it does not specify what this \"something\" is or how it could be improved. Without concrete evidence or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is not easy to follow and lacks a clear intuition for how the pieces fit together. It also notes that the experiments lack something to hang on to, which further contributes to the lack of clarity. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or intuition of the paper. While it highlights areas for improvement, the feedback is incomplete and lacks actionable steps, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network\"s performance may be improved by training them simultaneously. It explicitly asks for KID/FID metrics of the teacher network, providing a clear and concrete action for the authors to take. This guidance is explicit and specific, leaving no ambiguity about what the authors need to do to address the concern. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training of the student and refinement networks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of the comparison and requests KID/FID metrics for the teacher network. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. It prompts the authors to provide KID/FID metrics for the teacher network, which is a clear and actionable request. This feedback is 3 as it identifies a potential area for improvement and provides a specific direction for the authors to address. However, it could be more helpful if it included additional context or explanation about why this comparison is important or how it might impact the overall evaluation of the work. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. The reviewer suggests that having a scaling variable before the attention weight might help. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding a scaling variable before the attention weight. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the refined region vector and suggests that having a scaling variable before the attention weight might help. The comment provides a clear direction for improvement by asking whether the refined vector scales only the most important regions before global pooling. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. The reviewer suggests that having a scaling variable before the attention weight might help. However, the comment lacks specific reasoning or evidence to support why this change would be beneficial or how it would affect the results. Without detailed explanation or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. It suggests that having a scaling variable before the attention weight might help. This feedback is 3 as it prompts the authors to consider a potential improvement in their methodology. However, the comment lacks depth and does not provide specific guidance or examples on how to implement this change or why it might be beneficial. To be more helpful, the comment could offer suggestions on how to test or evaluate the impact of this change. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the LLM\"s accuracy or how to handle ambiguities in human language. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to goal misspecification in the LLM, particularly when faced with ambiguities in human language. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of goal misspecification and its consequences, such as failures on the ALFRED benchmark. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM, noting that failures on the ALFRED benchmark often occurred due to goal misspecification. It highlights that the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This feedback is valuable as it points out a critical area for improvement in the LLM\"s performance. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific techniques or approaches to improve goal misspecification. Despite this, the comment still offers a clear direction for the authors to improve their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to conduct the analysis or what specific aspects of the analysis should be focused on. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"improvement of this method over SOTA methods such as IGEV,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the distribution of disparities produced by IGEV compared to other baselines, suggesting that this analysis could help determine why the effect is not significantly improved on IGEV. Additionally, it raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvement of the method over SOTA methods like IGEV is small, and questions whether there is no multipeak distribution problem in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. The comment also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks like IGEV. While the comment provides a logical basis for the claim, it lacks specific examples or references to support the assertion about the distribution of disparities or the difficulty of SamplingGaussian. This makes the claim 3, as it requires further elaboration to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This feedback is valuable as it guides the authors to conduct a specific analysis that could help clarify the limitations of their method compared to SOTA methods. Additionally, the comment raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV, prompting the authors to consider potential limitations or areas for improvement. Overall, the comment is 4 as it offers clear and actionable guidance for the authors to enhance their draft. However, it could be more helpful if it provided additional context or examples to support the analysis suggestion. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide modelspecific insights by investigating how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a clear action to take, it does not specify how to conduct the modelspecific analysis or what specific aspects of the models should be investigated. The authors are given a clear direction but may need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ModelSpecific Insights\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the investigation into how specific models behave differently when ReGuide is applied and the presentation of differences in false positive rates (FPR) between models with and without ReGuide. This provides clear guidance on what additional analysis or data should be included to enhance the paper\"s conclusions. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper focuses on generic findings across models and recommends a deeper investigation into how specific models behave differently when ReGuide is applied. The reviewer provides a specific example of GPT4o and InternVL2, suggesting that differences in false positive rates (FPR) should be presented for a better comparison. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s analysis, but it lacks detailed evidence or references to support the claim that these specific models behave differently. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending a deeper investigation into how specific models behave differently when ReGuide is applied. It suggests presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is valuable as it directs the authors to focus on modelspecific insights, which could enhance the paper\"s conclusions and provide more nuanced understanding of the models\" behavior. However, the comment could be more helpful if it included specific guidance on how to conduct the modelspecific analysis or what aspects of the models should be investigated. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific in detailing what needs to be clarified, making it 5. Authors know exactly what needs to be done to improve their draft, ensuring that the action is concrete. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the Fourier modes as numbers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests clarifying whether these modes are real or complex numbers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is a specific and actionable suggestion that can help improve the clarity and precision of the paper. By addressing this point, the authors can ensure that their explanation is accurate and complete, which is beneficial for both the readers and the authors themselves. However, the comment could be more helpful if it provided additional context or examples to guide the clarification process. Overall, the comment is 4 as it identifies a specific area for improvement, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to supplement the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the draft. The comment provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be supplemented, which is the result comparison. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is important or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the overall understanding of the results. Despite this, the feedback is 4 as it points out a specific area for improvement, which the authors can address to strengthen their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include results using the GCPG model without pretrained initializations to clarify the contribution of the task formulation and pretrained language models. This is a clear and direct action for the authors to take, as it provides a specific step to address the issue of attribution. The comment is specific in detailing what additional results are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for results using the GCPG model without pretrained initializations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the contribution of the task formulation and pretrained language models. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks ablations, specifically the results without pretrained language models. The reviewer claims that it is unclear how much performance gain is due to the task formulation and how much is because of pretrained language models. The suggestion to include results using the GCPG model without pretrained initializations is a logical request to clarify the contribution of the task formulation. However, the comment does not provide specific examples or references to support the claim that the current results are unclear. This makes the claim 3, as the authors would need to make a logical inference to understand the basis of the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of ablations to clarify the contribution of the task formulation and pretrained language models. It suggests using the GCPG model without pretrained initializations to provide a clearer understanding of the performance gains. This feedback is clear and actionable, as it directs the authors to include additional results that can help clarify their findings. However, the comment could be more helpful if it provided more detailed guidance on how to implement these ablations or why the GCPG model is particularly relevant. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is difficult to understand what the axes are for Figure 1. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the axes should be labeled more clearly or if additional explanations are needed. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve the clarity of the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes in Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand what the axes are for Figure 1. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is 3 as it points out a clear area for improvement in the paper, which is the labeling and explanation of the axes. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or offer alternative ways to present the data. While it highlights an important issue, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider presenting results on ImageNet to enhance the convincingness of their proposed method. While the comment implies that the authors should include these results, it does not provide specific guidance on how to implement this suggestion or what aspects of the results should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should include results on ImageNet to improve the paper\"s credibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not specify which part of the paper should include these results or how they should be presented. The authors cannot confidently determine which section of the paper is being addressed, and the comment lacks specificity regarding what aspects of the results should be improved or how they should be presented. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this would be beneficial or how it would enhance the credibility of the method. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. While it provides a general direction for improvement, it lacks specific guidance or examples on how to achieve this or what aspects of the results should be emphasized. The feedback is 3 as it points out a potential area for enhancement, but it does not offer actionable steps or detailed suggestions for the authors to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which may require additional computational costs. This implies that the authors should include direct runtime comparisons to demonstrate the efficiency of their proposed approach. The comment is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of implicit differentiation and its potential impact on runtime efficiency, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which may require additional computational costs. The comment suggests that these comparisons are necessary to demonstrate the efficiency of the proposed approach. While the reasoning is logical and the claim is based on a common understanding of implicit differentiation and its computational implications, it lacks specific examples or references to support the claim fully. This makes the comment 3, as it provides a clear rationale but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper, noting the absence of direct runtime comparisons with existing methods. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach, which is based on implicit differentiation. This feedback is clear and actionable, as it directs the authors to include these comparisons to strengthen their claims about the efficiency of their method. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or suggested potential methods for doing so. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the proposed framework is a simple combination of metalearning and federated learning and does not see any technical contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the framework need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework for being a simple combination of metalearning and federated learning, indicating a lack of technical contribution. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment lacks specificity regarding what aspects of the framework are considered simple or lacking in technical contribution. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, lacking any technical contribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment critiques the proposed framework for being a simple combination of metalearning and federated learning, indicating a lack of technical contribution. However, it does not provide any specific examples or suggestions for improvement, nor does it explain why the current framework is considered simple or lacking in technical contribution. Without actionable feedback or detailed reasoning, the authors are left without a clear understanding of what aspects of their framework need attention or how to enhance it. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the insufficiency of the contribution and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. While the comment implies that more insightful findings or solutions should be included, it does not provide specific guidance on what these findings or solutions should be. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to be more comprehensive. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically the connection between complementary and model robustness. It suggests that while the authors have studied this connection, they have not explored how to leverage these characteristics to improve model robustness. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, more insightful findings or solutions to improve model robustness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution is insufficient and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. The reviewer provides a logical reasoning by stating that the conclusion is easily and intuitively obtained, given the relationship between multimodal complementary and robustness. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or to suggest how to improve it. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant concern about the contribution of the paper, noting that while the authors have studied the connection between complementary and model robustness, they have not explored how to leverage this connection to improve model robustness. The reviewer suggests that the conclusion is easily and intuitively obtained, and that more insightful findings or solutions should be included. However, the comment does not provide specific guidance or suggestions on how the authors might expand their analysis or what additional insights or solutions could be explored. While it highlights a potential area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should focus on what the differences in representation are between clusters rather than on which clusters are \"best.\" However, it does not provide explicit guidance on how to implement this change or what specific aspects of the representation differences should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should prioritize the differences in representation over the selection of \"best\" clusters. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should focus on the differences in representation between clusters rather than on which clusters are \"best,\" which is relevant to the motivation of the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this issue is discussed. The authors can infer that it relates to the analysis or results section, but the comment lacks full grounding. It is specific in suggesting a change in focus, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that focusing on which clusters are \"best\" rather than the differences in representation between them is an odd choice given the motivation of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is considered odd or how it deviates from the paper\"s stated motivation. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment points out a potential inconsistency in the paper\"s focus, suggesting that the authors should prioritize the differences in representation between clusters rather than which clusters are considered \"best.\" This feedback is 3 as it identifies an area where the paper may not align with its stated motivation. However, the comment lacks specific guidance or suggestions on how to address this issue or what aspects of the representation differences should be emphasized. While it highlights a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to correct the caption. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption for Figure 7, and provides the correct label (\"Edge Dynamics\"). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the caption for Figure 7 is incorrect and should be corrected. However, it does not provide any supporting evidence, reasoning, or references to justify why the current caption is incorrect or how it should be corrected. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the caption for Figure 7, noting that it should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This is a clear and actionable piece of feedback that the authors can easily implement to improve the accuracy and clarity of their paper. By addressing this issue, the authors can enhance the quality and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment explicitly states the need for case studies and error studies, it does not provide specific guidance on how to implement them or what aspects to focus on. The action is clear but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Elementlevel Graph Pretraining\" and the \"complex structure\" mentioned in the paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that case studies and error studies could be beneficial in demonstrating the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits. However, the comment lacks specific examples or detailed reasoning to fully substantiate why case studies and error studies are necessary or how they would enhance the paper. While it provides a logical argument, the lack of detailed evidence or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of each proposed component. It highlights the importance of such studies by referencing an example from \"Graph pretraining for AMR parsing and generation,\" which illustrates the potential benefits of including these analyses. This feedback is valuable as it offers a concrete way for the authors to enhance the persuasiveness and credibility of their work. However, the comment could be more helpful if it provided specific guidance on how to design and conduct these studies, such as what aspects to focus on or how to present the results. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer requests clarification on the rationale for considering these factors as separate evaluations. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their evaluation criteria. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The comment is specific in its critique of the evaluation criteria and provides a logical explanation of how they might be entangled. However, it does not explicitly mention which part of the paper discusses these evaluation criteria, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific examples or references to support the claim that these factors are already considered within the framework. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their motivation for considering these factors as separate evaluations. While it identifies a potential area for clarification, the feedback is 3 as it points out a potential weakness in the paper but does not provide actionable steps for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies what needs to be clarified: the standard deviation after multiple experiments and the improvement brought by SoRA compared to the baseline. The comment provides guidance on how to address this issue by suggesting the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the improvement brought by the SoRA method is limited due to random fluctuations, suggesting that the standard deviation after multiple experiments is not provided. The comment provides a logical reasoning by pointing out that the improvement may be due to random fluctuations, but it lacks specific examples or references to support this claim. The authors are left to infer the significance of the standard deviation and its impact on the results, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, noting the absence of standard deviation after multiple experiments. It also points out that the improvement brought by the SoRA method is limited, which may be due to random fluctuations. The comment provides clear and actionable feedback by suggesting that the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This guidance is valuable as it helps the authors understand the significance of their results and how to present them more effectively. However, the comment could be more helpful if it offered suggestions on how to address the issue of limited improvement or how to better present the results. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. While the comment provides explicit actions for the authors to take, such as increasing font size and ensuring proper placement, it does not offer detailed guidance on how to address these issues. The authors are left to infer the specific steps needed to improve the organization and layout of their paper. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figure 1,\" \"Figure 2,\" \"Table 2,\" and \"page 6,\" allowing the authors to accurately identify the areas being addressed. It also specifies the issues with the layout, such as the font size and placement of figures and tables, and the formatting of the top two lines on page 6. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and that the layout is rushed, providing specific examples such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These examples are detailed and provide clear justification for the claim, making the comment 4. However, the comment could be strengthened by providing additional examples or references to similar issues in other papers, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the organization and layout of the paper. It identifies issues such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. By pointing out these specific problems, the comment empowers the authors to make improvements that enhance the clarity and professionalism of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing examples of better formatting or offering alternative layout options. Overall, the comment is 4 as it provides clear guidance for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not provide specific guidance on how to assess or address these concerns. The authors are left to infer that they need to consider practicality and safety, but without concrete steps or examples on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not specify which part of the paper this issue pertains to, such as the intervention section or the results section. The authors can infer that it relates to the intervention or querying aspects, but this inference is not direct. The comment is specific in its suggestion to consider practicality and safety, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why these considerations are necessary or how they would impact the paper\"s findings. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the practicality and safety of the interventions included. It suggests that while the types of interventions are reasonable computationally, they need to be considered in terms of their practicality and safety for querying in the real world. This feedback is 3 as it highlights an important aspect that the authors should address, but it lacks specific guidance or suggestions on how to assess or improve the practicality and safety of the interventions. The authors are left to infer that they need to consider these aspects, but the comment could be more helpful with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or definitions, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper faces\" of the convex hull, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for better explanation of the dual subdivision and projection process, as well as the issue with the variable \"p\" not being explicitly defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the meaning of \"upper faces\" of the convex hull and the dual subdivision and projection process. It also points out the lack of explicit definition for the variable \"p,\" which has been used extensively throughout the paper. These are factual observations that do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several areas of confusion or lack of clarity in the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. These are important issues that could impact the understanding and interpretation of the paper. The comment suggests that these areas need better explanation or clarification, which is a clear and actionable piece of feedback. However, it could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how similar concepts have been explained in other works. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they could make to support the integration of images and their augmentations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the idea are questionable or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting that they can be interchangeable. However, it does not provide any specific reasoning or evidence to support this claim or offer suggestions for how the authors might address this concern. Without actionable feedback or detailed guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their proposed method separately from baseline detection or parsing techniques to better support their claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. The suggestion is concrete, as it specifies the need for separate evaluations and provides a rationale for why this is important. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generative shape model\" and the \"word parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that it is unclear which component contributes to the performance gain and recommends evaluating the method separately from baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain, and suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. The comment provides a logical reasoning by suggesting that the proposed approach follows a detectionparsing paradigm, which implies that evaluating separately would be beneficial. However, the comment lacks specific examples or references to support the claim, such as which baseline techniques should be used or how the proposed method compares to them. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that it is unclear which component contributes to the performance gain. It suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. This feedback is actionable as it provides a clear direction for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. By doing so, the authors can better understand the impact of their method and provide stronger evidence to support their claims. However, the comment could be more helpful if it included specific suggestions on which baseline techniques to use or how to interpret the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. While the comment implies that the authors should reconsider their approach, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their methodology and potentially revise the paper to include more automated disentangling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the manual disentangling process and suggests that the paper could be more interesting if it demonstrated everything being learned without manual intervention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The comment suggests that the paper could be more interesting if it demonstrated everything being learned without manual intervention. However, the comment lacks specific examples or references to support the claim that manual disentangling is not necessary or beneficial. Without detailed reasoning or evidence, the claim remains 3, as it provides a logical suggestion but lacks the necessary support to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the manual disentangling process in the paper, questioning why the semantic segmentation network is the first module in the pipeline and suggesting that the paper could be more interesting if it demonstrated everything being learned without manual intervention. This feedback is 3 as it prompts the authors to consider whether their approach is optimal and whether there are alternative methods that could be explored. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or methods for automating the disentangling process. While it identifies a potential area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of connection between the theoretical analysis and the proposed method, specifically questioning the enhancement of generalization for distant nodes. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific steps could be taken to strengthen the connection between theory and method. As a result, the authors are left without a clear understanding of what changes or improvements are needed to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical analysis and the proposed method, specifically mentioning the derivation of PACBayesian bound for GNNs in the transductive setting and the interplay between training and testing sets. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing the lack of a strong connection between the theoretical analysis and the proposed method, as well as the issue of adopting the selfattention mechanism from the transformer. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical analysis does not have a strong connection to the proposed method, and that the method seems to simply adopt the selfattention mechanism from the transformer. The reviewer questions how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a gap in the connection between the theoretical analysis and the proposed method, specifically questioning the enhancement of generalization for distant nodes. It points out that the proposed method seems to simply adopt the selfattention mechanism from the transformer and apply it to the graph. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or strengthen the connection between theory and method. While it highlights a potential weakness, it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether they should provide additional analysis, discuss the implications, or suggest alternative approaches. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Lipschitz Hessian assumption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the method\"s behavior without the Lipschitz Hessian assumption. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the method\"s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the robustness and generalizability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific aspects of the method might be affected. While it points out a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"equation (12)\" and \"the presentation of these methods,\" which provides some grounding by referencing specific parts of the paper. However, it does not specify which parts of the paper these references pertain to, making it weakly grounded. The comment is specific in pointing out the issue of vagueness in the presentation of existing methods, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some pieces rely on existing methods, such as equation (12), and that the presentation of these methods is vague. This feedback is 3 as it points out a potential weakness in the paper\"s originality and clarity. However, the comment lacks specific suggestions or guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment implies that the authors should provide explanations for these choices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for these decisions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the main rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the experimental setup need clarification or explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification about the rationales behind certain experimental decisions. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the rationales behind certain experimental decisions, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While it identifies areas that need clarification, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these questions. The feedback is 3 as it points out areas that need further explanation, but it could be more beneficial if it offered actionable advice or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include the results for all four datasets in Table 4, which provides a clear and direct action for the authors to take. The comment is specific in identifying the missing information and offers a concrete step to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely the results for all four datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and should include results for all four datasets. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and concrete step to improve their draft. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their results, which is crucial for the credibility and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific guidance or suggestions on how to improve it. There is no explicit or implicit action for the authors to take, such as suggesting ways to clarify or organize the content. Without any actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not specify which parts of the paper are affected. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or presentation are jumbled, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references, the authors may find it challenging to understand the basis of the critique or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific examples or guidance on how to improve the clarity or organization of the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what aspects of their writing need attention or how to address the issue. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or table where computational complexity is discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific in its inquiry about the computational complexity and power demand, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, the comment lacks specific examples or references to support the claim about computational complexity or power demand. Without detailed evidence or comparisons, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides a logical basis for the question but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment identifies a potential area for improvement by suggesting a comparison with other methods, it lacks specific guidance or suggestions on how to address this issue. The authors are left with a vague idea of what could be improved but are not provided with actionable steps to take. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It explicitly states that these heads are active at the S2 token but do not primarily attend to it, referencing Section 3 of Wang et al., 2023. This provides a clear and concrete action for the authors to correct the statement in their draft. The comment is explicit and provides specific guidance on how to revise the text, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the incorrect claim about the attention of these heads and references Section 3 of Wang et al., 2023 to support its assertion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect, citing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to the external work, which provides a clear and verifiable basis for the assertion. The reviewer logically explains the correct behavior of these heads, making the claim 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It points out that these heads are active at the S2 token but do not primarily attend to it, which is a critical correction for the authors to make. The comment is clear and actionable, providing the authors with specific guidance on how to correct their draft. By addressing this issue, the authors can improve the accuracy and clarity of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not provide any specific guidance or suggestions on how the authors could improve the pipeline or make it more novel. The comment lacks actionable details, such as recommending new approaches or improvements, making it difficult for the authors to know how to address the critique. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not specify which part of the paper this assessment is based on, such as the methodology, results, or discussion sections. Without explicit references to specific sections, the authors cannot confidently determine which parts need revision. The comment is specific in its critique of the pipeline being a \"pack of tricks,\" but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the pipeline is a \"pack of tricks\" or that the contribution is incremental. Without such support, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. It characterizes the pipeline as a \"pack of tricks\" to improve defense evaluation. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The authors are left without clear guidance on how to address the critique or enhance the originality of their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, it does not provide explicit guidance on how to develop a distributed version or what specific aspects need to be considered. The action is implied and somewhat vague, as the authors can infer that they need to develop a distributed version but are not given concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, suggesting that it is not scalable without a distributed version. However, it does not specify which part of the paper discusses the method or where the scalability issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the scalability issue but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the scalability of the method, suggesting that a distributed version is needed to accommodate realworld datasets. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specific guidance or suggestions on how to develop a distributed version or what aspects of the method need to be adapted for scalability. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the eta_ri term is not clearly explained as a noncentral chisquared distribution. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to clarify this point. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"eta_ri term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the eta_ri term being a noncentral chisquared distribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the eta_ri term being a noncentral chisquared distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this term should be considered unclear or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the eta_ri term being a noncentral chisquared distribution. This is a clear and actionable point that the authors can address to improve the understanding and clarity of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the implications of this clarification. Overall, the comment is 3 as it points out a specific area for improvement but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggests that the authors should provide more specific examples or references to support their claims. Additionally, it critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the examples later in the paper better illustrate generalization capabilities. While the comment provides some guidance on what needs to be clarified or revised, it does not offer explicit instructions on how to implement these changes. The actions are implicit and somewhat vague, as the authors need to infer the specific changes required to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L15\" and \"L1618,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggests that the examples later in the paper better illustrate generalization capabilities. The comment is specific in detailing what needs to be addressed, providing clear guidance on how to improve the clarity and coherence of the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggests that the examples later in the paper better illustrate generalization capabilities. The reviewer provides a reference to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to support their claim. This reference provides a clear and specific example of how generalization capabilities can be demonstrated, which strengthens the claim. However, the comment could be further strengthened by providing additional examples or detailed reasoning from the literature to fully substantiate the claim. Overall, the comment is 4, as it provides a solid foundation for the authors to address the issue of vagueness in their discussion.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and coherence of the paper. It points out that certain sections are vague, such as the discussion on certain RNNs working well for certain natural language reasoning tasks, and suggests that the examples later in the paper better illustrate generalization capabilities. The reviewer also critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the examples later in the paper better illustrate generalization capabilities. This feedback is actionable and provides clear guidance on how to improve the clarity and coherence of the paper. However, it could be more helpful if it offered specific suggestions on how to rephrase or restructure the content to enhance its effectiveness. Overall, the comment is 4 as it identifies areas for improvement and provides a direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more detailed analysis or justification for the proposed algorithm, but the comment lacks concrete steps or examples on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of difference in performance between the proposed sensitivelayer selection and randomized selection, as well as the absence of mathematical or theoretical justification for the proposed Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. The comment provides some logical reasoning by pointing out the lack of difference in performance and the absence of theoretical justification, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion. Additionally, it points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve their analysis. The feedback is 3 as it directs the authors to focus on these aspects, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. This is a clear and direct action for the authors to take, as it provides a specific guidance on how to improve the presentation of their data. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of triples as tuples instead of sets. This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuples instead of sets. This feedback is clear and directly addresses a potential issue with the presentation of the data, which could enhance the readability and understanding of the paper. By following this suggestion, the authors can improve the clarity and precision of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of speed analysis in the experiments, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. It suggests that the improvement on inference speed would be more interesting than reducing FLOPs. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include speed analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and the \"comparison of GFLOPs of different segmentation networks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of comparisons of inference speed between the proposed network and prior work. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of speed analysis is a significant issue, as it suggests that the experiments have focused on comparing GFLOPs of different segmentation networks but not on inference speed. The reviewer argues that the improvement in inference speed would be more interesting than reducing FLOPs. This claim is 3 as it provides a logical reasoning for why the inclusion of speed analysis is important. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of speed analysis in the experiments. It highlights the importance of comparing inference speed between the proposed network and prior work, suggesting that this would be more interesting than simply reducing FLOPs. This feedback is clear and actionable, as it directs the authors to include speed analysis in their experiments. However, it could be more helpful if it provided specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). The reviewer notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this scalability problem or suggest specific actions to improve the scalability of the quantization. The authors are left to infer that they need to address this issue, but without concrete steps, the comment remains 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of scalability in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the problem of quantization being a bottleneck for the method, which is crucial for the authors to understand and address. The comment is specific because it clearly outlines the issue with scalability and the impact on the method\"s purpose. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It also notes that even with clustering before, the cost of quantization is high in terms of both N (number of data) and M (dimension). The reviewer further explains that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. The claim is supported by logical reasoning and references to the paper, providing a clear understanding of the issue and its implications. Therefore, the comment is 5, aligning with a score of 5.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). This is a significant concern, as it affects the speed of VI (variable importance) and the method\"s applicability to big data/big model settings. The reviewer highlights that the quantization is a bottleneck for the method, which could lead to it losing its purpose. This feedback is clear and actionable, as it directs the authors to address the scalability issue and potentially explore alternative methods to improve scalability. However, the comment could be more helpful if it provided specific suggestions or examples of how to improve scalability. Overall, the comment is 4 as it identifies a critical weakness and offers a direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their methodology against existing methods, such as contrastive decoding, and to address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. The comment provides clear and concrete actions for the authors to take, specifying what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"core methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is comparing the effectiveness of the method against existing methods like contrastive decoding and addressing issues mentioned above. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. However, the comment does not provide specific examples or references to these existing methods or issues, making it difficult for the authors to understand the basis of the claim. The suggestion to aim for a more applicationoriented venue is vague without further explanation. Therefore, the claim is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. This feedback is specific and constructive, guiding the authors on how to enhance the rigor and relevance of their work. However, the comment could be more helpful if it provided examples of specific issues or comparisons to existing methods, which would help the authors understand the exact areas needing improvement. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. It also points out that the validation experiments are not comprehensive and that the time complexity and efficiency of the computation are not clearly analyzed. Additionally, it suggests that the authors should further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what changes are needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment also lacks specificity in terms of what needs to be addressed regarding the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questioning how it would operate effectively when the dataset is not fully perceptible. It also critiques the validation experiments as not comprehensive and points out the lack of analysis on the time complexity and efficiency of the computation. The reviewer expects the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claims. This makes the claim 3, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. It points out that the algorithm requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. Additionally, it critiques the validation experiments as not comprehensive and suggests that the authors should further elucidate the technical contribution rather than focusing solely on the form of the attack. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar problems have been addressed in similar works. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a statement in the paper that claims every kernel can be described by a feature space parameterized by a neural network, which is not true. The reviewer suggests that the limitation of representing infinitedimensional RKHSs with neural networks should be made more clear. While the comment identifies a specific issue with the claim, it does not provide explicit guidance on how to address it or what specific changes should be made to clarify the limitation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitation, but it lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of feature spaces and neural networks. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of representing infinitedimensional RKHSs with neural networks. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that every kernel can be described by a feature space parameterized by a neural network, pointing out a limitation with RBF kernels and their infinitedimensional representation. The reviewer provides a logical reasoning by referencing the fact that RKHS is famously infinitedimensional, making it impossible to represent with a neural network of finite width. This logical reasoning supports the claim, making it 4. However, the comment could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It points out a limitation with RBF kernels, which are famously infinitedimensional, making it impossible to represent them with a neural network of finite width. The reviewer suggests that the limitation should be made more clear, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a critical aspect of the paper that needs clarification, guiding the authors to enhance the accuracy and completeness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed method is not wellpositioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It suggests that the authors should conduct a thorough literature review to identify other works that use this property. While the comment explicitly states the need for a literature review, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of originality in the proposed method and the need for a thorough literature review to identify other works that use the same property. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and scoreinterpolation, which have used this property. This provides a clear and robust justification for the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known in the literature. It provides specific examples of existing works that use this property, such as the original denoising score matching objective and scoreinterpolation. This feedback is valuable as it highlights a potential gap in originality and suggests a thorough literature review to address it. However, the comment could be more helpful if it offered guidance on how to conduct the literature review or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or improve the handling of autoregressive decoding, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It mentions the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the handling of autoregressive decoding and the potential impact on inference benefits. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It suggests that the use of long token dimensions during training might limit the benefits of inference. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. This feedback is valuable as it prompts the authors to consider the limitations of their approach and how it might impact the inference phase. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how other approaches handle autoregressive decoding. Overall, the comment is 3 as it directs the authors to consider an important aspect of their work but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a weakness in the argument that PCC is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to substantiate this claim. This feedback is clear and concrete, as it specifies exactly what needs to be done to address the issue. The authors know exactly how to apply this suggestion to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption that PCC is more relaxed than KL divergence due to its invariance to scale and shift. The comment further provides a rationale for why this assumption is not convincing, suggesting that the constraint strength of a loss function is defined via its gradient distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the assumption that PCC is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by explaining that the constraint strength of a loss function is defined via its gradient distribution, using examples like KL divergence and MSE loss. This reasoning is based on a clear understanding of the concepts and their implications, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a key assumption in the paper regarding the relative relaxation of the Pearson correlation coefficient (PCC) compared to KL divergence. It questions the validity of this assumption by pointing out that the constraint strength of a loss function is defined by its gradient distribution, as exemplified by KL divergence and MSE loss. The comment suggests that a gradient comparison between KL and PCC is necessary to substantiate this claim. This feedback is clear and actionable, providing the authors with a specific direction to address the weakness in their argument. By addressing this point, the authors can enhance the robustness of their analysis and improve the clarity of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should provide additional analysis or discussion, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the reproducibility of GPI with noise added and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. The comment also mentions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the need for additional analysis or discussion based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to explore but are not provided with detailed steps or examples on how to proceed. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that if the authors have the resources, they should compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This is an explicit action that the authors can directly infer and implement. However, the comment does not provide specific guidance on how to conduct the comparison or what aspects to focus on, leaving some room for interpretation. Therefore, the action is explicit but somewhat vague in terms of execution. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting a comparison but lacks grounding as it does not explicitly mention a particular section or aspect of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be valuable or how it would contribute to the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, which could provide valuable insights into the performance of the proposed method. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. It does not offer detailed feedback or actionable advice, leaving the authors with a general suggestion that requires further exploration and interpretation. Therefore, the comment is 3 as it identifies an area for potential improvement but does not provide comprehensive guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. While the comment identifies an issue, it does not provide explicit guidance on how to address it or what specific experiments should be conducted. The authors are left to infer that they need to clarify this point and potentially conduct additional experiments, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the resolution of a debate left open in the paper. The comment questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the resolution of a debate left open in the paper and suggests that the distribution cannot be considered a factor in the results. It also questions whether experiments disentangle changes in distribution from the removal of information. While the comment raises valid points, it lacks specific examples or references to support the claim that the distribution is a significant factor. The reasoning is 3, as it highlights a potential issue but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is 3 as it points out a potential weakness in the paper that could be clarified or addressed. However, the comment lacks specific suggestions or guidance on how to resolve this issue or what experiments might be needed. While it highlights an area for improvement, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the other methods. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training and the comparison of methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that directly comparing results is unfair due to the different training settings. This provides clear guidance on what needs to be addressed to ensure fair comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that directly comparing results is unfair due to the different training settings used by the proposed method (AdamW with cosine lr) and the other methods (Adam with fixed lr). The reviewer suggests that reproducing the results using the same setting as the other methods would be more fair. This claim is 3 as it logically points out the issue with the comparison but lacks specific examples or references to support the argument. The authors would need to infer the specifics of the issue and determine how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods in the paper, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. This observation highlights a potential bias in the comparison, as the results may not be directly comparable due to the different training settings. The comment suggests that reproducing the results using the same setting as the other methods would be more fair, as most recent methods have their code released. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the fairness and validity of their comparison. By addressing this issue, the authors can enhance the credibility and reliability of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects to focus on. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section or experiment where this combination is discussed. Without explicit references or clear indications, the authors cannot confidently determine which part of the paper should be addressed. Additionally, the comment lacks specificity regarding what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it identifies an area of interest, it lacks specificity and actionable guidance for the authors. It does not provide details on how to conduct this analysis or what aspects to focus on, nor does it offer suggestions for potential improvements or insights. Without clear direction or context, the comment does not offer much value to the authors in terms of enhancing their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the plots are terrible, providing specific issues with the plot quality. It mentions that the plots are too small, colors are hard to distinguish, axis labels are poorly labeled, and labels are visually similar. The reviewer also points out that these issues are the main presentation of the experimental results, which should be clearer. This feedback is clear and provides concrete actions for the authors to take, such as improving the plot size, color contrast, and label clarity. The comment is 5 as it directly instructs the authors on how to enhance the clarity and quality of their plots, ensuring that they are easily understandable and visually appealing.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plots\" and provides specific issues with them, such as their size, color contrast, and label clarity. It also mentions the \"main presentation of the experimental results,\" which further reinforces the grounding. The comment is specific because it details the problems with the plots, such as the small size, hardtodistinguish colors, and unclear labeling. This provides clear guidance on what needs to be addressed to improve the clarity and quality of the plots. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the plots are terrible, with issues such as small size, hardtodistinguish colors, unclear labeling, and visually similar labels. The reviewer provides specific examples of these issues, such as pink vs red, sdropout(tr) vs edropout(tr), and poorly labeled error. These examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing additional examples or references to similar issues in other works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies several issues with the plots, including their small size, hardtodistinguish colors, unclear labeling, and visually similar labels. By pointing out these problems, the reviewer highlights areas where the authors can improve the clarity and quality of their plots, which is crucial for effectively communicating their findings. The comment is clear and direct, offering a clear path for the authors to enhance the presentation of their results. Therefore, it aligns with a score of 5, indicating that the comment is 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to address the issue of low performance gains. As a result, the comment lacks actionability, leaving the authors without any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the performance gains of the paper, specifically mentioning that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not specify which metrics or parts of the paper this analysis is based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the performance gains, but it lacks grounding as it does not reference specific sections or metrics. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific issue with the performance gains of the paper, noting that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). This is a clear and actionable observation that can guide the authors in understanding the limitations of their work. However, the comment could be more helpful if it provided suggestions on how to improve the performance gains or addressed potential sources of variability in the results. Overall, the comment is 3 as it identifies a specific area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a series of questions about the impact of the information about incorrect and corrected phrases and the type of mistake on the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. While the questions imply that the authors should analyze and present this information, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis and present the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"information about incorrect phrase / corrected phrase and the information about the type of the mistake,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the impact of this information on the feedback network and the performance without and with each of these two types of information. Additionally, it asks about the performance with just natural language feedback. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point poses a question about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information. It does not make any claims or suggestions that require verification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information. It also inquires about the performance with just natural language feedback. This line of inquiry could lead to valuable insights into the effectiveness of different types of feedback and how they impact the network\"s performance. However, the comment does not provide specific suggestions or guidance on how to address these questions or what specific analyses should be conducted. While it points out an area for further exploration, it lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with Table 1, noting that it does not show standard deviations. It suggests that this omission would make the submission stronger if the experiments were more extensive. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting which experiments should be included or how to present the standard deviations. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of standard deviations in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations, which would make the submission stronger if the experiments were more extensive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this omission is significant or how it affects the overall strength of the submission. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not show standard deviations. This is a clear and actionable point that could significantly improve the paper by including this information. However, the comment could be more helpful if it provided suggestions on how to present the standard deviations or which experiments should be included to enhance the submission. While it highlights an important area for improvement, the feedback is somewhat limited in its guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. However, it does not provide explicit guidance or suggestions on how the authors should address this question or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific tables (1, 2, and 3) and the addition of parameters in LinearTop and NLTop, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the question about the performance boost due to additional parameters, particularly in comparison to a different neural network. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. The comment references the use of a different neural network in [14], which provides some basis for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to conduct additional analysis or experiments to verify the claim fully. Therefore, the comment is 3, as it provides a starting point for further exploration but requires more detailed evidence or reasoning to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. It highlights the potential issue of using a different neural network in [14] and suggests that the authors should consider this when evaluating their results. While the comment identifies a potential weakness in the analysis, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it prompts the authors to consider a different baseline, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improving the paper\"s structure and focus. It suggests reordering the sections (introduction>method>experiments) and recommends placing more emphasis on the IEM in Figure 3, which is considered the main figure in the paper. Additionally, it suggests improving the visualization of Figure 7 and Figure. These actions are clear and concrete, providing the authors with specific guidance on how to enhance the clarity and focus of their paper. The comment is 5 as it directly instructs the authors on what changes to make to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"introduction,\" \"method,\" and \"experiments,\" allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be improved, such as the structure of the paper and the focus on the IEM in Figure 3. Additionally, it provides specific suggestions for improving the visualization of Figure 7 and Figure. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper is hard to follow and recommends improving the structure and focusing on the IEM in Figure 3. The comment provides a logical reasoning for the need to improve the structure, suggesting that it should be organized from introduction to method to experiments. However, the suggestion to focus on the IEM in Figure 3 is not supported by specific examples or detailed reasoning, making it 3. The comment also suggests improving the visualization of Figure 7 and Figure, but without further explanation or evidence, it lacks full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the structure and organization of the paper, suggesting improvements such as reordering the sections (introduction>method>experiments) and focusing on the IEM in Figure 3, which is considered the main figure in the paper. Additionally, it suggests improving the visualization of Figure 7 and Figure. This feedback is clear and provides the authors with concrete steps to enhance the clarity and focus of their paper. However, the comment could be more helpful if it offered additional suggestions or examples on how to improve the visualization or provided more detailed guidance on the structure and organization. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback implies that the authors should expand their discussion of related work to include a comparison with their own work. While the action is implicit, it is clear that the authors need to include a more detailed discussion of related work, which provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this discussion should be included in, such as the introduction, literature review, or results section. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting a more detailed discussion of related work, but without explicit references to sections or elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. However, the comment does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 2, as it lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback is 3 as it identifies an area where the paper could be improved by providing a more comprehensive comparison with existing work. However, the comment lacks specific guidance on how to structure this discussion or what aspects to focus on, leaving the authors with a general direction for improvement. While it points out a potential enhancement, it does not offer detailed suggestions or examples, making it 3 but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include attacks on other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should consider conducting experiments on these additional tasks, it does not provide specific guidance on how to implement these changes or what specific architectures or tasks should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper these experiments should be added to or which specific architectures or tasks should be considered. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment is not specific about what aspects of the experiments should be expanded or how they should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends expanding them to include attacks on other architectures and classification tasks. However, the comment does not provide any supporting evidence, examples, or references to justify why this expansion is necessary or beneficial. Without additional context or reasoning, the authors may find it challenging to understand the basis of the suggestion and how it could improve their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. This is a valuable suggestion as it could provide insights into the generalizability and robustness of the proposed method across different types of models and tasks. However, the comment lacks specific guidance on which architectures or tasks should be considered or how the authors might implement these changes. While it identifies a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. It highlights the concern that the authors only tested four different learning rates and suggests that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. While the comment explicitly states what information is missing and why it is important, it does not provide specific guidance on how to address this issue or what additional testing might be needed. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"deep models\" and \"CIFAR10 and CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing\u2014the final used learning rates for the deep models\u2014and why it is important for the authors to include this information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the authors only testing four different learning rates for the deep models, particularly CIFAR10 and CIFAR100, and suggests that this could affect the results if the optimal learning rate for the baseline is outside the tested interval. The comment provides a logical reasoning by highlighting the potential impact of testing a limited number of learning rates and the importance of knowing the final used learning rates. However, it lacks specific examples or references to support the claim that the optimal learning rate might be outside the tested interval. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the limited number of learning rates tested for the deep models, particularly CIFAR10 and CIFAR100. It highlights the potential impact of this limitation, suggesting that if the optimal learning rate for the baseline is outside the tested interval, it could affect the results. This feedback is clear and actionable, as it prompts the authors to consider whether their results are robust and whether additional testing is needed to ensure the validity of their findings. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional learning rates to test or discussing potential implications of the limited testing. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from neighborhood agents compared to faraway nodes. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or explain their choice. The comment lacks concrete steps or detailed advice on what aspects of the explanation should be improved or expanded. As a result, the authors are left without clear direction on how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from neighborhood agents compared to faraway nodes. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the transformer\"s lack of locality bias, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from neighborhood agents compared to faraway nodes. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the argument. As a result, the claim is not 5, making it difficult for the authors to understand and address the concern. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from neighborhood agents compared to faraway nodes. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or explain their choice. It does not offer detailed feedback or examples to help the authors improve their draft. As a result, the comment is 3, as it points out a potential weakness but does not provide enough direction for the authors to make significant improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the output from the algorithm depends on the order in which the data is processed and suggests that this should be clarified. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to clarify this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the order of data processing. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the output from the algorithm depends on the order in which the data is processed and recommends clarifying this point. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of the algorithm\"s dependence on data order, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data is processed, suggesting that this should be clarified. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output, suggesting that it depends on the order in which the data is processed. This is a clear and actionable point that the authors should address to improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify this aspect or offered examples of how other studies have addressed similar issues. Despite this, the feedback is 4 as it directs the authors to a critical area that needs attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the potential impact. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the potential impact of their mitigation strategies on performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies aimed at reducing memorization and questions their impact on overall performance. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and warns that significant impairment of the model\"s utility could deter adoption. However, the comment does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on performance, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the impact on performance. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies aimed at reducing memorization, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It raises a concern about the impact of these strategies on the overall performance of the model, noting that if they significantly impair the model\"s utility, it could deter their adoption. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or mitigate the potential impact on performance. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional actionable advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the reason for using 6fold crossvalidation in the experiments. It points out that other papers in the field did not use crossvalidation, which raises questions about its necessity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the rationale behind the crossvalidation. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clear explanation for the use of crossvalidation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of 6fold crossvalidation and the comparison with other papers that did not use it. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of clarity regarding the reason for using 6fold crossvalidation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reason for using 6fold crossvalidation is unclear because other papers in the field did not use it. However, the comment does not provide any supporting evidence or references to substantiate this claim. Without specific examples or detailed reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the reason for using 6fold crossvalidation. It points out that other papers in the field did not use this validation method, which raises questions about its necessity. This feedback is 3 as it highlights an area where the authors need to provide more detailed explanation or justification for their methodology. However, the comment could be more helpful if it suggested ways to address this issue, such as explaining the rationale behind the choice of crossvalidation or providing a comparison with other validation methods. Overall, the comment provides some insight but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide explicit instructions on how to do so. The action is clear but somewhat vague, as the authors know they need to conduct additional experiments but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three and there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This claim is 3 as it provides a logical reasoning for the need for additional experiments, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments themselves to fully understand the issue and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This feedback is clear and actionable, as it points out a critical weakness in the paper\"s results and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to conduct these additional experiments or what aspects of the analysis should be expanded. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the paper presents a highly effective engineering method for ReC and notes that the proposed framework incorporates combinatorial and heuristic aspects. It specifically points out the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information about the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the heuristic components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the impact of the heuristic components, such as the sophisticated filtering template. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC but notes that the framework incorporates combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential area for clarification, it lacks specific examples or references to support the claim that these heuristic components are problematic or unclear. The reasoning is 3, as it points out a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by clarifying the impact of the heuristic components, particularly the NonAmbiguous Query Generation procedure. It highlights a potential gap in the explanation of these aspects, which could be beneficial for the authors to address. However, the comment does not provide detailed guidance on how to clarify these aspects or what specific information should be included. While it points out an important area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the feasibility of training the proposed method without using camera information, specifically mentioning Line 223 and the \"knowledge of CAD model correspondences.\" It raises concerns about how ray marching can be performed without knowing the viewpoint and the origin of the ray. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification regarding the camera information and ray marching. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of training the proposed method without camera information, particularly regarding the \"knowledge of CAD model correspondences.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the feasibility of training the proposed method without camera information, specifically mentioning \"Line 223\" and the \"knowledge of CAD model correspondences.\" The comment raises logical concerns about how ray marching can be performed without knowing the viewpoint and the origin of the ray. However, the comment lacks specific examples or references to support the claim that camera information is necessary for training. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the feasibility of training the proposed method without camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. It highlights the importance of camera information for ray marching and understanding the origin of the ray. While the comment identifies a potential weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. The feedback is 3 as it points out a potential problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically mentioning the need for a detailed comparison of time complexity and competitiveness with prior art. While the comment implies that the authors should include such a comparison, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of the comparison should be addressed. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a particular comparison to be made. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, the comment does not provide specific examples or references to prior work that should be compared, nor does it explain why this comparison is necessary or how it would enhance the paper. Without detailed guidance or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. This feedback is 3 as it identifies an area where the paper could be improved by providing a more comprehensive comparison with existing work. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper discusses ODA as a method for solving the MOIP problem but does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the method should be emphasized. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA\" and \"MOIP problem,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not clearly explain how the presented method improves performance and computation speed over ODA. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not clearly explain how the presented method improves performance and computation speed over ODA, which is a method for solving the MOIP problem. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it does not clearly explain how the presented method improves performance and computation speed over ODA, which is a method for solving the MOIP problem. This feedback is 3 as it points out a gap in the paper\"s explanation, but it lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. While it highlights an area for improvement, the comment could be more helpful with additional guidance or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with some figures, particularly Figure 4, where the lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This feedback implies that the authors should provide additional explanations or labels to make these lines more selfexplanatory. While the action is implicit, it is concrete because it specifies the issue with the figure and suggests a clear way to address it by adding labels or explanations. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, specifically the lines \"No adapt\" and \"Finetune\" being covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 where lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This claim is 3 as it provides a specific example of an issue with the figure, which could be addressed by adding labels or explanations. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with some figures, particularly Figure 4, where lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it points out a specific area where the figures could be improved by providing additional labels or explanations. By addressing this issue, the authors can enhance the clarity and selfexplanatory nature of their figures, which is crucial for effective communication of their research findings. Therefore, the comment is 4, as it provides a concrete suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the evaluation. The comment suggests that the sampling method should be experimentally evaluated on the proposed benchmarks, but it does not specify which benchmarks or how the evaluation should be conducted. The lack of concrete details makes it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, the comment is 3, as it identifies an area for improvement but lacks specific guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sampling performed to obtain different initializations x_0, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this sampling is important for convergence to the optimum but is not evaluated carefully on the proposed benchmarks, except for Table 1 in the supplementary. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sampling method used to obtain different initializations x_0 is important for convergence to the optimum, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the sampling method should be evaluated on the proposed benchmarks, but it does not specify which benchmarks or how the evaluation should be conducted. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it points out that this sampling is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary. While the comment highlights an area for improvement, it lacks specific guidance on how the authors should address this issue or what additional experiments could be conducted. The feedback is 3 as it directs the authors to consider evaluating the sampling method more thoroughly, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions the authors\" choice of comparing the computational cost with [9] first and then [16], and why the authors only discuss the computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies areas for clarification and potential issues, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation or discussion of the computational cost and its relevance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific papers, \"[9]\" and \"16,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the logic of the comparisons, the choice of references, and the focus on computational cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. The reviewer questions why the authors compare the proposed method with [9] first and then [16], and why the authors only discuss the computational cost with [9]. The comment also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims. The authors would need to provide more detailed reasoning or evidence to fully address the reviewer\"s concerns. Therefore, the comment is 3, as it provides a starting point for the authors to explore and clarify the issues raised.", "helpfulness_rationale": "The review comment raises several pertinent questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions the authors\" choice of comparing the proposed method with [9] first and then [16], and why the authors only discuss the computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. These questions highlight areas where the authors could provide more detailed explanations or discussions to strengthen their work. However, the comment does not offer specific suggestions or guidance on how to address these issues, leaving the authors to infer the necessary improvements. While it identifies important areas for clarification and potential enhancements, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. While the comment explicitly states the need for additional experiments, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results, but this inference is not direct. The comment is specific in suggesting additional experiments and encouraging experiments on the full dataset, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why additional experiments are necessary or how they would improve the evaluation. The claim is based on a general suggestion, but without specific examples or detailed justification, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. This feedback is clear and actionable, as it directly instructs the authors to expand their experimental scope and improve the comprehensiveness of their evaluation. However, the comment could be more helpful if it provided specific suggestions on which datasets to include or how to conduct these experiments. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\" claims. It also mentions that the dataset transformation and experimental setup feel cumbersome and unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the tasks and experimental setup. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the proof of the authors\" claims and the clarity of the experimental setup. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task are unclear and that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper regarding the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. It highlights that the authors\" claims are not clearly supported by the tasks and experimental setup, which could lead to confusion for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their work. While it points out areas for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. The comment is clear and concrete, as it specifies exactly what needs to be added and how it should be presented. This provides the authors with a direct and specific action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of jointly discovering, hallucinating, and adapting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The comment provides a clear direction for the authors to include this analysis for a fair comparison with the baseline references. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of discussion regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide an analysis for a fair comparison with the baseline references. This feedback is clear and actionable, as it directs the authors to include a critical aspect of their work that could impact its validity and comparability. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it highlights a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, it does not provide specific guidance on how the authors should address this issue or what theoretical evidence should be presented. The comment implies that the authors should provide more detailed analysis or theoretical justification, but it does not offer concrete steps or examples of what this might entail. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of the correlation between dataset size and the Frobenius norm and singular values, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of theoretical evidence for the correlation and the need for more detailed analysis across different model architectures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is underwhelming and lacks theoretical evidence. It highlights the need for more detailed analysis and theoretical justification to support the trend observed. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional evidence could be presented. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential for information leaking in AutoAugment, which is used as a stronger augmentation strategy. It also questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, and its implications for SSL algorithms. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to mitigate them. The authors are left to infer that they need to consider these points and potentially revise their work, but the feedback lacks concrete steps or suggestions for improvement. Therefore, the comment is 3, as it highlights areas for consideration but does not provide detailed guidance on how to implement the necessary changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, and its implications for SSL algorithms. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the potential for information leaking in AutoAugment, which is used as a stronger augmentation strategy. It questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity and its implications for SSL algorithms. The comment is 3 as it provides a logical reasoning for the concern about information leaking, but it lacks specific examples or references to support the claim about the impact on SSL algorithms. The authors would need to further explore and substantiate the claim themselves, making the comment 3.", "helpfulness_rationale": "The review comment raises a concern about the potential for information leaking in AutoAugment, which is used as a stronger augmentation strategy. It questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity and its implications for SSL algorithms. This feedback is 3 as it prompts the authors to consider the potential impact of their method on information leakage and the broader implications for SSL algorithms. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these concerns or what alternative approaches might be considered. Overall, the comment identifies a relevant issue but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting but not necessary to explore how the model works with tabular data, specifically by considering each attribute dimension as a modality. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore tabular data but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this could be discussed. The authors can infer that it relates to the model evaluation or methodology sections, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality, would be interesting but not necessary. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exploration would be beneficial or necessary. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting but not necessary to explore how the model works with tabular data, specifically by considering each attribute dimension as a modality. This feedback is 3 as it identifies a potential area for further exploration or comparison, which could enhance the paper\"s contribution. However, the comment lacks specific guidance or suggestions on how to implement this exploration or what specific aspects of tabular data should be considered. While it points out a potential area for improvement, it does not provide detailed instructions or examples to help the authors fully understand and address the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include more analysis on the multilingual alignment of entity representations, specifically recommending visualizations or case studies for different types of languages. It also raises a question about the alignment of entities from lowresourced languages with highresourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific visualizations or case studies should be included. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the languageagnostic characters of entity representations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more analysis on the multilingual alignment of entity representations, including visualizations or case studies for different languages. The comment also raises a question about the alignment of entities from lowresourced languages with highresourced ones. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis on the alignment of entity representations, particularly in multilingual contexts. It recommends adding more analysis, including visualizations or case studies, for different types of languages. The comment also raises a question about the alignment of entities from lowresourced languages with highresourced ones. While the suggestion for additional analysis is logical, the comment lacks specific examples or references to support the claim that the current analysis is insufficient. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of analysis on the alignment of entity representations in multilingual contexts. It suggests that the authors should add more analysis, including visualizations or case studies, for different types of languages. Additionally, it raises a question about the alignment of entities from lowresourced languages with highresourced ones. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis and addressing a gap in their work. However, it could be more helpful if it included specific examples or references to similar studies that have successfully addressed this issue. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This explicit suggestion provides a clear action for the authors to take, which is to include additional details on using attention in an appendix. The comment is concrete, as it specifies the exact location where the additional information should be included, making it 5.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, it does not specify which part of the paper discusses attention or where the additional details should be added. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The suggestion to include more details is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why additional details are necessary or how they would enhance the paper. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including additional details on using attention. However, the comment could be more helpful if it elaborated on what specific aspects of attention should be addressed or how these details could improve the paper. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to check for duplicates and ensure the correct publication venues and years are included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the references list, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of duplicates and missing publication venues/years, providing clear guidance on what needs to be addressed. However, the comment does not provide detailed suggestions on how to resolve these issues, such as which specific papers are duplicates or how to ensure accurate publication information. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to verify and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the references list, noting that it contains duplicates and that the publication venues and/or publication years of many of the papers are missing. This feedback is clear and actionable, as it directs the authors to verify and correct the references list to ensure accuracy and completeness. However, the comment could be more helpful if it provided suggestions on how to identify and resolve duplicates or how to obtain missing publication information. Overall, the comment is 4 as it highlights a critical aspect of the paper that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It suggests that the authors should analyze and compare their theoretical results to those of other comparable methods. This feedback provides a clear and concrete action for the authors to take, which is to clarify the error bound and compare their results with others in the field. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound in Theorem 1 and the need for analysis and comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. The comment suggests that the authors should analyze and compare their theoretical results with those of other comparable methods. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim about the clarity of the error bound or the need for comparison. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and that the authors need to analyze and compare their results with other comparable methods. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the authors clarify the error bound and compare their results. By addressing these points, the authors can enhance the clarity and robustness of their theoretical analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or what specific aspects of the analysis should be clarified. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out that the pseudocode of the proposed method is missing. It also references external works that may be relevant to understanding the performance difference. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue or what specific aspects of the pseudocode should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include the missing pseudocode and explore the performance difference between explicit and implicit methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"locomotion tasks\" and the \"proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance difference between explicit and implicit methods and points out the missing pseudocode of the proposed method. Additionally, it references external works that could be relevant to understanding the performance difference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and mentions the missing pseudocode of the proposed method. It references external works by S\u00f8ren Asmussen and Peter W Glynn and P. Florence et al., which could provide some basis for the claim. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment could be strengthened by providing more detailed analysis or examples to fully justify the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a critical question about the performance of explicit methods compared to implicit methods on locomotion tasks, which is an important aspect of the paper. It also points out the missing pseudocode of the proposed method, which is a significant oversight. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the pseudocode should be included. While it identifies a significant gap in the paper, it does not provide actionable feedback or detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. It also mentions the method R3F and suggests that the authors should use it to maintain the generalization ability of the model. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the method R3F should be applied to. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of R3F and how it might impact their results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs to finetune the multilingual model and mentions the method R3F. It suggests that the improvement of 0.8 in some lowresource language translations is insignificant in practical terms. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The suggestion to use R3F is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. The reviewer supports this claim by referencing the method R3F, which is used to maintain the generalization ability of the model. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a reference to a relevant work, the explanation is somewhat vague, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs to finetune the multilingual model, suggesting that the improvement of 0.8 is insignificant in practical terms. It also mentions the method R3F as a potential solution to maintain the generalization ability of the model. While the comment provides some insight into the limitations of the current approach, it lacks specific guidance on how to address the issue or implement the suggested method. The reference to Aghajanyan et al. (2020) is helpful, but the comment could be more actionable with additional details or suggestions for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific reason for the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. While the comment implies that the authors should address this issue by providing a rationale or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the choice of Gaussian noise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper where the authors discuss their model\"s ability to work well for various image noise types, allowing the authors to accurately identify the relevant section. It is also specific because it questions the choice of Gaussian noise in the experiments and asks for a rationale or explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of Gaussian noise in the experiments, suggesting that there might be a particular reason for this choice. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specificity and does not offer a clear justification or explanation for the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. This is an important point as it highlights a potential limitation in the scope of the experiments. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional noise types could be considered. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and direct action for the authors to take, as it provides a specific request for visualization that is crucial to the research motivation of the paper. The comment is specific and actionable, as it clearly identifies what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the performance of existing PU learning methods as the dimensionality of the data increases. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the visualization of this effect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s claim about the performance of existing PU learning methods as the dimensionality of the data increases. It suggests that visualizing this effect is crucial to the research motivation of the paper. This feedback is clear and actionable, as it directs the authors to provide a visualization that can help substantiate their claim. By addressing this suggestion, the authors can enhance the credibility and clarity of their work. However, the comment could be more helpful if it provided specific guidance on how to create the visualization or what aspects to focus on. Overall, the comment is 4 as it highlights an important area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While the comment implies that the authors should consider moving this information to the supplementary materials, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider moving the information to the supplementary materials. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific, as it clearly identifies a potential improvement by recommending the inclusion of supplementary materials. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. The comment lacks specificity and does not offer a detailed explanation or references to support the claim. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While it provides a specific suggestion for improvement, it lacks depth and does not explain why this change would be beneficial or how it would enhance the paper. The comment does not offer detailed guidance or examples on how to implement this suggestion, leaving the authors with a general idea but without actionable steps to improve their draft. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide comprehensive guidance for the authors to address it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from [1] and references [2] to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. While the comment provides some guidance on what needs to be improved, it lacks explicit instructions on how to simplify the result descriptions or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from [1] and references [2] to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. However, the comment does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The suggestions are specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the result descriptions are needlessly convoluted and suggests that the authors consider a related idea from [1] and check for useful communication in light of [2]. The reviewer provides references to external works, which supports the claim by offering a logical connection to related literature. However, the comment could be strengthened by providing more detailed reasoning or examples of specific instances where the descriptions are convoluted. Despite this, the references provide a solid foundation for the claim, making it 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the complexity and clarity of the result descriptions, noting that some are needlessly convoluted. It provides a constructive suggestion by referencing a related idea from [1] and referencing [2] to check for useful communication. This feedback is actionable as it offers a clear direction for the authors to simplify their descriptions and potentially enhance the clarity of their work. However, the comment could be more helpful if it provided specific examples of convoluted descriptions or detailed guidance on how to simplify them. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the approximation error should be mathematically characterized, which provides a clear and direct action for the authors to take. This guidance is specific and concrete, as it specifies the exact improvement needed to clarify the approximation error. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the approximation error, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a mathematical characterization of the approximation error. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not provide any supporting evidence or reasoning to justify why the current definition is unclear or how a mathematical characterization would improve clarity. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approximation error definition, noting that it is ambiguous without additional context. It suggests that providing a mathematical characterization would improve clarity. This feedback is clear and actionable, as it directs the authors to make a specific improvement to enhance the clarity and understanding of their work. However, the comment could be more helpful if it provided examples or guidance on how to mathematically characterize the approximation error. Overall, the comment is 4 as it effectively points out a potential area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific line (ln. 180182) where Corollar 10 is discussed, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific changes should be made to the draft. As a result, the comment is 1, as it does not offer any direction for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made in Corollar 10, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out that the observation does not necessarily imply the desired outcome. However, it lacks specific examples or references to support the claim, making it 3. The authors may need to infer the full implications of the claim themselves, which could lead to some confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific line in the paper (ln. 180182) where Corollar 10 is discussed, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This feedback is 3 as it points out a potential weakness in the paper\"s argumentation, which could be clarified or expanded upon by the authors. However, the comment lacks specific suggestions or guidance on how to address this issue or what additional evidence might be needed to strengthen the argument. While it highlights an area for improvement, it does not provide detailed guidance on how to improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. While the comment identifies a specific issue with the model dynamics, it does not provide explicit guidance on how to address this problem or suggest alternative approaches. The action is implicit and somewhat vague, as the authors can infer that they need to consider ways to improve the dynamics and complexity of the model. However, without concrete suggestions or examples, the comment lacks clarity and is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"evolution model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the model dynamics, noting that the model produces only one node changing cluster per time step and that the evolution model is simplistic, with no other edges changing except those associated with the 1 node changing cluster. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. The comment provides logical reasoning by explaining the consequences of the reassignment probability and the simplicity of the evolution model. However, it lacks specific examples or references to support the claim that this is a significant issue or how it affects the overall performance of the model. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. This results in slow dynamics, as the model can only change one node at a time. Additionally, the comment points out that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. This feedback is valuable as it highlights a potential limitation in the model\"s dynamics and complexity, which the authors can address to improve their draft. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as proposing alternative models or methods for improving the dynamics. Overall, the comment is 4 as it identifies a critical area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there are missing details about the division to train and test sets, including numbers and the method of division (random or other considerations). It clearly instructs the authors to add these details, providing a direct action for improvement. The comment is specific and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division to train and test sets, including numbers and the method of division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, such as details about the division method and numbers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division to train and test sets, including numbers and the method of division. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the details about the division to train and test sets, including numbers and the method of division. It clearly states that these details should be added to improve the clarity and transparency of the paper. This feedback is actionable and provides a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered suggestions on how to present these details or provided examples of how similar studies have addressed this issue. Overall, the comment is 4 as it effectively points out a gap in the paper and provides a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for how to address the human labor issue or how to optimize the textual format for policy learning. Additionally, the comment does not offer guidance on how to mitigate the scalability issue. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment also lacks specificity regarding what aspects of the text descriptions or scalability issue need improvement. Without clear guidance on where to focus the revision, the authors may find it challenging to address these concerns effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that building text descriptions for each task still requires human labor and that the optimal textual format for policy learning varies from task to task and model to model. The reviewer also mentions the scalability issue with longtext inputs, which is based on a previous question. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. It acknowledges the complexity of determining the optimal textual format for policy learning, which varies across tasks and models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their work. While it highlights areas for consideration, it lacks actionable advice or detailed feedback that would help the authors make meaningful improvements to their draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance improvement of the proposed methods is not significant, as evidenced by the figure 3, and recommends using tables to show the key improvements more intuitively and in detail. While the comment provides a clear action\u2014using tables to present the key improvements\u2014it does not specify which tables should be used or how to present them. The authors are left to infer the details of implementing this suggestion, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods seems not so significant, with the biggest improvement in the bank dataset being around 0.02. Additionally, it suggests using tables to show the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, based on the figure 3, and suggests using tables to show the key improvements more intuitively and in detail. The comment provides a logical reasoning by pointing out the lack of significant performance improvement and the potential for more detailed presentation using tables. However, it does not provide specific data or references to support the claim about the performance improvement or the suggestion for using tables. This makes the claim 3, as the authors would need to make a concerted effort to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the performance improvement of the proposed methods seems not to be significant, as evidenced by figure 3. It suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results. By recommending the use of tables, the reviewer offers a method for making the improvements more understandable and detailed, which is valuable for the authors. However, the comment could be more helpful if it provided specific guidance on which tables to use or how to present the data in a more intuitive manner. Overall, the comment is 4, as it effectively points out a weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the experimental validation, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed information about the optimization strategy and consider related works, but the comment lacks specific instructions on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not offer concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental validation\" and \"shallow networks\" being considered, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental validation, such as the lack of description of the optimization strategy and the consideration of layer redundancy in the context of network pruning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, specifically mentioning the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. The reviewer also points out a minor issue with positioning with respect to related works, such as layer redundancy in the context of network pruning. While the comment provides some evidence by referencing a specific work on network pruning, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to conduct further research or analysis to fully understand and address the critique. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how to address them. The authors are left with a general understanding of the issues but without actionable steps to improve their draft. Therefore, the comment is 3, as it provides insight into areas for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not provide any guidance on how the authors might prove these results or what specific theoretical aspects should be explored. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical evidence or results to support their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the lack of theoretical results, but it is 1 as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what theoretical results could be explored. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors can provide more evidence to either prove or disprove it. While the comment implies that the authors should provide evidence to support or refute the hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to substantiate the hypothesis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. However, it does not specify which part of the paper this hypothesis pertains to, making it weakly grounded. The comment is specific in suggesting that the human test results might support the hypothesis but questions whether the authors can provide more evidence to prove or disprove it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion for additional evidence is a clear indication of what the authors could do to improve the draft, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a hypothesis about the two parts of the paper, suggesting that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. This feedback is 3 as it identifies a potential area for further exploration and provides a direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions on how to test or substantiate the hypothesis, such as recommending specific experiments or analyses. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the testing of the bAbI model, specifically asking whether it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should test the model on additional tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the model was only tested on a single supporting fact dataset, which is a clear and specific concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking about the testing of the bAbI model on other tasks. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the testing of the bAbI model, specifically asking whether it was only tested on a single supporting fact dataset (Task 1). This is a pertinent inquiry that could help the authors ensure that their model is thoroughly evaluated across different tasks. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback for improvement. Therefore, the comment is 3, as it identifies an area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should improve Section 3.2 by providing more illustrations and examples. This feedback is clear and direct, giving the authors a specific action to take to enhance the clarity and comprehensibility of their draft. The comment provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more illustrations and examples to improve the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to follow Section 3.2, implying that the content is unclear or lacks clarity. However, the comment does not provide specific examples or detailed reasoning to support this claim. It suggests that the authors might improve the section by adding more illustrations and examples, but this is not a fully developed argument. The lack of detailed justification or examples makes the claim 3, as it provides a direction for improvement but lacks the necessary evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It suggests that the authors might improve the section by providing more illustrations and examples, which could enhance its clarity and comprehensibility. While the comment highlights a potential area for improvement, it lacks detailed guidance or specific examples of what kind of illustrations or examples would be beneficial. This limits the comment\"s helpfulness, as it provides a general direction but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the technical contribution is limited, suggesting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve their technical contribution. The comment lacks actionable details, such as recommending alternative approaches or methods to enhance the technical contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is limited and does not provide a specific part of the paper where this issue is addressed. It mentions the crossdomain recommendation setting, but without explicit references to sections or figures, the authors cannot confidently determine which part of the paper is being discussed. The comment lacks specificity as it does not provide details on what aspects of the technical contribution are considered limited or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited and does not provide a significant extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is limited, specifically noting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their technical contribution. Without actionable feedback or detailed insights into what aspects of the paper could be strengthened, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the comment implies that the authors should add these baselines, it does not provide explicit instructions on how to implement this suggestion or what specific baselines to include. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the addition of fullysupervised baselines, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or how it would contribute to the understanding of the gap. Without such justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. This is a clear and actionable suggestion that could provide valuable insights into the performance of the models. However, the comment could be more helpful if it explained why this addition is necessary or how it would impact the understanding of the gap. Despite this, the suggestion is still valuable as it directs the authors to a specific area for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically asking about the time required to calculate the hypervolume of different regions in each step of the LaMOO algorithm. It also mentions that the computation of hypervolume could be timeconsuming, especially for problems with many objectives. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to improve the time complexity or optimize the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should address the time complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Time Complexity\" and the \"LaMOO algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the time complexity of the algorithm, particularly the repeated calculation of hypervolume for promising region selection. The comment suggests that the time complexity could be a problem for problems with many objectives, such as >3. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in the LaMOO algorithm could be timeconsuming, especially for problems with many objectives. The comment suggests that this could make LaMOO impractical for such problems. However, the comment lacks specific examples or references to support the claim that the time complexity is a significant issue. While it logically raises a concern, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in the LaMOO algorithm could be timeconsuming, especially for problems with many objectives. This is a relevant concern that could impact the practicality of the algorithm for certain types of problems. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or optimize the algorithm to reduce time complexity. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out an important area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the dataset used in the experiments is small but suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and does not affect the overall quality of the paper. The comment implies that the authors should consider running experiments on larger datasets, but it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider running experiments on larger datasets, but the comment lacks detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the dataset used in the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for results on larger datasets like ImageNet. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why larger datasets are necessary or how they would impact the paper\"s conclusions. Without additional context or examples, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges the issue of using small datasets in the experiments and suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and does not affect the overall quality of the paper. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address the issue of using small datasets. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, as well as the generic and vague title. It suggests being honest and direct in the critique and provides a specific example of what \"brittle convergence properties\" means. Additionally, it mentions that DeepRL methods are widely adopted and suggests considering the landscape 10 years ago. While the comment provides some guidance on what aspects to address, it lacks concrete details on how to implement these suggestions. The authors are given a general direction but may need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the limitations of evolutionary methods, the generic and vague title, and the need for more detailed discussion on leveraging state, reactiveness, and learning during an episode. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the title is too generic and vague and that the authors should be more precise in their critique. It also asks for clarification on the term \"brittle convergence properties\" and mentions the widespread adoption of DeepRL methods. Overall, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point makes several claims, including that the paper discusses limitations of evolutionary methods, the title is too generic and vague, and that DeepRL methods are widely adopted. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"brittle convergence properties\" is not explained, and the suggestion to be more precise in critiques is not accompanied by examples or detailed guidance. As a result, the claims are not 5, as they lack the necessary evidence or explanation to substantiate them. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, which could enhance the paper\"s depth and relevance. It also points out that the title is too generic and vague, suggesting that the authors be more precise in their critique. Additionally, the reviewer questions the term \"brittle convergence properties\" and notes that DeepRL methods are widely adopted, suggesting that the authors consider the landscape 10 years ago. While the comment provides some actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar works have tackled these topics. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack, the forward model, and the handling of depth discontinuities at edges. While it identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to address these issues. The questions are more of an inquiry into the methodology rather than direct actions for the authors to take. Therefore, the comment is 3, as it implies that the authors should provide more detailed explanations or examples to address these questions, but it does not specify exactly how to do so.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack, the forward model, and the handling of depth discontinuities at edges. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for clarification on the methodology, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the synthesis of the focal stack, the forward model, and the handling of depth discontinuities at edges. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they impact the paper\"s validity. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important questions about the synthesis of the focal stack, the forward model, and the handling of depth discontinuities at edges. These questions highlight areas where the paper could be improved by providing more detailed explanations or examples. However, the comment does not offer specific suggestions or guidance on how to address these issues, leaving the authors with a general idea of what needs to be improved but without actionable steps. While it identifies potential weaknesses, the feedback lacks depth and specificity, making it 3 but not comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper claims a unique contribution regarding the number of points and apriori knowledge needed for its algorithm, but it suggests that empirical justification would be beneficial. While the comment implies that the authors should provide empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first claimed contribution\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper lacks empirical justification for the claim about the number of points and apriori knowledge needed for the algorithm. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is unique because it does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment suggests that empirical justification would be beneficial. While the claim is based on logical reasoning, it lacks specific examples or references to support the claim. The authors are left to infer the need for empirical evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks empirical justification, which is the claim about the number of points and apriori knowledge needed for the proposed algorithm. It suggests that providing empirical evidence would strengthen the paper\"s contribution. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct the empirical analysis or what specific data or experiments should be included. This limits the comment\"s helpfulness, as it provides a direction for improvement but lacks detailed guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. While the comment identifies issues with novelty and similarity, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should improve the novelty and differentiate their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"specific components of the approach,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with novelty and similarity, such as the use of MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before, and the similarity in sampling strategy to epsilongreedy and BRPNAS. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. The reviewer also notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, the reviewer states that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. The comment provides specific references to external works, such as [2,3,7], which supports the claim that the components are not novel. However, the comment could be strengthened by providing more detailed comparisons or additional references to further substantiate the claim. Overall, the claim is 4, as it is supported by specific references and logical reasoning, but it could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty and originality of the approach, noting that the specific components are not novel as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also points out that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, the comment highlights that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. This feedback is 3 as it provides clear and actionable information about areas where the paper could be improved by differentiating the approach or presenting more novel aspects. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how the authors might differentiate their approach. Overall, the comment provides valuable insights but lacks depth and specific guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015) and suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and provides a concrete action for the authors to take, which is to include a detailed discussion on the comparison with RMED. The comment is specific in identifying the issue and provides a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed S1DBED algorithm\" and \"RMED (Komiyama et al. 2015),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion on the comparison with RMED. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the novelty of the proposed S1DBED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED to justify its novelty. This feedback is clear and actionable, as it directs the authors to include a detailed comparison with RMED to demonstrate the novelty of their work. However, the comment could be more helpful if it provided specific guidance on how to structure this discussion or what aspects to focus on. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the previous work should be discussed or how the authors should incorporate this discussion into their paper. The comment lacks explicit guidance or concrete suggestions on how to address this issue, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the discussion should be included. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. The comment is specific in identifying the need for a comprehensive discussion of previous work, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which previous works should be discussed or how this omission affects the paper\"s contribution. Without specific examples or references to previous works, the claim lacks verifiability. The authors would need to infer the importance of including a comprehensive discussion of previous work, making the comment 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical observation that could significantly impact the paper\"s contribution and credibility. However, the comment lacks specific guidance on what aspects of previous work should be discussed or how this discussion could be integrated into the paper. Without actionable suggestions or examples, the authors are left with a general direction but no clear path to follow. Therefore, the comment is 3, as it points out an important area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises questions about the OT sample selection process, specifically whether it runs once or iteratively, and suggests that more details and a flow chart would be helpful. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment implies that the authors should provide more details and a flow chart, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and a flow chart. However, the comment does provide specific questions about the process, which can guide the authors in understanding what information is missing and how to present it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. The comment also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment identifies areas for clarification and potential improvements, it does not provide specific evidence or references to support the need for these changes. The authors are left to infer the importance of these details, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the clarity of the paper regarding the OT sample selection process, specifically questioning whether it runs iteratively or only once. It suggests that more details and a flow chart would be beneficial for readers to understand the process. Additionally, it asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This feedback is clear and actionable, as it provides specific suggestions for improving the clarity and comprehensibility of the paper. By addressing these points, the authors can enhance the reader\"s understanding of the methodology and its execution. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the absence of experiments with continuous tasks and questions why the entropy methods for conditional optimization are not included in the experiments. It also asks how the empirical performance of these methods compares to ConBO. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to address this issue or what specific experiments should be conducted. The authors are left to infer that they need to include experiments with continuous tasks and compare the performance of the entropy methods to ConBO. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"continuous task setting\" and \"Section 7 in the appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the absence of experiments with continuous tasks and asks for clarification on the empirical performance of entropy methods compared to ConBO. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the absence of experiments with continuous tasks and questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix. It suggests that these methods should be included in the experiments and asks for a comparison with ConBO. However, the comment does not provide specific examples or references to support the claim that these methods should be included or how they might impact the results. The lack of detailed justification or evidence makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the absence of experiments with continuous tasks and questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix. It also asks for a comparison with ConBO, which is a relevant benchmark. This feedback is 3 as it points out a potential area for improvement and provides a specific question that the authors could address to enhance their work. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or provided examples of how to compare the entropy methods with ConBO. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a comparison between GCG and other LLMs could be included, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs. While the comment provides a clear action for the authors to include a comparison, it does not specify how to conduct this comparison or what specific aspects to focus on. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG\" and \"other LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison between GCG and other LLMs, and the issue with the jailbreaking percentage for certain LLMs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison between GCG and other LLMs could be included, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. The comment also points out a minor issue with the jailbreaking percentage for certain LLMs. While the comment provides a logical basis for the suggestion, it lacks specific examples or references to support the claim about the jailbreaking percentage. This makes the claim 3, as it provides a clear rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending the inclusion of a comparison between GCG and other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs. This feedback is valuable as it guides the authors on how to enhance their work by including a comparison that could strengthen their findings. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the authors\" explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it acknowledges the novelty of the approach, it explicitly requests a more detailed explanation to better understand the difference. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of unsupervised feature selection from a diffusion perspective, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of the difference between similarity and exit times in nature. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer acknowledges the novelty of the approach but expresses difficulty in understanding the distinction. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the explanation is unclear. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to better understand the distinction. This feedback is 3 as it points out a potential gap in the paper\"s explanation, prompting the authors to provide a clearer explanation. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of how the distinction might be clarified. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. While it implies that the authors should address this limitation, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations of the framework, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the framework is limited in this way. Without such information, the authors may find it challenging to address the question or understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. This is a relevant point that could help the authors identify potential areas for improvement or expansion in their work. However, the comment lacks specific guidance or suggestions on how to address this limitation or what specific aspects of the framework might need improvement. While it points out an important area for consideration, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the calculation of precision/recall/F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these metrics and AUC results. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the calculation of precision/recall/F1score for a 4class classification of breast density and the reporting of AUC results for breast cancer detection. It also specifies the need for sensitivity and specificity at different operating points for model performance comparisons. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual questions about the calculation of precision/recall/F1score and the reporting of AUC results for breast cancer detection. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the calculation and reporting of metrics for a 4class classification of breast density and breast cancer detection. It suggests that providing AUC results with sensitivity and specificity at different operating points could be more informative for comparisons. This feedback is clear and actionable, as it directs the authors to include specific metrics that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it provided examples of how these metrics are typically reported or suggested specific operating points to consider. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is wellstudied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\" dataset can be considered extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the Kialo dataset. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters, and that it is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The suggestion to consider using the Kialo dataset is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community. The reviewer claims that the Kialo dataset provides pairs of short claims and their counters and is cleaner than the dataset created by the authors. However, the comment lacks specific examples or references to support the claim that the Kialo dataset is cleaner or that it provides exactly what the authors need. While the suggestion to consider using the Kialo dataset is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community and provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner than the one created by the authors and can be considered extra data to learn from. While the comment provides a clear suggestion for the authors to consider using an existing dataset, it lacks detailed guidance on how to incorporate this dataset into their work or why it would be beneficial. The feedback is 3 as it identifies a potential source of data, but it could be more helpful with additional explanation or suggestions on how to integrate it effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Transformer in the paper, noting that it is no longer novel in the field and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement in the ablation study, suggesting that it is limited and not a significant improvement. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific modifications should be made to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the novelty and significance of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Transformer\" and \"crosslayer,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the modification does not bring much insight and that the selfcross attention improvement is limited. Additionally, it provides specific examples from the ablation study (table 4 and 5) to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of Transformer in the paper is not novel and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer supports this claim by referencing the widespread adoption of Transformer in NLP and vision tasks, which suggests that the modification is not a significant contribution. Additionally, the reviewer points out that the selfcross attention improvement is limited (<1%) and does not contribute significantly to the overall improvement. The comment is 4 as it provides logical reasoning and specific examples from the ablation study to support the claim. However, it could be strengthened by referencing specific studies or literature that demonstrate the limited impact of the selfcross attention improvement. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a critical analysis of the paper\"s contribution, specifically regarding the use of Transformer and the authors\" modification (crosslayer). It points out that the Transformer is no longer novel in the field and that the modification does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement, noting that it is limited to less than 1% in the ablation study. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution and suggests that the authors should reconsider the novelty and significance of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or what aspects of the paper could be improved. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses a concern about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. However, it does not provide specific guidance on how to implement these changes or what aspects of the experiments should be improved. The comment implies that the authors should address the weaknesses mentioned, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the limited number of tasks and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. The comment also asks the authors to address the weaknesses mentioned above, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the number of tasks in the experiments is limited and recommends including at least 10 tasks and sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning or evidence to support why the current number of tasks is insufficient or how adding more tasks would improve the experiments. The suggestion is based on a general expectation, but without detailed justification or examples, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically the limited number of tasks. It suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, as it provides a specific direction for improvement. However, the comment could be more helpful if it explained why the current number of tasks is insufficient or how adding more tasks would enhance the experiments. Despite this, the feedback is 4 as it guides the authors on how to strengthen their experimental design."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional tasks they should include in their experiments. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, specifically mentioning \"sentence similarity tasks and open domain QA tasks.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited and suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out that these tasks are common in the NLP field and could enhance the scope of the experiments. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the experiments. This makes the claim 3, as the authors would need to infer the importance of these tasks themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the scope of their work. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include the prompt in the appendix or supplement, providing a clear action for the authors to take. Additionally, it suggests that the abstract may be difficult to understand and recommends rephrasing it. The comment about Figure 2 is more vague, as it lacks specific guidance on how to clarify the figure or what changes are needed. However, it does point out a potential issue with the figure, which could be addressed by providing more detailed instructions or examples. Overall, the comment is 4, as it provides concrete actions for the authors to take, but it could be more detailed in some areas.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the appendix or supplement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the appendix or supplement and provides a suggestion for improving the abstract by rephrasing lines 016019. Additionally, it points out that Figure 2 is unclear and lacks labeled yaxes, providing specific guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, providing a clear and actionable suggestion for improvement. However, it does not provide any supporting evidence or reasoning to justify why this is necessary or how it would benefit the paper. The comment about the abstract being difficult to understand and suggesting rephrasing is also vague and lacks specific guidance. Similarly, the comment about Figure 2 is unclear about what is unclear and lacks detailed suggestions for improvement. Overall, the comment lacks sufficient justification and evidence to be 5, making it difficult for the authors to understand and address the issues effectively. Therefore, it is rated as 2.", "helpfulness_rationale": "The review comment provides two main pieces of feedback: first, it suggests that the prompt should be included in the appendix or supplement, which is a clear and actionable suggestion for improving the paper. Second, it points out that the abstract is difficult to understand and recommends rephrasing it. Additionally, it notes that Figure 2 is unclear and lacks labeled yaxes, which could be improved by providing more detailed explanations or examples. While the comment identifies specific areas for improvement, it could be more helpful by offering detailed guidance on how to address these issues. Overall, the comment is 4 as it provides actionable feedback, but it could be more comprehensive to fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. While the comment raises a valid point, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their motivation. The authors are left to infer that they need to provide a clearer explanation or rationale for their choice, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this analysis is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity in detailing what needs to be clarified or improved regarding the motivation for analyzing only the last convolutional layer. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the motivation for analyzing only the last convolutional layer, specifically questioning why numerosity would not appear in earlier layers. This is an important point that could impact the clarity and comprehensiveness of the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide a clearer explanation. While it identifies a potential weakness, it does not offer actionable steps or examples for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the parameter S remains a problem, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps the authors should consider to improve the parameter setting. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the issue of setting the parameter S, but it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the parameter S setting is problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment states that \"How to set the parameter S remains a problem,\" but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the parameter S, noting that setting it remains a problem. However, it lacks any actionable guidance or suggestions on how to address this issue or improve the parameter setting. Without detailed feedback or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider conducting a human evaluation, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The authors are left to infer that they should consider conducting a human evaluation, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper discusses the evaluation metrics or the caption generation process, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include human evaluation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion and how it could be applied to their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback highlights a potential weakness in the paper\"s evaluation methodology and provides a clear direction for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the caption generation process should be evaluated by humans. While it identifies an area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the claim in the introduction that \"these shape constraints do not require tuning a free parameter\" and the fact that the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be considered a hyperparameter that needs to be chosen or tuned. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this discrepancy. The action is implicit, as the authors can infer that they need to clarify or correct the statement in the introduction, but it is not explicitly stated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the claim about \"these shape constraints,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, noting that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim in the introduction that \"these shape constraints do not require tuning a free parameter,\" by pointing out that the choice of convex or concave constraints, and increasing/decreasing constraints, can be considered hyperparameters that need to be chosen or tuned. This is a logical observation based on the definition of hyperparameters, which are often tuned to optimize model performance. However, the comment does not provide specific examples or references to support the claim that these constraints should be considered hyperparameters. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the introduction regarding the claim that \"these shape constraints do not require tuning a free parameter.\" It points out that the choice of convex or concave constraints, and increasing/decreasing constraints, can be considered hyperparameters that need to be chosen or tuned. This feedback is valuable as it highlights a potential inconsistency in the paper that the authors should address to ensure clarity and accuracy. However, the comment could be more helpful if it provided specific suggestions on how to clarify this point in the introduction or offered examples of how the authors might present this information more clearly. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It highlights a specific assumption, Assumption 4.1, which indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be adapted from previous theorems with straightforward modifications, as outlined in Modification 1 in Appendix C. This provides a clear and concrete action for the authors to take, which is to review and potentially revise the convergence proof to enhance its novelty and rigor. The comment is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical proof for convergence, noting that it lacks novelty and rigor due to the trivial adaptation from previous theorems. The comment provides a clear rationale for why the proof is not substantial, which helps the authors understand the need for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial and lacks novelty and rigor. It supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted from previous theorems with straightforward modifications, as outlined in Modification 1 in Appendix C. This reasoning is based on logical deduction from the assumptions and the provided modifications, making the claim 4. However, the comment could be strengthened by referencing specific theorems or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It points out that the assumption of $X$ being i.i.d. leads to a clear covariance matrix for $Z$, which can be trivially adapted from previous theorems with straightforward modifications. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By highlighting the lack of novelty and rigor in the proof, the comment offers a constructive suggestion for improvement. However, it could be more helpful if it provided additional guidance on how to enhance the rigor or novelty of the proof. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental setup borrowed from [2] is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This provides a clear and direct action for the authors to take, which is to mention this fact clearly in their paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental setup borrowed from [2], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, namely that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup borrowed from [2] is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This claim is 3 as it provides a logical reasoning for the classification, based on the description of the experimental setup. However, it lacks specific examples or references to [2] to fully substantiate the claim. The authors would need to infer the details of the setup from the reference, which could be challenging without direct access to the original work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This is a clear and actionable observation that the authors should address by explicitly mentioning this aspect of the experimental setup. By doing so, the authors can clarify the nature of their experimental design and ensure that their results are accurately represented. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included in the clarification. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues: the limited scope of datasets and models used in the study and the lack of assessment of other important biases and datasets. It also points out the absence of assessments on stateoftheart generative models like GPT. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand their dataset and model selection and include assessments on additional biases and models like GPT. However, the comment lacks concrete suggestions on how to implement these changes or what specific biases and models should be included. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the limitations of the datasets and models used in the study, specifically mentioning the bias benchmarks and the absence of assessments on stateoftheart generative models like GPT. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the dataset and model selection and the need for additional assessments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the datasets and models used in the study are limited and that the bias benchmarks only assess gender, race, and religion. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies specific limitations, it lacks detailed justification or examples to fully substantiate the claim. The authors would need to infer the importance of these assessments and the potential impact on the study\"s conclusions. Therefore, the comment is 3, as it provides some basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant limitation in the study, noting that the datasets and models used are limited and that the bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. This feedback is valuable as it highlights areas where the study could be expanded to include a broader range of biases and models, which would enhance its scope and relevance. However, the comment could be more helpful if it provided specific suggestions on how to address these limitations, such as recommending additional datasets or models to consider. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it lacks detailed guidance on execution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential contradiction in the paper, noting that the multienv model is stated to have an inevitable performance loss but also outperforms the singleenv model due to knowledge sharing. The reviewer requests clarification, indicating that the authors need to address this contradiction. While the comment implies that the authors should clarify the contradiction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they need to clarify the contradiction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about the multienv model having an inevitable performance loss and the statement about knowledge sharing leading to outperformance. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of contradiction between the two statements and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contradiction between the claims that the multienv model has an inevitable performance loss and that it outperforms the singleenv model due to knowledge sharing. The reviewer does not provide any supporting evidence or reasoning to substantiate this claim, making it difficult for the authors to understand the basis of the contradiction. Without additional context or examples, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the performance of the multienv model. It points out that the model is stated to have an inevitable performance loss but also outperforms the singleenv model due to knowledge sharing. This is a clear and actionable observation that prompts the authors to clarify this contradiction. By addressing this issue, the authors can improve the coherence and consistency of their argument. However, the comment could be more helpful if it provided suggestions on how to resolve the contradiction or offered additional context to better understand the implications. Overall, the comment is 4 as it directs the authors to a critical area needing clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or a citation to the metrics. This feedback is explicit, as it clearly states what the authors need to do to improve their draft: either provide an explanation or a citation to the metrics used. The action is concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of the metrics,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation or a citation to the metrics used in the paper. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the metrics is limited and suggests that an explanation or citation to the metrics would be beneficial. However, the comment does not provide specific examples or detailed reasoning to support why the current description is insufficient or how an explanation or citation would improve the paper. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the lack of an explanation or citation for the metrics used. This is a critical feedback as it highlights an area where the authors could enhance the clarity and transparency of their work. By suggesting that an explanation or citation would be beneficial, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific examples of how the metrics are used or why they are important, which would guide the authors in addressing the issue more effectively. Overall, the comment is 4 as it points out a significant gap in the paper but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies issues with Figure 3, including the unclear workflow and captions, as well as the confusing representation of communication modes on the left side. This provides a clear and specific action for the authors to take, which is to clarify and improve the figure. The comment also suggests that the captions and representation need attention, offering concrete guidance on what aspects need to be addressed. Therefore, the comment is 5, as it provides explicit and detailed instructions on how to enhance the figure to improve the clarity and understanding of the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as the representation of communication modes on the left side. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks specific references or examples to clarify the issues, making it difficult for the authors to address the feedback effectively. Therefore, the claim is considered 2, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as the representation of communication modes on the left side. This feedback is clear and actionable, as it points out specific areas that need improvement to enhance the clarity and comprehensibility of the figure. By addressing these issues, the authors can significantly improve the figure and, in turn, the overall understanding and impact of their work. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered examples of how similar figures have been effectively communicated. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"learned [MASK] embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this term or what specific actions they should take to address this issue. The comment lacks concrete details or suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SSL pretraining stage\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"learned [MASK] embedding,\" which is unclear in the context of SSL pretraining. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"learned [MASK] embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to explain why this term is unclear or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary justification to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. This is a clear and actionable point that the authors can address to improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the issue and how to resolve it. Overall, the comment is 3 as it points out a specific area for improvement but lacks depth and detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented for standard networks in the literature. However, it does not provide specific guidance on how the authors should address this issue or what changes they should make to improve the originality of their work. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented for standard networks in the literature. However, it does not specify which part of the paper this issue pertains to, such as specific sections, figures, or tables where these results are presented. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented for standard networks in the literature. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented for standard networks in the literature. However, it does not provide specific examples or detailed guidance on how the authors could address this issue or improve the originality of their work. Without actionable suggestions or examples, the comment lacks depth and does not offer meaningful assistance to the authors in enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It highlights that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting specific ways to motivate the problem or providing examples of streaming applications that could benefit from such algorithms. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger rationale for the problem\"s relevance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the objective of the paper, which is to design fast label aggregation algorithms for a streaming setting. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the lack of motivation for the problem and the use of static datasets in the empirical analysis. It suggests that the paper should provide a stronger rationale for the problem\"s relevance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It notes that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide specific examples or references to support this claim, nor does it offer suggestions on how to address the issue. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of motivating the problem and the relevance of the datasets used. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It points out that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. The comment suggests that the problem should be well motivated to make the paper more valuable. While it highlights an important area for improvement, it does not provide specific suggestions or examples on how to address this issue or what additional motivation could be included. The feedback is 3 as it directs the authors to a critical area needing attention, but it could be more actionable with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for incontext learning of large language models should be included in Tables 2 and 3. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to add these baselines or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3\" and \"Question A,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional relevant CoT baselines for incontext learning of large language models. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach to smallscale language models. The reviewer provides a specific observation that additional relevant CoT baselines for incontext learning of large language models (such as text003 and ChatGPT) are missing in Tables 2 and 3. This claim is 3 as it provides a logical reasoning for the need to include these baselines, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for incontext learning of large language models (such as text003 and ChatGPT) should be included in Tables 2 and 3. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the scope and comprehensiveness of their study. By addressing this point, the authors can ensure that their work is more comprehensive and relevant to the field. However, the comment could be more helpful if it included specific examples or references to relevant CoT baselines. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their study."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Figure 3 is difficult to read, providing a clear action for the authors to take. However, it does not specify what aspects of the figure are challenging to read or how the authors might improve the figure to make it more readable. While the action is explicit, the lack of concrete details on how to address the issue makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, stating that it is difficult to read anything on the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 3, stating that it is difficult to read anything on the figure. This feedback is clear and actionable, as it directs the authors to address a specific visual aspect of their work that may impact the readability and comprehension of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as recommending adjustments to the figure size, font, or color scheme. Despite this, the feedback is 3 as it points out a clear area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the connection should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential area for further exploration or discussion, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. The comment lacks depth and specificity, leaving the authors without clear guidance on how to proceed. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether the GAT is trained with the whole model and suggests that the text needs to be reviewed by an English native speaker to improve clarity. While the comment implies that the authors should review the text for clarity, it does not provide specific guidance on how to achieve this or what aspects of the text need to be revised. The action is implicit and somewhat vague, as the authors can infer that they need to review the text but may not be entirely sure of the exact changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the training of the GAT with the whole model and suggests that the text needs to be reviewed for clarity. However, it does not specify which part of the paper this pertains to, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting that the text needs to be reviewed and rewritten for clarity, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training of the GAT with the whole model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the training of the GAT with the whole model, suggesting that it needs to be reviewed for clarity. While it identifies a potential issue with the clarity of the text, it lacks specific guidance or suggestions on how to improve the clarity or what aspects of the text need to be revised. The comment is 3 as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and questions the justification behind using an SGD learning rate of ~0.1. While the comment provides a specific action to take regarding the parameter `lambda`, it does not offer guidance on how to address the issue with the SGD learning rate or what the justification should be. The action is explicit but lacks concrete details on how to implement the change or justify the choice of `lambda`. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes two claims: (1) replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and (2) questioning the justification behind using an SGD learning rate of ~0.1. The first claim is 3 as it suggests a change in the mathematical expression but lacks detailed explanation or justification for the proposed change. The second claim is also 3, as it questions the justification behind the learning rate but does not provide specific reasoning or examples to support the claim. Overall, the review point is 3, as it provides some basis for the claims but lacks detailed evidence or references to fully substantiate them.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. It points out that the justification for these choices is unclear, which is a valuable observation that can help the authors improve their draft. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered alternative justifications for the choices made. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance on how to implement the suggested changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This guidance is clear and specific, giving the authors a direct action to take. The comment also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the importance of error analysis and its role in evaluating model performance and identifying potential issues. It also encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it clearly specifies the need for error analysis and its importance in guiding subsequent improvements and expansions of the ERC research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This claim is 3 as it logically supports the importance of error analysis in the context of model evaluation and improvement. However, the comment lacks specific examples or references to substantiate the claim fully. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of error analysis in evaluating model performance and identifying potential issues, and encourages the authors to conduct such analysis and provide detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by incorporating error analysis, which can significantly impact the understanding and interpretation of their results. However, the comment could be more helpful if it included specific examples or suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a general direction for improvement, it lacks specific guidance on how to conduct the analysis or what aspects of the domain gap should be discussed. The authors are left to infer the specific actions they need to take, such as identifying which datasets are closer and how to assess the adaptation issue. The feedback is 3 as it provides a general direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should include this analysis or discussion, nor does it provide detailed guidance on how to conduct the analysis or what aspects of the domain gap should be discussed. While the authors might have an idea of where to focus their efforts, the lack of explicit grounding and specificity makes it challenging to pinpoint the exact sections that need attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a logical reasoning for the importance of analyzing the domain gap, it lacks specific examples or references to support the claim about the gap between datasets or the value of finetuning on synthetic data. This makes the claim 3, as it provides a general direction but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to analyze the domain gap and discuss the gap between datasets. It highlights the importance of understanding the adaptation issue and the potential value of the approach if it can finetune a pretrained model on synthetic data. This feedback is valuable as it guides the authors to consider specific aspects of their work that could be improved or expanded upon. However, the comment could be more helpful if it provided examples of how to conduct the analysis or what specific aspects of the domain gap should be discussed. Overall, the comment is 4 as it offers clear and actionable guidance for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the scalability of the model, specifically noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, such as 10, and questions how the authors plan to scale up without compromising performance. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider how to scale up without compromising performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and the issue of scalability, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the performance degradation as the maximum number of identities grows, and it suggests that the capacity should be set to a small number, such as 10. The comment further questions how the authors plan to scale up without compromising performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the model degrades as the maximum number of identities grows, suggesting that the capacity should be set to a small number, such as 10. The reviewer provides a logical reasoning by explaining that in realworld scenarios, the number of objects can be more than 10, and the authors should consider how to scale up without compromising performance. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the model, noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, such as 10, to address this issue. The comment also raises a valid concern about how the authors plan to scale up without compromising performance in realworld scenarios. This feedback is clear and actionable, as it provides a concrete suggestion for improving the model\"s scalability. However, it could be more helpful if it included examples or references to similar studies or methods that have successfully addressed similar scalability challenges. Overall, the comment is 4 as it directs the authors to a critical area for improvement and offers a specific suggestion for addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors claim their work as preliminary but question the NLPspecific aspects of their approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be revised to better align with an NLPspecific focus. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim made by the authors regarding their work being preliminary and discusses the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the lack of NLPspecific aspects in the approach, but without explicit references to sections or details, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim made by the authors that their work is preliminary, specifically regarding the application of LLP to NLP tasks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim made by the authors that their work is preliminary, specifically regarding the application of LLP to NLP tasks. It points out that the approach does not appear to have any NLPspecific aspects, which is a valid observation. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their approach to better align with an NLPspecific focus. Without detailed guidance or examples, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that at least one NCEbased method should be included for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, as it specifies the exact action the authors need to take by including a specific method for comparison. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison should be included. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in suggesting the inclusion of an NCEbased method for comparison, but it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This reference provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how this method could be integrated into the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is 3 as it provides a clear direction for the authors to consider adding a relevant method for comparison. However, the comment could be more helpful if it explained why this particular method is relevant or how it could enhance the paper\"s contribution. Additionally, it could offer suggestions on how to integrate the new method into the existing work or discuss its potential impact on the results. Overall, the comment provides a starting point for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a clear direction for improvement, it does not specify which specific tests should be conducted or how to conduct them. Additionally, it does not mention which recent LLMs should be compared. While the action is explicit, the lack of concrete details on how to implement the suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the experiment section, specifically mentioning the need for significance tests on human evaluation results and comparing the proposed method with recent LLMs. However, it does not specify which part of the experiment section needs improvement or which specific LLMs should be compared. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting improvements, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these changes would significantly enhance the experiment section. The absence of detailed justification or evidence makes the claim 3, as the authors would need to make a significant effort to understand and implement the suggested improvements.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment section, specifically suggesting the inclusion of significance tests on human evaluation results and the comparison of the proposed method with recent LLMs. While the comment provides a clear direction for enhancing the experiment section, it lacks specific guidance on how to conduct these tests or which recent LLMs should be compared. This limits the comment\"s helpfulness, as it offers actionable suggestions but does not provide detailed instructions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to discuss a previous work on joint error for UDA, specifically mentioning \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. It also suggests that the authors should illustrate the relationship between this work and their proposed method, as well as highlight why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the joint error for UDA and references a specific work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" from ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the relationship between the proposed method and the previous work, and why the proposed method is better. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about the joint error for UDA is incorrect, as it has already been studied in previous works like \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. The reviewer supports this claim by referencing the specific work, providing a clear and direct reference to substantiate the claim. This reference offers a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or comparisons between the proposed method and the existing work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the joint error for UDA and points out that this problem has already been studied in previous works, such as \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. It suggests that the authors should discuss this work and its relationship to their proposed method, as well as highlight why their method is better. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the existing literature and justifying the novelty of their approach. By addressing these points, the authors can enhance the clarity and rigor of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the largerscale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors can infer that they should consider the impact of dataset size on performance and potentially adjust the comparison with SOTA methods. However, the comment lacks concrete steps or suggestions on how to conduct this adjustment or what specific aspects of the comparison should be revised. Therefore, the comment is 3, as it highlights an area for consideration but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with stateoftheart (SOTA) methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison with SOTA methods. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the difference in dataset size. The reviewer provides a logical reasoning by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential bias in the comparison, suggesting that the superiority of the proposed method may be due to the largerscale datasets. However, the comment lacks specific examples or references to existing methods or datasets to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the proposed method with stateoftheart (SOTA) methods. It points out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential bias in the comparison, suggesting that the superiority of the proposed method may be due to the largerscale datasets. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a fairer comparison method or suggesting ways to adjust the dataset size for a more accurate comparison. While the comment raises an important point, it lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It also notes the absence of a discussion on the research gap, such as why existing methods cannot be applied. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the research gap should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification for the need of a new curriculum learning method and address the research gap, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, as existing methods cannot be applied. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It points out the absence of a discussion on the research gap, such as why existing methods cannot be applied. This feedback is 3 as it highlights a potential gap in the paper that the authors should address to strengthen their argument. However, the comment could be more helpful if it provided suggestions on how to address this gap or what specific aspects of the research gap should be discussed. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest ngram features. This is an explicit and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done and how it can be done, making it 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach to address the domain adaptation problem, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. This claim is 3 as it provides a logical reasoning for the suggestion, based on the common use of such models in domain adaptation tasks in the NLP field. However, the comment lacks specific examples or references to support the claim fully, such as studies or experiments that demonstrate the effectiveness of these models in domain adaptation. This makes the claim 3, as it provides a reasonable basis but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods in their domain adaptation work. This feedback is valuable as it offers a clear and concrete way to improve the draft by leveraging existing resources and methodologies. By following this advice, the authors can enhance the robustness and generalizability of their results. However, the comment could be more helpful if it explained why these models are particularly effective in domain adaptation or provided examples of their successful application. Overall, the comment is 4 as it offers a clear direction for improvement but could be further enhanced with additional context or justification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed analysis or clarification in their ablation study. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology and results sections where the method and its performance are discussed. The comment is specific in detailing what needs to be addressed, namely the need for more detailed analysis or clarification in the ablation study. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions whether the main performance gain is due to a specific module or the increased number of parameters. It suggests that the current version of the ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or references to support the claim that the current study is insufficient. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the claim is considered 2, as it provides a logical basis but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters, and points out that the current version of the ablation study does not provide definitive answers to these questions. This feedback is 3 as it highlights an area where the authors could improve their analysis and provide more detailed explanations of the method\"s performance. However, the comment could be more helpful if it suggested specific ways to address this issue, such as providing additional analyses or clarifying the contribution of each module. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of explanation in the paper regarding the two quantities mentioned in lines 196197. It explicitly asks for more clarification on why the two quantities are different and how they capture the difference in learning settings. This feedback provides a clear and direct action for the authors to take, which is to provide additional explanation in these lines. The comment is specific and concrete, giving the authors a clear idea of what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l 1967,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation regarding the two quantities and their relationship to learning settings. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the explanation provided in lines 196197, asking for more clarification on why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is necessary or how it would impact the paper\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires more explanation, specifically the two quantities mentioned in lines 196197. It asks for clarification on why the two quantities are different and how they capture the difference in learning settings. While the comment highlights a potential gap in the paper\"s explanation, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a specific area for improvement, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and direct request, providing the authors with a specific action to take. The comment is specific in detailing what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the sensitivity of fixed tuning parameters in the model, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the strengths and weaknesses of these parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it prompts the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a relevant and important aspect to consider, as it could impact the robustness and generalizability of the model. However, the comment lacks specific guidance or examples on how to approach this discussion or what aspects to focus on. While it identifies a potential area for improvement, it does not provide detailed instructions or suggestions for the authors to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed framework should be tested with different policy gradient approaches and provides a specific question about the number of random seeds used for learning the policies (DDPO and IPPG). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment results. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its request for information about the random seeds used, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they would impact the framework\"s performance. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion or the importance of addressing these points. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). This feedback is 3 as it identifies a potential area for further exploration and experimentation, which could enhance the robustness and generalizability of the framework. However, the comment lacks depth and does not provide specific guidance on how to implement these changes or what specific policy gradient approaches should be considered. While it points out a potential area for improvement, it does not offer detailed suggestions or examples, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. While it implies that the authors should expand their analysis, it does not provide specific guidance on which datasets or tasks to include or how to conduct the additional evaluations. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should evaluate on more datasets and tasks to strengthen the results and conclusions. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting that the analysis should be expanded, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would be stronger if it evaluated on more datasets and tasks. However, it does not provide specific reasoning or evidence to support why this would enhance the results or conclusions. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically that it only evaluates on one dataset and one task. It suggests that expanding the analysis to more datasets and tasks would strengthen the results and conclusions. This feedback is 3 as it points out an area for improvement, but it lacks specific guidance on which datasets or tasks to consider or how to conduct the additional evaluations. While it highlights a potential weakness, the comment does not provide detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific areas where the writing could be improved, providing examples of unclear or difficulttointerpret definitions. It explicitly asks for clarification on the \"relevant\" auxiliary model weights in definition 2.1. This feedback is clear and provides concrete guidance on what needs to be addressed to improve the clarity of the writing. The authors know exactly what needs to be done to enhance the clarity of their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the \"relevant\" auxiliary model weights in definition 2.1. This provides clear guidance on what needs to be improved in the writing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the writing in specific sections, such as definition 2.1. It provides examples of unclear or difficulttointerpret definitions, which is a logical observation. However, the comment does not offer specific examples or references to support the claim that the writing is unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is 3, as it provides a basis for the critique but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies specific areas where the writing could be improved, providing examples of unclear or difficulttointerpret definitions. This feedback is actionable and constructive, as it points out specific parts of the paper that need clarification. By addressing these issues, the authors can enhance the clarity and accessibility of their work, which is valuable for improving the overall quality of the draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the definitions or provided examples of clearer explanations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It suggests that the use of ULiRA [1] is recommended. However, the comment does not provide explicit instructions on how to address this concern or implement the suggested use of ULiRA. While the authors can infer that they should consider using ULiRA, the comment lacks concrete guidance on how to integrate it into their work. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and raises concerns about the robustness of MIA testing for privacy guarantees. It also mentions the use of ULiRA [1] as a recommendation. However, the comment does not specify which part of the paper discusses the use of MIA testing or the recommendation for ULiRA. This makes it difficult for the authors to pinpoint the exact sections that need attention or improvement. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of robustness and the recommendation for ULiRA, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It suggests that the use of ULiRA [1] is recommended. The comment provides a logical reasoning by pointing out the potential limitations of MIA testing and the need for a more robust approach. However, it lacks specific examples or references to support the claim about the robustness of MIA testing or the effectiveness of ULiRA. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It points out that the robustness of MIA testing itself is questionable for privacy guarantees. The comment suggests using ULiRA [1] as a more robust alternative. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement the suggested use of ULiRA or how to address the robustness concerns. The feedback is 3 as it provides a direction for improvement but could be more comprehensive with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that it could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit instructions or concrete steps for the authors to take. The comment implies that the authors should consider presenting this information, but it lacks specific guidance on how to do so or what aspects of kernel regression should be addressed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting this information in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion to present the information in the language of kernel interpolation/smoothing, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that the information could be presented in the \"language of kernel interpolation/smoothing.\" However, the comment lacks any supporting evidence, reasoning, or references to justify why this is relevant or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it does not provide sufficient justification for the authors to address the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression, suggesting that it could be presented in the \"language of kernel interpolation/smoothing.\" While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue or what aspects of kernel regression should be included. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. It explicitly asks if it is possible to conduct such a comparison. The comment provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. This guidance is explicit and concrete, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and suggesting a comparison with final outputs. The comment further questions whether a quantitative comparison on the final outputs is possible, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. The comment provides a logical reasoning by pointing out that the current evaluation does not fully demonstrate ModelAngelo\"s superiority to competitors. However, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing in demonstrating ModelAngelo\"s superiority to competitors. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct such a comparison or provided examples of how it might be done. Overall, the comment is 4 as it points out a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, it recommends including error bars and/or pvalues when statistical inferences are made. While the comment provides specific actions to take, such as adding more details and including error bars, it does not explicitly instruct the authors on how to implement these changes. The action is concrete but somewhat vague in terms of execution, as the authors need to determine which specific details should be added and how to present them. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"simulation or experimentbased evidence\" and \"fig. 2,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues with the explanations, the lack of detailed procedures, and the confusion regarding \"sample count\" in fig. 2. Additionally, it provides specific suggestions for improvement, such as adding more details to the paper and including error bars or pvalues when statistical inferences are made. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations in the paper are qualitative and that the procedures are described minimally or not at all, with some figures being confusing. The reviewer suggests that adding more details and supplementary information would be beneficial. Additionally, the comment recommends including error bars and/or pvalues when statistical inferences are made. While the comment identifies specific issues with the paper, it lacks detailed examples or references to support the claim about the qualitative nature of the explanations or the confusion in the figures. The suggestion to include error bars and pvalues is logical, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, it recommends including error bars and/or pvalues when statistical inferences are made. These points are clear and actionable, providing the authors with specific guidance on how to improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided examples of what kind of details should be added or how to present the figures and statistical inferences more effectively. Overall, the comment is 4 as it offers concrete suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add supportive references for claims that may be inspired by existing studies. It provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment is clear and concrete, as it specifies which parts of the paper need references and provides a specific example of where these references should be added. This gives the authors a direct action to take to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to add supportive references for claims inspired by existing studies. The comment provides a detailed example of the factors that need references, such as order sensitivity, complexity, diversity, and style sensitivity. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims may be inspired by existing studies and suggests that it is critical to add supportive references. The reviewer provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. However, the comment lacks detailed reasoning or specific references to existing studies that support the claims. While it highlights a potential issue, the lack of detailed evidence or examples makes the claim 3. The authors would need to further investigate and provide references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references are necessary. It provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. This feedback is clear and actionable, as it directs the authors to include references to support their claims. However, the comment could be more helpful if it suggested specific references or examples of existing studies that address these factors. Overall, the comment is 4 as it highlights a critical area for improvement and provides a concrete direction for the authors to enhance the credibility and robustness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback implies that the authors should include this information in their paper to enhance its clarity and usefulness to the community. However, the comment does not provide specific guidance on how to present these settings or what aspects should be included. While the action is implied, it is not as concrete as it could be, as the authors are left to infer the exact details of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting that providing these settings would help the community by providing a single review of advances in this area. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This claim is 3 as it provides a logical reasoning for improvement, suggesting that such a comparison would enhance the paper\"s clarity and usefulness to the community. However, the comment lacks specific examples or references to prior work that have successfully implemented this approach, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and usefulness of their work. By including this information, the authors can contribute to the community\"s understanding of advances in this area. However, the comment could be more helpful if it provided examples of how these settings were presented in prior work or suggested specific ways to present them in the paper. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts, noting that while the bias can happen, the general applicability of these situations is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or detailed advice on how to improve the clarity or applicability of these examples. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the general applicability of the examples presented. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases and prediction shifts but does not clarify how general these situations are. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the presentation of examples of biases and prediction shifts in the paper. It points out that while the authors present these examples, they do not clarify how general these situations are, leaving the reader uncertain about their applicability. This feedback is 3 as it highlights a potential weakness in the clarity and comprehensiveness of the paper. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as providing additional context or examples to illustrate the generalizability of these examples. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that adding a few more datasets would be beneficial, particularly in terms of crosstask transferability. While the comment implies that the authors should consider adding more datasets, it does not provide specific guidance on which datasets to include or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should add more datasets but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on crosstask transferability. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need to be revised. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would impact the paper\"s findings. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they would enhance the analysis. The feedback is 3 as it points out a potential gap in the study, but it does not offer actionable steps for the authors to address this suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the tasks are somewhat standard and implies that the authors could have included more unique tasks to showcase the diversity of images/plots. It provides a specific example of interleaved imagetext tasks, such as question answering from images, as a potential area for improvement. While the comment does not explicitly instruct the authors to implement these tasks, it clearly outlines a direction for enhancing the paper by suggesting a specific area for innovation. The action is implicit but concrete, as the authors can infer the need to explore unique tasks and understand the potential benefits of doing so. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also mentions the potential for unique tasks that could showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the tasks or experiments described. The comment is specific in suggesting a potential area for improvement, which is to include more unique tasks. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also implies that the authors could have included more unique tasks to showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. The comment provides a logical reasoning for why the tasks could be considered standard and suggests a potential area for improvement. However, it lacks specific examples or references to support the claim that unique tasks could have been considered. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the tasks are somewhat standard and could benefit from more unique tasks to showcase the diversity of images/plots. It suggests specific areas for improvement, such as interleaved imagetext tasks like question answering from images. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by incorporating more innovative tasks. However, the comment could be more helpful if it offered additional guidance on how to implement these tasks or provided examples of similar studies that have successfully integrated such tasks. Overall, the comment is 4 as it provides a clear path for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether there is any additional novel effort in the section on 3D Gaussians generation, specifically mentioning the previous work by Luciddreamer. This request is clear and provides a direct action for the authors to take, which is to address the issue by either explaining the novelty or providing evidence of additional effort. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether there is any additional novel effort in this section, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussians generation is merely a repetition of previous work, specifically mentioning \"Luciddreamer.\" However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the section on 3D Gaussians generation, specifically questioning whether there is any additional novel effort beyond the previous work by Luciddreamer. This feedback is 3 as it prompts the authors to clarify whether their work builds upon existing efforts or introduces new contributions. However, the comment lacks specific guidance on how the authors might address this issue or what additional efforts could be highlighted. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide explicit instructions, they imply that the authors should address these issues in their paper. The action is implicit but concrete, as it points to specific areas that need clarification or elaboration. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it specifically references the \"nonvanishing duality gap\" and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the comment does not explicitly mention a specific section or page, the authors can infer that it relates to the theoretical aspects of the framework or the application to nonconvex losses. The comment is specific in its inquiry about the relevance and potential use of the framework, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. The reviewer also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not present claims, they imply that the authors should provide more detailed explanations or justifications for their work. However, the comment lacks specific examples or references to support these questions, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the relevance and applicability of the framework to nonconvex losses and nonnorm type defenses. It seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints, as well as the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide specific guidance or suggestions for improvement, they prompt the authors to consider and address these important aspects of their work. The feedback is 3 as it encourages the authors to clarify and strengthen their theoretical foundations, which could enhance the overall rigor and applicability of their framework. However, it could be more helpful if it offered specific suggestions or examples on how to address these questions. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is clear but lacks concrete details on how to execute the experiment, such as which specific features to select or how to evaluate the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would impact the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This is a clear and actionable suggestion that could potentially improve the paper by providing additional insights into the performance of the baselines. However, the comment lacks depth and does not explain why this approach might be beneficial or how it could be implemented effectively. While it provides a direction for further exploration, it could be more helpful with additional guidance or rationale. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance. While the comment provides a clear list of specific questions that need to be addressed, it does not offer explicit guidance on how to implement these improvements. The authors are left with a clear understanding of what needs to be added but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the techniques and the reproducibility of the results. It provides detailed questions about the sparsification process, landmark generation, and number of landmarks used, as well as how to achieve shape invariance. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be clarified or improved in each area. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of detail in the paper regarding the techniques used and the reproducibility of the results. It highlights specific areas that are unclear, such as the sparsification process, landmark generation, and number of landmarks used. The reviewer also questions how to achieve shape invariance. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support the claims. This makes the comment 3, as it points out areas that need clarification but lacks the depth and evidence needed for full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks detail and clarity, particularly regarding the techniques used and the reproducibility of the results. It highlights specific questions that need to be addressed, such as the sparsification process, landmark generation, and number of landmarks used. The comment also questions how to achieve shape invariance and provides a detailed list of questions that, if answered, could significantly improve the clarity and reproducibility of the paper. This level of detail and specificity offers the authors clear guidance on what needs to be addressed to improve their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to reorganize the Appendix H section, which is difficult to follow. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific about the issue of difficulty in following the section, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Appendix H section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is that it is difficult to follow. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Appendix H section is difficult to follow. However, it does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions for improvement or alternative approaches. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. This feedback is clear and actionable, as it directs the authors to reorganize the section to improve its clarity and accessibility. However, the comment could be more helpful if it provided suggestions on how to reorganize the section or what specific changes might improve its readability. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on execution. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a concern that the paper does not provide sufficient details for reproducibility, despite the inclusion of pseudocode in the supplementary material. It points out that while the paper provides an intuitive understanding of the work, more technical details are needed to fully reproduce it. The reviewer explicitly states that these details are not provided in the paper or supplementary material, such as the number of units in the RNN implementation. This feedback is clear and provides concrete actions for the authors to take, such as including the missing technical details in the paper or supplementary material. The comment is 5 as it directly instructs the authors on what additional information is needed to improve the reproducibility of their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the specific technical details that are missing, such as the number of units in the RNN implementation, and other technical details required for reproducibility. This provides clear guidance on what needs to be addressed to improve the reproducibility of the work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide sufficient details for reproducibility, despite the inclusion of pseudocode in the supplementary material. The reviewer suggests that the paper is more focused on providing an intuitive understanding of the work rather than detailed technical information required for reproduction. This claim is 3 as it highlights a potential issue with the paper\"s reproducibility, but it lacks specific examples or references to support the claim. The authors would need to further explore the details and implications of this issue to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that while the pseudocode in the supplementary material provides an intuitive understanding of the work, it does not provide sufficient details for reproducibility. The reviewer highlights specific areas that are missing, such as technical details about the RNN implementation, which are crucial for reproducing the work. This feedback is clear and actionable, as it points out specific gaps in the paper that need to be addressed to improve its reproducibility. By providing concrete examples of what is missing, the comment empowers the authors to make targeted improvements to their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars or more random trials to potentially reduce random fluctuations in the results. While the comment implies that the authors should consider adding these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars or more trials to improve the figure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger with the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these additions would be beneficial or how they would impact the results. Without such details, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in Figure 1, suggesting that the inclusion of error bars or more random trials could strengthen the figure by potentially reducing random fluctuations in the results. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the figure\"s robustness and clarity. However, the comment could be more helpful if it explained why error bars or additional trials are beneficial or how they might impact the interpretation of the results. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can significantly enhance the figure."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. It also references external works that discuss contextaware robust finetuning, finetuning impact on foundation models, and robust finetuning of zeroshot models. While the comment provides explicit actions, it does not specify how to implement these suggestions or what specific details should be included in the introduction or Figure 1. The authors are given clear guidance on what needs to be added but lack detailed instructions on how to execute these actions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"related work section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing a brief introduction to energy models in the related work section and clarifying the correspondence between different learning rates and steps in Figure 1. The comment also references external works, which provides additional context and specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. The reviewer references external works to support their claim, such as \"Contextaware robust finetuning,\" \"Finetuning can cripple your foundation model; preserving features may be the solution,\" and \"Robust finetuning of zeroshot models.\" These references provide a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section and clarify the correspondence between different learning rates and steps in Figure 1. It also references external works that discuss contextaware robust finetuning, finetuning impact on foundation models, and robust finetuning of zeroshot models. This feedback is clear and offers a concrete direction for improvement, helping the authors enhance the clarity and completeness of their draft. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate these references or what specific aspects of the energy models should be highlighted in the introduction. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of premature evictions. The comment lacks concrete details or suggestions on how to improve the approach or validate its effectiveness. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach used in FIITED, specifically the potential for biases due to temporary high utility scores for recent chunks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue of premature evictions due to temporary high utility scores. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the risk of premature evictions due to temporary high utility scores for recent chunks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the bias or how it might manifest in their work. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. This is a valuable observation that could lead to premature evictions of other valuable chunks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the risk of biases. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the focus on DNNs is not relevant to the paper\"s core focus on detecting drift types and magnitude. The comment implies that the authors should reconsider the content and relevance of this paragraph, but it does not provide specific guidance on how to revise it or what alternative content could be included. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper\"s focus. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is 3 as it logically argues that the introduction of DNNs is not directly relevant to the paper\"s focus on detecting drift types and magnitude. However, the comment lacks specific examples or references to support the claim, making it 3. The authors may need to infer the relevance of the DNN introduction themselves, which could lead to some confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the paper\"s core focus. This feedback is clear and actionable, as it suggests that the authors should reconsider the relevance and content of this paragraph to ensure it aligns with the paper\"s central theme. By addressing this issue, the authors can improve the clarity and focus of their introduction, making the paper more effective for its intended audience. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the paper lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include quantitative experiments and comparisons, as well as detailed explanations of the algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not offer specific steps for execution.", "grounding_specificity_rationale": "The comment addresses the methodology and experimental aspects of the paper, specifically mentioning the lack of quantitative experiments and comparisons with other algorithms. It also highlights the need for more detailed explanations of the presented algorithms. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the need for quantitative experiments and comparisons, and the need for more detailed explanations of the presented algorithms. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the lack of quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones, makes it unclear what the exact performance of the framework and individual parts are compared to other solutions. The comment provides a logical reasoning for the need for more detailed information, but it does not cite specific examples or references to support the claim. This makes the claim 3, as it provides a reasonable basis for the critique but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. This feedback is valuable as it highlights a critical area for improvement in the paper, specifically the need for more comprehensive experimental and analytical sections. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps, such as which experiments to conduct or how to present the results more effectively. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the clarity of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its concern about the model\"s ability to generate novel knowledge or testable hypotheses, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. While the comment implies that the authors should create a simplified version, it does not provide specific guidance on how to achieve this or what aspects of Theorem 2 should be simplified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests presenting a simplified version of Theorem 2, similar to Theorem 1, to make it more accessible to the general audience. However, it does not specify which part of the paper contains Theorem 2 or where the simplified version should be placed. The authors can infer that it relates to the section containing the theorem, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. However, the comment does not provide any reasoning, examples, or references to support why this simplification is necessary or how it would benefit the paper. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a simplified version of Theorem 2 should be presented, similar to Theorem 1, to make it more accessible to the general audience. This feedback is 3 as it identifies a potential issue with the presentation of the theorem, which could improve the clarity and comprehensibility of the paper. However, the comment lacks specific guidance on how to achieve this simplification or what aspects of Theorem 2 should be simplified. While it points out a potential area for improvement, it does not provide detailed instructions or examples, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of their model. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to implement this suggestion or what aspects of the model might be affected by the change in resolution. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine how to conduct them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by using a larger image resolution, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. This is a valuable suggestion that could provide insights into how the model might perform with different image resolutions. However, the comment lacks depth and does not explain why this change might be beneficial or how it could impact the results. Additionally, it does not offer specific guidance on how to implement this suggestion or what aspects of the model might be affected by the change in resolution. While the suggestion is 3, it could be more actionable and comprehensive with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the calculation of the keypoint mask averaged feature vector, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the calculation of the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the calculation of the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While this question may be relevant to the authors, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address the issue or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use styles (e.g., dashed lines) or add color to make it easier to distinguish between the different curves in Figure 2. While the comment provides a specific suggestion for improving the visual clarity, it does not explicitly instruct the authors on how to implement these changes or which specific styles or colors to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the difficulty in distinguishing between the different curves. The comment provides a clear suggestion to use styles or add color to improve the visual clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the curves in Figure 2 are difficult to distinguish, and it provides a specific suggestion to use styles (e.g., dashed lines) or add color to improve the visual clarity. However, the comment does not provide any detailed reasoning or examples to support why the current visual presentation is challenging or how the proposed changes would improve clarity. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the visual clarity of Figure 2, noting that the different curves are difficult to distinguish. It suggests using styles (e.g., dashed lines) or adding color to improve the visual distinction. This feedback is actionable and can help the authors enhance the clarity and readability of their figure. However, the comment could be more helpful if it provided examples of how these changes could be implemented or suggested specific styles or colors to use. Overall, the comment is 4 as it identifies a clear area for improvement and offers a concrete suggestion for enhancing the figure."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors tone down the introduction and not refer to the task as \"language learning.\" It suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is 5 as it gives a direct and specific direction for improvement, ensuring that the authors know exactly how to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"claims made in the introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the overstatement of the task as \"language learning\" and the evaluation on question answering, suggesting that it is more accurately described as a feedbackdriven QA in the form of a dialog. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are far from what has been achieved by the tasks and models, and suggests that the authors should tone down the introduction and not refer to it as \"language learning.\" The reviewer provides a logical reasoning by pointing out that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment lacks specific examples or references to support the claim that the task is significantly different from language learning. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are far from what has been achieved by the tasks and models. It suggests that the authors should tone down the introduction and not refer to it as \"language learning,\" as it is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the draft. By recommending a more accurate description, the comment helps the authors clarify their work and enhance its clarity. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or provide a convincing analytical or empirical argument. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of inaccuracy in neural ODEs and the need for a convincing analytical or empirical argument. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the central contribution of the paper, which is modeling weight evolution using ODEs, is based on a problem of neural ODEs exhibiting inaccuracy while recomputing activations. The reviewer questions the accuracy of this issue and suggests that a previous paper first reported it. However, the comment lacks specific references or detailed evidence to support the claim that the issue is inaccurate or that it has been previously reported. This makes the claim 3, as the authors would need to conduct further research to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s central contribution, which is the use of ODEs to model weight evolution. It questions the accuracy of neural ODEs while recomputing activations, suggesting that this issue has been previously reported. The comment highlights a gap in the paper\"s analysis or evidence, noting that the current paper does not provide a convincing analytical or empirical argument to support its claim. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential weakness, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While the comment implies that the authors should add this information, it does not explicitly instruct them to do so or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include this detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section, figure, or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting what needs to be mentioned, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not provide any supporting evidence, reasoning, or examples to justify why this mention is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While it identifies a potential area for clarification, it lacks specificity and does not provide guidance on how to effectively mention this detail or why it is important. The feedback is 3 as it points out a potential gap in the explanation, but it does not offer actionable advice or context for the authors to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it notes that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment implies that the authors should focus on the collaborative ranking results, it does not provide explicit instructions or concrete steps on how to apply this insight to improve the paper. The action is implicit and somewhat vague, as the authors need to infer the implications and potential improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also notes that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the results and methodology sections where the lower bound results are discussed. The comment is specific in detailing what is problematic, namely the ease of obtaining the lower bound results due to the reduction from collaborative ranking. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. The comment provides a logical reasoning for why the lower bound results are not as challenging as initially thought, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to understand the reduction from collaborative ranking and its implications to fully verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also points out that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. This feedback highlights a potential weakness in the paper\"s originality and contribution, as it suggests that the results are not as novel as initially presented. While the comment provides some insight into the potential limitations of the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. While the comment implies that the authors should consider using more advanced prompting techniques, it does not provide specific guidance on how to implement this suggestion or what specific prompts might be effective. The action is implicit and somewhat vague, as the authors need to infer the need for more advanced prompting techniques and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use carefully curated prompts is specific, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment provides a logical argument for the need to improve the prompting technique, it lacks specific examples or references to support the claim that carefully curated prompts would lead to better results. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the study, namely the basic nature of the prompting technique used and its failure to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement this suggestion or what criteria should be used to curate prompts. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the concerns were addressed. However, the comment does not explicitly instruct the authors to conduct these additional experiments or provide guidance on how to manage the compute issue. The action is implicit and somewhat vague, as the authors can infer that they should consider conducting additional experiments but are not given specific steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on larger datasets, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment also acknowledges the issue of compute and thanks the authors for their response, but does not provide further details or specificity regarding the compute issue. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting additional experiments and acknowledging the compute issue. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger datasets, which is a suggestion for improvement. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. The comment does not provide specific reasoning or evidence to support why maintaining probabilities might be an issue or how it could be addressed. While it acknowledges the concern, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, which could provide valuable insights into the model\"s performance and robustness. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address the compute issue or how to design the additional experiments. The feedback is 3 as it points out a potential area for improvement but lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the performance of the model on REC and RES is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance or suggestions for potential improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the performance of the model on REC and RES being behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by references to external works, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or specific metrics to support the claim further. As it stands, the claim is 4 due to the inclusion of references, but it could be more fully substantiated with additional evidence or reasoning. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a significant issue with the performance of the model on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This comparison serves as a clear and actionable piece of feedback, as it indicates that the current model is behind more advanced models in terms of performance. By pointing out these specific examples, the comment provides the authors with a concrete direction for improvement, namely, to improve the performance on REC and RES to match or surpass the results of these more recent models. However, the comment could be more helpful if it offered suggestions on how to achieve this improvement, such as potential modifications to the model architecture or training process. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to take action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the term \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This implies that the authors should revise the language in their draft to be more precise and accurate. However, the comment does not provide specific guidance on how to rephrase the statement or what alternative wording would be more appropriate. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific figure, \"Fig. 5,\" which provides evidence that some information is learned before the model can use the concepts. However, it does not specify which part of the figure or the paper this evidence is presented in, making it weakly grounded. The comment is specific in suggesting that \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This provides clear guidance on what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the term \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This is a suggestion for clarification rather than a claim or opinion that requires verification. It does not present an argument or evidence to support the claim that \"evidence\" is inappropriate, making it a factual observation rather than a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in the paper, suggesting that the term \"evidence\" might be too strong and recommending a more appropriate wording, such as \"Fig.\" This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and accuracy of the language used in the paper. However, the comment could be more helpful if it explained why \"evidence\" might be inappropriate or provided additional context on how to choose the appropriate wording. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation instead of crossattention. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue or improve the novelty of their approach. The action is implicit and somewhat vague, as the authors can infer that they need to explore ways to enhance the innovation of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed video storyboarding approach\" and \"framewise SDSA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty in the approach, noting that it relies heavily on framewise SDSA and that the only notable difference is the mask source. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation rather than crossattention. This claim is 3 as it provides a specific comparison to ConsiStory, which is a wellknown approach, and highlights the difference in the mask source. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer highlights the only notable difference as the mask source, which uses CLIPseg and OTSU segmentation rather than crossattention. This feedback is 3 as it points out a specific area where the paper could be improved by exploring more innovative approaches or techniques. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. To be more helpful, the comment could provide specific suggestions or examples of alternative methods that could be considered. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison, but it is not as concrete as it could be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, and it proposes a comparison with previous approaches on fewshot classification in such datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with previous approaches, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. However, it does not provide any supporting evidence or references to substantiate this claim. The suggestion to compare the method with previous approaches on fewshot classification in such datasets is logical but lacks specific examples or detailed reasoning to fully support the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks the necessary evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, which is a valuable observation. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. This feedback provides a clear direction for the authors to consider, which could enhance the relevance and impact of their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to explore further."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or specify how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation of the bounds. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be added. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the bounds need explanation or how they should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this additional explanation is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to effectively explain the bounds or what aspects should be clarified. The comment is 3 as it points out a potential weakness, but it does not offer actionable steps for the authors to address it. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not provide any guidance on how the authors should revise or adjust their explanation. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this explanation is provided in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the explanation are considered unnecessary or how the authors might improve it. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not provide any specific guidance or suggestions on how the authors might revise or improve their explanation. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability. The reviewer also points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the transferability and complexity of the tasks, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the zeroshot nature of the work and the transferability of the policy, suggesting that the difficulty of the source and target tasks might limit the transferability. It also provides specific examples of the manipulation scenario, such as the 3prong task with clockwise and counterclockwise rotations, and the 4prong task, which could provide sufficient information about the target task. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the transferability and the complexity of the tasks, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims. While it provides some logical reasoning, it does not offer sufficient evidence or examples to fully support the claims, making them 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or clarify their claims in the paper. While it identifies potential weaknesses and areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as suggesting ways to improve the method on larger backbones or providing specific examples of how to test the method on different models. The action is implicit and somewhat vague, as the authors can infer that they need to consider testing on larger backbones but are not given clear steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. It also suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the relative gains and the potential impact of the global pooling structure, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to make a significant effort to understand and address the concern, as the comment does not provide sufficient evidence or detailed reasoning to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that the relative gains are not very strong, even on smaller backbone models like ResNet50. It suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the method\"s performance on larger backbones like SwinB or SwinL. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the analysis or what specific aspects of the neural network analysis need attention. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. It references specific sections, \"Section 3.2, 3.3,\" which allows the authors to accurately identify the parts of the paper being addressed. However, the comment lacks specificity in detailing what needs to be addressed or improved in these sections. It does not provide specific suggestions or examples of how the analysis could be strengthened. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the analysis of neural networks is less significant due to the existing NTK theorem and the work bypassing the core problem of overparametrized neural networks. The comment provides a logical reasoning by pointing out that the extension from linear models to wide fullyconnected neural networks is trivial and that the work only considers easy cases. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. It points out that the analysis only considers easy cases and does not address the challenges of overparameterization. While the comment identifies a potential weakness in the analysis, it lacks specific suggestions or guidance on how the authors could address this issue or improve their work. The feedback is 3 as it highlights a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a specific suggestion to consider using more datasets to ensure rigor. However, the comment does not provide explicit guidance on how to increase the number of datasets or which datasets should be used. While the action is implied, it lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the rigor of the evaluation, specifically the number of datasets used for each task (5, 6, and 4). It suggests that having such a limited number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The comment provides a specific suggestion to consider using more datasets to ensure rigor. However, it does not explicitly mention which part of the paper this issue pertains to, such as the methodology or results sections. While the authors can infer that it relates to the evaluation section, the comment lacks full grounding. It is specific about the issue of limited datasets, but it does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the rigor of the evaluation, suggesting that the limited number of datasets for each task (5, 6, and 4) might not be sufficient. The reviewer provides a logical reasoning by pointing out that some datasets might be too large for all algorithms to be used, which could affect the evaluation\"s thoroughness. However, the comment lacks specific examples or references to support the claim that the datasets are insufficient. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The comment provides a specific suggestion to consider using more datasets to ensure rigor. Additionally, it acknowledges the authors\" detailed reply and the provision of a repository and online platform for reproducing the experiments. The feedback is 4 as it identifies a potential weakness in the evaluation and offers a clear and actionable suggestion for improvement. However, it could be more helpful if it provided additional guidance on which datasets should be considered or how to select them. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of results with larger models like ResNet101/152, which is a specific action for the authors to take. However, it does not provide guidance on how to conduct these experiments or what specific aspects to focus on. The comment implies that the authors should include results with larger models, but it lacks concrete details on how to implement this action. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the performance of ResNet models on imageNet classification, specifically mentioning ResNet50/34/18 and noting the absence of results with larger models like ResNet101/152. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in identifying the issue of not including results with larger models, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no results with larger models like ResNet101/152, but it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to previous studies or benchmarks, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of results with larger models like ResNet101/152. This feedback highlights a gap in the paper\"s experimental evaluation, which could potentially impact the authors\" conclusions and the generalizability of their findings. However, the comment lacks depth and does not provide suggestions on how to address this issue or what specific aspects of the larger models should be evaluated. While it identifies a potential area for improvement, it does not offer actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential confusion in the paper regarding the use of terms like \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific changes should be made to clarify the terms. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, specifically mentioning a reference to Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al., 2017). This provides full grounding as it clearly identifies the part of the paper being addressed. The comment also specifies the issue of confusion regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" and \"expensive to evaluate\" are confusing, as they appear in different parts of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these terms are confusing or how they could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" used in different parts of the document. This is a clear and actionable observation that can help the authors clarify their language and improve the coherence of their writing. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific changes or clarifications to be made in the text. Overall, the comment is 3 as it points out a specific area for improvement, but it lacks detailed guidance on how to implement the suggested changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the method addresses sparse reward problems and questions whether it can solve sparsereward tasks as well as other methods (Qmix). However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, or suggesting ways to improve the method\"s performance in sparsereward scenarios. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the method and the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the method addresses sparse reward problems and whether it can solve sparsereward tasks as well as other methods (Qmix). The comment provides a clear direction for improvement by asking for clarification on the method\"s performance in sparsereward scenarios. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the method\"s ability to address sparse reward problems and suggests that the experiments do not support this claim. The reviewer provides a logical reasoning by comparing the proposed method to dense reward signals and subtaskspecific rewards, which could be seen as a way to address sparse reward issues. However, the comment lacks specific examples or references to support the claim that the method does not address sparse reward problems effectively. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems effectively, based on the experiments presented. It suggests that the proposed method requires subtaskspecific rewards, which is similar to dense reward signals, and questions whether it can solve sparsereward tasks as well as other methods (Qmix). The comment also includes minor comments that suggest specific areas for improvement. However, the feedback lacks detailed guidance or suggestions on how the authors might address these issues or improve their method. While it identifies potential weaknesses, the comment could be more helpful by providing actionable steps or examples to enhance the draft. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"curated AH36M dataset\" and the need for clarification on whether it is used for training. It also raises questions about whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of the curated AH36M dataset for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This is an important consideration for ensuring the fairness and validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their methodology. While it identifies a potential area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies two main issues: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper lacks new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or discussion need clarification or improvement. The authors are left to infer that they need to improve the clarity and depth of their work, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies specific issues with the proof of the main results, suggesting that there are confusing mistakes. It also mentions the lack of a detailed discussion and comparison with previous work, and the absence of new insights. However, it does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the confusion in the proof and the need for a detailed discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are confusing mistakes in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. Additionally, it suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of specific examples or references makes the claim 1, as it does not provide sufficient evidence or justification to support the claims. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper lacks new insights. While the comment highlights areas for improvement, it does not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses several issues related to the motivation, experimental results, and comparison of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment does provide some specificity by mentioning the addition of CAT and GAN, which could be used to guide the authors in identifying the relevant sections. Overall, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in identifying the issues. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the motivation for using an adversarial network is unclear and that the experimental results are unfair. It also suggests that the proposed model is equipped with a larger CAT and GAN, which could be considered an unfair comparison. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. While it highlights these areas for improvement, the comment does not provide specific suggestions or guidance on how the authors might address these issues. It lacks actionable advice or detailed feedback that could help the authors improve their draft. As a result, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to compare their captioning experiment results to the official COOC leader board on the blind test set, which is a clear and concrete action. It also suggests that the paper should compare to other approaches that have been evaluated on the blind challenge set, providing a specific example of [5,17] and mentioning that several other approaches have been proposed since then. This feedback is detailed and provides specific guidance on how to improve the paper by including comparisons to official test sets and other relevant works. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the captioning experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison to related work on the official COOC leader board on the blind test set. The comment provides a clear rationale for why this comparison is necessary and suggests specific examples of approaches that have been evaluated on the blind challenge set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the captioning experiment should be compared to the official COOC leader board on the blind test set, which is a specific suggestion for improvement. The reviewer provides a reference to the official COOC leader board and examples of approaches that have been evaluated on the blind challenge set, such as [5,17]. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on how the authors can improve their captioning experiment. It points out that the paper currently compares to related work only on some not official test set or dev set, which is not ideal for demonstrating the final results. The reviewer suggests that the paper should compare to the official COOC leader board on the blind test set, which is a widely recognized benchmark in the field. Additionally, the comment suggests that the authors should compare their results to other approaches that have been evaluated on the blind challenge set, such as [5,17], and provide a more comprehensive evaluation of their work. This feedback is clear and provides a clear path for the authors to enhance the rigor and credibility of their results. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the reliability of the results or what specific steps to take to validate them. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the MSE being significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results and highlights a potential weakness in the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the reliability of their experimental results. Without specific recommendations or examples, the feedback lacks depth and does not fully support the authors in improving their draft. Therefore, the comment is rated as 2, as it points out a problem but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as recommending ways to differentiate the methodology or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique is based on, such as specific sections or methods where the extension is evident. Without explicit references to sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or references to existing methods to substantiate this claim. Without detailed comparisons or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might differentiate their work or enhance its originality. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific techniques or approaches to incorporate adversarial loss or explaining why it is necessary. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where this is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the adversarial loss are missing or how it could be incorporated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is no adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting the absence of adversarial loss to ensure that perturbed data is similar to authentic data. This is a relevant point that could impact the validity and reliability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate adversarial loss. Without actionable advice or detailed explanation, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific line (L248) where the term \"wrong\" is used and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5 as it offers a direct and specific suggestion for clarification, making it easy for the authors to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"wrong\" and the use of terms like \"good\" and \"bad\" explanations. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the term \"wrong\" in a specific context and suggests that the authors clarify what is meant by \"good\" and \"bad\" explanations before using these concepts. This is a request for clarification rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the term \"wrong\" in the paper and suggests that the authors clarify what is meant by \"good\" and \"bad\" explanations before using these concepts. This feedback is clear and actionable, as it points out a potential confusion in the paper that could be resolved by providing additional context or explanation. By addressing this issue, the authors can improve the clarity and coherence of their argument. However, the comment could be more helpful if it provided suggestions on how to clarify these concepts or offered examples of how they might be clarified. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The reviewer is open to changing their rating based on feedback from the authors and comments from other reviewers. While the comment implies that the authors should provide additional analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific analysis required. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for additional analysis, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The comment provides a logical reasoning by pointing out the limited comparison and the need for analysis to address the issue. However, it lacks specific examples or references to support the claim that the results violate the motivation. This makes the claim 3, as it provides a reasonable basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. This feedback is clear and actionable, as it points out a specific area where the authors need to improve their work. However, the comment could be more helpful if it provided examples of the analysis that should be conducted or suggested specific methods for evaluating the performance. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the current experimental comparison only compares ELF (the author\"s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. This feedback provides a clear and concrete action for the authors to take, which is to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. The comment is 5 as it directly instructs the authors on how to enhance their experimental setup to address the critique.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental demonstration of the contribution points\" and the \"experimental comparison between ELF (the author\"s method) and the baseline without Mid Vision Feedback (MVF),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the lack of a comparison with the image classification result of Mid Vision Feedback (MVF)\u2014and why this is important for proving the superiority of the schema searched by ELF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment provides a logical reasoning by pointing out that the current experimental comparison only compares ELF (the author\"s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. However, the comment does not provide specific examples or references to support the claim that a comparison with the image classification result of MVF is necessary. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It points out that the current experimental comparison only compares ELF (the author\"s method) with the baseline without Mid Vision Feedback (MVF), but not with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it suggests that the authors should include a comparison with the image classification result of MVF to demonstrate the superiority of their method. By addressing this feedback, the authors can significantly enhance the experimental section of their paper, providing stronger evidence for their claims. Therefore, the comment is 5, as it offers a concrete and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should add more content on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors can infer that it relates to the dataset analysis or discussion, but the comment lacks full grounding. It is specific in suggesting what needs to be addressed, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they could be addressed. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it points out a gap in the paper that could enhance its depth and relevance. However, the comment could be more helpful if it provided examples or detailed suggestions on how to address this issue, such as which types of activities should be covered or how they could be integrated into the existing analysis. Overall, the comment is 4 as it directs the authors to a meaningful area for expansion and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should use different notation to avoid confusion between the dimensionality of points and the dilation factor. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the clarity of their paper. The comment is concrete, as it specifies the need for different notation, and it is also somewhat vague as it does not provide detailed guidance on what specific notation should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"D\" to represent both dimensionality and dilation factor, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of different notation to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using \"D\" to represent both dimensionality and dilation factor can cause confusion. However, it does not provide any supporting evidence or examples to substantiate this claim. The comment lacks specific reasoning or references to justify why using different notation would be beneficial or how it would clarify the paper. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, suggesting that using \"D\" to represent both dimensionality and dilation factor can cause confusion. This is a clear and actionable suggestion that can help improve the clarity and readability of the paper. However, the comment could be more helpful if it provided examples of alternative notations or explained why the current notation is problematic. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can enhance the clarity and accessibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions\" in a specific section of the paper. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more elaboration on the concept of state and its relationship to elements or actions. The action is implicit and somewhat vague, as it lacks concrete steps on how to improve the clarity of the concept. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It suggests that more elaboration is needed to clarify this concept. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the concept is unclear. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It questions the equivalence of these terms and suggests that more elaboration is needed to clarify the concept. This feedback is 3 as it points out a potential area of confusion that the authors should address to improve the clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the concept or examples of how it might be misinterpreted. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by the baseline methods, specifically mentioning the use of a Jaccard index. This feedback provides a clear and explicit action for the authors to take, which is to conduct a comparison using a Jaccard index. The suggestion is concrete, as it specifies the exact metric to use and the comparison to make, giving the authors a direct path to implement the suggested improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by the baseline methods, specifically mentioning the use of a Jaccard index. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. The authors can infer that it relates to the results or evaluation section, but this inference is not direct. The comment is specific in suggesting the use of a Jaccard index for comparison, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by the baseline methods, specifically mentioning the use of a Jaccard index. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered actionable. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by the baseline methods, specifically mentioning the use of a Jaccard index. This feedback is 3 as it provides a specific suggestion for improving the paper by including a comparison that could enhance the understanding and evaluation of the proposed solution. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s overall contribution. Additionally, it could offer guidance on how to conduct the comparison or what specific aspects to focus on. Despite these gaps, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific observation regarding the behavior of a generator equipped with a standard RGCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. While it implies that the authors should investigate and explain the reason behind the difference, it lacks detailed guidance on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not offer specific steps for implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the tendency of a generator equipped with a standard RGCN as a discriminator to collapse after several iterations, while the proposed module does not. The comment suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, it does not provide specific suggestions on how to address this issue or what aspects of the proposed module should be explored. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a generator equipped with a standard RGCN as a discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to further explore the issue to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific observation regarding the behavior of a generator equipped with a standard RGCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. This observation is important as it highlights a potential difference between the proposed method and previous ones, which could be crucial to understanding the mechanism of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out an area for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the originality of the paper, noting similarities to a previous study. It implies that the authors should address this issue by either explaining how their work differs from the previous study or demonstrating novel contributions. However, the comment does not provide specific guidance on how to do this, such as suggesting ways to differentiate the work or highlighting areas where novelty is present. The action is implicit and somewhat vague, as the authors need to infer that they should address the originality concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the paper, specifically mentioning a previous study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning.\" This provides some grounding by referencing a specific work, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what aspects of the paper are similar to the previous study or how the authors can address the originality concerns. The lack of specificity regarding the issues or suggestions for improvement makes it 2, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s originality is questionable due to similarities with a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The mention of the previous study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning,\" serves as a reference but does not offer sufficient evidence or analysis to support the claim. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to further explore the similarities themselves to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the paper, noting similarities to a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address the originality concerns. It does not provide actionable feedback or detailed advice on how to differentiate the work or demonstrate novelty. As a result, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit suggestions on how the authors should clarify these comparisons or what specific aspects need to be addressed. There is no guidance on whether additional explanations or examples are needed, nor is there a recommendation for how to present the comparisons more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical comparisons to adaptive learning of GPRGNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the theoretical comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN. It points out that the comparisons are not clear, which is a critical issue for understanding the paper\"s contributions and implications. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these comparisons or what aspects need to be addressed. While it highlights an important area for improvement, the feedback is incomplete and does not fully support the authors in making the necessary changes. Therefore, the comment is 3, as it provides a direction for improvement but lacks actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination. It highlights that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when performing other tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the measurement. The action is implicit and somewhat vague, as the authors can infer that they need to consider alternative methods for measuring object hallucination, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is used. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination, suggesting that a simple yes response does not necessarily indicate comprehension of the object in the image. The reviewer provides a logical reasoning by explaining that the model may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support the claim that a simple yes/no response is insufficient. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. It points out that the model may still produce incorrect objects when undertaking other tasks. This feedback is 3 as it identifies a potential limitation in the methodology and encourages the authors to consider alternative methods for measuring object hallucination. However, the comment could be more helpful if it provided specific suggestions or examples of alternative methods that could be used. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and that the discussion requires improvement. It provides a specific action for the authors to take, which is to conduct experiments on more datasets and train the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is explicit and provides concrete steps for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the verylongterm forecasting task being of limited practical significance and suggests that the discussion requires improvement. However, it does not specify which part of the paper discusses this task or the specific aspects that need improvement. The authors can infer that it relates to the discussion section, but the comment lacks full grounding as it does not explicitly mention the section. Additionally, while it suggests conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon, it does not provide detailed guidance on how to implement these improvements. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion requires improvement. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the authors may find it challenging to understand and respond to the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the practical significance of the verylongterm forecasting task and suggests that the discussion requires improvement. It provides a specific action for the authors to take, which is to conduct experiments on more datasets and train the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is clear and actionable, offering a concrete way for the authors to enhance the discussion section of their paper. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects of the discussion need improvement. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. It suggests that this is a key difference between the work and VideoChatGPT and other works. The reviewer implies that the authors should include experiments and explanation to address this gap. While the comment does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to conduct them, it clearly points out the missing components and suggests a direction for improvement. The action is implicit but concrete, as the authors can infer the need to include these experiments and explanations. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experiments  Ablation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the inclusion of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. The reviewer suggests that this is a key difference between the work and VideoChatGPT and other works. However, the comment lacks specific examples or references to support the claim that these queries are crucial or how they would impact the results. Without detailed justification or evidence, the claim remains 3, as it provides a logical suggestion but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the experiments and explanation of the different queries used in spatiotemporal representation. It highlights the importance of including these components, as they are key to differentiating the work from VideoChatGPT and other works. The comment provides a clear and actionable suggestion for the authors to include experiments and explanation regarding the different queries, which is crucial for understanding the methodology and results. However, the comment could be more helpful if it offered specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer concrete steps or examples of what these details should include. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not specify which part of the paper discusses the FRM, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment does not provide specific guidance on what aspects of the FRM should be elaborated upon or how the innovation could be detailed. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed FRM, which is a combination of channel attention and spatial attention, suggesting that it lacks innovation. However, it does not provide specific guidance or examples on how the authors could enhance the innovation or what aspects of the FRM should be detailed. The comment is vague and lacks actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider the potential social impacts of their work, such as increased automation and the risks from dual use. While the comment does not explicitly instruct the authors to include these aspects in their paper, it provides a clear direction for improvement by highlighting areas that could be explored. The action is implicit but concrete, as it specifies the potential social impacts that should be addressed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential social impacts of the work, such as increased automation and dual use risks. The comment provides a clear direction for improvement by suggesting that the authors should consider these aspects. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not consider the potential negative social impacts of their work, specifically mentioning increased automation and dual use risks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a general idea but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the lack of consideration of social impacts, such as increased automation and dual use risks. While it acknowledges that the work is unlikely to have significant negative social impacts, it suggests that the authors could address this aspect by discussing the social impacts. This feedback is 3 as it points out a relevant area for improvement, but it could be more actionable by providing specific suggestions on how to incorporate these considerations into the paper. Overall, the comment offers a clear direction for enhancing the paper\"s consideration of societal impacts, but it lacks detailed guidance on how to implement these improvements. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a specific reorganization of the sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides a clear and concrete action for the authors to take, as it offers a specific way to restructure the sections to improve clarity and coherence. The comment is explicit in its suggestion and provides a concrete implementation, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 and Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a specific reorganization of these sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Sections 3 and 4 are redundant and proposes a specific reorganization to improve clarity. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the sections are redundant or how the suggested reorganization would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential redundancy in Sections 3 and 4, suggesting that the first paragraph of Section 4 could be moved to Section 3 and the remainder of Section 4 placed before Section 3. This feedback is 3 as it points out an area for potential improvement in the organization and flow of the paper. However, the comment lacks depth and does not provide specific guidance on how to achieve this reorganization or why it would be beneficial. While it offers a direction for improvement, it could be more helpful with additional explanation or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should provide more details to establish a connection between these concepts. However, the comment does not specify what kind of details are needed or how to present them, leaving the authors to infer the necessary actions. While the comment identifies an area for improvement, it lacks concrete guidance on how to address the issue, making it 3.", "grounding_specificity_rationale": "The comment addresses a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the connection between these concepts and the zeroshot learning effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or establish a connection between these concepts. While it highlights an area for improvement, the feedback lacks depth and actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these analyses to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"strong empirical results\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the potential contribution of finding out the reasons behind the empirical results through theoretical analyses or experiments. However, the comment lacks specificity regarding what kind of theoretical analyses or experiments would be needed to address the questions raised. Therefore, this comment is 4, aligning with a score of 4.", "verifiability_rationale": "The review point suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment raises valid questions about the empirical results, it lacks specific examples or references to support the claim that these analyses are missing from the paper. The suggestion is logical and relevant, but the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper could provide theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It points out that the simple greedy selection approach outperforms more principled acquisition functions and that deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment highlights a valuable area for exploration, it lacks specific guidance on how to conduct these analyses or what aspects to focus on. The authors are given a direction for improvement but not detailed steps to follow. Therefore, the comment is 3, as it provides a general direction for enhancing the paper but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for a citation regarding the kmax problem, which is a clear and direct action for the authors to take. The comment provides a specific request for additional information, making it 5. The authors know exactly what is expected of them, which is to provide a citation for the kmax problem. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for a citation regarding the kmax problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the citation for the kmax problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for a citation regarding the kmax problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where additional information or clarification is needed. By asking for a citation regarding the kmax problem, the reviewer prompts the authors to provide more context or references to support their claims. This feedback is clear and actionable, as it directs the authors to include relevant information that could enhance the paper\"s comprehensiveness and credibility. However, the comment could be more helpful if it provided additional context or suggestions on how to address the kmax problem or integrate the cited work into the paper. Overall, the comment is 3 as it guides the authors toward improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback implies that the authors should provide additional details or analysis regarding the estimation process and the model\"s reliability. However, the comment does not explicitly instruct the authors to include these details, nor does it provide specific guidance on how to present this information. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what is expected. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would impact the paper\"s validity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is valuable as it highlights a potential gap in the paper that could impact its credibility and robustness. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending additional analyses or discussions. While it points out a critical area for improvement, it lacks actionable advice, making it 3 but not comprehensive. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the applicability or what specific steps to take to mitigate the assumptions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the assumptions made and their impact on applicability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods, specifically noting that strong assumptions are made about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. This feedback highlights a potential weakness in the paper that could impact its relevance and practicality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. While it points out a relevant concern, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a discrepancy in the language used in Figure L006, specifically noting that \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level.\" This feedback is clear and provides a direct action for the authors to take, which is to revise the language in the figure to be more accurate. The suggestion is concrete, as it specifies the exact change needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the language used in the figure and suggests a possible correction by adding \"on the subword level.\" This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figure caption, \"thousands,\" is not accurate. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment suggests a possible correction by adding \"on the subword level,\" but without further explanation or examples, it lacks verifiability. The authors may find it challenging to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in Figure L006, noting that the term \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level,\" which could improve the accuracy of the figure. This feedback is clear and actionable, as it provides a direct suggestion for the authors to consider when revising their draft. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the suggested correction would enhance the figure\"s clarity. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It notes that several hyperparameters, such as regularization, are not explicitly mentioned and asks for clarification on why the y value in the latent path figures is always 0 at x=0. The reviewer also expresses interest in seeing further analysis on the model, specifically mentioning interpolations. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are somewhat vague, as they do not specify how to address the issues or what specific analyses should be conducted. Therefore, the comment is 3, as it points out areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig 3\" and \"regularization,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues by questioning why the y value in the latent path figures is always 0 at x=0 and asking for clarification on the normalization. Additionally, it suggests further analysis on the model using interpolations. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the absence of certain hyperparameters, such as regularization, and the constant value of y at x=0 in the latent path figures. It also suggests that further analysis on the model could be beneficial. While the comment identifies areas for clarification and potential improvements, it lacks specific examples or references to support the claims. The authors would need to make a significant effort to understand and address the issues raised, as the comment does not provide detailed reasoning or evidence. Therefore, the comment is 3, as it points out potential areas for improvement but lacks the necessary justification to be 5.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the absence of certain hyperparameters, such as regularization, and the constant value of y at x=0 in the latent path figures. It also suggests that further analysis on the model could be beneficial, specifically mentioning interpolations. While the comment raises important questions and points out potential weaknesses, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general sense of what needs to be improved but are not provided with actionable steps or detailed advice on how to implement these improvements. Therefore, the comment is 3, as it provides insight into areas for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It specifically points out that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions is in the appendix rather than the main sections. While the comment provides a clear indication of what needs to be addressed, it does not offer specific guidance on how to improve the clarity of the contributions or suggest ways to integrate the material into the main sections. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"deeprag algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for clearer contributions in the Introduction and the placement of supporting material in the main sections versus the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. The reviewer provides specific examples, such as Figure 1 and the deeprag algorithm, to support this claim. However, the comment lacks detailed reasoning or references to substantiate why this is a significant issue or how it affects the paper\"s clarity or impact. While the examples are helpful, the lack of detailed justification makes the claim 3, as the authors may need to infer the full extent of the problem and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It provides specific examples, such as Figure 1 and the deeprag algorithm, to illustrate the problem and suggests that the exact contributions need to be written more clearly in the Introduction. Additionally, it points out that the material supporting the main contributions is in the appendix rather than the main sections. This feedback is clear and actionable, as it directs the authors to improve the clarity and organization of their paper by integrating the material into the main sections. However, the comment could be more helpful if it provided suggestions on how to effectively integrate the material into the main sections or offered guidance on how to present the contributions in a clearer manner. Overall, the comment is 4 as it identifies a significant issue and provides clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the effect of rounding core tensors on the full tensor error and seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should provide more information on the theoretical aspects of the approximation error, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the rounding of core tensors to smaller ranks with a given accuracy by clustering values or imposing some error decision epsilon. This allows the authors to accurately identify the relevant section. The comment is also specific because it asks for clarification on the effect of rounding on the full tensor error and seeks information on any error bound in terms of epsilon. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical aspects of rounding core tensors and the effect on the full tensor error. It seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The authors are left to infer the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors discuss the rounding of core tensors to smaller ranks with a given accuracy. It raises a question about the effect of this rounding on the full tensor error and seeks clarification on whether there is an error bound in terms of epsilon. This feedback is valuable as it prompts the authors to consider the theoretical aspects of their method and provides a clear direction for further exploration and explanation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have approached similar questions. Overall, the comment is 4 as it guides the authors toward a deeper understanding of their method and its implications."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. While the comment implies that the authors should add results on the generative setting, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"visual dialog,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on the generative setting in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. The reviewer suggests that the authors should include results on the generative setting as well. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. This feedback is clear and actionable, as it directs the authors to address a gap in their experimental evaluation. However, the comment could be more helpful if it provided additional context or examples on how to conduct the analysis on the generative setting. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what kind of evidence or examples would be sufficient or how the authors should present them. The comment lacks explicit guidance on how to implement this suggestion, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or example that needs improvement. The comment is 1, as it does not specify where in the paper this issue is addressed. Additionally, it lacks specificity as it does not provide details on what kind of evidence or examples would be sufficient to convince the reader. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. While it identifies a potential weakness in the paper, it lacks specificity and does not provide guidance on what kind of evidence or examples would be sufficient to address this concern. The comment is 3 as it points out an area for improvement, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive and detailed."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to explore the effectiveness of the approach for other language families. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the effectiveness of the proposed approach for other language families, which is a clear and specific point. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of unknown effectiveness, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the effectiveness of the proposed approach for other language families. It highlights a gap in the paper that needs to be addressed, which is important for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how to explore or demonstrate the effectiveness of the approach for other language families. While it points out a relevant issue, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, it does not provide any guidance on how the authors should address this issue or what specific aspects of security should be analyzed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of analysis on the security (protection of privacy) of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of security analysis, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. This is a critical oversight that could impact the overall robustness and trustworthiness of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of security should be analyzed. While it points out a critical area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. This provides a clear and direct action for the authors to take, which is to explicitly mention the form of p in their draft. The comment also references the reviewer\"s previous comment, which adds context and clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the form of p and its assumed Gaussian distribution. This provides clear guidance on what the authors need to clarify or add to their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or necessary. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the form of p is not explicitly described near line 135, despite being assumed to be a Gaussian distribution. This feedback is clear and actionable, as it directs the authors to clarify or specify the form of p in their draft. By addressing this point, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it guides the authors toward a specific improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. While it implies that the authors should expand on these differences, it does not explicitly instruct them to do so or provide specific guidance on how to approach this enhancement. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed descriptions of the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not specify which parts of the related work section are lacking in detail or which works are not described adequately. Without explicit references to specific sections or works, the authors cannot confidently determine which parts need attention. The comment is 1 as it does not specify where in the paper the related work section is located, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not provide specific examples or references to the works that are lacking in detail or clarity. Without these details, the claim is not fully substantiated, making it difficult for the authors to understand the exact areas that need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the related work section, specifically suggesting that the differences between the works mentioned are not described enough. This feedback is 3 as it points out a specific area where the paper could be strengthened, but it lacks depth and does not provide detailed guidance on how to address this issue. The authors are given a general direction to enhance the related work section, but the comment could be more helpful with additional suggestions or examples on how to improve the descriptions of the differences. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to explain what type of understanding is gained by looking at the PPP maps, which is a clear and direct action. This request is specific and provides a concrete direction for the authors to improve their draft. The comment is 5 as it guides the authors on how to enhance the clarity and comprehensiveness of their explanation regarding the importance of PPP metrics.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors state the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely an explanation of the understanding gained by looking at the PPP maps. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding the understanding gained from looking at PPP maps. It does not make a subjective claim or express an opinion but rather seeks clarification on the content. Therefore, it is a factual request for more detailed explanation, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft, namely by providing a more explicit explanation of the understanding gained from looking at PPP maps. This feedback is clear and actionable, as it directs the authors to clarify their explanation to enhance the comprehensiveness and clarity of their work. By addressing this point, the authors can significantly improve the understanding of their results and the significance of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This implies that the authors should include such comparisons to enhance the credibility of their work. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other stateoftheart methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which affects the credibility of their work. However, the comment does not provide specific examples or references to these stateoftheart methods or explain how the absence of such comparisons impacts the credibility of the work. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the significance of the omission themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided sufficient evidence for the credibility of their work. It points out the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT, which is a relevant benchmark for evaluating the effectiveness of the proposed methods. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the credibility of their work. However, the comment could be more helpful if it provided examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. It also mentions that the connection between the text and the figure, as well as the equations, is difficult to understand. This provides clear and concrete actions for the authors to take, such as redrawing the figure and improving the explanations in the text. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the schematic representation of the forward prediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear schematic representation in Figure 2(b) and the difficulty in connecting the text and the figure with the equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. The reviewer provides a specific example of the figure not showing the schematic representation and notes the difficulty in connecting the text and the figure with the equations. This provides a clear and detailed justification for the claim, making it 4. However, the comment could be strengthened by providing additional examples or references to similar models to further substantiate the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clear explanation and representation of the forwardprediction model in Figure 2(b). It points out that the figure does not adequately convey the schematic representation of the model, making it difficult for readers to understand the connection between the text and the figure. The comment suggests that the figure should be redrawn to better represent the model. This feedback is clear and actionable, providing the authors with a concrete step to improve the clarity and comprehensibility of their work. However, it could be more helpful if it included suggestions on how to improve the explanation or presentation of the model in the text. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The reviewer also questions the authors\" claim that FP + RBI is better than RBI alone and suggests that the authors should provide a stronger baseline to prove the usefulness of FP. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger baseline or address the training issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the training process for RBI, specifically noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The comment also questions the authors\" claim about the usefulness of FP + RBI and suggests that a stronger baseline should be provided to prove its effectiveness. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the training process or results sections. The comment is specific in detailing what needs to be addressed, such as the training process and the need for a stronger baseline. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the significance of the training process and the potential impact on the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This is a significant observation that could impact the effectiveness of RBI. The reviewer suggests that this could be a factor contributing to the superiority of FP + RBI over RBI alone. Additionally, the comment questions the authors\" claim about the usefulness of FP + RBI and suggests that a stronger baseline should be provided to prove its effectiveness. While the comment provides valuable insights into potential weaknesses and areas for improvement, it could be more helpful if it offered specific suggestions on how to address these issues or what kind of baseline should be used. Overall, the comment is 3 as it highlights important areas for consideration, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer suggests that the only benefit is the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the statement, it does not provide explicit guidance on how the authors should address this misleading aspect. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the time scales involved and possibly revise the statement to be more accurate. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiscale statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, explaining that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The comment further suggests that the only benefit is the reduction of gradient path by the slow RNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer supports this claim by explaining the distinction between physical and logical time scales and the potential benefit of reducing gradient path by the slow RNN. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. As it stands, the comment is 4, as it provides a logical explanation but lacks specific references or detailed evidence to fully support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential misleading aspect in the paper regarding the multiscale statement. It points out that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and understanding of the work. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this aspect or address the misleading nature of the statement. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestion to discuss the similarity and difference with reinforcement learning is a vague direction, and the comment lacks specific guidance on how to address these issues. The authors are left with a general idea of what needs to be improved but without clear steps on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses several issues, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specificity by suggesting a direction for the conclusion, it lacks full grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and that there is no discussion of limitations. It suggests that the paper could benefit from a comparison with reinforcement learning. While the comment identifies specific areas for improvement, it lacks detailed evidence or references to support the claim about the baseline methods or the need for a discussion on limitations. The suggestion for a comparison with reinforcement learning is somewhat vague, as it does not provide specific guidance on how to conduct such a comparison or what aspects to focus on. Therefore, the comment is 3, as it provides some basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. It suggests a direction for the conclusion by proposing a discussion on the similarity and difference with reinforcement learning, which could enhance the generalizability of the results. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what aspects of the comparison with reinforcement learning should be emphasized. The feedback is 3 as it points out areas for improvement but could be more comprehensive with additional details and suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should clarify the distinction between the expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. While the comment implies that the authors should make this distinction clearer upfront, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction, but it is concrete in that it provides a clear direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. The comment provides a clear direction for improvement by suggesting that the distinction should be made clearer upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). The reviewer suggests that in the current paper, the decisionmaker does care about the noise, and the objective function of interest is a stochastic noisy function. The comment provides a logical reasoning for the distinction between the two scenarios, but it lacks specific examples or references to support the claim that the current paper\"s approach is misleading. Therefore, the claim is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s approach to evaluation, noting that the expected performance under observation noise is typically used because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. However, in the current paper, the decisionmaker is interested in the stochastic noisy function, which is a different objective. The comment suggests that the distinction between these two should be clarified upfront to provide a clearer understanding of the evaluation approach. While the comment highlights an important distinction, it lacks specific suggestions on how to clarify this distinction or what specific changes should be made to the paper. This limits the comment\"s helpfulness, as it points out an area for improvement but does not fully guide the authors on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It also proposes a minor point about optimizing the inference part of the model by keeping the generative model fixed and parameterizing it as either SIGVAE or VGAE to compare the representations. While the comment provides a clear action to take regarding the VGAE implementation, it lacks specific guidance on how to implement the suggested comparison with SIGVAE or VGAE. The minor point about optimizing the inference part is also somewhat vague, as it does not provide detailed instructions on how to implement this suggestion. Overall, the comment is 3 as it provides a clear action for the VGAE implementation but lacks concrete details on the minor point.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VGAE with a vamp prior\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential benefits of the generative model and the inference part of the model. The comment provides a clear suggestion to run VGAE with a vamp prior to better match the doubly stochastic construction and offers a minor point about optimizing the inference part of the model. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This claim is 3 as it provides a logical reasoning for the suggestion, which is to test whether the benefits are due to a better generative model or better inference. However, the comment lacks specific examples or references to support the claim, such as studies that have demonstrated the effectiveness of this approach. Additionally, the minor point about optimizing the inference part of the model is somewhat vague, as it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help inform whether the benefits are due to a better generative model or better inference. This is a clear and actionable suggestion that could significantly impact the authors\" understanding of their results. Second, it offers a minor point about optimizing the inference part of the model by keeping the generative model fixed and parameterizing it as either SIGVAE or VGAE to compare the representations. While this suggestion is somewhat vague, it could be clarified by providing more details on how to implement this comparison. Overall, the comment is 4 as it offers valuable insights and suggestions for improving the draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to enhance the novelty or contribution of their work. The action is implicit and vague, as the authors are left to infer that they need to improve the novelty or contribution of their work, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method, specifically mentioning Table 2, and acknowledges the novelty and contribution of the work. However, it does not specify which part of the paper discusses the novelty or contribution, making it weakly grounded. The comment does specify that the main contribution is a new network design inspired by prior work for sound source localization, which provides some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method\"s performance is good, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment lacks specific examples or references to support the claim that the method is incremental or lacks novelty. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. While the comment identifies a potential issue with the novelty and contribution of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the importance of longrange dependencies in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the importance of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment lacks specific examples or references to support the claim that learning longrange dependencies is not always necessary. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This feedback is 3 as it prompts the authors to consider the importance of longrange dependencies in their work and to address the potential ambiguity in their claims. However, the comment could be more helpful if it provided specific suggestions on how to frame this discussion or what aspects of the topic should be explored. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definition of $e_l$ and consider the impact of $M$ on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3 and Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of $e_l$ and pointing out the exponential dependence on the diameter $M$ of the domain of data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment lacks specific examples or references to support the claim about the exponential dependence on $M$. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the definition of $e_l$ in Equation (3) and pointing out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that this dependence affects the constant factor of the required feature size. Additionally, the comment provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. This feedback is clear and actionable, as it guides the authors to clarify the definition of $e_l$ and address the issue of exponential dependence on $M$. However, the comment could be more helpful if it provided suggestions on how to improve the theoretical results or the experimental setup to mitigate this issue. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, another phenomenon observed in the context of very deep graph networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to improve the modeling ability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs and suggests that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. However, it does not specify which part of the paper discusses the longrange modeling ability or oversmoothing, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of oversmoothing, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modeling ability of DGNs is due to oversmoothing, a phenomenon observed in the context of very deep graph networks. The reviewer supports this claim by referencing a specific work, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI'18,\" which discusses oversmoothing. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how oversmoothing affects the modeling ability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. While the comment provides a reference to a specific work that discusses oversmoothing, it does not offer detailed guidance or suggestions on how the authors might address this issue or improve their modeling ability. The feedback is 3 as it points out a potential problem but lacks actionable advice or detailed analysis, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there is a demonstration or result related to the model collapsing less than other methods. It also asks about the specific observation of gradients becoming 0 and collapsing, mentioning line 159. While the comment implies that the authors should provide evidence or examples to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a demonstration or result related to the model collapsing less than other methods, and it raises questions about the common occurrence of gradients becoming 0 and collapsing. This provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the demonstration or result related to the model collapsing less than other methods. It also questions the common occurrence of gradients becoming 0 and collapsing, mentioning line 159. While the comment identifies a potential area for improvement by asking for evidence or examples to support the claim, it lacks specific guidance or suggestions on how to address this issue. The authors are prompted to provide additional information, but the feedback is somewhat vague and does not offer detailed guidance on how to improve the draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these issues are related to. Without explicit references to sections or examples, the authors cannot confidently determine where to focus their revisions. The comment is specific in identifying the issue of unclear problem formulation, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim. Without specific references or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide guidance on how to improve the clarity or what aspects of the formulation are unclear. Without actionable suggestions or examples, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives. This provides a clear and concrete action for the authors to take, as it specifies the exact models to include in the experiments and the purpose of doing so. The suggestion is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for experiments with different LLM families, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical reasoning for the need to conduct experiments with different LLM families to enhance the applicability and generalizability of the method. However, the comment lacks specific examples or references to support the claim, such as explaining why these particular models are relevant or how they would impact the results. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directs the authors to a specific area for improvement that could enhance the paper\"s contribution. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement and offers a concrete direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method seems to only work for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper this observation pertains to, making it weakly grounded. The comment is specific in its critique of the method\"s applicability, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the method, specifically that it only works for generative models that can be finetuned as an in/outpainting model. This is a relevant observation that could impact the applicability and scope of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or expand the method\"s applicability. While it identifies an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\"s imagination. However, it does not provide specific guidance on how to address this issue or what changes should be made to improve the connections. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first part\" and \"FGE,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the perceived weakness in the connections between the curve finding and FGE, and it provides a rationale for the discrepancy between the title and the content. However, the comment lacks specific suggestions on how to address this issue or improve the connections. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the connections between the curve finding and FGE are weak, based on the author\"s interpretation of the first part and the title. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\"s imagination. It points out that the process could be computationally demanding, which is a relevant concern. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the connections between the two parts. While it highlights a potential problem, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results for linear scalarization + Concorde, which is a heuristicbased solver, in their experimental analysis. This is an explicit action that the authors can directly implement to improve their draft. The comment provides a clear rationale for why this inclusion is necessary, as it highlights the competitive nature of learningbased solvers compared to heuristicbased solvers and the fact that the SOTA heuristicsolver usually has the best performance for single objective TSP. However, the comment could be more concrete by specifying which section of the paper should include these results, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"Pareto front,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results for linear scalarization + Concorde, a heuristicbased solver, for a better comparison. This provides clear guidance on how to improve the paper by including these results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, based on experimental results. However, it does not provide specific details or references to support this claim, such as specific experimental settings, results, or comparisons. The mention of \"SOTA heuristicsolver\" (e.g., Concorde) suggests that the authors should include results for linear scalarization + Concorde for a better comparison. While the comment highlights a potential area for improvement, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include results for linear scalarization + Concorde, a heuristicbased solver, in their experimental analysis. This feedback is actionable as it provides a clear and concrete suggestion for enhancing the comparison between learningbased and heuristicbased solvers. By including these results, the authors can better demonstrate the performance of their learningbased solver in the context of a competitive landscape. However, the comment could be more helpful if it explained why this inclusion is important or how it would impact the overall analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use generalized Voronoi graphs, semantic maps, or pose graphs for exploration. While the comment implies that the authors should provide a comparison or discussion of their method with these existing methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of their method in relation to these existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"generalized Voronoi graph or semantic maps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the proposed method in relation to existing methods that use similar concepts for exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer supports this claim by referencing existing methods, such as graphbased SLAM, where loop closure is applied. This provides a clear and specific rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to these existing methods, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas presented are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer suggests that the paper should discuss the proposed method in relation to these existing methods, which could enhance its originality and contribution. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by incorporating a discussion of their method in relation to existing methods. However, the comment could be more helpful if it offered specific examples or references to these existing methods, which would guide the authors in their analysis and comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some experimental details and tasks back into the main text and moving background information from Section 2 to the appendix. While the comment provides a clear action\u2014moving specific details and information\u2014it does not specify which details or information should be moved or how to structure them in the main text. The authors are left to infer which details are relevant and how to integrate them effectively. The action is explicit but lacks concrete guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, tasks, and other details being moved to the appendix, making it difficult to interpret the paper. It suggests moving some of these details back into the main text and moving background information from Section 2 to the appendix. However, the comment does not specify which details or information should be moved or where in the main text they should be placed. This lack of specificity makes it difficult for the authors to effectively address the feedback. Therefore, the comment is weakly grounded because it does not specify which parts of the paper are being addressed, and it is not specific in detailing what needs to be changed. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the experimental setup, tasks, and other details are moved to the appendix, making it difficult to interpret the paper. The reviewer proposes moving some of these details back into the main text and suggests moving background information from Section 2 to the appendix. However, the comment lacks specific examples or detailed reasoning to support why these changes would improve the clarity or interpretability of the paper. Without specific examples or references, the claim is 3, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and presentation of the experimental setup, tasks, and other details, which are currently placed in the appendix. It suggests moving some of these details back into the main text and moving background information from Section 2 to the appendix. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accessibility of the paper. However, the comment could be more helpful if it offered specific examples of which details should be moved or how to structure them in the main text. Overall, the comment is 4 as it guides the authors on how to enhance the organization and presentation of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that providing glosses in Figure 2 would be helpful. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the figure. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests providing glosses in Figure 2, which implies that it is referring to a specific figure in the paper. However, it does not explicitly mention the figure, making it weakly grounded. The comment is specific in suggesting what needs to be added, which is the provision of glosses. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests providing glosses in Figure 2, which is a request for clarification or additional information. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"", "helpfulness_rationale": "The comment suggests providing glosses in Figure 2, which is a specific and actionable piece of feedback. By suggesting this addition, the reviewer helps the authors improve the clarity and accessibility of their figures, making it easier for readers to understand the content. However, the comment could be more helpful if it provided additional context or examples of what kind of glosses would be beneficial. Overall, the comment is 4 as it directs the authors to a specific improvement that can enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that \"Memb\" is mentioned as the previous stateoftheart but there is no reference provided. This implies that the authors should include a reference to the work that Memb is based on. However, the comment does not specify which work or where the reference should be added, leaving the authors with a vague understanding of what needs to be done. The action is explicit in identifying the missing reference, but it lacks concrete guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment mentions \"Memb\" as the previous stateoftheart, but it does not specify which part of the paper this claim is made in. The authors cannot confidently determine which section or discussion refers to Memb. Additionally, the comment lacks specificity regarding what needs to be addressed regarding the lack of a reference. Without explicit references or detailed guidance, the authors cannot effectively identify and address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"Memb\" is mentioned as the previous stateoftheart but lacks a reference to any work. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential oversight in the paper, noting that \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. This is a clear and actionable observation that can help the authors ensure their work is properly contextualized and referenced. However, the comment lacks depth and does not provide suggestions on how to address this issue or what specific references might be relevant. While it identifies a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or what specific changes they should consider. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of grouping for quantization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of pertensor and perchannel grouping and suggests considering finer grouping instead. This provides clear guidance on what aspect of the quantization method is being questioned and what alternative might be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be preferable. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. This is a valid point that could lead to a more efficient or accurate quantization process. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific advantages finer grouping might offer. While it identifies a potential area for improvement, the feedback is incomplete and does not fully support the authors in making changes to their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It explicitly recommends conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact aspect to investigate and offers a specific direction for further analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this analysis could be conducted. The authors can infer that it relates to the model evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular aspect to investigate, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the study. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient justification for the authors to act on it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests studying the impact of the ratio of unseen classes on the performance of the model. It provides a specific direction for further analysis by recommending conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback is actionable and offers a clear and constructive suggestion for the authors to enhance their study. However, the comment could be more helpful if it provided additional context or examples of how this analysis could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. While the comment implies that the authors should provide an explanation or rationale for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address this question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these architectures are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of using GRU for the Pyramid and LSTM for the sequential part, questioning whether the combination of these architectures is a reason for the improvements. This is a valuable point as it prompts the authors to consider the rationale behind their choice and whether it is justified. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it could be more helpful with additional context or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in a specific line of the paper. While it identifies a potential issue with the clarity of the definition, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the definition, but it lacks concrete instructions or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices\" and seeks clarification on how they are defined in this context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the definition of \"active vertices\" in a specific line of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in a specific line of the paper, which is a clear and actionable point. By asking for clarification on the definition, the reviewer prompts the authors to provide more detailed explanations or definitions to ensure that their work is clear and understandable. This feedback is valuable as it helps the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it suggested alternative ways to present the definition or provided examples to illustrate the concept. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy between the paper\"s claims and the limitations it discusses. It points out that the theory is not mentioned as a limitation in the main text, despite being applicable to the used model. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text. Additionally, the comment notes the vagueness of unspecified \"structural assumptions\" in the appendix, which makes it difficult to find the theoretical limitation. The reviewer also suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general, as they are widely used in industry. While the comment provides clear and explicit actions for the authors to take, it does not offer detailed guidance on how to elaborate on the negative societal impact. Therefore, the comment is 4, as it provides concrete steps for improvement but lacks specific instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"structural assumptions\" and the \"vagueness\" of these assumptions, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the theoretical limitation not being mentioned in the main text and suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the theoretical limitation of its theory being applicable to the used model, despite the vagueness of unspecified \"structural assumptions\" in the appendix. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and should elaborate on the potential negative societal impact of these networks. The comment provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about the current use of graph neural networks in industry. Additionally, the suggestion to elaborate on the negative societal impact is somewhat vague, as it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks sufficient evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the theoretical limitation of the theory being applicable to the used model is not mentioned in the main text. It points out the vagueness of unspecified \"structural assumptions\" in the appendix, which makes it difficult for readers to find the theoretical limitation. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text and elaborating on the potential negative societal impact of graph neural networks in general. This feedback is clear and actionable, as it provides specific guidance on how to improve the paper by addressing a critical limitation and offering a direction for further exploration. However, the comment could be more helpful if it provided examples of how other papers have addressed similar limitations or how the authors might elaborate on the societal impact. Overall, the comment is 4 as it offers valuable insights and suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"epsilongreedy\" in the context of training, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"epsilongreedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. This question highlights a potential area of confusion or misunderstanding in the paper, which could be clarified to enhance the readers\" comprehension. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but not comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or what specific changes should be made to enhance its novelty. The authors are left without any direction on how to address the issue of lack of novelty. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this combination is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in detailing the combination of GCN and normalizing flow, but without grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not provide any specific insights or suggestions for improvement, such as identifying areas where the method could be enhanced or suggesting alternative approaches. The comment lacks actionable feedback, leaving the authors without direction on how to address the issue of lack of novelty. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to ensure that both heads are affected. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the affected layers, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). This is a clear observation that could be relevant for the authors to address, as it highlights a potential imbalance in the paper\"s focus. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific changes could be made to ensure a more balanced presentation. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide explicit guidance on what specific part of the framework is vital or how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the importance of the framework in the context of weakly supervised learning. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspect of the framework is vital or how it contributes to the use of CLIP. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not provide any supporting evidence, reasoning, or references to justify why this part is crucial or how it distinguishes the paper from other related work. Without such information, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the discussion. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is not strong. It also highlights the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment identifies areas for improvement, it does not provide explicit guidance on how to strengthen the analogy or clarify the connection between the decomposition/integration steps and Fourier analysis. The authors are left to infer that they need to address these issues, but the lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment critiques the analogy between HOI analysis and Harmonic analysis, noting that the link is weak. It also points out the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. However, the comment does not specify which part of the paper discusses the analogy or the basis for HOI analysis, making it weakly grounded. The comment is specific in detailing the issues with the analogy and the connection to Fourier analysis, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, and that the connection between the decomposition/integration steps and Fourier analysis is not close. The reviewer provides logical reasoning by pointing out the limited basis for HOI analysis, with only two elements (human and object), and the lack of a direct connection between the decomposition/integration steps and Fourier analysis. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the basis of the analogy and the connection to Fourier analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is not strong. It also highlights the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment points out areas for improvement, it lacks specific suggestions or guidance on how to strengthen the analogy or clarify the connection between the decomposition/integration steps and Fourier analysis. The feedback is 3 as it provides insight into potential weaknesses, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. However, it also acknowledges that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore its implications further. The action is implicit and somewhat vague, as the authors can infer that they might need to consider the impact of this limitation on the applicability of their methodology. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the potential limitation of the proposed methodology, specifically regarding the performance gains of dynamic precision control during training on bitserial accelerators. It also mentions the use of bitparallel fixedpoint numbers by most existing ML accelerators, which could restrict the implications of the proposed methodology. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the applicability of the methodology to existing accelerators. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which is a specific observation about the applicability of the proposed methodology. However, the comment lacks supporting evidence or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 2, as it provides a logical reasoning but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. This is a relevant observation that could impact the applicability of the methodology to most existing ML accelerators, which typically use bitparallel fixedpoint numbers. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore its implications further. While it highlights an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer asks if the focus distance extends beyond these examples and if it generalizes well. While the comment implies that the authors should consider including additional focus distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the focus distance range. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the focus distance shown in the figure, suggesting that it should include other distances beyond those present in the training data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer suggests that the focus distance should be expanded to include other distances, implying that it may not generalize well. However, the comment lacks specific examples or references to support the claim that other distances are necessary or how they would impact the generalizability. This makes the claim 3, as it provides a logical suggestion but lacks detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 8, noting that it only shows focus distances of 1m and 5m, which are both present in the training data. It raises a valid question about the generalizability of the focus distances shown, suggesting that the authors should consider including other distances to test the model\"s robustness. This feedback is clear and actionable, as it prompts the authors to expand their experimental setup to address a potential limitation in their work. However, the comment could be more helpful if it provided specific suggestions on which distances to include or how to test generalizability. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a clear direction for the authors to consider broadening their definition of content and style, it does not offer specific guidance on how to implement this suggestion. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of content and style in the context of their neural application. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a logical reasoning for broadening the definition of content and style, it lacks specific examples or references to fully substantiate the claim. This makes the comment 3, as it provides a basis for the suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider defining content and style more broadly in the context of their neural application. It offers an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. Additionally, the comment raises a pertinent question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. This feedback is valuable as it prompts the authors to reconsider their definition of content and style, which could lead to a clearer and more comprehensive understanding of their work. However, the comment could be more helpful if it provided additional guidance or examples on how to broaden the definition or address the question about the temporal dynamic structure. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. It provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. While the comment identifies areas that need further explanation, it does not explicitly instruct the authors on how to improve the analysis or provide specific guidance on how to address the issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the analysis could be explained in depth, particularly regarding the information distortion and the quantization of MHSA. The comment provides specific examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. The reviewer provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This provides a logical and detailed explanation of the issue, making the claim 4. However, the comment could be strengthened by referencing specific studies or literature that support the claims about information distortion and quantization. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the information distortion and the quantization of MHSA. It highlights the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This feedback is 5 as it identifies specific areas where the authors need to provide more depth and clarity in their analysis. By pointing out the limitations of the proposed approach and referencing existing works, the comment offers actionable guidance for the authors to improve their draft. However, it could be further enhanced by suggesting specific ways to address the issues or providing additional references to support the claims. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness of the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN, and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to include comparisons to STN and provide more detailed explanations of the novelty of their approach. However, the comment lacks concrete suggestions on how to conduct these comparisons or what specific aspects to focus on. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses a specific issue with the paper, namely the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It mentions the proposed Xtransformation and its similarity to STN, as well as the use of STN in PointNet. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these topics are discussed. The comment is specific in detailing what needs to be addressed, such as the need for comparisons to STN and the need for more detailed explanations of the novelty of the proposed approach. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to spatial transformer networks (STN) and the absence of comparisons to STN. The reviewer supports this claim by pointing out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, the reviewer notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment provides some logical reasoning and references to existing works, it lacks specific examples or detailed comparisons to fully substantiate the claim. This makes the comment 3, as it provides a basis for the claim but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper, which is important for demonstrating the novelty of the work. The comment provides clear and actionable feedback by highlighting areas where the authors need to improve their work, such as including comparisons to STN and providing more detailed explanations of the novelty of their approach. This feedback is valuable for the authors to enhance the originality and impact of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a confusion regarding the reward in Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. It provides references to external works that may help clarify the issue, such as [1] and [2], which are articles on the topic of reinforcement learning. However, the comment does not explicitly instruct the authors to include these references or provide specific guidance on how to clarify the reward or network model. While the action is implied, it is not as direct as it could be, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of confusion regarding the reward and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. The references provided, such as [1] and [2], could be helpful in clarifying the issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Eq. 12, specifically questioning where the reward comes from and whether one of the r_i is taken from Eq. 11. The reviewer suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment identifies a potential issue with the clarity of the equations, it lacks specific examples or detailed reasoning to fully substantiate the claim. The references provided could be helpful in understanding the context, but the comment itself does not provide enough evidence or detailed reasoning to fully verify the claim. Therefore, the comment is 3, as it highlights a potential issue but lacks sufficient evidence or detailed explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Eq. 12, noting that the reward source is not clearly explained and questioning whether one of the r_i is taken from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to address the issue or suggest specific ways to clarify the equations. The references provided could be helpful, but the comment itself lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It explicitly instructs them to correct the labeling of \"Fig.7\" to \"Fig.12\" in Supp. Page 31 and to attach each theorem and corollary to its corresponding proof link. Additionally, it highlights the primary concerns of motivation, methodology soundness, and experiment persuasion, which the authors should address to improve the paper. The comment is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected (the labeling of \"Fig.7\" to \"Fig.12\") and suggests attaching each theorem and corollary to its corresponding proof link. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the labeling of \"Fig.7\" in Supp. Page 31 and suggests attaching each theorem and corollary to its corresponding proof link. The reviewer provides a logical reasoning by explaining that this would make it easier for readers to follow the paper. However, the comment lacks specific examples or references to support the claim about the importance of attaching theorems and corollaries to their proofs. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It points out a specific error in the labeling of \"Fig.7\" in Supp. Page 31, which should be corrected to \"Fig.12.\" Additionally, it suggests attaching each theorem and corollary to its corresponding proof link to enhance the reader\"s understanding and ease of navigation. This feedback is clear and offers concrete steps for the authors to improve the clarity and organization of their paper. However, the comment could be more helpful if it provided additional context or examples on how these changes would impact the reader\"s experience. Overall, the comment is 4 as it offers actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the definition and implementation of certain concepts in the paper. It specifically questions the determiner missing in Section 3, asking about the selection of 50 classes and the choice of action verbs. Additionally, it inquires about the \"action frames\" and how they are chosen. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors can infer that they need to clarify these points, but the comment lacks detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the determiner missing in Section 3, the selection of 50 classes, the choice of action verbs, and the concept of \"action frames.\" The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the definition and implementation of certain concepts in the paper, specifically regarding the determiner missing in Section 3, the selection of 50 classes, the choice of action verbs, and the concept of \"action frames.\" While the questions are clear and highlight areas that need clarification, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it identifies potential areas for improvement, but it could be more beneficial with additional context or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a single spelling mistake on line 32 of page 1, suggesting that the word \"Empiically\" should be corrected to \"Empirically.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies the exact spelling correction needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the spelling of \"Empiically\" on line 32, suggesting that it should be corrected to \"Empirically.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about a spelling mistake in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor but specific issue with the spelling of the word \"Empiically\" on line 32 of page 1, suggesting that it should be corrected to \"Empirically.\" This is a clear and actionable suggestion that can help improve the accuracy and professionalism of the paper. However, the comment does not provide any context or explanation for why this correction is necessary or how it might impact the overall quality of the paper. While it is helpful in pointing out a specific error, it could be more beneficial if it included additional guidance or reasoning. Therefore, the comment is 3, as it provides a clear and actionable suggestion but lacks depth and context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. It also points out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. The comment provides a clear direction for the authors to consider incorporating representation learning into the feature selection process in Section 4.2. This feedback is explicit and concrete, as it specifies the exact area that needs improvement and how to address it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue with the proposed invariant learning module, suggesting that it could be improved by considering representation learning. Additionally, it provides a specific suggestion for improvement by mentioning the appendix, where representation learning is discussed. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed invariant learning module focuses on mask selection and rawlevel features, while the framework discussed in Section 4 seems not to be limited to rawlevel selection. The reviewer suggests that the feature selection in Section 4.2 could be improved by considering representation learning, which is currently discussed in the appendix. The comment provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that representation learning would improve the feature selection process. This makes the claim 3, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the proposed invariant learning module, noting that it focuses on mask selection and rawlevel features. It suggests that the framework could be further improved by considering representation learning, which is currently discussed in the appendix. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by integrating representation learning into the feature selection process. By addressing this suggestion, the authors can significantly improve the clarity and depth of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards as an example. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific steps to clarify the reward design or suggesting ways to improve the explanation. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the design of rewards, indicating that some details are missing. However, it does not specify which part of the paper discusses the rewards, making it weakly grounded. The comment is specific in identifying the issue with the reward design, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions for improvement or additional information. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, specifically mentioning the design of rewards as an example of missing details. This feedback is 3 as it points out a potential gap in the paper that the authors should address to improve clarity. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the explanation of the reward design. While it highlights an area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the generalizability of a model to different numbers of entities, specifically mentioning Figure 3 of INs as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the generalizability of the model. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes or improvements are needed to enhance the generalizability of their model. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3 of INs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity on how to generalize a model to different numbers of entities, as shown in Figure 3 of INs. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the number of entities is fixed and that it is unclear how to generalize a model to different numbers of entities, citing Figure 3 of INs as an example. However, the comment lacks specific reasoning or evidence to support this claim, such as explaining why the number of entities is fixed or how it affects the generalizability of the model. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the number of entities is fixed and questioning how the model can be generalized to different numbers of entities. It references Figure 3 of INs as an example, which provides some context for the reviewer. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve the generalizability of their model. While it points out a potential weakness, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required. It also mentions that the experimental design is good. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest improvements, offer guidance on how to address the weakness, or provide specific feedback on the execution effort or experimental design. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"double edge point,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, backed by good experimental design. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. However, it also points out that the approach lacks novelty and that the execution effort may outweigh the novelty. The comment suggests that the lack of code release after the revision process could be a weakness, but it does not provide specific examples or detailed reasoning to support this claim. While the comment provides some insight into the potential weaknesses, it lacks the necessary evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the authors to consider but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. However, it points out that the approach lacks novelty and that the execution effort may outweigh the novelty. The comment suggests that the lack of code release after the revision process could be a weakness, but it does not provide specific suggestions or guidance on how to address this issue. While the comment identifies a potential weakness, it lacks actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it provides insight into a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and highlights the importance of runtime as a limitation for MLbased emulators of climate model parametrizations. The comment is concrete, as it specifies what needs to be discussed and why, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Prithvi WxC\" emulator, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the runtime of Prithvi WxC and its potential limitations for applications. This provides clear guidance on what aspect of the emulator needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count, as it could be a limitation for MLbased emulators of climate model parametrizations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why runtime is a critical issue or how it affects the applicability of the emulator. Without additional context or examples, the claim remains 3, as the authors may find it challenging to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and actionable suggestion that could help the authors address a potential limitation of their emulator in the context of MLbased climate model parametrizations. By discussing the runtime, the authors can provide valuable insights into the practicality and applicability of their emulator, which could enhance the overall quality and impact of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or complexity of the idea, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the novelty or straightforwardness are problematic, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions for how the authors might enhance the novelty or complexity of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of what improvements could be made to address the critique. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as specific sections, figures, or claims. Without explicit references to these elements, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity regarding what aspects of the framing contribute to the overselling and how it affects the clarity of the contribution. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed guidance on how the framing of the paper contributes to this overselling. Without actionable feedback or suggestions on how to improve the clarity of the contribution, the authors are left without a clear understanding of what changes to make. This lack of specificity and actionable advice makes the comment 2, as it identifies a potential issue but does not provide a path for improvement. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. While the comment provides a clear direction for improvement, it does not specify which steps should be taken or how to implement the changes. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is 3, as it provides a clear direction but lacks concrete guidance on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the model description is discussed. The authors can infer that it relates to the model description or methodology sections, but this inference is not direct. The comment is specific in suggesting improvements, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the model description or understanding. The suggestion is based on general logic but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is considered 2, as it provides a logical basis but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be presented in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table, which could enhance the clarity of the description. While the comment provides actionable suggestions, it lacks depth and does not explain why these changes would be beneficial or how they would impact the overall understanding of the model. The authors are given a clear direction for improvement but could benefit from more detailed guidance on how to implement these changes effectively. Therefore, the comment is 3, as it provides a starting point for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the quality of paraphrases generated for training data, specifically noting that the paraphrases need to be sufficiently different from the original sentences to ensure the model\"s reliance on them. However, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve the quality of the paraphrases. The comment lacks concrete details or suggestions on how to improve the paraphrasing process, leaving the authors uncertain about how to apply the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the process of generating paraphrases for training data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear paraphrases and its impact on the quality of the final training data. The comment provides a clear rationale for the concern, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paraphrases generated for training data are unclear and impact the quality of the final training data. This claim is supported by logical reasoning, as it explains the importance of paraphrases being sufficiently different from the original sentences to ensure the model\"s reliance on them. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the impact of paraphrase quality on model performance. As it stands, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the quality of paraphrases generated for training data, noting that the paraphrases need to be sufficiently different from the original sentences to ensure the model\"s reliance on them. This is a crucial point that could significantly impact the quality of the final training data and, in turn, the model\"s performance. The comment provides a clear and actionable suggestion for improvement, suggesting that the authors should focus on ensuring the paraphrases are sufficiently distinct from the original sentences. However, the comment could be more helpful if it offered specific guidance on how to achieve this goal, such as suggesting metrics or techniques for evaluating paraphrase quality. Overall, the comment is 4 as it highlights a critical issue and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggests that another color or a larger font might help in highlighting the humanidentified rationales better. While the comment provides a clear and concrete suggestion for improving the figure, it does not explicitly instruct the authors on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider changing the font or color to enhance readability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that identifying rationales for more complicated NLP tasks like machine translation is not a simple problem, and that the paper is wellorganized and easy to follow. The comment suggests that Figure 2 is cluttered and that the \"bold\" text is hard to see, proposing a solution of using another color or a larger font to enhance readability. While the comment provides a logical reasoning for the issue with Figure 2, it lacks specific examples or references to support the claim about the complexity of identifying rationales for NLP tasks. The suggestion to improve the figure is 3, as it provides a clear rationale but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This feedback is actionable and provides a clear direction for improving the figure\"s readability. However, the comment could be more helpful if it offered additional suggestions or examples of alternative colors or font sizes that might work better. Overall, the comment is 4 as it provides a clear and actionable suggestion for improving the figure, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should verify the effectiveness and universality of the FlippedQA framework beyond LLMbased models, specifically mentioning HiTeA and InternVideo as examples. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct additional experiments to verify the framework\"s effectiveness and universality, but the comment lacks concrete details on how to implement this action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the FlippedQA framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to verify the effectiveness and universality of the framework beyond LLMbased models. This provides clear guidance on what additional experiments or analysis are needed to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FlippedQA framework is a general framework for various generative VideoQA models but is only applied to LLMbased models. The reviewer suggests that verifying its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo would be beneficial. While the comment provides a logical reasoning for the need to test the framework on a broader range of models, it lacks specific examples or references to support the claim that these other models would be ideal for testing. This makes the claim 3, as it provides a clear direction but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, noting that the FlippedQA framework is only applied to LLMbased models. It suggests that verifying its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope and demonstrate the generalizability of their framework. By addressing this point, the authors can enhance the robustness and applicability of their work. However, the comment could be more helpful if it included suggestions on how to conduct these additional experiments or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific guidance or suggestions on how to improve the writing. The authors are left without any concrete steps or examples to follow in order to enhance their draft. As a result, the comment lacks actionability, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly challenging to understand or where the writing could be improved. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific examples or guidance on how to improve the writing, such as suggesting ways to clarify the main points or improve the flow of the paper. Without actionable feedback or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address these concerns to improve the paper. However, it does not provide specific guidance on how to address these concerns or what aspects of the method should be improved. The mention of existing methods and references to ClopperPearson intervals and Gaussian elimination suggest that the authors should provide more detailed explanations or comparisons to these methods. However, the comment lacks concrete instructions or examples on how to enhance the theoretical novelty or address the concerns effectively. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the combination of existing methods used in the proposed method, specifically mentioning ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the concerns about the lack of theoretical novelty and the need for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer acknowledges a willingness to improve their score if the authors address these concerns. However, the comment does not provide specific examples or detailed reasoning to support the claim about the lack of novelty. The references to ClopperPearson intervals and Gaussian elimination suggest that the reviewer is familiar with these methods, but this alone does not fully substantiate the claim. The comment could be strengthened by providing more detailed reasoning or examples to support the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant concern about the proposed method, noting that it primarily builds upon existing methods and lacks significant theoretical novelty. It acknowledges the authors\" willingness to improve their score if the concerns are addressed. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues, such as suggesting ways to enhance the theoretical novelty or differentiate the method from existing approaches. While it points out a critical area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it highlights a significant weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks explicit or implicit actions, leaving the authors without direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the concatenation of text input by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the concatenation process, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the concatenation of text input by the four text elements of an object. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the concatenation of text input by the four text elements of an object. While it highlights a potential area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what implications it might have for their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper should provide a stronger motivation for why the topic is important. However, it does not specify what kind of motivation is needed or how the authors should present it. The comment lacks explicit guidance on how to address this issue, leaving the authors uncertain about what specific actions to take. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not specify which part of the paper this issue pertains to, such as the introduction or the main results section. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this suggestion. Additionally, the comment lacks specificity regarding what kind of motivation is needed or how it should be presented. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this motivation or what kind of motivation would be effective. Without actionable advice or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made to the sentence. The action is implicit and vague, as the authors are left to infer that they need to revise the sentence but without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence in lines 1217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the sentence is cumbersome and could be made clearer. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any specific reasoning or examples to support this claim. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the abstract, specifically the sentence in lines 1217. It points out that the sentence is cumbersome and could be made clearer, providing a clear direction for improvement. However, the comment lacks depth and does not offer specific suggestions or examples on how to improve the clarity of the sentence. While it highlights an area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a starting point for the authors but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative comparisons that might be more fair. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their comparisons, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the comparisons to zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model and zeroshot singleimage 3D reconstruction models are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This feedback highlights a potential bias in the experimental setup that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or suggest alternative comparisons that might be more fair. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance. It also points out that Table 5 shows a tradeoff between head and tail categories but notes that similar tradeoffs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. Additionally, the reviewer encourages the authors to continue this line of work for future submissions. While the comment provides explicit actions to take, such as investigating the tradeoffs and improving the baselines, it lacks specific guidance on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple [Kang et al.],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple [Kang et al.] and suggests exploring the tradeoff between head and tail categories for the baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, and it provides a specific example of this by referencing Table 5. Additionally, it suggests that similar tradeoffs have not been fully investigated for the baselines, specifically by changing hyperparameters in Decouple [Kang et al.]. This claim is 3 as it provides a specific example of the tradeoff between head and tail categories and suggests that further investigation is needed. However, the comment lacks detailed evidence or references to support the claim that the proposed approach is worse than Decouple [Kang et al.] or that similar tradeoffs have not been fully explored. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several pieces of constructive feedback that can help the authors improve their draft. First, it points out that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, which is a significant concern. It also highlights the tradeoff between head and tail categories shown in Table 5 and suggests that similar tradeoffs have not been fully explored for the baselines. The reviewer encourages the authors to continue this line of work for future submissions, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to investigate these tradeoffs or improve the baselines. Overall, the comment is 4 as it identifies areas for improvement and offers a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. While the suggestion is clear, it lacks specific guidance on how to conduct these experiments or what specific aspects of the C2D method should be tested on these datasets. The authors are left to infer that they should conduct additional experiments, but without detailed instructions on how to do so, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention which part of the paper should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the method. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This is a clear and actionable suggestion that could enhance the robustness and generalizability of the method. However, the comment lacks specific guidance on which aspects of the C2D method should be tested or how these experiments should be designed. While it points to a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully beneficial."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the evaluation, specifically the reliance on only four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for more datasets, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" and \"4 OCR QA datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited evaluation and the need for more scenarios like the LLaVA benchmark in ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited and relies on only four OCR QA datasets, which may be unreliable. The reviewer supports this claim by referencing Fig 4(5), which shows the limited evaluation. However, the comment could be strengthened by providing specific examples or references to studies that have demonstrated the limitations of these datasets or by explaining why the LLaVA benchmark is expected to be more reliable. Despite this, the claim is 4 due to the reference to Fig 4(5) and the suggestion to include more scenarios.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, specifically the reliance on only four OCR QA datasets. It suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation and enhance the robustness of their findings. By addressing this suggestion, the authors can improve the comprehensiveness and credibility of their evaluation. However, the comment could be more helpful if it explained why the LLaVA benchmark is considered a more reliable benchmark or provided examples of how it could be integrated into the evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the clarity of their visual reasoning tasks. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses specific concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the tasks and the need for proof that more complex tasks are necessary. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 2, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the interpretation of the models\" learning and whether simpler tasks would suffice. The comment also asks for proof that more complex tasks are necessary. While the feedback identifies potential issues with the paper\"s approach, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the clarity of their visual reasoning tasks. The comment provides some insight into potential weaknesses but does not offer actionable steps for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of weak supervision could be improved by addressing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, suggesting that the authors\" embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should improve the realism of their evaluation and generation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the generation process, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the realism of the evaluated tweets and the generation process, suggesting that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. The reviewer also points out that the authors\" embeddings are initialized by averaging artificial tweets, which further undermines the realism. These claims are based on logical reasoning and observations about the nature of the prompt and the generation process. However, the comment lacks specific examples or references to support the claim that the evaluation is unrealistic. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, suggesting that the authors\" embeddings are initialized by averaging artificial tweets. This feedback is valuable as it highlights areas where the authors could improve the realism and credibility of their evaluation. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how to make the evaluation more realistic. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of essential visualization of intermediate processes and comparisons, which is a clear actionable point. However, it does not provide specific guidance on what visualizations or comparisons are missing or how they should be presented. The authors are left to infer that they need to include visualizations and comparisons, but without concrete suggestions on what to include or how to present them, the comment remains vague. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualization of intermediate processes and comparisons, but it does not specify which parts of the paper these visualizations should be included in. The authors can infer that it relates to sections discussing these processes or comparisons, but without explicit references to specific sections, the comment lacks full grounding. The comment is specific in identifying the need for visualization and comparisons, but without clear grounding, it is challenging for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what is missing or how visualization could enhance the understanding of the paper, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it points out an area where the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on what types of visualizations or comparisons would be beneficial or how they could be integrated into the paper. Despite this, the feedback is valuable as it directs the authors to a critical area for improvement, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. However, it does not provide any guidance on how the authors should address this issue or what specific changes need to be made to ensure compliance with the stated condition. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Definition 1\" and \"expected counterfactual,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This is a clear and actionable point that the authors can address to improve the accuracy and validity of their work. However, the comment lacks depth and does not provide suggestions on how to resolve the issue or what specific changes need to be made. While it highlights a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve the paper. The authors are left to infer that they might need to reconsider the importance of their result in light of the external work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the iteration complexity in Theorem 3 is no longer dimensionfree, which is a clear concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. However, the comment does not provide specific examples or detailed reasoning from the external work to support the claim that the result is not surprising or significant. While the reference to [15] provides some context, the comment lacks sufficient evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the concern but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. While the comment identifies potential weaknesses in the paper, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the paper. The feedback is 3 as it highlights areas for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action, providing the authors with a specific task to accomplish. The comment is specific in detailing where the results should be included, making it 5. Authors know exactly what needs to be done to address the feedback, ensuring they can effectively implement the suggested changes. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included, namely \"keypoint detection results.\" This provides clear guidance on what the authors need to address in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by suggesting that keypoint detection results should be included in the experiments section. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s content and clarity. However, the comment could be more helpful if it explained why this inclusion is important or how it would enhance the understanding of the results. Overall, the feedback is valuable but could be more comprehensive with additional context or explanation. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This explicit action provides a clear direction for the authors to take, as it specifies a specific comparison to be made. The comment is concrete, as it directly instructs the authors on what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with existing models, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific comparison that could enhance the paper by comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is actionable and provides a clear direction for the authors to improve their draft by including a comparison that could strengthen the paper\"s contribution. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. It also mentions minor problems, but does not provide further details or suggestions for improvement. The comment implies that the authors should clarify this aspect of their methodology, but it lacks explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the grid search process but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grid search of learning rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking whether the grid search is performed on the validation set, providing clear guidance on what needs to be clarified. However, the comment does not provide specific suggestions or examples on how to improve the clarity or accuracy of this part of the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking about the grid search for learning rate, specifically whether it is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. This is a relevant point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an issue with the use of \"discourse\" for nondiscourse elements in the Universal Dependencies (UD) framework. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions to take. The authors are left to infer that they might need to clarify the use of \"discourse\" or investigate the high number of discourse relations, but the comment lacks concrete details on how to implement these actions. Therefore, the comment is 3, as it identifies an area for consideration but does not provide explicit instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an issue with the use of \"discourse\" for nondiscourse elements in the Universal Dependencies (UD) framework. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an issue with the use of \"discourse\" for nondiscourse elements in the Universal Dependencies (UD) framework. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an issue with the use of \"discourse\" for nondiscourse elements in the Universal Dependencies (UD) framework. This is a relevant point that could prompt the authors to reconsider their methodology or the interpretation of their results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what specific actions to take. While it identifies a potential problem, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. However, it does not provide any supporting evidence, reasoning, or references to justify why this diversity is important or how it might impact the results. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. This is a relevant and insightful point that could prompt the authors to consider the broader implications of their findings and ensure that their work is inclusive and applicable to diverse populations. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional analyses or discussions. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment does not provide specific guidance on how the authors should improve the output quality or what aspects of the paper need attention. The action is implicit and somewhat vague, as the authors can infer that they need to work on improving the output quality, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is still room for improvement. However, it does not specify which part of the paper discusses the output quality, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the output quality and the need for improvement, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. The reviewer suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment lacks specific examples or references to recent GAN works that demonstrate the improvement in quality. This makes the claim 3, as it provides a general idea but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the output quality of the paper, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment lacks specific suggestions or guidance on how the authors might improve the output quality or what aspects of the paper need attention. While it highlights an area for improvement, the feedback is 3 as it points out a potential weakness but does not provide actionable steps for the authors to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their work. It lacks concrete details on what specific changes or improvements are needed, leaving the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies areas of concern but does not offer detailed instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"soft labels is essentially on top of CRM and Cross entropy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the use of subpar hyperparameters and the results being impressive but potentially misleading due to the use of subpar hyperparameters. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the concerns or how to address them. The lack of detailed justification or evidence makes the claim 2, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters, suggesting that the authors may be using suboptimal parameters. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it points out areas of concern, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the simple/traditional experiment for unseen characters is a good idea but is presented as an afterthought. It implies that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific translations to include. The action is concrete but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more evaluation on classifying unseen words and the addition of translations to Figure 6 for nonChinese speakers. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is presented as an afterthought and that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a logical reasoning for the need to expand the evaluation, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim 3, as the authors would need to infer the need for additional evaluation and translations based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the presentation of the simple/traditional experiment for unseen characters as an afterthought. It suggests that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. Additionally, the comment recommends adding translations to Figure 6 for nonChinese speakers. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these suggestions or what specific translations to include. This limits the comment\"s helpfulness, as it provides actionable feedback but does not fully support the authors in making those improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the number of images provided in the VioT dataset is small, which may impact the validity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the number of images, provide additional data, or justify the current number of images. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the VioT dataset, specifically mentioning the number of images provided in each of the four categories. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspect of the dataset\"s size is problematic or how it affects the validity of the approach. Without specific guidance on how to address this issue, the authors may find it challenging to understand and implement the suggested improvements. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is small, which may impact the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim and how it affects the validity of the approach. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the VioT dataset, noting that the number of images provided is small, which may impact the validity of the approach. However, it does not provide any specific suggestions or guidance on how the authors might address this issue, such as recommending an increase in the number of images or suggesting alternative datasets. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance (perf) in the context of Named Entity Recognition (NER). While the suggestion is clear, it lacks specific guidance on how to conduct the study or what specific aspects to focus on. The authors are given a general direction but are not provided with detailed instructions on how to implement this suggestion. Therefore, the comment is 3, as it provides a clear action but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study of the number of layers versus performance (perf) in the context of Named Entity Recognition (NER). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a potential area for exploration, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study of the number of layers versus performance (perf) in the context of Named Entity Recognition (NER). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this study would be beneficial or how it would contribute to the paper. Without such information, the claim remains 1, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance (perf) in the context of Named Entity Recognition (NER). This is a specific and actionable suggestion that could provide valuable insights into the impact of layer number on performance. However, the comment lacks depth and does not offer detailed guidance on how to conduct the study or what specific aspects to focus on. While it points out a potential area for improvement, it could be more helpful if it included suggestions on how to design and execute the ablation study. Therefore, the comment is 3, as it provides a clear direction but lacks comprehensive guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and they had to read the text multiple times. While the comment provides some guidance on what needs to be improved, it lacks concrete details on how to implement these changes. The authors are given a general idea of what needs to be addressed but are not provided with specific steps or examples of how to improve the explanations. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig. 1 and 2\" and \"figure captions,\" allowing the authors to accurately identify the areas being addressed. It is also specific because it details the issues with the paper, such as the difficulty in following the mathematical derivations and the lack of explanations in the figure captions. The comment suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also mentions that figure captions are lacking and require additional explanations and legends. The reviewer provides specific examples, such as the need to explain the colors in Fig. 2, which adds a level of detail and specificity to the claim. However, the comment could be strengthened by providing more detailed reasoning or references to similar works that have successfully addressed similar issues. Overall, the claim is 4, as it is supported by specific examples and observations, but it could be further substantiated with additional evidence or references.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and they had to read the text multiple times. This feedback is clear and actionable, as it points out specific areas where the paper could be improved to enhance its clarity and accessibility. However, the comment could be more helpful if it provided suggestions on how to improve the explanations or offered examples of how similar issues have been addressed in other works. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. It explicitly states that resolving this issue would influence the reviewer\"s rating. While the comment does not provide specific guidance on how to address this issue, it implies that the authors should investigate the sensitivity of their results to hyperparameter choices and consider potential improvements. The action is implicit but concrete, as the authors know they need to address the sensitivity of their results to hyperparameters. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"empirical results\" and the \"hyperparameter choices,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of sensitivity to hyperparameter choices and the potential impact on the method\"s effectiveness. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. This claim is 3 as it highlights a potential issue with the robustness of the results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer suggests that resolving this issue would influence their rating, implying that the authors should address this concern. However, without more detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. This is a crucial point that could significantly impact the validity and reliability of the results. The reviewer explicitly states that resolving this issue would influence their rating, providing a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it offered specific guidance on how to investigate and mitigate the sensitivity to hyperparameters. Overall, the comment is 4 as it highlights a significant concern and provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation of their method\"s novelty, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the novelty and contribution, as it highlights the need for a more detailed explanation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is similar to existing attack methods on a surrogate model, suggesting that the novelty and contribution of the proposed method are not adequately explained. However, the comment does not provide specific examples or references to existing methods, making it difficult for the authors to understand the exact nature of the similarity. Without detailed comparisons or references, the claim lacks verifiability, as it relies on a general observation without specific evidence or reasoning. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the proposed method is similar to existing attack methods on a surrogate model. It suggests that the authors need to further claim the novelty and contribution of their method, implying that the current explanation is insufficient. While the comment highlights an important area for improvement, it lacks specific guidance on how the authors might effectively demonstrate the novelty and contribution of their method. The feedback is 3 as it points out a potential weakness but does not provide detailed suggestions for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. It also provides specific references to external works that could be used to improve the paper. While the comment identifies the issues, it does not offer explicit guidance on how to address them, such as suggesting font size changes or providing examples of how to include the gradient symbol. The references are helpful but do not fully replace the need for explicit instructions. Therefore, the comment is 3, as it provides some direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the text in Table 1 being too small and hard to read, and the missing gradient symbol in Algorithm 1. Additionally, it provides specific references to external works, which further clarifies the context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes two claims: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. The reviewer supports these claims by providing specific references to external works, which could be used to improve the paper. However, the comment does not explain why these issues are problematic or how they impact the overall quality of the paper. While the references provide some context, the lack of detailed justification or explanation makes the claim 3, as the authors may need to infer the significance of these issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including the text in Table 1 being too small and hard to read, and the missing gradient symbol in Algorithm 1. It also provides references to external works that could be used to improve the paper. While the comment highlights these issues, it lacks detailed guidance or suggestions on how to address them. The references are helpful but do not fully replace the need for actionable feedback. Therefore, the comment is 3, as it provides some insights but does not fully support the authors in making improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed discussion on computational aspects and address the practical limitations of their methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It specifically mentions the appendix and the algorithm\"s requirement to solve several LPs in high dimensions, which is not easily calculable. The comment also points out that the experiments are performed on small datasets. However, it does not explicitly mention which part of the paper discusses computational aspects or where the appendix is located, making it weakly grounded. The comment is specific in detailing the issues with the computational aspects and the experiments, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods for high dimensions. The reviewer supports this claim by pointing out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific calculations or examples to illustrate the practical limitations. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects and the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This feedback is valuable as it highlights a critical area for improvement in the paper, particularly regarding the scalability and practicality of the proposed methods. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues or improve the discussion of computational aspects. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. While the comment implies that the authors should consider this baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet shares parameters between the residual blocks, and it suggests a potential baseline for comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the ResNet in section 7.1 and its parameter sharing. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the ResNet in section 7.1, specifically inquiring whether it shares parameters between the residual blocks. This is a relevant point that could impact the validity of the experiments. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what potential implications it might have. While it identifies a potential area for further exploration, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It notes that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the motivation or what specific changes should be made to the architecture. As a result, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the motivation of the crossencoder architecture, which is not ignoring crossentity comparison but instead attending to all candidates at once. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the motivation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for the crossencoder architecture is poorly explained, as it is not ignoring crossentity comparison but instead attends to all candidates at once. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It points out that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the motivation for their architecture. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their design choice. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to justify the decision. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unjustified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. This feedback highlights a potential issue with the design and encourages the authors to reconsider their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their design. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the work uses an outdated GNN model and method, which affects the performance of the framework. It also mentions that the baseline algorithms/methods are also outdated. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting newer models or methods to be used. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of an outdated GNN model and method, which affects the performance of the framework. However, it does not specify which part of the paper discusses the GNN model or method, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the GNN model or method are outdated or how they could be improved. Without clear guidance on what needs to be addressed, the authors may struggle to effectively address the critique. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an outdated GNN model and method, which impacts the performance of the framework. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the use of outdated methods affects the performance. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the work, noting that it uses an outdated GNN model and method, which impacts the performance of the framework. This is a critical observation that could significantly affect the paper\"s credibility and relevance. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue, such as suggesting newer models or methods to be used. Without detailed feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it highlights a significant weakness but does not offer actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed method produces the type of explanation mentioned in Figure 1. It suggests that additional adhoc postanalysis might be required to extract shared motifs to explain a set of instances. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or what specific steps the authors should take to improve the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or examples to clarify the process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding how the proposed method produces the type of explanation mentioned in the figure. The comment suggests that additional adhoc postanalysis might be required to extract shared motifs, and it implies that this analysis might be easier with the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanation in Figure 1 is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. The reviewer provides a quote from Line 48 to support this claim, which suggests that the analysis might be easier with the proposed method but still requires additional effort. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the quote provides some context, it does not fully address the issue of clarity or the necessity of additional analysis. Therefore, the comment is 3, as it provides some support but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that the explanation provided is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. It references Line 48 to provide context and implies that the proposed method might make this analysis easier but still requires additional effort. While the comment highlights a potential weakness in the explanation, it does not offer specific suggestions or guidance on how to address this issue or improve the clarity of the figure. The feedback is 3 as it points out a specific area for improvement, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides two ways to strengthen the experiment: by either using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. While the comment provides some guidance on how to address the issue, it lacks specific instructions on how to implement these suggestions. The action is explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, which relies on pseudo feature importance due to the unavailability of true feature importance. The comment provides specific guidance on how to strengthen the experiment by suggesting two ways: using a different method to estimate true feature importance or providing a more detailed explanation of the perturbation value. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment relies on pseudo feature importance due to the unavailability of true feature importance. It suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The reviewer provides a logical reasoning by explaining the potential issue with the experiment\"s reliance on pseudo feature importance and suggests ways to strengthen it. However, the comment lacks specific examples or references to Proposition 3.2 or the perturbation value, which would make the claim more 5. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires additional details to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests two ways to strengthen the experiment: by using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. This feedback is clear and actionable, as it offers specific suggestions for improving the experiment\"s reliability and credibility. By addressing these points, the authors can enhance the robustness and trustworthiness of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific properties of Z should be considered or how to address the issue of nonconvexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 182184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies the issue of nonconvexity and suggests that it may not be a problem if the function Z has certain properties. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific line in the paper (ln. 182184) and suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. While this feedback highlights a potential issue, it lacks depth and does not provide specific guidance or examples of what properties of Z would be beneficial for convergence. The comment could be more helpful if it offered suggestions on how to explore or test these properties or provided references to relevant literature. As it stands, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies specific lines in the SuppMat that should be moved from red to green. This provides clear and direct instructions for the authors to follow, ensuring they know exactly what changes to make. The action is concrete, as it specifies the exact lines and their corresponding changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the exact lines that need to be moved from red to green, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the SuppMat, specifically mentioning lines that should be moved from red to green. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific lines in the SuppMat that should be moved from red to green, providing clear and actionable feedback. This guidance is valuable as it directly addresses a formatting issue that could impact the clarity and readability of the paper. By specifying the exact lines and their corresponding changes, the authors can easily make the necessary corrections to improve the presentation of their work. However, the comment could be more helpful if it explained why these lines were incorrectly placed in red or provided additional context on the importance of maintaining consistent formatting. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on how to conduct this analysis or what aspects should be included. The comment implies that the authors should expand their analysis, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not specify which part of the paper this analysis should be applied to, nor does it provide details on what aspects should be included or how the analysis should be conducted. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. The comment lacks specificity and does not offer a clear path for the authors to follow, making it difficult for them to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on what aspects of the analysis should be expanded or how to conduct it. The comment acknowledges the limitations of the paper\"s length, but it does not offer actionable steps for the authors to take. Without detailed suggestions or examples, the feedback lacks depth and specificity, making it 2. Therefore, the comment aligns with a score of 2, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the lack of proper experimental settings and the absence of code. While it points out the importance of result reproducibility, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to include experimental settings and provide the code, but the comment lacks concrete details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental settings\" and the absence of \"code,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of result reproducibility and the importance of providing the code, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly and that the result reproducibility is critical. It also notes the absence of code, which is a significant concern. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of these issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings and result reproducibility, noting that the provided information is insufficient. It highlights the importance of including experimental settings and the absence of code, which is a significant concern for result reproducibility. However, the comment does not provide specific guidance on how to address these issues or what additional information should be included. While it points out a significant problem, it lacks actionable advice or suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of a proper comparison against online learning approaches and reinforcement learning (RL). It suggests that the authors should clarify why online learning cannot be used, particularly in relation to retraining cost. The reviewer also questions how to compare retraining cost with incremental updates in online learning and why it is discarded. While the comment provides a clear direction for the authors to address these issues, it does not offer specific guidance on how to conduct the comparison or what aspects to focus on. The action is explicit but somewhat vague in terms of execution, as the authors need to determine the exact methodology for comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors mention that online learning formulation overlooks key practical considerations. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of a proper comparison against online learning approaches and reinforcement learning, and the need to clarify why online learning cannot be used. It also raises questions about the comparison of retraining cost and incremental updates in online learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of a proper comparison against online learning approaches and reinforcement learning, suggesting that the abstract and other parts of the paper overlook key practical considerations. The reviewer questions why online learning cannot be used and proposes a comparison of retraining cost with incremental updates in online learning. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further develop the reasoning or provide additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that the abstract and other sections mention the overlooking of key practical considerations in the online learning formulation. It suggests that a proper comparison against online learning approaches and reinforcement learning is missing, which would clarify why online learning cannot be used. The reviewer raises important questions about the retraining cost and incremental updates in online learning, challenging the authors to address these issues. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or examples on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and prompts the authors to address a significant gap in their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cite works related to metalearning and distinguish their approaches from those already cited. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a clear direction for the authors to expand their literature review and improve the connection between their work and related literature, it does not specify which works should be cited or how to distinguish them. The action is explicit but somewhat vague, as the authors need to infer the specific details of how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also mentions the work on RL for architecture search and optimizers, which should be linked to continual learning. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the need for citation and distinction, but without explicit references to sections or elements of the paper, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a logical reasoning for the need to cite and distinguish related works, it lacks specific examples or references to support the claim about the deeper tie to metalearning. The suggestion to link the RL work is more concrete, but the overall claim is 3 due to the lack of detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors should cite and distinguish their approaches from related works in the field of metalearning. It also recommends linking the work on RL for architecture search and optimizers to continual learning, which could enhance the connection between the current work and the broader literature. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific examples of related works or detailed guidance on how to distinguish the approaches. Overall, the comment is 4 as it directs the authors to important areas for improvement and expansion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might have an idea of where this feedback is relevant, it is not explicitly grounded. The comment is specific in suggesting alternative approaches to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not provide any supporting evidence, examples, or references to justify why this diversity is important or how it would improve the paper. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand the significance of this suggestion without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the diversity of teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. This feedback is 3 as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other studies have addressed this issue. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. While the comment implies that the authors should include a summary of the supplementary experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a summary of the supplementary experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the main text should be revised or where the summary should be placed. The authors can infer that it relates to the sections discussing the experiments or results, but this inference is not direct. The comment is specific in suggesting the need for a summary of the supplementary experiments, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. This feedback is 3 as it identifies a potential area for improvement in the clarity and organization of the paper. However, the comment lacks specific guidance on how to achieve this clarity or what aspects of the supplementary experiments should be highlighted. While it points out a potential issue, it does not provide detailed suggestions or examples on how to address it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a comprehensive comparison with the works mentioned, GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer provides specific references to these works, making it clear what needs to be done. Additionally, the comment mentions that the societal impact is shown on the last page of the manuscript, which is not relevant to the action being requested. Therefore, the action is explicit and concrete, as the authors know exactly what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, \"GFF[1]\" and \"EfficientFCN[2],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer suggests a comprehensive comparison with these works. However, the comment does not provide specific examples or detailed reasoning to support why these references are important or how they could enhance the paper. While it identifies potential gaps, the lack of detailed justification makes the claim 3, as the authors would need to infer the significance of these references themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, which could significantly enhance the paper\"s contribution and relevance. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript. While the comment highlights a critical area for improvement, it could be more helpful if it provided specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a significant area for enhancement, but it could be more actionable with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. However, it does not provide any guidance on how the authors should address this issue or what specific actions they should take to support their claim. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the slight improvement reported in these tables and the claim about the effectiveness of the proposed prompts. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the slight improvement reported in Tables 6 and 7 does not support the claim that experimental results prove the effectiveness of the proposed prompts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the slight improvement reported in Tables 6 and 7 and the claim that experimental results prove the effectiveness of the proposed prompts. This is a critical observation that could impact the validity of the authors\" claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental design to better support their claims. Without actionable feedback or specific advice, the authors are left without a clear path forward. Therefore, the comment is rated as 2, as it points out a potential problem but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". While the comment implies that these comparisons could provide valuable insights, it does not explicitly instruct the authors to conduct these comparisons or explain why they are necessary. The action is implicit and somewhat vague, as the authors need to infer that these comparisons would be beneficial. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, it does not specify which part of the paper these comparisons should be included in, making it weakly grounded. The comment is specific in suggesting the need for these comparisons, as it clearly identifies the potential benefits of including them. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, the comment does not provide any justification or reasoning for why these comparisons would be beneficial or how they would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of the paper with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This feedback is 3 as it provides a clear direction for the authors to consider in terms of benchmarking their work against existing approaches. However, the comment lacks depth and does not explain why these comparisons are particularly relevant or how they could enhance the paper. Additionally, it does not offer suggestions on how to integrate these comparisons into the paper or what specific aspects to focus on. While the feedback points to potential improvements, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the analysis, specifically the alignment of features at different spatial locations to the same channel. It suggests that there could be many different designs for this analysis, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they need to explore different designs or variations, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. However, it does not specify which part of the paper this analysis is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment does provide a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes, which adds some level of specificity. However, without explicit references to sections or figures, the comment remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of Cycle FC align features at different spatial locations to the same channel is insufficient. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment suggests exploring different designs, such as experiments or analysis with different sampling intervals and sample sizes, but this is not enough to substantiate the claim. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. It provides a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes. This feedback is 3 as it points out a potential area for improvement and offers a direction for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or what specific aspects of the analysis should be expanded. Overall, the comment offers some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of standard deviations in the paper, which raises concerns about the validity of the results. It suggests that the authors should include standard deviations to provide more transparency and confidence in their findings. While the comment explicitly states the action needed (displaying standard deviations), it does not provide specific guidance on how to present these deviations or what aspects to focus on. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which raises concerns about the validity of the results. However, it does not specify which part of the paper this issue pertains to, such as specific sections or tables where standard deviations should be displayed. This makes it difficult for the authors to pinpoint the exact location of the issue. While the comment is specific in identifying the absence of standard deviations, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the paper raises concerns about the validity of the results. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to similar studies that have included standard deviations, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the absence of standard deviations. This is a critical observation that could impact the validity and reliability of the results. However, the comment does not provide specific guidance on how to address this issue or what aspects of the results might be affected by the lack of standard deviations. While it highlights a potential problem, it lacks actionable advice or suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide explicit guidance or suggestions on how to achieve this extension. The comment implies that the authors should consider broadening the scope of their work, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the specificity of the setting, suggesting that the authors need to know the model or have access to a generative model for expanding or generating trajectories. It also mentions the episodic nature of the problem and the reward given at the end of a task. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the setting and its potential limitations, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide any supporting evidence, reasoning, or references to justify why the current setting is limiting or how it could be expanded. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the specificity of the setting, noting that the authors need to know the model or have access to a generative model for expanding or generating trajectories. It also questions whether the approach could be extended to more general settings. While the comment identifies a potential limitation in the current setting, it does not provide actionable suggestions or guidance on how to address this issue. The authors are left with a general idea of what needs to be improved but without specific steps or examples on how to achieve this extension. Therefore, the comment is 3, as it points out a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the feature extractor used for dimensionality of each region, specifically asking about the feature extractor used in line 201. This is an explicit question that directly asks for clarification, providing a clear action for the authors to take. However, it does not offer specific guidance on how to address the issue or what information should be included in the response. The action is explicit but somewhat vague in terms of detail, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the feature extractor used for dimensionality, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the feature extractor used for dimensionality in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the feature extractor used for dimensionality in line 201. This is a clear and actionable point, as it prompts the authors to clarify an important aspect of their methodology that could impact the understanding and reproducibility of their work. By addressing this question, the authors can improve the clarity and transparency of their paper, which is valuable feedback. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information in the paper. Overall, the comment is 4 as it identifies a specific area for clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it implies that the authors should include these details, it does not explicitly instruct them to do so or provide specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should include these details but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what specific aspects of the computation, algorithm, or implementation should be highlighted. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would enhance the paper. Without specific examples or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what details should be included or how they could be presented. Without further elaboration or examples, the authors may find it challenging to understand the exact nature of the feedback and how to address it. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer actionable steps for the authors to take."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of p < 0.4 in Algorithm 1, indicating that the reviewer is seeking clarification or explanation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific information they should include in their response. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed explanation or justification for their choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4 in Algorithm 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the choice of p < 0.4 in Algorithm 1, indicating a potential area for clarification or explanation. While it highlights a specific aspect of the paper that may need further elaboration, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It specifically mentions the need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback provides clear and concrete actions for the authors to take, such as adding explanations or analysis to these figures. The comment is 5 as it directly instructs the authors on what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanations or analysis for Figures 1, 2, and 3. The comment provides detailed guidance on what needs to be clarified, such as the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. The reviewer suggests that the authors need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This claim is 3 as it logically points out the need for additional analysis or explanation, but it lacks specific examples or references to support the claim. The authors would need to infer the need for clarification themselves, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It highlights the need for clarification regarding the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback is clear and actionable, as it directs the authors to address these gaps in their analysis and explanation. By providing specific guidance on what needs to be clarified, the comment offers valuable insight into how the authors can improve their draft. However, it could be more helpful if it provided examples or suggestions on how to address these issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not provide specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. The comment lacks concrete details or suggestions on how to enhance the explanation, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a clearer explanation of the motivation, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the clarity of the motivation behind applying CMD in federated learning. It suggests that the motivation could benefit from a more explicit demonstration or explanation. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to enhance the clarity or what aspects of the motivation should be emphasized. This limits the comment\"s usefulness, as it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. While the comment implies that the authors should provide more analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more analysis and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper should include this analysis or comparison, making it somewhat specific. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides a logical reasoning by suggesting that such comparisons would clarify the unique advantages of the method. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the claim, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of analysis regarding the effectiveness of data augmentation methods. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison sections. However, the comment could be more helpful if it offered examples or guidance on how to conduct these comparisons. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is concrete, as it specifies what the authors should do to improve their draft, but it is somewhat vague because it does not provide detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an ablation study and providing examples of alternative approaches, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. The comment provides a logical reasoning by suggesting alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, it lacks specific examples or references to support the claim that these alternative approaches would be beneficial. The suggestion is 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is actionable and offers a clear direction for the authors to improve their draft by conducting an ablation study to better understand the impact of each component. However, the comment could be more helpful if it provided additional guidance on how to design and conduct the ablation study, such as which components to focus on or how to interpret the results. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the model\"s performance should be evaluated. The comment lacks explicit instructions or concrete details on how to apply the information, leaving the authors uncertain about what actions to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the model\"s performance should be evaluated or how it relates to the paper\"s content. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the model\"s performance should be evaluated. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It suggests that RLCD (or RLCDRescore) may not be able to scale to larger language models that are better at differentiating responses near the decision boundary. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific steps they should consider to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the shrinking advantage of RLCD over RLAIF as the model size increases, and it raises a question about whether RLCD can scale to larger language models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, and it questions whether RLCD can scale to larger language models. However, the comment lacks specific examples, data, or references to support this claim. Without additional evidence or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It raises a question about whether RLCD (or RLCDRescore) can scale to larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an important aspect of the comparison, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input, and questions whether there is a solution to address this issue. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue or improve the practical contribution of their paper. The authors are left to infer that they need to consider scalability, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed NC measure, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the method when applied to large datasets like ImageNet. However, it does not provide specific suggestions or examples on how to address the scalability issue, which would make the comment more actionable. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the scalability of the proposed NC measure, suggesting that it may not be practical for large datasets like ImageNet. However, the comment lacks specific examples or evidence to support this claim, such as data or references to similar methods that have successfully addressed scalability issues. Without such details, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 2, as it provides a logical concern but lacks sufficient evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It raises a valid concern about the practicality of the method when applied to large datasets like ImageNet. However, the comment does not provide specific suggestions or examples on how to address the scalability issue or improve the practical contribution of the paper. While it highlights an important area for consideration, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a quantitative analysis on the computational gains, specifically mentioning GPU hours, memory usage, or training time. This provides a clear and concrete action for the authors to take, as it specifies the exact measurements they should include to substantiate their claims of computational benefits. The comment is 5 as it gives precise guidance on how to improve the draft by including quantitative analysis.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for quantitative analysis on GPU hours, memory usage, or training time to substantiate the computational benefits. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational benefits of replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is 3 as it logically suggests that quantitative analysis would strengthen the paper\"s claims, but it lacks specific examples or references to similar studies that have used such analyses. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of quantitative analysis on the computational gains. It suggests that including measurements such as GPU hours, memory usage, or training time would provide stronger evidence to substantiate the computational benefits claimed in the paper. This feedback is clear and actionable, as it directs the authors to conduct a quantitative analysis that would enhance the credibility and robustness of their findings. However, the comment could be more helpful if it provided examples of how such analyses have been conducted in similar studies or offered guidance on how to conduct them effectively. Overall, the comment is 4 as it effectively points out a gap in the paper and provides a concrete suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or what specific changes should be made to account for this time. The action is implied and somewhat vague, as the authors need to infer that they should consider this aspect in their evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to consider the time aspect, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this time consideration is important or how it affects the efficiency of the method. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the efficiency of the method, specifically the time required for COLMAP and scenebyscene finetuning. This is a relevant point that could impact the practicality and applicability of the method in certain scenarios. However, the comment lacks specific guidance or suggestions on how the authors should address this issue, such as recommending alternative methods or techniques for improving efficiency. While it points out a relevant concern, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the \"filter manifold network\" (FMN) and its scalability with the number of filter parameters. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these questions, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the scalability of the FMN with larger input and output channels, and it suggests that the authors should experiment with other architectures for FMN. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. The reviewer also questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors are left to infer the need for more analysis and discussion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It raises important questions about the scalability of the FMN with larger input and output channels, suggesting that the authors should experiment with other architectures and explore the impact of adaptive convolutions on the number of filter parameters. This feedback is clear and actionable, as it prompts the authors to address specific areas for improvement in their draft. However, the comment could be more helpful if it provided examples of alternative architectures or detailed guidance on how to conduct the suggested experiments. Overall, the comment is 4 as it directs the authors to enhance their discussion and analysis of the FMN, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform and suggesting that comparisons to UNets are necessary. While the comment identifies a potential issue with the model, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should make comparisons to UNets, but the comment lacks specific instructions on how to conduct these comparisons or what aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fractional transform\" and the \"UNet part,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the contribution of the UNet part in the fractional Fourier domain and suggests comparisons to UNets, which are necessary to understand the performance boost. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contribution of the UNet part in the CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the claimed performance boost. The reviewer references external works, such as Raonic et al and Gupta et al, to support their claim about the strong performance of UNets on regular gridded domains. This provides some evidence for the claim, but the comment could be strengthened by providing more detailed comparisons or examples from the referenced works. Therefore, the comment is 3, as it provides some support but lacks comprehensive evidence or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform. It suggests that the performance boost might be due to the fractional transform or the UNet operation in the fractional Fourier domain, which is comparable to pointwise multiplication as done in FNOs. The comment also references external works, such as Raonic et al and Gupta et al, to support the claim that UNets have strong performances on regular gridded domains. While the comment highlights a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or conduct comparisons to UNets. This limits the comment\"s helpfulness, as it points out a problem but does not provide actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It also suggests that a comparison of computation complexity should be included in the experiment part. While the comment identifies a specific issue with the computational complexity, it does not provide explicit guidance on how to reduce it or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison of computation complexity in the experiment part. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"the calculation of all the flipped previous layer output into the current layer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of computation complexity in the experiment part. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. The comment suggests that a comparison of computation complexity should be included in the experiment part. While the claim is based on logical reasoning and specific observations about the algorithm, it lacks detailed evidence or references to support the assertion that the PSA method requires more computation. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the computational complexity of the proposed PSA method compared to baselines, noting that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to include a specific comparison that could help validate the efficiency of their method. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or suggested specific metrics to use. Overall, the comment is 4 as it highlights an important area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger, increasing the size of V_mem, Th_i, and U_i^t, and using a larger font for the \"CTRL\" long form explanation. Additionally, it points out the lack of details comparison with other stateoftheart Transformer designs, suggesting a \"table\" manner to emphasize the data for readers. While the comment provides explicit actions and concrete details on how to implement these improvements, it could be more helpful if it offered suggestions on how to present the data comparison in a more effective way. Overall, the comment is 4 as it provides clear guidance on what needs to be addressed, but it could be more detailed in its suggestions for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures, such as \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other stateoftheart Transformer designs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes several claims about the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other stateoftheart Transformer designs. While the comment provides specific examples of issues with the figures, such as font size and the \"CTRL\" long form explanation, it lacks detailed reasoning or references to support why these issues are problematic or how they impact the paper\"s overall quality. The suggestion to use a \"table\" manner for data comparison is a logical suggestion, but it does not provide sufficient evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some support but lacks detailed justification or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the figures, suggesting improvements such as increasing the font size of certain elements like the words in the grey box, the \"CTRL\" long form explanation, and the size of V_mem, Th_i, and U_i^t. It also points out the lack of details comparison with other stateoftheart Transformer designs, suggesting a \"table\" manner to emphasize the data for readers. This feedback is clear and provides the authors with concrete steps to enhance the clarity and comprehensiveness of their figures and comparisons. However, the comment could be more helpful if it offered suggestions on how to present the data comparison in a more effective way or provided examples of how similar comparisons have been presented in other works. Overall, the comment is 4 as it identifies specific areas for improvement and provides actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what specific steps to take to improve the results. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It raises a concern about the model parameters being garbage early in training and the planning component potentially hurting more than helping. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the results and the need for exploring the agent\"s behavior during learning, but without clear grounding, the authors cannot confidently identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a logical observation but lacks specific evidence or references to support the claim. The comment is 3 as it provides a logical basis for the concern but requires further elaboration or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a thoughtprovoking observation that could prompt the authors to consider how their results might be affected by the agent\"s behavior during learning. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or explore the agent\"s behavior during learning. While it identifies a potential area for improvement, the feedback is 3 as it prompts the authors to consider a new aspect of their results but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests that the authors rewrite the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This is a clear and direct action for the authors to take, as it provides a specific line and page number for them to address. The comment also indicates that the current sentence is unclear, which further guides the authors on what changes are needed to improve the clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and pages (\"P. 5, p. 3, l.\") where the issue is located, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarity of the sentence regarding the use of \"j\" to simulate errors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and a specific suggestion to rewrite a sentence. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a sentence, requesting that the authors rewrite it to improve understanding. By providing a clear and actionable suggestion, the comment helps the authors address a potential source of confusion in their draft. However, the comment could be more helpful if it offered additional context or explanation about why the current sentence is unclear or how it might be rewritten to improve clarity. Overall, the comment is 3 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. While the comment identifies a potential gap in the manuscript, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information about their approach but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED\" and \"the documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the handling of documents as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what needs to be addressed in the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is missing from the manuscript. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the manuscript is lacking, specifically regarding the handling of documents in DocRED. It asks whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. This feedback is clear and actionable, as it points out a gap in the manuscript that the authors need to address to provide a more comprehensive understanding of their approach. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar approaches have been handled in the literature. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived marginality or how to improve the contribution. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as the methods or the stage where they are used. This lack of specificity makes it difficult for the authors to identify the exact sections that need improvement or clarification. Additionally, the comment does not provide specific guidance on how to address the issue of marginality or what changes could be made to enhance the contribution. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific methods or stages where the methods are demonstrated, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the contribution of the paper is marginal, as the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. While the comment identifies a potential weakness in the contribution, it lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might address the marginality or enhance the contribution, such as by providing additional context or justification for the methods used. As a result, the comment is 3, as it points out a potential issue but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the use of PBSD. It suggests that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer asks if there are any other motivations for using PBSD besides improving the discriminative representation on tail classes. While the comment identifies a potential issue with the clarity of the main contribution, it does not provide explicit guidance on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the motivation behind the use of PBSD and its connection to supervised contrastive learning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study\" and the \"DSCL part,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the clarity of the main contribution, particularly regarding the motivation behind the use of PBSD. The comment further asks if there are any other motivations for using PBSD besides improving the discriminative representation on tail classes. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the use of PBSD. The reviewer notes that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The comment suggests that there may be other motivations for using PBSD besides improving the discriminative representation on tail classes. However, the comment lacks specific examples or references to support the claim that the motivation is unclear. The reasoning is 3, as it points out a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the main contribution, specifically questioning the motivation behind the use of PBSD. It points out that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer asks if there are any other motivations for using PBSD besides improving the discriminative representation on tail classes. This feedback is 3 as it highlights a potential area for clarification and expansion in the paper. However, it could be more helpful if it provided specific suggestions on how to address this issue or what additional information might be needed to clarify the motivation. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment implies that the authors should consider including more details about these experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should provide more information but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment appreciates the comprehensive Appendix and acknowledges the additional detail it provides. However, it does not specify which part of the paper the Appendix is attached to, making it weakly grounded. The comment does not provide specific details about the additional experiments described in the Appendix, such as the Brusselator, which would help the authors understand what aspects need attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This statement is a factual observation about the reviewer\"s experience and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment appreciates the inclusion of a comprehensive Appendix, which provides additional detail about parts of the paper. However, it acknowledges that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment highlights a potential area for improvement by suggesting that the authors should consider including more details about these experiments in the main text, it does not provide specific guidance or suggestions on how to do so. This limits the comment\"s helpfulness, as it points out an area for improvement but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer implies that the description could be misleading if the two methods are not the same. However, the comment does not provide explicit guidance on how the authors should clarify this distinction or what specific changes should be made to the description. While the action is implied, it is not concrete, as the authors are left to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"step 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\" claim of using active learning and asks for clarification on whether the \"active learning pipeline\" method is the same as traditional active learning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of using active learning in step 2, specifically asking whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer provides a logical reasoning by pointing out that the description could be misleading if the two methods are not the same. However, the comment lacks specific examples or references to support the claim that the methods are different. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the authors\" claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. This is an important clarification that could impact the readers\" understanding of the methodology and its applicability. The comment prompts the authors to clarify this distinction, which is crucial for ensuring the accuracy and clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the distinction or examples of how the two methods differ. Overall, the comment is 4 as it identifies a critical issue and prompts the authors to take action, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the distribution should be clarified, how it should be clarified, or what specific aspects of the distribution are unclear. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not specify which part of the paper discusses the dataset or where the distribution should be clarified. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of the distribution. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It proposes an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. While the comment implies that the authors should consider this alternative approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. However, the comment does not specify which part of the paper discusses the method or where the limitation is discussed, making it weakly grounded. The suggestion to consider a selfsupervised approach is specific, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. However, the comment lacks specific examples or references to support the claim that a selfsupervised approach would be more effective. The reasoning is based on a logical assumption, but without detailed evidence or examples, it is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed method, specifically the requirement for annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in improving their method. However, the comment could be more helpful if it included examples or references to support the argument for the selfsupervised approach. Overall, the comment is 4 as it guides the authors toward a potential improvement in their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these additional experiments to fully demonstrate the scalability of their method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to demonstrate scalability on more challenging tasks, but without explicit references to sections or figures, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. The claim is 3 as it logically argues that demonstrating scalability on more complex tasks is important. However, it lacks specific examples or references to support the claim that these tasks are indeed more challenging or how LFF could improve them. Providing such examples or references would strengthen the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of the LFF method, it is important to show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental setup and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or what specific aspects of the LFF method should be emphasized in these more complex tasks. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract should include a specific measurement, such as \"attain greater expressivity, as measured by the change in linear regions in output space after [citation], instead of just \"attain greater expressivity.\" Additionally, it recommends including learning curves for all experiments in an appendix. While the comment provides explicit actions, it does not specify which experiments should include learning curves or how to present them. The authors are given clear guidance on what to add to the abstract and an appendix, but the execution of these actions is not detailed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be changed in the abstract, suggesting a specific measurement to include and recommending the inclusion of learning curves in an appendix. This level of detail provides clear direction for the authors to make improvements. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests changes to the abstract, specifically recommending a specific measurement to include and the inclusion of learning curves in an appendix. While the comment provides a logical reasoning for these suggestions, it lacks specific examples or references to support the claim that these changes would improve the paper. The authors are left to infer the benefits of these changes without detailed justification or evidence. Therefore, the comment is 3, as it provides a logical basis but lacks the necessary evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract section of the paper. It suggests a more precise measurement for expressivity, which is a clear and concrete suggestion that can help the authors improve the clarity and rigor of their abstract. Additionally, it recommends including learning curves for all experiments in an appendix, which is a valuable suggestion for providing additional insights and visual aids. However, the comment could be more helpful if it explained why these changes would enhance the paper\"s clarity or impact. Overall, the feedback is 4 as it offers clear and actionable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and application, specifically questioning the need for domain adaptation and the usefulness of the proposed method. It suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. While the comment implies that the authors should provide examples of how the method could be applied in practice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of domain adaptation tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results of mapping one RGB image to another RGB image with a different style, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the motivation and usefulness of the paper, suggesting that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the motivation and usefulness of the paper, suggesting that the proposed method does not have a clear application or demonstrate its value in domain adaptation tasks. The reviewer provides a logical reasoning by pointing out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily justify the need for domain adaptation. However, the comment lacks specific examples or references to support the claim that demonstrating the methodology\"s use on actual tasks would be beneficial. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the motivation and usefulness of the proposed method. It points out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily justify the need for domain adaptation. The reviewer suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by showing the practical applications of their method. However, the comment could be more helpful if it offered examples of such tasks or provided guidance on how to effectively demonstrate the methodology\"s utility. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider other baselines or update their references to more recent works. As a result, the authors are left without a clear direction on how to address this issue. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"MISA,\" \"M2FNet,\" and \"MMDFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This claim is 3 as it provides a specific reference to MULT and its publication year, which supports the assertion that it is outdated. However, the comment lacks detailed reasoning or examples to fully substantiate why MULT is considered out of fashion or how it impacts the current work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but points out that MULT was proposed in 2019 and is therefore out of fashion. This feedback is 3 as it highlights an area where the paper may be outdated and suggests that the authors consider more recent works. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as suggesting alternative baselines or explaining why MULT is still relevant. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a major issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks for all models and the omission of tensor completion results for fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the clarity and fairness of the comparisons. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It also provides specific guidance on how to address this issue by suggesting that the authors compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the value of the used ranks is omitted, making it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This claim is 3 as it provides a logical reasoning for the need for a fair comparison and suggests a method to achieve it. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It provides a clear and actionable suggestion by recommending that the authors compare tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback is valuable as it guides the authors on how to improve the clarity and fairness of their experimental comparison, making it 5. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include ATA in the comparison under the leave one out setting in Table 2. This is a clear and direct action for the authors to take, as it provides a specific recommendation to enhance the comparison by including ATA. The comment also references the results in Table 1, which further guides the authors on where to make the change. The action is concrete and specific, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of ATA in the comparison under the leave one out setting. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should include ATA in the comparison under the leave one out setting, as ATA is better than FP according to the results in Table 1. However, the comment does not provide any specific evidence, references, or detailed reasoning to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+\"LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, as ATA is reported to be better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the comparison and improve the clarity of their results. However, the comment could be more helpful if it explained why ATA is considered better or how it might impact the overall conclusion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the normalization module, noting that it appears different in two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in the context of Fig. 4, where the chosen symbols overlap. Additionally, the reviewer points out minor issues with the text, such as overlapping symbols in Fig. 4 and a lack of clarity after equation (4). While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to standardize the pictograms or address the overlapping symbols issue. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"normalization module\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. Additionally, it provides specific feedback on the figures, particularly Fig. 4, where the chosen symbols overlap. The comment also mentions minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the normalization module appears different in two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in Fig. 4, where the chosen symbols overlap. The reviewer also points out minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4). However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the specific issues and how to address them, which could be challenging without additional context or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. This is a clear and actionable point that the authors can address to improve the consistency and clarity of their work. Additionally, the comment highlights the importance of standardizing the pictograms, particularly in Fig. 4, where the chosen symbols overlap. This feedback is valuable as it helps the authors ensure that their figures are clear and easy to understand. The comment also points out minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4), which can be addressed to improve the overall readability. Overall, the comment is 4 as it provides clear and actionable suggestions for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the authors\" claims and the theoretical part of the paper. It highlights that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks details on how the proposed algorithm removes these splines. The reviewer questions whether the algorithm requires extra computation cost for space partitioning. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this discrepancy or what additional details should be included in the theoretical part. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations of the algorithm and its computational requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the observation and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detail in the theoretical part regarding the proposed algorithm for removing subdivision splines and the potential extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the observation that only parts of subdivision splines are useful for decision boundaries. It points out that the theoretical part lacks details on how the proposed algorithm removes these splines, and it raises a concern about the potential extra computation cost for space partitioning. The comment is 3 as it highlights a gap in the paper\"s explanation and seeks clarification on the algorithm\"s computational requirements. However, it does not provide specific examples or references to support the claim or the need for additional details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claims and the theoretical part of the paper. It points out that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks details on how the proposed algorithm removes these splines. The reviewer also questions whether the algorithm requires extra computation cost for space partitioning. This feedback is 3 as it highlights a gap in the paper that the authors need to address to provide a more complete understanding of their work. However, the comment could be more helpful if it offered specific suggestions on how to address this discrepancy or what additional details should be included in the theoretical part. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that W1 and W2 are not defined, and it speculates that they might denote the Encoder and Decoder networks. It also mentions that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and directs the authors to define these terms, which is a concrete action for them to take. The comment is 5 as it provides specific guidance on what needs to be clarified or defined in the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1 and W2\" and \"W and V,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these terms are not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"W1 and W2 are not defined\" and speculates that they might denote the Encoder and Decoder networks. It also mentions that \"W and V are not defined\" and provides specific references to page 3, line A4, and equation 3. This claim is 3 as it points out specific sections where the terms are not defined, providing some basis for the assertion. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that W1 and W2 are not defined and speculating that they might denote the Encoder and Decoder networks. It also points out that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and actionable, as it directs the authors to clarify these terms to avoid confusion and ensure the paper is understandable. However, the comment could be more helpful if it offered suggestions on how to define these terms or provided examples of how they might be used in the context of the paper. Overall, the comment is 4 as it effectively guides the authors on how to improve the clarity and completeness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. It suggests that a better comparison should be considered. While the comment implies that the authors should reconsider their comparison, it does not provide specific guidance on how to improve the comparison or what alternative baselines should be used. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with baselines, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the comparison, stating that it is unfair due to the lack of prior knowledge of users or language embedding computation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of baselines, noting that the lack of prior knowledge of users or language embedding computation may unfairly skew the results. This is a valuable observation that could lead to a more robust and fair evaluation of the baselines. However, the comment does not provide specific suggestions on how to address this issue or what alternative comparisons could be considered. While it highlights an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. While the comment identifies areas that need clarification or expansion, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they need to address these issues, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses several issues, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and the absence of limitations and potential negative societal impact discussions. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of Figure 4 and the presentation of Pixelshuffle details. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and the absence of limitations and potential negative societal impact discussions. While the comment identifies areas that need clarification or expansion, it does not provide specific examples or references to support the claims. The authors would need to make a significant effort to address these issues, and the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas of confusion and potential improvement in the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and the absence of limitations and potential negative societal impact discussions. While the comment highlights important areas for clarification and expansion, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or analysis regarding the behavior of negative chips and the potential impact of the alternating process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the behavior of negative chips and the potential impact of the alternating process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also inquires whether this alternating process could help improve performance. This feedback is 3 as it prompts the authors to clarify their methodology and potentially explore avenues for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or improve their work. Overall, the comment offers a starting point for the authors to consider, but it lacks depth and actionable guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide specific guidance on how to do so or what aspects of the evaluation should be prioritized. The action is implicit and somewhat vague, as the authors need to infer the details of the evaluation themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should evaluate their proposed approach on both new and old patients, which implies that it relates to the methodology or results section. However, it does not specify which part of the paper this evaluation should be included in, such as a specific section or table. The comment is specific in its suggestion to evaluate the approach on both new and old patients, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would impact the paper\"s conclusions. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a relevant and actionable suggestion. However, it lacks depth and does not provide specific guidance on how to conduct this evaluation or what aspects of the approach should be tested on each patient group. While it identifies a potential area for improvement, the comment could be more helpful if it included detailed instructions or examples on how to implement this suggestion effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights an issue with the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use this dataset in their training. The reviewer questions whether 300WLP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This comment implies that the authors should clarify the use of the 300WLP dataset in their experiments and address the potential bias. However, it does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to clarify the dataset usage, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental methodology, specifically the use of the 300WLP dataset. It also specifies the issue by questioning whether the dataset is used in all experiments or just some, and whether it provides an unfair advantage to the proposed method. This level of detail allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly outlines the concern about the dataset usage and its potential impact on the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset. The reviewer notes that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. The comment suggests that if 300WLP is used in all experiments, it could provide an unfair advantage to the proposed method. This claim is 3 as it points out a potential issue with the experimental setup, but it lacks specific examples or references to support the claim that the use of 300WLP provides an unfair advantage. The authors would need to further investigate and substantiate this claim to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. This raises a concern about whether the use of 300WLP provides an unfair advantage to the proposed method. The comment is clear and actionable, as it prompts the authors to clarify whether 300WLP is used in all experiments and, if so, to address the potential bias this could introduce. By providing this feedback, the reviewer helps the authors ensure the fairness and transparency of their experimental results. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the technique should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying potential issues with the novelty of the technique, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any evidence, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. While it identifies a potential issue with the novelty of the algorithm, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the novelty of their work. The comment is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed feedback for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It also points out that the authors\" formulation assumes observations are obtained by averaging over the support, which may not be accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their assumptions about the observations and their aggregation process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the integral in Equation (1)\" and references specific works, \"Law et al., NeurIPS\"18\" and \"4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. The comment provides a clear direction for the authors to consider alternative aggregation methods, such as simple summation or population weighted average, and suggests that the disease incident data is often available in count or rate per the number of residents. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to the bag observation model in [Law et al., NeurIPS\"18] or the spatial aggregation process in [4]. The reviewer provides references to these works, which supports the claim by establishing a connection to existing literature. However, the comment also suggests that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. This claim is 3 as it relies on the references to support the assertion, but it could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. The comment suggests that the data might be aggregated by other methods, such as simple summation or population weighted average, and provides examples of how disease incident data is often available in count or rate per the number of residents. This feedback is clear and actionable, as it directs the authors to reconsider their assumptions about the observations and their aggregation process. However, it could be more helpful if it included specific suggestions on how to address this issue or what alternative methods to consider. Overall, the comment is 4 as it highlights a critical area for improvement and provides a direction for the authors to explore."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks indepth analysis and suggests that the authors should provide an explanation for the training dynamics observed. This feedback is clear and provides a direct action for the authors to take, which is to include an analysis of the training dynamics. The comment is specific in its request for an explanation, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and specifically mentions the observation of inverse scaling over compute. However, it does not specify which part of the paper this observation is made in, making it weakly grounded. The comment does provide some specificity by suggesting that an explanation of the training dynamics would strengthen the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks indepth analysis and suggests that the authors should provide an explanation for the observed training dynamics. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of indepth analysis and suggesting that the authors provide an explanation for the observed training dynamics. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened by including more detailed analysis. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of mathematical definition for certain architectural details, specifically mentioning multihead attention. It also questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer implies that a formal definition would be beneficial for readers to understand the architecture. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide a formal definition, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"multihead attention,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multihead attention, and questions the purpose of a split arrow in Figure 2. The comment further specifies that a formal definition would be beneficial for readers to understand the architecture. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of mathematical definition for certain architectural details, specifically mentioning multihead attention. It questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer assumes that these are the inputs for the attention layer, namely query, keys, and values. The comment suggests that a formal definition would be beneficial for readers to understand the architecture. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that a formal definition is necessary. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the lack of mathematical definition for certain architectural details, such as multihead attention, and questions the purpose of a split arrow in Figure 2. It also seeks clarification on the inputs for the attention layer and whether the same vectors are used for keys and values. The comment implies that a formal definition of these concepts would be beneficial for readers to understand the architecture. While the comment highlights areas for improvement, it does not provide detailed suggestions or guidance on how to address these issues. The authors are left to infer that they need to provide a formal definition, but the feedback lacks actionable steps. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. While the comment implies that the authors should modify their experimental setup, it does not provide explicit instructions on how to implement this change or what specific tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or the discussion of the results. The authors can infer that it relates to the latter part, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes that tasks could be made more complex to test the policy\"s adaptability. However, the comment lacks specific examples or references to support this claim or to justify why the current setting is insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. This feedback is 3 as it identifies a potential area for improvement in the experimental setup. However, the comment lacks specific guidance on which tasks to consider or how to implement this change. Additionally, it does not provide detailed reasoning or examples to support the claim that tasks need to be more complex. While the suggestion is 3, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the comprehensiveness of the experimental analyses and the method itself, noting that the focus is primarily on the presentation of results. It suggests that the authors should provide more detailed analyses of the method and its performance, particularly in light of the baseline\"s underperformance. While the comment does not explicitly instruct the authors on how to conduct these analyses, it implies that they should include more detailed descriptions and comparisons. The action is implicit but concrete, as it points to a specific area for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"majority of the experiments\" and the \"analyses of the method itself and the experimental outcomes,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the analyses are not comprehensive enough and questioning the extent to which the performance improvement can be attributed to the authors\" claim. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments focus on the presentation of results and that the analyses of the method and experimental outcomes are not comprehensive enough. It questions the extent to which the performance improvement can be attributed to the authors\" method. The comment provides some logical reasoning by pointing out that the baseline underperforms the authors\" method in certain instances, which could affect the validity of the authors\" claims. However, the comment lacks specific examples or references to support the claim that the analyses are inadequate. This makes the claim 3, as it provides some basis but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the majority of the experiments focus on the presentation of results rather than comprehensive analyses of the method and experimental outcomes. It highlights the importance of understanding the extent to which the performance improvement can be attributed to the authors\" method, particularly given the underperformance of the baseline in some instances. This feedback is clear and actionable, as it prompts the authors to reconsider the balance between presenting results and providing detailed analyses of their method and experimental outcomes. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the method and results should be emphasized. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to broaden the scope of the paper or what specific aspects of multitask models should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this issue is related to, such as specific sections or examples where the focus on multitask models is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the multitask models are problematic or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper\"s focus on multitask models limits its applicability. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper\"s focus on multitask models limits its applicability, which is a valid point. However, it does not provide any specific suggestions or guidance on how the authors might broaden the scope of their work or address this limitation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the current work. The reviewer provides a specific question about the Assumption 2 and the rate of QSGD in the stochastic regime, implying that the authors should consider these papers for further analysis. While the comment does not explicitly instruct the authors to include these papers, the action is implicit and concrete, as it clearly identifies the need for additional analysis and provides a specific direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"next section\" and the \"Literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of relevant papers, [1] and [2], and suggests that VRMARINA and DASHAMVR could be relevant to the current work. The comment provides a clear direction for the authors to consider these papers and address the Assumption 2 and QSGD rate in the stochastic regime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. The reviewer provides a specific example of VRMARINA and DASHAMVR, which are mentioned in these papers, and suggests that they could be relevant to the current work. The reviewer also poses a question about the Assumption 2 and the rate of QSGD in the stochastic regime, providing a logical basis for the claim. However, the comment lacks specific references to these papers or detailed analysis of their relevance, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the literature review, noting that it ignores several relevant papers. It specifically mentions [1] and [2], which are believed to be relevant to the current work. The reviewer suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it provides specific guidance on which papers to consider and how they might impact the current work. By addressing this feedback, the authors can significantly enhance the rigor and comprehensiveness of their literature review. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how the authors could improve the presentation to make it more understandable. There is no explicit or implicit action for the authors to take, such as recommending changes to the structure, organization, or content of the paper. Without actionable advice, the authors are left without a clear path to follow to enhance the clarity of their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is hard to follow, but it does not specify which part of the paper is particularly challenging to understand. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need improvement. Additionally, the comment lacks specificity regarding what aspects of the presentation are confusing or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation of the paper is hard to follow. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment states that the presentation of the paper is hard to follow, but it does not provide any specific guidance or suggestions on how the authors could improve the clarity or organization of the paper. Without actionable feedback or detailed insights into what aspects of the presentation are confusing or ineffective, the authors are left without a clear path to enhance the readability and comprehensibility of their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: whether the authors have any additional insights into modest performance gains on Clothing1M and how the algorithm performs on other realworld datasets like WebVision, evaluated by DivideMix. While these questions imply that the authors should provide additional information or analysis, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights or data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions about the performance of the algorithm on Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for additional insights or performance evaluations on specific datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could help the authors gain additional insights into the performance of their algorithm on realworld datasets. By asking about modest performance gains on Clothing1M and the algorithm\"s performance on WebVision, evaluated by DivideMix, the reviewer encourages the authors to provide more detailed evaluations and comparisons. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional insights would be beneficial. While it points out areas for potential improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct additional experiments on different LLMs like LLaMA and Falcon as benchmark baselines. While the comment implies that more experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on different LLMs like LLaMA and Falcon as benchmark baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results discussion. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why these specific LLMs are necessary or how they would impact the results. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the experimental setup by suggesting that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. This feedback is 3 as it points out an area where the authors could enhance their work by including additional comparisons. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects to focus on, such as the impact of different LLMs on the results. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper, noting that it does not describe the hyperparameters used by each defense nor how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to include this information, but the lack of concrete guidance on how to do so makes the action implicit. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding the hyperparameters used by each defense and how those hyperparameters are derived. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the need for a maximally charitable evaluation of defenses that optimizes hyperparameters against the attack and demonstrates how much clean data is required to remove the attack. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim that such an evaluation is necessary or how it would be conducted. This makes the claim 3, as the authors would need to infer the importance of this aspect themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific guidance on how to implement this evaluation or what specific hyperparameters should be considered. Overall, the comment is 4 as it directs the authors to a crucial aspect of their work that needs attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the theoretical results do not have immediate practical implications, but acknowledges that this is understandable given the novelty of the work. It also expresses a desire for more practical takeaways for practitioners, specifically mentioning the idea of querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate this suggestion or what specific aspects of the paper should be revised to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should focus on making their results more practical and actionable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the paper could provide more practical takeaways for practitioners. It mentions a specific takeaway point regarding querying a cluster proportionally to the square root of its size, but does not specify which part of the paper this relates to. The authors can infer that it pertains to the theoretical results or methodology sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in suggesting that the paper should provide more practical insights, but it is 1 as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results do not have immediate practical implications, which is 3. The reviewer acknowledges the novelty of the work but suggests that more practical takeaways should be provided for practitioners. The comment provides a specific example of a takeaway point, which is the idea of querying a cluster proportionally to the square root of its size. However, the comment lacks detailed reasoning or references to support why this takeaway point is not novel or how it could be improved. The suggestion is 3, as it provides a specific example but lacks comprehensive justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work and suggests that the theoretical results do not have immediate practical implications. It identifies a specific takeaway point, which is the idea of querying a cluster proportionally to the square root of its size. However, the comment lacks depth and does not provide detailed guidance on how to incorporate this takeaway point into the paper or what specific aspects of the theoretical results should be emphasized for practical relevance. While it points out a potential area for improvement, the feedback is 3 as it highlights a specific aspect that could be addressed, but it does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the purpose of separators in section 4, specifically asking for additional information on what they contribute beyond T/I/O. While the comment identifies an area for clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide more information or explanation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of separators and what additional information they provide beyond T/I/O. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This is a request for clarification and does not make a subjective claim or express an opinion. It is a factual inquiry seeking more information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the purpose of separators in section 4, specifically asking for additional information on what they contribute beyond T/I/O. This feedback is 3 as it identifies a potential area for clarification or expansion in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information could be provided. While it points out a potential gap in the explanation, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. While it implies that the authors should consider alternative approaches, it does not explicitly instruct them to do so or provide specific guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative pooling strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. It does not present an opinion, judgment, or suggestion that requires verification. It is a request for clarification and does not contain subjective claims or assertions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This is a thoughtprovoking observation that could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific guidance or suggestions on how to explore alternative pooling strategies or what specific aspects of mean pooling might be problematic. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison of the real search cost in terms of GPU days. The comment is specific and provides concrete guidance on how to enhance the table, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a comparison of the real search cost in terms of GPU days. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback is 3 as it identifies a potential area for improvement in the presentation of data, which could provide a more comprehensive view of the system\"s performance. However, the comment lacks depth and does not explain why this comparison is important or how it would enhance the understanding of the system\"s performance. To be more helpful, the comment could provide additional context or examples of how such a comparison could be implemented. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VQGAN\" and \"Computer Vision Figures dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training details of the VQGAN, specifically whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, particularly inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. This question highlights a potential gap in the paper that could impact the reader\"s understanding of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include works such as [] Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and compare them to their work conceptually. Additionally, it recommends discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). These suggestions provide clear and explicit actions for the authors to take, including identifying relevant works and discussing their differences. The comment is concrete and provides specific guidance on how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests including works such as [] Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of these works and the need for a discussion on differences, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include specific works, such as [] Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. The comment also recommends discussing how their work differs from other chatbox research works. While the suggestion is based on logical reasoning and common knowledge about the importance of including relevant works, it lacks specific examples or detailed justification for why these works are particularly relevant or how they differ from others. This makes the claim 3, as it provides a general direction but lacks detailed evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include relevant works, such as [] Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. It also recommends discussing how their work differs from other chatbox research works. This feedback is 4 as it guides the authors on how to enhance their draft by incorporating relevant references and discussing their unique contributions. However, it could be more helpful if it provided additional context or examples of how these works differ from the current paper. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed methods, DualIS and DualDIS, in terms of their generic applicability on crossmodel retrieval tasks, specifically mentioning the minor improvements in MSVD (Table 3). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the generic applicability or suggestions for further experiments to explore. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS,\" allowing the authors to accurately identify the specific methods being discussed. It also specifies the issue by pointing out that the methods are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. However, the comment does not provide specific details or examples of these tasks or the performance improvements, making it difficult for the authors to understand the basis of the claim. The lack of detailed evidence or references to support the claim renders it 1. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed methods, DualIS and DualDIS, by pointing out that they are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This feedback is 3 as it highlights an area for improvement, but it lacks specific suggestions or guidance on how to address this issue. The authors are informed of a potential weakness but are not provided with actionable steps to improve their work. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. However, the comment does not provide explicit instructions on how to implement this alternative method or why it might be preferable. While the suggestion is clear, it lacks concrete guidance on how to execute it, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. However, the comment does not specify which part of the paper this critique is based on, such as the experimental section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the alternative method and the rationale behind it, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point questions the experimental strengths of the approach, specifically the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. This claim is 3 as it provides a logical reasoning for the alternative method, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments to validate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. This feedback is 3 as it identifies a potential weakness in the experimental setup and offers a constructive suggestion for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the alternative method. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship or what specific steps to take to improve the study. As a result, the authors are left without any clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the study, namely the lack of establishment of the relationship between the top selected patches and the disease. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this relationship should be discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying the issue of incomplete study, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease is not yet established. This is a critical point that could impact the validity and impact of the study. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to establish this relationship. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path forward. Therefore, the comment is 3, as it points out a critical area for improvement but does not provide enough detail for the authors to effectively address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a typographical error in the phrase \"for \"inbetween\" uncertainty\" by noting that the first quotation mark should be a forward mark rather than a backward mark. This is a clear and concrete action for the authors to take, as they are provided with specific guidance on how to correct the error. The comment is 5 as it directly instructs the authors on what to change to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the quotation marks, providing detailed guidance on how to correct the typographical error. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a typographical error in the paper, specifically noting the incorrect placement of the quotation marks in the phrase \"for \"inbetween\" uncertainty.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific typographical error in the paper, namely the incorrect placement of the quotation marks in the phrase \"for \"inbetween\" uncertainty.\" This is a minor but important detail that can impact the clarity and professionalism of the paper. By pointing out this error, the comment provides actionable feedback that the authors can easily address to improve the quality of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the performance of FedSP in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting improvements or additional analyses. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of FedSP is not the best in these tables on some datasets. However, it does not provide detailed guidance on what specific aspects of FedSP are not performing well or how the authors might address this issue. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Tables 1 and 2 on some datasets. However, it does not provide any specific data, comparisons, or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance of FedSP in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve the performance. Without detailed guidance or examples, the authors are left without a clear path forward. Therefore, the comment is 2, as it points out a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the clarity of certain aspects in the paper, specifically asking for more explicit explanations. It suggests that the authors should provide information about what Omega is and clarify the link function. Additionally, it asks for more explicit references to the theorem in [32] for the regret guarantee. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations and references, but the action is implicit and lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the clarity of certain aspects, such as what Omega is and the link function, as well as the reference to a theorem in [32] for the regret guarantee. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and references, rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or statements that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved by requesting more explicit explanations and references. It points out that the authors should clarify what Omega is and provide more information about the link function. Additionally, it asks for a more explicit reference to the theorem in [32] for the regret guarantee. This feedback is clear and actionable, as it directs the authors to enhance the clarity and completeness of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar concepts have been addressed in the literature. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. However, it does not provide any guidance or suggestions on how the authors should address this issue or improve their work. There is no explicit or implicit action for the authors to take, nor is there any indication of what the implications of this observation might be. As a result, the comment lacks actionability and does not provide any direction for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment mentions \"the models are learned directly from pixels without a Markovian state,\" which suggests that the models are not Markovian. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the models being learned directly from pixels without a Markovian state, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation or how it affects the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific aspect of the models being learned directly from pixels without a Markovian state, which could be a potential issue or limitation. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and explicit action. The comment is specific in identifying the need for references and provides a concrete direction for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"sequence example\" and \"Example 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the use of the Hamming distance over entire parts of the sequence as a scoring loss, which is a specific practice in the context of CRF. The comment suggests providing references for this approach, which is a clear and specific request for additional information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer expresses surprise and suggests that they are not familiar with this approach, which is a claim that requires further explanation or evidence to be 5. However, the comment does provide a specific example of a \"nodewise\" approach, which could be used to clarify the issue. Therefore, the comment is 3, as it highlights a potential gap in understanding but lacks detailed justification or references to support the claim fully.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and actionable suggestion. By addressing this point, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided specific references or examples of works that use this approach. Overall, the comment is 4 as it identifies a potential gap in the paper and offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment provides a clear action to take, it lacks specific guidance on how to implement these changes or what specific metrics should be included. The authors are given a general direction but may need to infer the details of execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation or metrics sections. The suggestion to change the name and mention metrics is specific, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also recommends mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the claim that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are wellknown and used as standard practice. However, the comment lacks specific examples or references to support the claim that the metrics are wellknown and standard practice. This makes the claim 3, as the authors would need to infer the reasoning behind the suggestion themselves.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to change the name of the \"Evaluation\" element to \"Metrics,\" which is a clear and concise improvement. It also recommends removing the corresponding sections and mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the rationale that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are wellknown and used as standard practice. By making these changes, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided examples of specific metrics to include or explained why these changes would enhance the paper\"s clarity. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it does not provide specific guidance on how to do so or what aspects of the dataset should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their discussion of the dataset. Therefore, this comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper should have more exploration of the dataset, nor does it provide details on what aspects of the dataset should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this exploration is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to incorporate this exploration into the paper. The comment does not provide details on what aspects of the dataset should be highlighted or how the authors might integrate this exploration into their analysis. As a result, the feedback is 3, as it points out a potential area for improvement but does not offer actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. While the comment provides a specific suggestion to use more objective terms, it does not offer concrete guidance on what terms to use or how to present the improvement in a more objective manner. The action is implicit and somewhat vague, as the authors need to infer the specific terms to use and the exact way to present the improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"axes\" and \"squished,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement and points out that the axes are squished, making it difficult to characterize the improvement as remarkable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"remarkable\" is subjective and that the axes are squished, making it difficult to characterize the accuracy improvement as remarkable. However, the comment does not provide any supporting evidence, reasoning, or references to justify why \"remarkable\" is inappropriate or how the squished axes affect the interpretation of the improvement. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. This feedback is actionable and constructive, as it offers a clear direction for the authors to improve the clarity and precision of their language. By addressing these points, the authors can enhance the credibility and objectivity of their claims. However, the comment could be more helpful if it provided examples of alternative, objective terms to use or explained why \"remarkable\" is not appropriate. Overall, the comment is 4 as it offers clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could benefit from using longer video sequences, such as 16 frames, to address issues with inconsistent motion, changing color, or object disappearing over time. It also mentions that running the LSTM over many time steps could be interesting. While the comment implies that the authors should consider these changes, it does not provide explicit instructions or concrete steps on how to implement them. The authors are left to infer the actions needed to improve their draft, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the synthesized results for UCF101, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with inconsistent motion, changing color, or object disappearing over time and suggests using longer video sequences. Additionally, it provides a positive assessment of the paper, noting its interesting idea and extensive experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes a claim about the synthesized results for UCF101, suggesting that the issue is inconsistent motion, changing color, or object disappearing over time. The reviewer suggests that using longer video sequences could address these issues. However, the comment lacks specific examples or detailed reasoning to support the claim about the synthesized results. While it provides a general direction for improvement, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a positive assessment of the paper, noting its interesting idea and extensive experiments. It also identifies specific issues with the synthesized results, such as inconsistent motion, changing color, or object disappearing over time. The reviewer suggests that using longer video sequences could address these issues. While the comment highlights areas for improvement, it lacks detailed guidance or specific suggestions on how to implement these changes. This limits the comment\"s helpfulness, as it provides some direction but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states a fact about the limitations of pruning techniques on GPUs, which is not an actionable statement. It does not provide any guidance or suggestions for the authors to improve their draft. As a result, the authors are left without any actionable steps to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses. It is a general statement about the limitations of pruning techniques on GPUs, which does not provide any context or reference to a specific section, table, or figure in the paper. As a result, the authors cannot determine which part of the paper needs attention or improvement. The comment is also not specific, as it does not provide details on what aspects of the pruning techniques are not efficient on GPUs or how the authors might address this issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"it is not yet possible to realize efficiency gains on GPU\" regarding pruning techniques. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment provides a general observation about the limitations of pruning techniques on GPUs, which is relevant but not actionable. It does not offer any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with [5] being unfair because [5] is designed for a more complex problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the evaluation. The comment lacks actionable details, such as suggesting alternative evaluation methods or providing specific examples of how the comparison could be improved. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the numerical evaluation and the comparison with [5], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the complexity of the problem. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the unfair comparison with [5]. However, the comment does not provide specific reasoning or evidence to support why the comparison is unfair or how it affects the validity of the evaluation. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is unfair due to the complexity of the problem. This feedback is valuable as it highlights a potential weakness in the paper\"s evaluation, which could impact the credibility of the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending alternative evaluation methods or suggesting ways to improve the comparison with [5]. Despite this, the comment still offers a clear direction for the authors to enhance the rigor and validity of their evaluation, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this experiment to strengthen their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"PGD attack\" and the \"32bit logit,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of the effect of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. This provides clear guidance on what the authors should consider in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack. The reviewer suggests that intuition suggests that having a 32bit logit should improve robustness against a more powerful adversary. However, the comment lacks specific evidence or references to support this claim, making it 3. The authors would need to make a logical inference to understand the basis of the suggestion, which is not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the study of numbers of bits in logits and their effect on robustness against a larger epsilon in the PGD attack. It suggests that intuition suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to conduct this experiment or what specific aspects to focus on. The feedback is 3 as it points out a potential area for enhancement, but it lacks actionable details that would fully support the authors in making improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. While it does not explicitly instruct the authors to provide this information, the question implies that the authors should include this analysis in their paper. The action is implicit but concrete, as the authors can infer that they need to include this information to address the reviewer\"s concern. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment poses a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this information should be addressed. Additionally, the comment lacks specificity regarding what aspects of the insurance costs should be analyzed or how the method affects them. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a specific question about the impact of the method on insurance costs for men and women. This is a clear and actionable request for additional information that could help the authors better understand the practical implications of their work. By addressing this question, the authors could provide more comprehensive and relevant information about their method\"s realworld applications. However, the comment does not offer suggestions on how to present this information or what specific aspects to focus on. While it identifies a relevant area for improvement, it lacks depth and guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to Foester et al. (NIPS 2016) as an example. This provides a clear and concrete action for the authors to take, as they are given a specific area to address and a reference to guide their understanding. The comment is 5 because it directly tells the authors what to do and provides a concrete example to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta solvers\" and the \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL, and provides a reference to Foester et al. (NIPS 2016) to guide the authors in their understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers, and suggests that the authors should clarify the difference between them and centralized RL. The reviewer provides a reference to Foester et al. (NIPS 2016) to support this claim. However, the comment lacks detailed explanation or analysis of why the meta solvers are considered centralized controllers, which would help the authors understand the basis of the claim. The reference to Foester et al. provides some support, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is 3, as it provides a starting point for the authors to explore but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the classification of the meta solvers as centralized controllers. It suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al. (NIPS 2016) as an example of centralized RL, which is a clear and actionable suggestion for the authors to consider. This feedback is 4 as it guides the authors to clarify a key aspect of their work, which could enhance the understanding and clarity of their methodology. However, it could be more helpful if it included additional details or examples on how the authors might address this issue. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October, suggesting that the authors should consider this issue in their paper. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the availability of papers on arxiv. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of splitting papers according to their publication years on the ACL anthology, noting that many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October. However, the comment does not specify which part of the paper discusses the splitting of papers, making it weakly grounded. The comment is specific in pointing out the issue of papers being available on arxiv before being published in the ACL anthology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. The reviewer provides an example of the BERT paper being available on arxiv in October, which supports the claim. However, the comment could be strengthened by providing more examples or detailed reasoning on why this issue is significant. As it stands, the claim is 3, as it relies on a specific example but lacks comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s methodology, noting that it splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. This is a relevant observation that could impact the paper\"s credibility and relevance. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should consider providing examples to explain the concept of M_T, which is currently defined over the probabilities of atomic events. This feedback is clear and provides a specific action for the authors to take, which is to include examples to clarify the concept. The comment is concrete in its request for examples, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the definition of M_T and the notation used, and suggests providing examples to clarify the concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of M_T is over the probabilities of atomic events and that the notation is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of M_T, noting that it is defined over the probabilities of atomic events and that the notation is not clear. It suggests that the authors consider providing examples to clarify this concept. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to present these examples or what specific aspects of the notation should be clarified. This limits the comment\"s helpfulness, as it points out an issue but does not fully support the authors in addressing it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two concerns: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to clarify the use of \u03b2 and the difference between QRS and RS, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the proposed relaxation of rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. The comment provides a clear direction for improvement by suggesting that the authors clarify the use of \u03b2 and the difference between QRS and RS. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the use of an arbitrary parameter \u03b2 in rejection sampling and questions the lack of clarity regarding the difference between QRS and RS in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should have used Importance sampling instead of rejection sampling. Additionally, the comment lacks specific examples or detailed explanations to support the claim about the difference between QRS and RS. As a result, the claim is not verifiable, making it difficult for the authors to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the observed performance enhancements are modest and implies that there is room for further refinement in the future. However, it does not provide specific guidance on how to achieve this refinement or what aspects of the work need improvement. The action is implicit and vague, as the authors are left to infer that they need to make improvements but without clear direction on what those improvements should be. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, such as specific experiments or results. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the work need refinement or how to achieve it. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation and how it relates to their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work need improvement. Without actionable advice or detailed feedback, the authors are left with a general observation without clear direction for improvement. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230234 and 234235, and to clarify what \"MLP\" refers to in Figure 2. These are clear and direct actions that the authors can take to improve their draft. Additionally, the comment highlights a missing reference, which is also actionable. The feedback is specific and provides concrete details on what needs to be added or clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in Section 3.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for references for two passages and clarifies what \"MLP\" refers to in Figure 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of requests for references and clarifications, which are factual in nature and do not contain subjective claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying specific lines in Section 3.2 that lack references and asking for clarification on what \"MLP\" refers to in Figure 2. This detailed guidance helps the authors address specific gaps in their work, ensuring that their references are accurate and their figures are clearly explained. Additionally, the comment highlights a missing reference, which is an important point for the authors to consider. Overall, the comment is 5 as it directs the authors to specific areas for improvement and provides clear instructions on how to address them."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the validity of the proposed method. However, it does not provide specific guidance on how the authors should address this issue or what steps they should take to improve the results. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, specifically mentioning the performance being similar to IRM. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the experimental results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method. However, it does not provide specific reasoning or evidence to support this claim, such as detailed analysis or comparisons with other methods. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the validity of the proposed method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or improve their experimental results. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment implies that the authors should provide a clearer explanation or rationale for this distinction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of detecting both entities in the example and asking for clarification on the difference between detecting both entities and just detecting the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment identifies a potential area of confusion or misunderstanding in the paper, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a vague understanding of what needs to be clarified, which limits the comment\"s helpfulness. Therefore, the comment is 3, as it points out a potential area for improvement but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is no empirical validation and suggests including experiments to validate the bounds. This provides a clear and direct action for the authors to take, which is to conduct experiments to validate the bounds. The comment is specific in its request for empirical validation and offers a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of empirical validation, which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of experiments to validate the bounds. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is no empirical validation and suggests including experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical validation for the bounds. It suggests that including experiments to validate the bounds would be beneficial. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of empirical validation. However, the comment could be more helpful if it offered examples of what kind of experiments might be appropriate or how to design them. Overall, the comment is 4 as it highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. However, it does not provide any explicit guidance or suggestions on how the authors should address this confusion or clarify their terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider their terminology. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \"nonsequential information such as chunks,\" suggesting that the term \"chunks\" might be considered sequential information. This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the phrase \"nonsequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. This question highlights a potential confusion in the paper that could be clarified to improve the clarity and coherence of the text. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their terminology. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a discrepancy between equation 9 and figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it or what specific changes should be made to the figure or the methodology. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the figure and possibly use bilinear sampling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions, and suggesting that bilinear sampling might provide better results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The reviewer suggests that the figure is misleading and proposes an alternative method, bilinear sampling, as a potential solution. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the misleading nature of Figure 1. The suggestion to use bilinear sampling is logical but could be strengthened with more detailed explanation or references. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a discrepancy between equation 9 and Figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. This feedback is 3 as it points out a potential issue with the figure and provides a suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to address the discrepancy or why bilinear sampling might be a better approach. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the upper bound in Theorem 1, which seems incorrect due to a separate node with 0 neighbors. The reviewer asks how to explain this exception. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this question or clarify the exception. The action is implicit and somewhat vague, as the authors can infer that they need to provide a response but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound in Theorem 1 and suggests an explanation for an exception. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the correctness of Theorem 1, specifically regarding the upper bound in the context of a separate node with 0 neighbors. The reviewer acknowledges that this is obviously not true and asks for an explanation of the exception. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the theorem is incorrect. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the correctness of Theorem 1, specifically regarding the upper bound in the context of a separate node with 0 neighbors. The reviewer acknowledges that this is obviously not true and asks for an explanation of the exception. This feedback is 3 as it identifies a potential issue in the paper that the authors may need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to resolve the issue or improve the explanation. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). It suggests that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous papers. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to enhance their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and the similarity to the mentioned papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The comment provides a specific comparison with the papers, noting that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous works. This provides a logical basis for the claim, as it highlights the similarity between the papers. However, the comment could be strengthened by providing more detailed examples or references to specific sections of the papers that demonstrate the similarities. As it stands, the claim is 4, as it provides a clear rationale but lacks comprehensive evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it lacks technical novelty and is similar to two mentioned papers (Xing and Tsang, 2022a, b). It provides a specific comparison with the papers, highlighting the similarities in the idea, coattention mechanism, and architecture. This feedback is 3 as it points out an area where the paper could be improved by differentiating itself from existing work. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their approach to enhance originality. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. It suggests that this observation should be revised or deleted from the discussion. However, the comment does not provide explicit instructions on how to revise or delete the content. The action is implicit and somewhat vague, as the authors need to infer that they should revise or delete the content. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, noting that the training time reduction is less drastic than the parameter reduction due to the computation of gradients for early downsampling layers. The comment suggests that this observation should be revised or deleted from the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion on training time reduction and parameter reduction. It points out that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers. This observation is relevant and could be a source of confusion or misinterpretation in the discussion. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the discussion. While it highlights a potential problem, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a weakness but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the problem being discussed is specific to binding affinity prediction or applies to other downstream tasks. It implies that the authors should provide a justification for why the problem is specific to binding affinity prediction. However, the comment does not explicitly instruct the authors to provide this justification or specify how it should be presented. While the action is implied, it is not concrete, as the authors are left to infer what additional information is needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem to other downstream tasks or whether it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a justification or explanation of why the problem is specific to binding affinity prediction. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. This is a relevant point that could prompt the authors to clarify the scope and limitations of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific analyses or solutions could be proposed. The comment lacks actionable details, leaving the authors uncertain about how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the handling of rumors generated by GPT, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the need for further analysis or solutions regarding the challenges of detecting rumors generated by GPT, and it questions the rationale behind why GPTgenerated rumors are similar to natural rumors. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect, suggesting that Artificial Rumor should be about the same difficulty as Natural Rumor. The comment provides a logical reasoning by pointing out that Artificial Rumor is also written by humans, which should make it similar to Natural Rumor. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the rationale themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It points out that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, yet the experimental result shows the opposite. This feedback is valuable as it highlights a potential area for further analysis or discussion in the paper. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or what additional analyses could be conducted. Overall, the comment is 3 as it directs the authors to consider a specific aspect of their work that could be improved, but it lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, stating that it is limited and not about a formal and principled solution but rather about heuristics. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution of the paper, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. This feedback highlights an area where the paper could be improved by providing a more comprehensive and rigorous approach to the technical contribution. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the heuristics should be improved. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and concrete, as it instructs the authors to adjust the font size to make it more readable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a factual observation about the font size in Figure 6, which does not contain any subjective claims, opinions, or suggestions. It is a descriptive statement that requires no verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is 3 as it identifies a specific issue with the font size in Figure 6, which could impact readability. However, it does not provide any suggestions or guidance on how to address this issue, such as recommending a specific font size or discussing potential consequences of the small font. While the comment points out a potential problem, it lacks actionable advice that could help the authors improve their draft. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the probability mass function (PMF) is not being fully utilized in the experimental setting and recommends considering various PMFs for each learner class. It also mentions that the quasiuniform distribution used in MixBoost is dependent on a single parameter and suggests that individual consideration of each learner class would add depth to the experimental setting. However, the comment does not provide specific guidance on how to implement this suggestion or which PMFs to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"probability mass function\" and \"MixBoost,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the probability mass function is not being fully utilized and recommends considering various probability mass functions for each learner class. This provides clear guidance on what needs to be addressed in the experimental setting. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the probability mass function is not being fully utilized in the experimental setting and suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. The reviewer provides a logical reasoning by pointing out that the quasiuniform distribution used in MixBoost is dependent on a single parameter and that individual consideration of each learner class would be beneficial. However, the comment lacks specific examples or references to support the claim that the quasiuniform distribution is not ideal. This makes the claim 3, as the authors would need to make a logical inference to understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setting, noting that the probability mass function is not being fully utilized in the MixBoost method. It suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. While the comment highlights a potential area for improvement, it lacks specific guidance on how to implement this suggestion or which probability mass functions to consider. The feedback is 3 as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this issue, provide additional context, or clarify their methodology. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this issue affects the paper\"s conclusions or analysis. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point questions the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair or inappropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. This is an important point that could impact the interpretation and conclusions of the study. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. However, the comment does not provide explicit instructions on how to incorporate these references or discuss the connections. While the authors can infer that they need to include these references and discuss the connections, the lack of concrete guidance on how to do so makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, such as [a], which are relevant to the topic of the paper. It also suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper is missing relevant references, specifically mentioning [a], which uses supervised learning in QBF solving. The reviewer claims that this reference is relevant to the topic of the paper, especially since QBF generalizes SMT. However, the comment does not provide specific details or reasoning on why [a] is relevant or how it relates to the paper\"s topic. This lack of detailed justification makes the claim 3, as the authors would need to infer the connection themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This feedback is clear and actionable, as it directs the authors to include relevant references and explore potential connections with the existing literature. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these references or discuss the connections effectively. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It also suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide specific guidance on how to do so or what specific alternative relationships to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training process and the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests exploring alternative relationships and provides a reference to a related work for further consideration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss is replaced by other relationships. The reviewer supports this claim by referencing a related work, \"Learning the Pareto Front with Hypernetworks,\" which suggests that the mono tonic relationship can be replaced by other relationships. However, the comment does not provide detailed reasoning or examples from the referenced work to fully substantiate the claim. This makes the comment 3, as it provides a reference but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific aspect of the training process that could be improved by exploring alternative relationships to the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this could lead to a continuous parameterization of the Pareto Front. The comment also references a related work, \"Learning the Pareto Front with Hypernetworks,\" which provides a potential direction for further exploration. While the comment highlights an area for improvement, it lacks specific guidance on how to implement this exploration or what alternative relationships to consider. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what aspects of the computation cost or running time should be compared, nor is there any suggestion for how the authors might address this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost or running time should be compared or how the authors might address this issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time, but it does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the comparison in terms of computation cost or running time, which could be an important aspect of the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the computation cost or running time should be compared. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a specific suggestion for improvement, it lacks concrete guidance on how to implement this change or what specific aspects of the paper need to be revised to address this issue. The authors are left with a general idea of what to do but without detailed instructions on how to execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, suggesting that the examples chosen do not convincingly demonstrate problems requiring interprocess communication. The comment provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the examples chosen in the paper do not convincingly demonstrate problems requiring interprocess communication, particularly in the second paragraph where samplingbased Bayesian methods are mentioned. The reviewer suggests that the paper\"s results are irrelevant in this context and recommends focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the current examples are inadequate. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that the examples chosen do not convincingly demonstrate problems requiring interprocess communication. It suggests that the paper\"s results are irrelevant in this context, particularly in the second paragraph where samplingbased Bayesian methods are mentioned. The reviewer provides a specific recommendation to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This feedback is clear and actionable, offering a concrete direction for the authors to improve their draft by focusing on more relevant examples and addressing the issue of interprocess communication. However, the comment could be more helpful if it provided additional context or examples of how the authors might apply this suggestion to their work. Overall, the comment is 4 as it guides the authors toward a more focused and relevant approach."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address these concerns or improve the paper in response. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the privacy preservation issue and the example of traffic signal control, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate these claims. Without detailed justification or examples, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. While the comment identifies a potential weakness in the paper\"s argument, it lacks specific guidance or suggestions on how the authors might address this issue or improve the paper. The feedback is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of fairness in the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pretraining module. It suggests that to ensure fairness, the authors should compare CPEF with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design of CPEF. This feedback provides a clear and explicit action for the authors to take, specifying which model to compare and why. The suggestion is concrete, as it directly instructs the authors on how to improve the fairness and clarity of their comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of fairness in the comparison between CPEF and PMEF. The comment provides a clear suggestion to compare CPEF with another pretrained model, such as ExpertBert, to ensure fairness and highlight the advantages of the innovative pretraining module design of CPEF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF is unfair due to the lack of a pretraining module in PMEF. The reviewer suggests that to ensure fairness, the authors should compare CPEF with another pretrained model, such as ExpertBert. This claim is 3 as it logically argues that a fair comparison should include models with similar pretraining capabilities. However, the comment lacks specific examples or references to support the claim that ExpertBert is a suitable alternative for comparison. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It points out that PMEF lacks a pretraining module, which makes the comparison unfair. The reviewer provides a clear and actionable suggestion to ensure fairness by recommending a comparison with another pretrained model, such as ExpertBert. This feedback is valuable as it guides the authors on how to improve the fairness and clarity of their comparison, which is crucial for the validity of their findings. However, the comment could be more helpful if it explained why ExpertBert is a suitable alternative for comparison or provided additional context on the implications of this comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and fix the hyperlinks. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hyperlinks for footnotes 3 and 4 do not work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address to improve the quality of their draft. By pointing out this issue, the reviewer helps the authors ensure that their references are functional and accessible, which is an important aspect of academic writing. However, the comment could be more helpful if it provided additional guidance on how to verify the hyperlinks or suggested alternative solutions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is explicit and provides concrete details on what changes need to be made, making it 5. The authors know exactly what needs to be revised to improve the clarity of their discussion.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This provides full grounding as it explicitly mentions the modeling section and the figure, allowing the authors to identify the exact parts of the paper that need revision. The comment is also specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples of what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure is misleading, suggesting that the Label Embeddings are the output of the encoder. This feedback is 4 as it provides logical reasoning and specific examples to support the claim. However, the comment could be strengthened by referencing specific sections or figures to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the clarity of the discussion in the modeling section. It suggests revising the architecture section to better formalize the model and clarify the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is 5 as it guides the authors on how to improve the clarity and accuracy of their discussion, which is crucial for effective communication of their work. By addressing these specific points, the authors can significantly enhance the comprehensibility and impact of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph that clarifies it. While the comment provides a specific suggestion to improve the clarity of the section, it does not offer detailed guidance on how to achieve this clarity or what specific changes should be made to the description. The action is implicit and somewhat vague, as the authors need to infer that they should start the section with the clarifying paragraph. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, suggesting that it is hard to understand and recommending starting the section with the final paragraph that clarifies it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand and suggests starting the section with the final paragraph that clarifies it. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand. It suggests starting the section with the final paragraph that clarifies the description, providing a clear and actionable suggestion for improvement. This feedback is 3 as it points out a specific area that needs attention and offers a concrete way to address it. However, it could be more helpful if it included additional context or examples to help the authors understand the challenges in the current description. Overall, the comment is 3 as it provides a clear direction for improvement but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it implies that the authors should consider this option, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not specify which part of the paper this limitation or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an alternative approach, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not provide any supporting evidence, reasoning, or references to justify why the current approach is limited or how attentionbased training might be beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples on how to implement this change or what benefits it might offer. The comment is 3 as it points out a potential direction for improvement, but it could be more beneficial with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes should be made to the tables. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggesting that one type (the column header) should work. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any supporting evidence, reasoning, or references to justify why this division is problematic or how it could be improved. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any actionable feedback or suggestions for improvement. Without additional context or guidance, the authors are left without a clear understanding of what changes, if any, should be made to address this concern. As a result, the comment is not helpful, as it lacks depth and does not assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. It provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment does not explicitly instruct the authors to use these methods or provide guidance on how to integrate them into their work. While the suggestion is clear, the lack of explicit instructions or detailed guidance on implementation makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attack methods\" and \"toy setting with classification tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper does not consider other classical attack methods in NLP and suggests specific examples from other papers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment lacks detailed reasoning or references to support why these methods are considered more effective or why the current methods are inadequate. This makes the claim 3, as the authors would need to further explore the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the attack methods used are naive and that the paper does not consider other classical attack methods in NLP. It provides specific examples of alternative methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. This feedback is clear and actionable, as it guides the authors to consider a broader range of attack methods that could enhance the robustness and generalizability of their work. However, the comment could be more helpful if it offered additional insights or suggestions on how to integrate these alternative methods into the paper. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the impact of mitigation methods or suggestions for improving image quality. As a result, the authors are left without any clear direction on how to improve their draft in response to this comment. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation methods on the image generation capabilities of diffusion models, suggesting that this could lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the mitigation methods affecting image quality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, which could lead to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their mitigation methods. The comment highlights a potential problem but lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance on how to address these concerns or what specific steps the authors should take to mitigate these risks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper this concern is related to, such as specific sections or experiments where this issue might arise. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specific guidance on how to address these concerns or what steps to take to mitigate the risks. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to studies or literature that demonstrate similar issues or offer suggestions on how to address them. As a result, the claim is 3, as it provides a logical concern but lacks the necessary evidence or references to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. While the comment identifies a significant issue, it lacks specific guidance or suggestions on how the authors might address this concern or mitigate the risks. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise about the dominance of function words over content words in a Japanese sentence. However, the comment lacks specificity regarding what aspect of the dominance is surprising or how it might impact the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it lacks any actionable feedback or suggestions for improvement. Without further explanation or context, the authors are left without a clear understanding of what aspect of this observation is relevant to their work or how it might impact their analysis. As a result, the comment does not provide any meaningful guidance for the authors to enhance their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, [1] and [2], which discuss the properties of kmeans clustering and its applicability to different datasets. This explicit suggestion and the inclusion of references provide clear guidance on what the authors should consider as a more reasonable baseline. The action is concrete, as it specifies the change needed and offers concrete references to support the claim. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this baseline is used. The comment does provide references to external works, which could help the authors identify the relevant section, but without explicit mention, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer supports this claim by referencing two external sources, [1] and [2], which discuss the properties of kmeans clustering and its applicability to different datasets. These references provide a logical basis for the claim, making it 4. However, the comment could be strengthened by further explaining why the average is not ideal or how the minimum objective might be more appropriate. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion to improve the paper by recommending the use of the minimum kmeans objective over multiple seeds as a baseline instead of the average. This feedback is actionable and offers a clear direction for the authors to enhance their methodology. The reviewer supports the suggestion by referencing two external sources, [1] and [2], which provide additional context and justification for the recommendation. This level of detail and clarity makes the comment 5, as it guides the authors toward a more robust and accurate baseline for their analysis. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment implies that the authors should clarify these differences, it does not provide specific guidance on how to do so or what aspects of the task should be clarified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to clarify the differences against Argument Mining/Discussion Summarization, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the task described in the paper is closer to Argument Mining rather than Summarization. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why the task is closer to Argument Mining, making it difficult for the authors to understand and address the critique. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment identifies a potential issue with the task categorization, it lacks specific guidance on how to clarify these differences or what aspects of the task should be emphasized. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It suggests that the authors clarify this point and provides a specific example of where the confusion arises (lines 155160). Additionally, it questions the motivation of reducing entropy to make predictions more confident, as this contradicts the paper\"s goal of calibrating networks. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the confusion and address the contradiction in the motivation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 155160,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the relationship between temperature calibration and uncertainty calibration, as well as the contradiction in the motivation of reducing entropy. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. The reviewer questions whether both are required for uncertainty calibration, as stated in lines 155160, while also pointing out that temperature calibration is applied after training. The comment suggests that the authors clarify this point. Additionally, it questions the motivation of reducing entropy to make predictions more confident, as this contradicts the paper\"s goal of calibrating networks. The comment provides logical reasoning and references specific lines in the paper to support its claims, making it 4. However, it could be strengthened by providing more detailed examples or references to external works that address similar issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. This is a clear and actionable observation that the authors should address to clarify their work. Additionally, the comment questions the motivation of reducing entropy to make predictions more confident, as this contradicts the paper\"s goal of calibrating networks. This feedback is valuable as it highlights a potential inconsistency in the paper that the authors need to address to improve the clarity and coherence of their work. Therefore, the comment is 4, as it provides clear and actionable guidance for the authors to enhance the clarity and consistency of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of an important reference, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. It also highlights the importance of discussing similarities and differences with Lista and placing the paper in appropriate context. While the comment identifies the missing reference and the need for contextualization, it does not provide specific guidance on how to integrate these elements into the paper. The action is clear but lacks detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing reference, \"Lista,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the importance of discussing similarities and differences with the reference and placing the paper in appropriate context. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. The reviewer suggests that the paper should discuss similarities and differences with \"Lista\" and place itself in appropriate context. While the comment identifies the missing reference, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of discussing similarities and differences, and the contextualization of the paper. Therefore, the comment is 3, as it provides a clear direction but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies a critical omission in the paper, specifically the absence of an important reference, \"Lista,\" which is relevant to the idea of unrolling. It highlights the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This feedback is clear and actionable, as it directs the authors to include a missing reference and provide a more comprehensive discussion of their work in relation to existing literature. However, the comment could be more helpful if it offered specific suggestions on how to integrate these elements into the paper or provided examples of how similarities and differences might be discussed. Overall, the comment is 4 as it guides the authors toward improving the clarity and contextualization of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the linear program in Theorem 3 needs to be explained more intuitively. It acknowledges that this is a main theorem but suggests that providing an explanation of the objective and constraints in (3) would be beneficial for the reader. This feedback is clear and provides a concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of the objective and constraints in (3) of the linear program. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 needs to be explained more intuitively. While it acknowledges that this is a main theorem, it does not provide specific reasoning or examples to support why the explanation is necessary or how it would benefit the reader. The comment lacks detailed justification or references to common practices or standards, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need to provide a more intuitive explanation of the linear program in Theorem 3. It acknowledges that this is a main theorem but emphasizes the importance of explaining the objective and constraints in (3) to enhance the reader\"s understanding. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work that could enhance its clarity and accessibility. However, the comment could be more helpful if it provided examples or suggestions on how to present this explanation more effectively. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the FLOT cost matrix in Algorithm 1 is not defined, which is a clear and explicit action for the authors to take. The comment provides a specific issue to address, indicating that the cost matrix should be defined. However, it does not offer guidance on how to define it or provide examples of what such a definition might look like. While the action is explicit, the lack of concrete details on implementation makes the comment somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"FLOT cost matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of a definition for the FLOT cost matrix in Algorithm 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their work. However, the comment lacks depth and does not provide suggestions on how to define the matrix or what implications this might have for the paper. While it highlights an important area for improvement, it could be more helpful with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the algorithm, specifically regarding the use of multiple connected nodes and the computation of \"avg.\" The reviewer suggests that the authors clarify these points and provide more information on \"j\"\" and \"i\".\" While the comment identifies areas that need clarification, it does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to improve the clarity of the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as clarifying the use of multiple connected nodes and the computation of \"avg,\" as well as the meaning of \"j\"\" and \"i\".\" This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the use of multiple connected nodes and the computation of \"avg.\" It also questions the meaning of \"j\"\" and \"i\".\" While the comment identifies areas of confusion, it does not provide specific examples or references to support the claim that these elements are unclear. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several areas of confusion and potential improvement in the paper, specifically regarding the clarity of Algorithm 2 and the use of multiple connected nodes. It points out that \"avg\" is computed but not used, and questions the meaning of \"j\"\" and \"i\".\" While the comment provides some insight into areas that need clarification, it lacks depth and does not offer specific suggestions or guidance on how to address these issues. The authors are given a general direction to clarify the algorithm, but the comment could be more helpful if it provided more detailed feedback or examples of how to improve the clarity. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on the definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. It also recommends showing the advantages of the proposed method compared to existing methods. While the comment provides clear and specific actions for the authors to take, it does not offer detailed guidance on how to present this evidence or what specific aspects to focus on. The authors are given a clear direction but may need to infer the exact steps to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the definition and suggests providing evidence to support the sparsity assumption across various noisy cases. Additionally, it recommends comparing the proposed method with existing methods to show its advantages. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It suggests that the authors provide evidence to support the sparsity assumption across various noisy cases and recommends comparing the proposed method with existing methods to show its advantages. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim that the sparsity assumption is not wellfounded. The suggestion to provide evidence is logical, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the definition of the sparsity of the residual term in the paper. It suggests that the authors provide evidence to support the sparsity assumption across various noisy cases and recommends comparing the proposed method with existing methods to show its advantages. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and robustness of their work. By addressing these points, the authors can enhance the understanding and credibility of their method. However, the comment could be more helpful if it provided specific examples or references to existing methods that demonstrate the advantages of the proposed method. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the terminology. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the term \"connectivity,\" explaining that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"connectivity,\" noting that it is misleading as it does not refer to the structural connections between the brain and body. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and precision of the terminology. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what alternative terminology might be more appropriate. While it points out a relevant concern, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what aspects are missing or how to address these issues. The authors are left to infer that they need to improve the clarity, quality, novelty, and reproducibility of their work, but without concrete suggestions or examples, they may struggle to know exactly what changes to make. The comment is vague and lacks explicit instructions, making it barely actionable.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details, making it difficult for the authors to pinpoint the exact sections that need improvement. Additionally, the comment references \"Clarity, Quality, Novelty And Reproducibility,\" but does not provide specific examples or details from these sections. This lack of specificity and grounding makes it challenging for the authors to understand and address the issues effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas that need improvement, but without further elaboration or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas where the paper is lacking, including clarity, quality, novelty, and reproducibility. However, it does not provide specific examples or detailed feedback on what aspects of these categories are missing or how they could be improved. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that the authors should address these issues, but without further guidance or suggestions, the comment lacks depth and actionable advice. This makes it 3, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance on what the authors should do to improve their draft. It suggests that the authors should study the essentialness of using an orthogonal matrix weight for the local window MLP, which is not currently presented in the paper. This feedback is clear and concrete, as it specifies the need for further exploration and validation of the orthogonal matrix weight. The authors know exactly what needs to be done to address this point, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the importance of studying the essentialness of using an orthogonal matrix weight for the local window MLP. The comment provides a clear direction for the authors to improve their draft by suggesting that they should explore the validity of using an orthogonal matrix weight. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Step 2 and Step 3 are important for validating the use of an orthogonal matrix weight in the local window MLP. The reviewer suggests that Step 2 can be done regardless of the weight matrix, and that Step 3 is crucial for validating the use of an orthogonal matrix weight. However, the comment lacks specific examples or references to support these claims, making it 3. The authors may find it challenging to fully understand and address the claims without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of exploration into the essentialness of using an orthogonal matrix weight for the local window MLP. It suggests that Step 2, which involves the transpose of the matrix, can be done regardless of the weight matrix, and that Step 3 is crucial for validating the use of an orthogonal matrix weight. The comment provides a clear and actionable suggestion for the authors to further explore the implications of using an orthogonal matrix weight, which could enhance the paper\"s contribution. However, the comment could be more helpful if it offered specific examples or references to support the claim about the importance of Step 3. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any explicit or implicit actions for the authors to take, such as suggesting further analysis or experiments to address the issue. The comment lacks guidance on how the authors might investigate or resolve the drop in accuracy. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the drop in accuracy after a certain order around 45 and asks if it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the drop in accuracy in Figure 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any suggestions or guidance on how the authors might address this issue or investigate the cause of the drop in accuracy. While it prompts the authors to consider a potential explanation, such as overfitting, it lacks actionable feedback or detailed analysis that could help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the models and datasets used are too toylike and recommends using CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also asks if there are foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides specific recommendations for datasets and models, it lacks concrete guidance on how to implement these changes or what specific aspects of the language tasks should be addressed. The action is explicit but somewhat vague, as the authors know what changes to make but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for CIFAR100, ResNet 34 or 50, and ViTtiny or small, and raises questions about language tasks. However, the comment does not provide specific guidance on how to address these issues or what aspects of the language tasks should be considered. Therefore, it is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the models and datasets used are \"toylike\" and suggests that the authors should consider using CIFAR100, ResNet 34 or 50, and ViTtiny or small. The reviewer also asks about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides a logical reasoning for the need for more diverse datasets and models, it lacks specific examples or references to support the claim that the current models are too toylike. The suggestion to use CIFAR100 is a specific example, but the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks sufficient evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the models and datasets used in the paper, noting that they are too toylike and suggesting the inclusion of more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also raises a question about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides clear and actionable feedback on improving the dataset and model selection, it could be more helpful if it offered specific guidance on how to address the language task challenges or provided examples of how other studies have addressed similar issues. Overall, the comment is 4 as it directs the authors to make significant improvements in their work, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of natural ablation studies, specifically mentioning the impact of pretraining on scratchGAN. It suggests that this is a crucial baseline to include, especially given the central argument against pretraining. The comment also includes minor comments and questions, such as the need for more discussion on the results. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these changes or what specific aspects of the ablation studies should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of natural ablation studies, specifically mentioning scratchGAN and the need for a baseline with pretraining. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a baseline with pretraining and the need for more discussion on the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some natural ablation studies are missing, specifically mentioning the impact of pretraining on scratchGAN. The reviewer claims that this is a crucial baseline to include, as it relates to the central argument against pretraining. However, the comment lacks specific examples or detailed reasoning to support why this baseline is crucial or how it would impact the central argument. The suggestion is 3, as it provides a direction for improvement but requires more detailed justification to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of natural ablation studies, particularly the impact of pretraining on scratchGAN. This is a crucial baseline that the authors should consider, as it relates to the central argument against pretraining. Additionally, the comment includes minor comments and questions, such as the need for more discussion on the results. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions on how to conduct these studies or what aspects of the results should be discussed. Overall, the comment is 4 as it directs the authors to a critical area for improvement and offers some guidance on enhancing their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, and that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. The reviewer suggests that these decisions should be explained in the paper to help readers understand them without needing to check the code. The comment provides clear and concrete actions for the authors to take, ensuring that they know exactly what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the handling of comparisons between episodes with different lengths and the use of padding to compare trajectories. The comment provides a detailed explanation of the issue, including the use of a normalization factor of 1/T and how this affects the distance metric. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides a detailed explanation of the issue, noting that the authors pad the shorter sequence by replicating its last state to compare both trajectories. Additionally, the comment points out that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. This reasoning is supported by logical reasoning and specific examples, making the claim 4. However, the comment could be strengthened by providing references to similar issues in the literature or additional examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the paper, namely the lack of clarity regarding how the authors handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It provides a detailed explanation of the problem, noting that the authors pad the shorter sequence by replicating its last state to compare both trajectories, and that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. This feedback is clear and actionable, as it guides the authors to clarify their methodology and provide additional explanation in the paper to help readers understand the implications of these decisions. By addressing these points, the authors can significantly improve the clarity and comprehensibility of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential oversight in the experiment, noting that the Vision Transformer was not considered and questioning its applicability to larger image datasets like ImageNet. It also raises a question about the pruning strategy in selfattention layers. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should consider including the Vision Transformer and address the pruning strategy question, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of the Vision Transformer model and raises questions about its applicability to larger datasets like ImageNet. The comment also questions the pruning strategy in selfattention layers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment did not consider the Vision Transformer, which is an important SOTA model in image classification. It also questions whether such a technique would still work for larger datasets like ImageNet. The comment suggests that the pruning strategy in selfattention layers might differ. While the comment identifies a potential oversight, it lacks specific examples or references to support the claim that the Vision Transformer is an important model or that the pruning strategy would differ. This makes the claim 3, as the authors would need to make a significant effort to understand and address the critique.", "helpfulness_rationale": "The review comment identifies a potential oversight in the experiment by noting the absence of the Vision Transformer, an important SOTA model in image classification. It also raises a question about the applicability of the technique to larger datasets like ImageNet. Additionally, it questions whether the pruning strategy in selfattention layers would differ. This feedback is 3 as it points out a gap in the experiment and suggests potential areas for improvement. However, it lacks specific guidance or suggestions on how to address these issues, such as recommending the inclusion of the Vision Transformer or providing more details on the pruning strategy. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of comparison against baselines and notes that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. It suggests that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparison (or codesearch). While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include comparisons against baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but does not offer specific steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison against baselines and the need for architectureagnostic similarity comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparison against baselines and that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. The reviewer supports this claim by referencing the widelyunderstood nature of binary analysis applications and the existence of architectureagnostic similarity comparison (or codesearch) in many papers. This provides a logical basis for the claim, but the comment could be strengthened by providing specific examples or references to these papers. Therefore, the comment is 3, as it provides a logical reasoning but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of comparison against baselines and the limited scope of the functionality similarity comparison study. It highlights that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparison (or codesearch). This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific suggestions on how to address this gap, such as which baselines to consider or how to extend the current study to include them. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the preprocessing in SI 6.5 is identical to that in Mnih et al. [7], but the evaluation is slightly different because no human starts are used. This is a clear and direct action for the authors to take, as it provides a specific point to address in their draft. The comment is concrete, as it specifies the exact part of the paper where the mention should be made and the issue with the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to mention that the preprocessing is identical to that in Mnih et al. [7], despite the evaluation being slightly different due to the absence of human starts. This provides clear guidance on what the authors need to include in their paper to address the reviewer\"s concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in SI 6.5 is slightly different from that in Mnih et al. [7] because no human starts are used. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the evaluation in SI 6.5 is slightly different from that in Mnih et al. [7] because no human starts are used. This is a clear and actionable point that the authors can address to improve the clarity and accuracy of their work. By mentioning the difference in evaluation methods, the comment provides a concrete suggestion for the authors to make their work more transparent and comparable with related work. However, the comment could be more helpful if it offered additional guidance on how to address this issue or suggested ways to improve the clarity of the evaluation section. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the figures, including the size of the text, the clarity of the inputs and outputs, and the selfcontained nature of the captions. It provides a clear and concrete action for the authors to take, suggesting that they make the figures more readable by increasing the font size, explaining the inputs and outputs, and ensuring that the captions are selfcontained. This feedback is explicit and provides concrete details on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the small font size, unclear inputs and outputs, and the lack of selfcontained captions. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures in question are difficult to parse due to small font size, unclear inputs and outputs, and lack of selfcontained captions. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support why these elements are problematic or how they impact the clarity of the figures. The lack of specific examples or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the claim is 3, as it provides some basis but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that they are difficult to parse due to small font size, unclear inputs and outputs, and lack of selfcontained captions. It provides clear and actionable feedback by suggesting that the authors make the figures more readable by increasing the font size, explaining the inputs and outputs, and ensuring that the captions are selfcontained. This feedback is detailed and constructive, offering the authors a clear path to improve the clarity and accessibility of their figures. However, the comment could be more helpful if it provided examples of how these improvements might be achieved or suggested specific ways to enhance the captions. Overall, the comment is 4 as it effectively guides the authors on how to address the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while the authors claim advantages over previous work in terms of efficiency, the paper does not report any metric to substantiate this claim. This implies that the authors should include metrics to demonstrate the efficiency of their proposed method. However, the comment does not specify which metrics should be used or how they should be presented, leaving the authors with a general direction but without concrete guidance on execution. The action is implicit and somewhat vague, as it highlights a gap in the paper but does not provide detailed instructions on how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss advantages over previous work in terms of efficiency. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of metrics to demonstrate the efficiency of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method. However, it does not provide any supporting evidence or references to substantiate this claim. Without specific examples or comparisons to previous work, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while the authors claim advantages over previous work in terms of efficiency, they do not report any metrics to substantiate this claim. This is a critical point that could impact the credibility of the paper, as it lacks empirical evidence to support the claim. The comment highlights a clear area for improvement, suggesting that the authors should include metrics to demonstrate the efficiency of their proposed method. However, it does not provide specific guidance on which metrics to use or how to present them, leaving some room for interpretation. Overall, the comment is 3 as it points out a critical issue but could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to expand the contribution or what specific aspects of the paper could be strengthened. As a result, the authors are left without any clear direction on how to address the reviewer\"s concerns. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered limited or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment lacks specific reasoning or evidence to support why the contribution is considered limited. It does not provide examples, comparisons, or references to similar work that might substantiate the claim. As a result, the claim is 3, as it requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide specific feedback or suggestions on how the authors could enhance the contribution or what aspects of the paper could be improved. The comment lacks actionable guidance or detailed critique, leaving the authors without clear direction on how to address the reviewer\"s concerns. As a result, the feedback is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment provides clear and direct actions, it does not specify how to implement these details or what specific information should be included. The authors are left to infer the exact steps to take, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing more details about the statespace, whether it is finite or continuous, and the actions involved. The comment also questions the space in which theta lies and suggests that the authors should be precise in their explanations. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for more details about the statespace, whether it is finite or continuous, and the actions involved. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a lack of detail in the paper, specifically asking for more information about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment highlights areas where the paper could be improved, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out potential gaps in the paper, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the method\"s effectiveness on general reasoning tasks or suggestions for potential improvements. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method are not effective on general reasoning tasks or how they could be improved. Without clear guidance on where to focus the revision or what changes are needed, the authors are left without a clear path for action. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential weakness in the method\"s effectiveness on general reasoning tasks compared to mathematical reasoning. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the method\"s performance. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The reviewer also mentions that the authors acknowledge this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the proof technique and its applicability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. The reviewer provides a specific reference to Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve the proof technique. The feedback is 3 as it points out a specific area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional molecule generation framework based on GDSS, which was recently proposed in [2], as a baseline. The comment provides explicit actions for the authors to take, such as including the continuous diffusion model as a baseline and considering the conditional framework based on GDSS. The suggestions are concrete and provide clear guidance on how to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison of the continuous diffusion model (e.g., GDSS) as a baseline in Table 3 and the suggestion to use a conditional molecule generation framework based on GDSS. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. The reviewer provides a logical reasoning by pointing out that the continuous diffusion model should be considered as a baseline for the conditional generation task. Additionally, the comment suggests using a conditional molecule generation framework based on GDSS, which was recently proposed in [2]. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by referencing [2] directly or providing more detailed reasoning on why GDSS should be considered a baseline. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional molecule generation framework based on GDSS, which was recently proposed in [2], as a baseline. This feedback is valuable as it directs the authors to include a relevant baseline and provides a specific suggestion for improvement. However, the comment could be more helpful if it explained why GDSS is a suitable baseline or how the proposed conditional framework would enhance the analysis. Overall, the comment is 4 as it offers clear and actionable guidance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation is the best choice due to its ability to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment does not provide explicit instructions or concrete steps on how to implement this change or what specific aspects of the current approach need to be adjusted. While the suggestion is clear, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this change could be implemented. The comment also lacks specificity regarding why LiDARbased segmentation is considered the best choice or how it would improve the paper. Without explicit references or detailed reasoning, the authors cannot confidently determine which parts of the paper need attention or how to address the suggestion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice for the downstream task than object detection, based on the reviewer\"s personal belief. The comment provides a rationale for this opinion by stating that LiDARbased segmentation can learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the reasoning is logical, it could be strengthened with more detailed evidence or references to support the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides a personal opinion on the choice of downstream task, suggesting that LiDARbased segmentation is a better option than object detection. The reviewer provides a rationale for this suggestion by stating that LiDARbased segmentation can learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific guidance or suggestions on how the authors might implement this change or what aspects of their current approach might need adjustment. While the feedback provides a direction for improvement, it does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Principle (IPO). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this contradiction or suggestions for clarifying the issue. Without actionable advice or steps, the authors are left without a clear understanding of what changes, if any, are needed to resolve this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the objective of Equation (12) and its potential contradiction with the Inverse Proportionality Principle (IPO). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the contradiction and suggesting a potential resolution, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the objective of Equation (12) is in contradiction with the Inverse Proportionality Principle (IPO). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Principle (IPO). This is a critical observation that could impact the validity and applicability of the work. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or clarify the contradiction. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to resolving it. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. While the comment explicitly states the action to take, it lacks concrete guidance on how to implement this change or why it is necessary. The authors are left to infer that they should make this change to enhance clarity, but without specific instructions or examples, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of \"t\" in the kernel and the suggestion to replace it with the size of T to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. However, the comment does not provide any reasoning or evidence to support why \"t\" is unclear or why replacing it with the size of T would improve clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests a specific improvement to the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of T. This feedback is actionable and provides a clear direction for the authors to enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why \"t\" is unclear or why the suggested change would improve clarity. Despite this, the suggestion is valuable and offers a straightforward way for the authors to improve their draft, making the comment 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the adaptation capacity. The comment lacks actionable details, such as recommending specific experiments or modifications to the model architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the adaptation capacity of the proposed visual memory in accommodating evergrowing concepts, specifically questioning whether the image encoder can produce meaningful embeddings for new concepts. However, it does not specify which part of the paper this concern is discussed in, making it weakly grounded. The comment is specific in questioning the adaptation capacity for concepts with different levels of geometric and semantic correlation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the adaptation capacity might be an issue. Without such evidence or examples, the claim remains somewhat speculative and difficult for the authors to address effectively. Therefore, the comment is categorized as 3, as it provides a logical basis for the concern but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, it acknowledges that for concepts where class label correlates more with semantics rather than geometry, the adaptation capacity might be less of a concern. While the comment identifies a potential weakness in the model\"s adaptability, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This is a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be added to, such as the results or discussion sections. The authors can infer that it relates to the experimental evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what needs to be added. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s contribution by including a comparison with established methods. However, the comment lacks specific examples or references to these stateoftheart loss functions, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification. This is a clear and actionable suggestion that could significantly enhance the paper\"s contribution by demonstrating the effectiveness of the proposed method against established benchmarks. By including this comparison, the authors can provide a more robust evaluation of their work and potentially improve its impact. However, the comment could be more helpful if it specified which loss functions should be included or provided examples of how they might be used in the comparison. Overall, the comment is 4 as it offers a concrete direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as giving the EF and D2 transcription norms, correcting specific phrases in the text, and addressing issues with repeated words in a table. Additionally, it points out a discrepancy in the DOI number and the link behind the title. These actions are clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and tables in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the phrasing in lines 029 and 188, the repeated words in Table 3, and the discrepancy in the DOI number. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of technical corrections and observations, such as correcting phrasing, addressing repeated words, and pointing out discrepancies in the DOI number. These are factual statements that do not involve subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of technical corrections and observations, which can be helpful for the authors in improving the clarity and accuracy of their work. The technical corrections include correcting phrasing and addressing discrepancies in the DOI number, which are specific and actionable improvements. Additionally, the comment points out repeated words in a table and suggests giving the EF and D2 transcription norms, which could enhance the clarity and completeness of the paper. However, the comment could be more helpful if it provided additional context or explanation for why these corrections are necessary or how they impact the overall understanding of the paper. Overall, the comment is 3 as it offers actionable suggestions but lacks depth in its guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the notation used in the paper, including the lack of definitions for M and N and the small font size in Figure 1. It provides a specific suggestion to spell out F.L.T.R in Figure 4 and recommends crossreferencing notation and figures to avoid confusion. While the comment does not explicitly instruct the authors to make these changes, the suggestions are clear and actionable, providing concrete steps for the authors to improve the clarity of their work. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as spelling out F.L.T.R in Figure 4 and making the text larger. The comment also suggests crossreferencing notation and figures to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation is confusing and suggests spelling out F.L.T.R in Figure 4. It also mentions that the font size in Figure 1 is too small to see and recommends crossreferencing notation and figures. While the comment identifies specific issues with the notation and figure presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to crossreference notation and figures is a logical step, but the comment could be strengthened with more detailed justification or examples. Therefore, the claim is 3, as it provides some support but lacks comprehensive evidence or explanation.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including confusing notation and font size in figures. It provides specific suggestions for improvement, such as spelling out F.L.T.R in Figure 4 and making the text larger in Figure 1. Additionally, it recommends crossreferencing notation and figures to avoid confusion. These suggestions are clear and actionable, offering the authors a concrete path to enhance the clarity and readability of their draft. However, the comment could be more helpful if it provided additional guidance on how to address the confusion in the notation or why it is currently unclear. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this confusion. The authors are left to infer that they should clarify the use of these variables, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1\" and \"inner loop in Phase 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of $p$ to denote both the phase mixing probability and a dummy variable, which could be confusing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"$p$\" to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential source of confusion in Algorithm1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This feedback is 3 as it points out a specific area that could be clarified or revised to improve the clarity of the paper. However, the comment lacks depth and does not provide suggestions on how to address the confusion or improve the clarity of the notation. While it highlights an issue, it does not offer actionable guidance for the authors to make improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper could benefit from a more detailed mathematical formulation, particularly in the appendix, to enhance the understanding of the approach. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and align it with the main contribution of the paper, which is improvements on the WiC task. The comment provides specific suggestions for reworking the figure to better align with the WiC task, offering actionable steps for the authors to improve their draft. The explicit nature of these suggestions and the concrete guidance on how to implement them make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for a more detailed mathematical formulation in the appendix and the confusion caused by the figure, including the need for text labels and better alignment with the main contribution of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description and figure could benefit from a more detailed (e.g., mathematical) formulation and that the figure is confusing due to its abstract nature and lack of alignment with the main contribution of the paper. The reviewer provides specific suggestions, such as adding text labels and aligning the figure with the WiC task, to improve clarity and understanding. These suggestions are based on logical reasoning and specific observations, making the claim 4. However, the comment could be strengthened by providing more detailed examples or references to similar works that have successfully addressed similar issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the paper\"s presentation, suggesting that the highlevel description could benefit from a more detailed mathematical formulation, particularly in the appendix. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and better align it with the main contribution of the paper, which is improvements on the WiC task. The comment offers a clear and constructive suggestion for reworking the figure to better serve its intended purpose, making it 5 for the authors to enhance the clarity and effectiveness of their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include additional benchmarking tasks outside of AitW. However, it does not provide specific guidance on which tasks should be included or how they should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should consider additional benchmarking tasks but are not given concrete steps on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which parts of the paper should include these tasks or which specific benchmarking tasks should be considered. Without explicit references to sections or specific tasks, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 and lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be beneficial. However, it does not provide specific examples or guidance on which tasks should be included or how they could enhance the paper. While it identifies a potential area for improvement, the lack of detailed suggestions limits its helpfulness. The authors are left to infer the specific tasks that could be included, making the feedback 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on the comparison results between YOSO and linformer in terms of iterationwise convergence and accuracy in downstream tasks. It also suggests that an explanation should be provided to analyze the difference in performance. The feedback is clear and provides specific actions for the authors to take, such as including the steps vs PPL of linformer with YOSO in Figure 4 and analyzing the performance difference. The explicit nature of the request and the concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments: YOSO takes linformer as baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the lack of comparison results between YOSO and linformer in Figure 4, and the need for an explanation of the difference in performance. The comment provides specific questions about the comparison results and suggests an analysis of the performance difference, which gives the authors clear guidance on what to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of comparison results between YOSO and linformer in Figure 4, specifically questioning the iterationwise convergence and accuracy in downstream tasks. The reviewer suggests that linformer demonstrates better performance in these tasks, and asks for an explanation of this difference. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that linformer performs better. The absence of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the pretraining experiment part does not provide steps vs PPL of linformer with YOSO in Figure 4. It also questions the comparison result of YOSO with linformer on iterationwise convergence and suggests an analysis of the performance difference in downstream tasks. Additionally, it points out that linformer demonstrates better accuracy in downstream tasks such as SST2. The comment provides clear and actionable feedback by asking for a comparison of YOSO and linformer, which would help the authors understand and potentially improve their results. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear path for enhancing their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. While it identifies the issue, it does not provide explicit guidance on how the authors should address this discrepancy. The comment lacks concrete suggestions or actions for the authors to take, such as suggesting a correction or clarification in the abstract or text. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and the text, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract statement about requiring the proposal distribution to upper bound the target everywhere is not true, as the authors themselves clarify in the text. However, the comment does not provide specific references or examples from the text to support this claim, making it difficult for the authors to verify the accuracy of the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a critical issue that could impact the validity of the paper\"s claims. However, the comment does not provide specific guidance or suggestions on how the authors might address this discrepancy or clarify the text. While it points out a potential problem, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an important issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion regarding the name \"PointNet\" in Figure 1, noting that it is not mentioned in the paper and that there is another paper with the same name. The reviewer suggests that the authors should clarify this issue by referring to the correct paper or providing additional context. While the comment explicitly identifies the problem and suggests a solution, it does not provide detailed guidance on how to implement this correction. The action is clear but somewhat vague in terms of execution, as the authors need to determine the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"PointNet,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of \"PointNet\" as it is not mentioned in the paper and there is another paper with the same name. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to [15] as \"PointNet\" is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to another paper titled \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which supports the claim by providing a clear example of the correct name. This reference helps verify the claim by providing a concrete example of the correct name, making the comment 4. However, the comment could be strengthened by further explaining why this confusion is problematic or how it affects the reader\"s understanding of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the labeling of \"PointNet\" in Figure 1, noting that it is confusing as the name does not appear in the paper and there is another paper with the same name. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their paper. By addressing this issue, the authors can improve the clarity and accuracy of their figure captions, which is valuable guidance for improving the draft. However, the comment could be more helpful if it suggested how to handle the confusion in the caption or provided additional context on the importance of accurate labeling. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the policy gradient and the phrases in question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without explicit references to sections or lines, the authors cannot confidently determine the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect, which could be a significant contribution to the paper. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas for improvement, it lacks specific guidance on how to address these issues or what specific clarifications are needed. The feedback is 3 as it highlights potential weaknesses and areas for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it does not explicitly instruct the authors to make a specific change or provide guidance on how to address this question, it does prompt the authors to consider the implications of these assumptions and the potential differences between them. The action is implicit but concrete, as the authors can infer that they need to explore the implications of these assumptions and potentially make a change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these assumptions are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry about the difference between these distributions, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm, seeking clarification on the difference between these distributions. While it identifies a potential area of confusion or misunderstanding, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, making it 2 for the authors in terms of improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the limitations of freezing the partitioning in the first iteration, which seems like a risky choice. This feedback is clear and provides a specific action for the authors to take, which is to address the limitations of this choice. The comment is concrete because it specifies the need for a discussion on the limitations, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the risky choice of freezing the partitioning in the first iteration and the need to discuss its limitations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. The reviewer suggests that at least the limitations of this choice should be discussed. However, the comment does not provide specific examples or references to support this claim, nor does it explain why freezing the partitioning is risky or what assumptions are being made. Without additional context or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without more detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of freezing the partitioning in the first iteration, noting that it may be a risky choice that assumes strong coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided additional context or examples of how the authors might address these limitations. Despite this, the feedback is 4 as it directs the authors to a critical area needing attention and improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this question or how to clarify the intent of the section. Without any actionable suggestions or advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper, such as a specific section or figure, is being addressed. It lacks specificity because it does not provide any details on what the reviewer finds unclear or what needs to be clarified about the intent of Section 5.2. Without explicit references or detailed feedback, the authors cannot effectively identify the areas that need improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question about the intent of Section 5.2, which does not contain any subjective claims, opinions, or suggestions. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which is a valid point as it could be unclear or misleading. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might clarify or improve this section. Without actionable feedback or detailed feedback, the authors are left without a clear path forward. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It acknowledges that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific guidance on what aspects need clarification or how to clarify them. It lacks concrete suggestions or examples of what the authors should focus on to improve the clarity of their approach. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It mentions that the paper gets into highly technical details too quickly without explaining the overall approach and its benefits. However, the comment does not specify which parts of the paper need clarification or provide detailed comments on what is unclear. Without specific references or examples, the authors cannot confidently determine which sections need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. The reviewer mentions that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or examples, the authors may find it challenging to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas where the paper needs clarification, specifically regarding the interaction between the approach and knowledge about verbs to overcome reporting bias. It points out that the paper dives into technical details too quickly without explaining the overall approach and its benefits, which can lead to confusion and lack of understanding. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to clarify these aspects. The authors are given a general direction to improve the clarity of their approach but are not provided with actionable steps or detailed feedback to fully address the issues. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity. This feedback provides clear and concrete actions for the authors to take, such as creating a new section or expanding the existing one to address the clarity issues. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, including the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This claim is 3 as it logically suggests that such clarification would enhance the clarity of the paper, particularly around the assumed whitebox access to the victim model. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the threat model. It suggests that the authors should define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity of their work. By suggesting a dedicated section for this information, the reviewer offers a practical way to improve the paper\"s presentation and understanding. However, the comment could be more helpful if it included specific examples or references to similar works that have successfully addressed this issue. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests an explanation for the decision to use early stopping only based on link prediction accuracy. It does not provide suggestions for alternative explanations or methods to consider. The action is clear and concrete, as the authors know exactly what needs to be addressed: providing an explanation for the decision. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for the decision to use early stopping only based on link prediction accuracy. The comment provides a clear direction for improvement by asking for an explanation of the decisionmaking process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping only based on link prediction accuracy, suggesting that an explanation is needed. However, it does not provide any reasoning or evidence to support why this decision might be problematic or inadequate. Without additional context or examples, the claim lacks verifiability, as it does not provide a clear basis for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further explanation, namely the decision to use early stopping only based on link prediction accuracy. It suggests that the authors should provide an explanation for this choice, such as why not to average with type accuracy. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their methodology. However, the comment could be more helpful if it provided additional context or examples of alternative approaches that could be considered. Overall, the comment is 4 as it guides the authors toward improving the clarity and transparency of their methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It explicitly asks the authors to provide concrete details on how to set a reasonable classimbalanced task, given the few examples available for each class. This request is clear and specific, providing the authors with a direct action to take in order to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how to set a reasonable classimbalanced task in the fewshot learning setting, given the limited number of examples per class. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement \"sampling classimbalanced tasks\" in the context of fewshot learning, where each class has only a few examples. The reviewer asks for concrete details on how to set a reasonable classimbalanced task in this setting. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It questions how to set a reasonable classimbalanced task given the limited number of examples per class. The comment is 3 as it prompts the authors to provide concrete details on how they address this issue, which is an important aspect of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to set a reasonable classimbalanced task. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the chatgpt baseline is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a clear action to test a fewshot approach and includes a suggestion for enhancing the baseline, it lacks specific guidance on how to implement these changes or what specific aspects of the fewshot approach should be tested. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the chatgpt baseline, suggesting that it is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. However, the comment does not specify which part of the paper discusses the chatgpt baseline or the fewshot approach, making it weakly grounded. The suggestion to include discourse relation information is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the chatgpt baseline is \"very rudimentary\" and suggests testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a logical reasoning for the suggestion to test a fewshot approach, it lacks specific examples or references to support the claim that the chatgpt baseline is \"very rudimentary.\" The suggestion to include discourse relation information is 3, as it provides a direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the chatgpt baseline, suggesting that it is \"very rudimentary\" and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. This feedback is clear and actionable, as it provides specific suggestions for improving the baseline and enhancing the evaluation of the paper. However, the comment could be more helpful if it explained why the current baseline is considered rudimentary or how the fewshot approach might improve the results. Despite this, the feedback is 4 as it guides the authors on how to enhance their work and offers a clear direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It points out that the authors only state that they estimate a layer\"s sensitivity by pruning, but do not provide details on how the actual pruning was done. The comment implies that the authors should provide more information on the pruning process to clarify the methodology. While the action is implicit, it is clear and concrete, as it specifies the need for more detailed information on the pruning process. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail on how the ground truth of sensitivity is achieved and the need for more information on the pruning process. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. The reviewer suggests that the authors should provide more information on the pruning process to clarify the methodology. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 2, as it provides a general direction for improvement but lacks the necessary evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved. It points out that the current explanation, which mentions pruning, lacks details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to provide more information on a crucial aspect of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies specific parts of the text that could be written more clearly, such as line 97 regarding proper rotation matrices and line 105106 regarding the matrix being non positive semidefinite. It provides clear and concrete actions for the authors to take, such as explicitly explaining the concepts in these sections. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the text, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the definition of a proper rotation matrix and the problem of the matrix being non positive semidefinite. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification regarding specific terms and concepts in the text. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific parts of the text that could be written more clearly, providing actionable feedback for the authors. By pointing out the lack of clarity in lines 97 and 105106, the comment guides the authors to explicitly explain the concepts of proper rotation matrices and the problem of the matrix being non positive semidefinite. This feedback is clear and constructive, offering a direct path for the authors to improve the clarity and comprehensibility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is explicit and provides a concrete suggestion for how the authors might improve their draft by changing the terminology. The action is clear and specific, leaving no ambiguity about what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The comment also references the activationpooling operator introduced by Cohen and Shashua, which helps clarify the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The reviewer provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This reference provides a logical basis for the suggestion, making the claim 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It offers a clear and actionable piece of feedback by providing a concrete example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is valuable as it helps the authors improve the clarity and consistency of their terminology, potentially enhancing the readability and comprehensibility of their paper. However, the comment could be more helpful if it explained why this change might be beneficial or how it would impact the paper\"s overall message. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for their methods or related work. This is a clear and direct action that the authors can take to improve the presentation of their figures. The comment provides a specific suggestion for how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1\" and \"Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they should be shrunk to leave more space for the authors\" methods or related work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, and it provides a specific suggestion to shrink the captions to leave more space for the authors\" methods or related work. This claim is 3 as it logically suggests a way to improve the presentation of the figures, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to experiment with different caption sizes to determine the optimal size for their purposes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to shrink the captions to leave more space for the authors\" methods or related work. This feedback is valuable as it directs the authors to a specific area that could be improved, offering a concrete way to enhance the clarity and presentation of their figures. However, the comment could be more helpful if it included examples of how the captions could be revised or if it explained why this change would be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al, 2021, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider including this work as a benchmark. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide specific reasoning or evidence to support why Vidgen et al, 2021, should be included as a benchmark. The absence of detailed justification or references makes the claim 3, as the authors would need to infer the importance of including Vidgen et al, 2021, based on the suggestion alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This feedback is 3 as it points out a potential oversight in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to incorporate Vidgen et al, 2021, or provided examples of similar studies that could be included as benchmarks. Overall, the comment provides some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10) and ideally with errorbars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. The comment provides clear and concrete actions for the authors to take, specifying the exact changes needed to improve the presentation of their results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results comparing standard vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with errorbars, and it points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. This provides clear guidance on how to improve the presentation of the results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with errorbars, as the plotted curves are from single runs and might be subject to significant fluctuations. The reviewer also suggests that the models are small, so there is no excuse for not providing statistics. The comment is 4 as it provides a logical reasoning for why the results should be presented in a more robust manner, and it suggests a specific improvement. However, the comment could be strengthened by providing examples or references to similar studies that have used similar methods to present their results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on the presentation of results comparing standard vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs (at least 10) with errorbars, which is a standard practice in scientific research. This suggestion is based on the observation that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the comment points out that the models are small, so there is no excuse for not providing statistics. This feedback is 5 as it guides the authors on how to improve the robustness and credibility of their results. By addressing these points, the authors can enhance the quality and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, which is a specific solver. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the draft. The authors are left to infer that they need to improve the approach\"s universality and adaptability, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it provides a direction for improvement but not detailed guidance on execution.", "grounding_specificity_rationale": "The comment critiques the proposed approach for learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in detailing what needs to be addressed, such as the need for universality and adaptability. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. The comment provides logical reasoning by explaining the limitations of current operator learning methods compared to specialized numerical solvers, suggesting that the proposed approach needs to be more universal and adaptable. However, the comment lacks specific examples or references to support the claim about the limitations of current operator learning methods. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed approach, noting that it is merely learning a surrogate model for solving linear/linearized systems arising in FEM. It highlights the need for careful choice of basis functions and meshes and points out that the approach heavily relies on FEniCS, a specific solver. The comment suggests that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal and do not need to be adapted to specific PDEs. While the comment provides a clear critique of the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve the universality and adaptability of their method. The feedback is 3 as it points out a potential weakness but does not offer actionable steps for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the clarity of the experimental setup. The comment is specific and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the impact of different versions of the experimental environment on training and inference speed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This claim is 3 as it logically suggests that different versions of the experimental environment could impact training and inference speed. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about the experimental environment, including the CUDA and PyTorch versions. This feedback is clear and actionable, as it directly addresses a potential issue with the clarity and reproducibility of the experimental setup. By providing this information, the authors can ensure that their work is more robust and easily replicable. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how other studies have addressed similar issues. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve their draft to account for the limitations of realistic datasets. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of controlling multiple aspects of variation with precision in the context of fully realistic datasets. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its agreement with the authors\" judgement about the lack of immediate societal impact, but it does not provide further details or suggestions on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work in response to the limitations of realistic datasets. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the authors clarify the concept of bandit algorithms and the figure. The comment provides explicit guidance on what needs to be clarified and improved, offering concrete suggestions for the authors to enhance the clarity of their draft. Therefore, the comment is 5, as it provides clear and specific instructions on how to enhance the understanding of the content.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paragraph number (L156166), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the paragraph, including the difficulty in understanding the content and the vagueness of the figure description. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paragraph is difficult to understand, particularly regarding the Gittins strategy and the figure. The reviewer suggests that the description is vague and provides examples of unclear phrases, such as \"Dashed lines indicate that the agent can plan ahead...\". However, the comment lacks specific references or detailed explanations to support the claim that the description is unclear or vague. While the reviewer provides some examples, the lack of detailed reasoning or references makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is 3, as it provides some evidence but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the authors clarify the concept of bandit algorithms and the figure. The comment provides actionable feedback by highlighting specific areas that need improvement, which can help the authors enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to clarify the content or provided examples of clearer explanations. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and actionable, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (078079 and 08) and the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the evaluation metric to clarify the scale of the improvement and for comparability with other works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It references a previous work, Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020), where a similar expression was used. This claim is 3 as it provides a logical reasoning for why clarifying the evaluation metric is important and references a specific example to support the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how this clarification would enhance the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work, which is relevant to the current paper. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their results section. By addressing these points, the authors can improve the transparency and reproducibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the standard deviation of the noise in the simulation study is stated as 3 but appears to be too low based on observations. While the comment implies that the authors should investigate this further, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this study. The action is implicit and somewhat vague, as the authors need to infer that they should explore higher noise levels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the noise standard deviation being too low and suggests studying the behavior of the model under higher noise levels. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise in the simulation study is too low, based on observations compared to the true trajectories. However, the comment does not provide specific examples or detailed reasoning to support this claim, such as specific observations or data that demonstrate the discrepancy. Without such evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the standard deviation of the noise in the simulation study, suggesting that it may be too low based on observations compared to the true trajectories. It provides a clear and actionable suggestion for the authors to study the behavior of the model under higher noise levels. This feedback is valuable as it points out a specific area where the paper could be improved and offers a concrete direction for further exploration. However, the comment could be more helpful if it provided additional context or examples of how the authors might conduct this study. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and suggests that this could limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to ensure the applicability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds of the approach, specifically mentioning the o(1) terms and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential limitation of the approach due to the o(1) terms, but it does not provide details on how this limitation affects the applicability of the approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds of the approach have o(1) terms and that this could limit the applicability of the approach. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the approach, specifically the use of o(1) terms in the bounds. It raises a concern about the applicability of the approach due to the potential size of inputs required for the approach to be effective. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the approach might be problematic. While it highlights an important consideration, the feedback is incomplete and does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects of DVP performance should be examined. As a result, the authors are left without any clear direction on how to address this interest. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not specify which part of the paper this interest pertains to, such as a specific section or experiment. Without explicit references to sections or experiments, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of DVP performance should be examined or how the results should be interpreted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses interest in seeing how DVP performs on videos with different lengths. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual statement about the authors\" interest in exploring a particular aspect of their work. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it lacks any specific guidance or suggestions on how the authors might explore this aspect or what aspects of DVP performance should be examined. Without actionable feedback or detailed instructions, the comment does not provide meaningful assistance to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how the authors should address this issue. The comment lacks explicit guidance on how to clarify the target or what specific changes should be made to improve the clarity. As a result, the authors are left without clear instructions on how to improve the draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. However, it does not specify which part of the paper this confusion arises from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does not provide specific guidance on how to address this issue, such as suggesting where the clarification should be added or what aspects of the paper are unclear. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. The reviewer acknowledges that the clarification is provided in the conclusion but does not provide any supporting evidence or reasoning to justify this confusion. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the confusion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\"s focus or what aspects of the paper are unclear. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without guidance on how to address the confusion or enhance the clarity of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. It provides a clear and concrete action for the authors to take, specifying the exact calculation that needs to be performed. This level of detail makes the comment 5, as the authors know exactly what steps to take to address the issue. Therefore, the comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely evaluating the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that it has ignored the KLdivergence term in equation (3). It provides a clear and actionable suggestion by asking the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is valuable as it directs the authors to a specific area that needs attention and provides a concrete step for improvement. However, the comment could be more helpful if it explained why this evaluation is important or how it might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the connection or depth of the analysis. The comment implies that the authors should make improvements, but it lacks concrete details on how to implement these changes. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not specify which part of Section 2 is lacking a connection or how the theoretical analysis could be improved. The authors can infer that the comment relates to the theoretical analysis and its connection to the methodology section, but this inference is not direct. The comment is specific in identifying the issue of a lack of connection and the need for more depth in the theoretical analysis, but it is 1 as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the connection between Section 2 and the methodology section, noting that the theoretical analysis appears simplistic and closely related to a specific reference. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and does not provide specific suggestions on how to address the issue or improve the theoretical analysis. The comment highlights an area for improvement but does not offer detailed guidance or examples on how to enhance the connection or depth of the analysis. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should further discuss the situations in which the losses help, particularly in specular areas. While the comment implies that the authors should provide more information about the effectiveness of the losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the effectiveness of the losses in specific situations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations in which the losses help, particularly in specular areas. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a particular area for further discussion, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the losses discussed in the paper might be particularly helpful in specular areas. However, it does not provide any evidence, examples, or references to support this claim. The comment lacks specific reasoning or data to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors further discuss the situations in which the losses help, particularly in specular areas. This feedback is 3 as it identifies a potential area for improvement by encouraging the authors to provide more detailed information about the effectiveness of their losses. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the losses should be discussed in more detail. While it points out a potential gap in the paper, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses doubt about the paper\"s current strength for the ICLR conference, but it does not provide any specific guidance or suggestions on how the authors might improve their draft to meet the standards of the conference. There is no explicit or implicit action for the authors to take, nor are there any concrete details on what aspects of the paper need improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is being addressed, making it 1. It also lacks specificity as it does not provide details on what aspects of the paper are insufficient for the ICLR conference or how the authors might improve their draft to meet those standards. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"doubtful\" for the ICLR conference, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the paper\"s weaknesses or how it compares to other works, the authors are left without a clear understanding of what needs to be improved or addressed. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment expresses doubt about the paper\"s current strength for the ICLR conference, indicating that it may not be suitable for the event. However, it does not provide any specific feedback or suggestions on how the authors might improve their draft to meet the standards of the conference. Without actionable guidance or detailed insights into what aspects of the paper need improvement, the comment offers limited value to the authors. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, it does not provide any explicit guidance or suggestions on how the authors might clarify or enhance their contributions. The comment implies that the authors should make their contributions more explicit, but it does not offer concrete steps or examples of what these contributions might be. As a result, the action is implicit and vague, leaving the authors uncertain about how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the major contributions of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the major contributions and the comment\"s assertion that analyzing previous work does not constitute a contribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the major contributions are unclear and that analyzing previous work does not constitute a contribution. This is a critical observation that can help the authors clarify and strengthen their paper. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending ways to highlight the novelty or impact of the contributions. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also mentions that the answer is difficult to find in reference [30]. This provides a clear and concrete action for the authors to take, which is to clarify the definition and usage of n_t in the algorithm. The comment is specific and provides a direct path for the authors to follow in order to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the \"appropriate number\" in line 225 and notes that the answer is difficult to find in reference [30]. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of \"appropriate number\" in Algorithm 2, specifically in line 225, and notes that it is difficult to find the answer in reference [30]. This claim is 3 as it highlights a potential issue with the clarity of the algorithm, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to refer to the referenced material to understand the issue fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also points out that the answer is difficult to find in reference [30]. This feedback is clear and actionable, as it directs the authors to clarify the definition and usage of n_t in the algorithm. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the explanation or offered additional guidance on how to improve the algorithm. Overall, the comment is 4 as it effectively identifies a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be publicly available. While the comment implies that the authors should make the code available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the code available to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. The comment is specific in its request for the code to be publicly available, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code should be made publicly available. Without additional context or explanation, the claim lacks verifiability, making it challenging for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the difficulty in reproducing the results and questions the availability of the code. While it identifies a potential issue with reproducibility, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the transparency of their work. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it points out a potential problem but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the claims about the mixing time being better in practice are not adequately supported by the experiments and suggests that the evidence provided is limited. However, it does not provide specific guidance on how the authors should address this issue or what additional evidence or experiments would be needed to support their claims. The comment lacks concrete suggestions or detailed instructions on how to improve the draft, leaving the authors uncertain about what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claims about the mixing time being better in practice, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient support for these claims in the experiments and the limited evidence provided to practitioners. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims about the mixing time being better in practice are not sufficiently supported by the experiments. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims about the mixing time being better in practice, noting that the evidence provided is limited. It highlights the need for more robust support from the experiments to substantiate these claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional evidence could be included to strengthen their claims. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider this extension and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the protected feature to a vector form, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. This is a 3 suggestion as it could potentially enhance the paper\"s contribution by allowing for more comprehensive analysis and interpretation of the data. However, the comment lacks depth and does not provide specific guidance on how to implement this extension or what benefits it might offer. Without further explanation or examples, the authors may find it challenging to fully understand and act upon the suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the reviewer should denote the vector representations of the words in the equation and whether they are L2normalized. Additionally, it asks for clarification on whether the nearest neighbor examples are computed using cosine or dotproduct. These questions are direct and specific, providing clear guidance on how the authors can improve their draft. The action is explicit and the authors know exactly what needs to be done to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223\" and \"following ones,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including denoting the vector representations of the words, whether the vectors are L2normalized, and the method used for computing nearest neighbor examples. This level of detail provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific aspects of the paper, such as the notation used for vector representations and the method for computing nearest neighbor examples. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas for clarification and improvement in the paper. It points out that the notation for vector representations of words is not clearly defined and suggests that the authors denote these somehow. Additionally, it asks whether the vectors are L2normalized and whether the nearest neighbor examples are computed using cosine or dotproduct. These questions provide the authors with actionable steps to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to denote the vector representations or provided examples of how this could be done. Overall, the feedback is valuable but could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should run experiments multiple times and report statistics, as a way to address the reproducibility issue in deep RL. It references a recent paper that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a clear action to take, it does not specify how many times the experiments should be run or what specific statistics should be reported. The authors are given a general direction but may need to infer the exact details of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that experiments should be run multiple times and that statistics should be reported to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. However, the comment does not specify which part of the paper this issue pertains to, such as the experimental section or the discussion on reproducibility. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for multiple experiments and statistics, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that experiments should be run multiple times to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a reference to an external source, it lacks detailed reasoning or specific examples of how running multiple experiments would improve reproducibility. The suggestion is 3, as it provides a logical basis but requires more detailed explanation or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with deep RL, specifically the reproducibility of their results and the significance of their improvements. It suggests that experiments should be run multiple times and that statistics should be reported to address this issue. The comment references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL, providing a relevant external reference to support the suggestion. While the comment highlights a significant area for improvement, it could be more helpful by offering specific guidance on how to implement these changes or what specific statistics should be reported. Overall, the comment provides valuable insight into a critical area for improvement, but it could be more actionable with additional details. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for minor issues with the ending punctuation of equations. It also explicitly states that they should ensure consistency in the punctuation. This feedback provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be corrected. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ending punctuation of equations, instructing the authors to ensure consistency in the punctuation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the ending punctuation of equations in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the punctuation of equations in Figure 2, Line 433, and Line 468. It provides clear and actionable feedback by instructing the authors to ensure consistency in the ending punctuation of equations. This is a minor but important detail that can improve the clarity and professionalism of the paper. However, the comment could be more helpful if it explained why this consistency is important or provided examples of how it affects the overall presentation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to differentiate the method or what specific aspects could be improved to enhance the technical contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses $kNNECD$ or $kNNMT$, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the similarity should be addressed or how the authors could differentiate their method. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, the comment does not provide any specific examples, comparisons, or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any specific guidance or suggestions on how the authors could differentiate their method or what aspects of the similarity should be addressed. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This feedback implies that the authors should clarify the nature of the figures and potentially conduct additional experiments to validate their findings. While the action is implicit, it is clear and concrete, as it specifies what the authors need to do to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially, and suggests conducting realworld experiments to support the phenomenon shown in the figures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This claim is 3 as it logically suggests that realworld experiments could provide additional validation for the results presented in the figures. However, the comment lacks specific examples or references to support the need for such experiments, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon shown in the figures. This feedback is valuable as it prompts the authors to consider the validity and robustness of their results, which is an important aspect of scientific research. However, the comment could be more helpful if it provided specific guidance on how to conduct these realworld experiments or what aspects of the figures need further validation. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance the robustness of their findings."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors did not clearly state the number of parameters used in each approach in Section B.3. This is a direct request for clarification, providing the authors with a clear action to take. The comment is specific and concrete, as it identifies the exact part of the paper that needs attention and the specific information that is missing. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the number of parameters used in each approach. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a request for clarification regarding the number of parameters used in each approach in Section B.3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual statement seeking clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the clarity of the number of parameters used in each approach in Section B.3. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the parameters used in their methods. By addressing this point, the authors can improve the clarity and transparency of their work, which is valuable for readers who may be interested in replicating or understanding their methods. However, the comment could be more helpful if it suggested how to present this information or provided examples of how other studies have effectively communicated similar details. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This provides a clear and direct action for the authors to take, which is to include these elements in their draft to enhance understanding. The suggestion is concrete, as it specifies exactly what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment suggests adding an example and a figure to help explain the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the definition is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an example and a figure, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why this addition would be beneficial or how it would enhance the understanding of the concept. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to determine the necessity or impact of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This feedback is 3 as it identifies a specific area where the paper could be improved by providing visual aids to enhance understanding. However, the comment lacks depth and does not explain why examples or figures would be beneficial or how they could be integrated into the paper. While it points out a potential improvement, it does not offer detailed guidance or suggestions on how to implement this change. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. The comment lacks actionable details, such as recommending ways to differentiate the method or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the method is considered common or how it can be improved to enhance its novelty. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel because it is related to a common approach in semisupervised learning, specifically selftraining methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without clear guidance on how to enhance the novelty or impact of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the assumption among classes not being practical, but it does not provide any explicit or implicit actions for the authors to take. It mentions that the formulation or definition is trivial but suggests that the focus should be on optimization and theoretical property analysis for potential insights. However, without specific guidance or suggestions on how to address this issue, the authors are left without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption among classes and suggests that the formulation or definition is trivial, but highlights the importance of optimization and theoretical property analysis for potential insights. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and the potential value of optimization and theoretical analysis, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the formulation or definition is trivial, but it lacks specific examples or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption among classes, suggesting that it may not be practical. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve their work. The comment mentions the importance of optimization and theoretical property analysis, but it lacks depth and actionable advice. Without clear instructions or examples, the authors may find it challenging to understand and implement the feedback. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation results in Table 1 are based on only three trials for each case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the evaluation or the claims made in the paper. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the statistical significance of their results and potentially revise their claims accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation results, noting that the three trials per case are not statistically significant and that the deviations reported are not meaningful. The comment further explains why this is problematic, suggesting that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials per case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense. The comment provides a logical reasoning by pointing out the insufficient statistical power of the trials, which is a commonsense observation. However, it lacks specific examples or references to statistical methods or standards to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation results presented in Table 1, noting that the three trials per case are not statistically significant. This observation is critical, as it highlights a potential flaw in the paper\"s methodology and the claims made about performance. The comment further explains why the deviations reported are not meaningful and suggests that statements like \"our performance is at least two standard deviations better than the next best baseline\" are not valid. This feedback is clear and actionable, as it prompts the authors to reconsider the statistical significance of their results and potentially revise their claims. However, the comment could be more helpful if it provided specific guidance on how to address this issue or what alternative methods could be used to strengthen the evaluation. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific guidance on which papers should be included or how to improve the depth of the feature comparison. The authors are left to infer that they need to include these papers, but without concrete instructions or examples, the action remains vague. Therefore, the comment is 3, as it identifies an issue but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment explicitly mentions the feature comparison with prior work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the shallow comparison and the absence of two relevant papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is \"shallow\" and mentions the absence of two relevant papers. However, it does not provide specific details about which papers are missing or how they would enhance the comparison. Without these details, the claim lacks sufficient evidence or justification to be 5. The authors would need to infer the relevance of the missing papers and determine how they could improve the comparison. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the shallow feature comparison with prior work and the absence of two relevant papers. This feedback is clear and actionable, as it points out a gap in the literature review that the authors can address to enhance the depth and relevance of their analysis. However, the comment could be more helpful if it provided the names or titles of the missing papers, which would guide the authors in their literature search. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims of equivalence without verification. While the comment provides a specific suggestion for improvement, it does not offer concrete guidance on how to apply this suggestion or what specific changes should be made to the wording or claims. The authors are left to infer that they should be more cautious in their usage of the word \"equivalent,\" but without detailed instructions on how to implement this change, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it suggests a more cautious usage of the word \"equivalent\" and advises caution when making claims without verification. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims without verification. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their claims and provide verification for any equivalence claims. This feedback is clear and actionable, as it points out a potential weakness in the paper\"s language and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered examples of how the authors might verify the equivalence or provided guidance on how to use the word \"equivalent\" more effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a lack of understanding regarding the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests that there is a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed analysis of the views. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis and the need for more comprehensive exploration of the views. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach and highlights the dominance of the paraphrase similarity view over other views. It suggests that there is a need for a more detailed analysis of the differences and similarities between the views, except for the task directly. The comment provides a logical reasoning for the need of such an analysis, but it lacks specific examples or references to support the claim about the dominance of the paraphrase similarity view. This makes the claim 3, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the effectiveness of the multiview clustering approach, specifically the dominance of the paraphrase similarity view over other views and their combination. It questions the usefulness of the other views and suggests that a more detailed analysis of the differences and similarities between them is needed. The comment highlights a gap in the analysis and provides a specific example of how the different views help in clustering paraphrases of the word \"slip.\" However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects should be explored. Overall, the comment provides valuable insights and actionable feedback, but it could be more comprehensive with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This implies that the authors should provide a more detailed explanation of the architecture in their paper. However, the comment does not specify which parts of the paper need more detail or how to present the architecture information. While the action is implied, it is not explicitly stated, and the lack of concrete guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear explanation of the architecture and the reliance on external work for details. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This suggests that the paper lacks selfcontainment. However, the comment does not provide specific examples or references to the architecture or the external work, making it difficult for the authors to understand the exact issue and address it. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specifics of the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained and that the authors rely on external work for details. This lack of selfcontainment makes the paper less accessible to readers who may not be familiar with the referenced work. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to include more detailed explanations of the architecture in their paper. However, it could be more helpful if it offered specific guidance on how to present this information or what aspects should be emphasized. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out an inconsistency in the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback provides a clear and direct action for the authors to take, which is to ensure consistency in the typesetting of these terms. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in typesetting these terms throughout the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"BertScore\" and \"BLEURT\" are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback is clear and actionable, as it points out a specific area where the authors can improve the consistency and readability of their paper. However, the comment could be more helpful if it provided examples of how the inconsistency affects the clarity or understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can enhance the overall quality of their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback implies that the authors should include these results to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. While the action is implied, it is not as clear as it could be, as the authors may not be entirely sure of the exact details or format required for these results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or analysis sections, but this inference is not direct. The comment is specific in suggesting the inclusion of detailed results, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is unreasonable to expect that increasing the model size would hurt performance, as recent work by Ni et al. demonstrates that scaling laws apply to dense retrieval models. However, the comment does not provide specific references or examples from the Ni et al. work to support this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback is 3 as it points out a potential weakness in the authors\" argument regarding the impact of model size on performance. However, the comment lacks specific guidance on how to present these results or what aspects of the results should be emphasized. While it identifies an area for improvement, it does not provide detailed instructions or examples, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific weaknesses in the presentation quality of the paper, such as the figures, tables, and the management of figures and tables. It provides a list of examples, including the use of a \"Dataset\" column in tables that is not informative, the management of Figure 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. While the comment highlights these issues, it does not provide explicit guidance on how to address them or suggest specific improvements. The authors are left to infer that they need to improve the presentation quality, but without detailed instructions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures and tables, such as Figs 1&2, Table 1, and Table 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these figures and tables, such as the use of a \"Dataset\" column in tables that is not informative, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation quality of the paper is a weakness, specifically mentioning examples such as Figs 1&2, the use of a \"\" for the method, the \"Dataset\" columns in tables, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. These examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in highquality publications like NeurIPS. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the presentation quality of the paper, such as the use of a \"Dataset\" column in tables that is not informative, the management of Figures 3 and 2, and the use of a \"*\" in Table 1 without indication of its meaning. It provides a detailed list of examples, which is helpful in guiding the authors on what aspects of their presentation need improvement. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar issues have been resolved in highquality publications. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance on how to achieve them."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include related experiments to demonstrate the utility of the information axis tool. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct additional experiments, but the lack of explicit instruction makes it somewhat vague. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the conclusion or discussion, but this inference is not direct. The comment is specific in suggesting the need for related experiments, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support this claim. The comment is based on a logical assumption that additional experiments would be beneficial, but it lacks the necessary evidence or reasoning to fully substantiate the claim. Therefore, the comment is considered 2, as it provides a suggestion but lacks the necessary detail to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors include additional experiments to validate their claims. However, the comment lacks specific guidance on what kind of experiments would be beneficial or how they should be conducted. While it points out a potential gap in the paper, it does not provide detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they could take to investigate it further. As a result, the comment lacks actionability and does not provide any direction for the authors to improve their draft. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about the current setup or the Greek language. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspect of the Greek language might be causing issues or how it could be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for information about whether other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. While it raises an interesting question, it does not provide any actionable feedback or suggestions for the authors to address this issue or improve their work. Without further context or guidance, the authors may find it challenging to understand how this information could be relevant to their paper or how to incorporate it into their analysis. Therefore, the comment is rated as 2, as it identifies a potential area of interest but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" The reviewer implies that the authors should clarify this point to improve clarity. However, the comment does not provide specific guidance on how to clarify this point or what aspects need to be addressed. While the action is implicit, it is vague, as the authors are left to infer the necessary changes without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement \"we manually observed the generated examples and find the results acceptable.\" This provides clear guidance on what aspect of the paper needs improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, noting that it makes a particular point unclear. It points out that the statement \"we manually observed the generated examples and find the results acceptable\" is difficult for readers to understand and evaluate. While the comment highlights an area for improvement, it does not provide detailed guidance or suggestions on how to clarify the text or what specific aspects need clarification. This limits the comment\"s helpfulness, as it offers some insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to conduct experiments on realworld datasets, but the lack of explicit instruction means the action is not as direct as it could be.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper discusses the synthetic versus realworld datasets or the outofdistribution setting. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this suggestion fits, the comment lacks full grounding. It is specific about the need for realworld datasets but does not provide detailed guidance on how to implement this change. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is 3 as it identifies a potential area for improvement in the paper\"s experimental setup. However, the comment lacks specific guidance on how to conduct these experiments or what aspects of the synthetic datasets might be limiting the results. While it points out a potential issue, it does not provide detailed instructions or examples on how to address it, making the feedback 3 but not fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on what specific aspects of the explanation are unclear or how they could be clarified. The comment implies that the authors should clarify these parts, but it lacks concrete instructions or examples of what needs to be improved. As a result, the authors are left with a vague understanding of what changes are needed to make the explanation clearer. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the last paragraph of Section 3 (lines 207210), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the explanations are vague and provides a specific example of the last paragraph in Section 3. This level of detail helps the authors understand what needs to be clarified or improved in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the vagueness and how it affects the clarity of the explanation. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the explanations in the paper, particularly in the last paragraph of Section 3 (lines 207210) regarding the single image case. It points out that the explanations are vague, which is a valuable observation that can help the authors improve the clarity and comprehensibility of their work. However, the comment lacks detailed guidance or suggestions on how to address this issue, such as recommending specific changes or improvements to the language used. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, which is described as a more interesting and practical setting. However, it does not provide explicit instructions or concrete steps on how to extend the analysis to multiple trucks and drones. The authors are left to infer that they should consider this extension, but without specific guidance on how to implement it, the action remains vague. Therefore, the comment is 3, as it implies an action but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests that the paper should consider multiple trucks and drones, which is a suggestion for extending the analysis. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of what needs to be addressed, which is the consideration of multiple trucks and drones. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the suggestion.", "helpfulness_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, which is described as a more interesting and practical setting. This feedback is 3 as it identifies an area for potential expansion and improvement in the paper. However, it lacks specific guidance or suggestions on how to implement this change or what specific benefits it might bring. While it points out a potential enhancement, the comment could be more helpful if it provided more detailed advice on how to incorporate multiple trucks and drones into the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the proposed approach to pretraining is not novel since it follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit suggestions for how the authors could make their approach more novel or differentiate it from ELECTRA. There is no guidance on potential modifications, alternative approaches, or additional features that could be incorporated to enhance the novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, specifically mentioning that it follows the strategies used in ELECTRA. However, it does not specify which part of the paper discusses this approach, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the novelty, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, the comment does not provide any specific examples or references to the strategies used in ELECTRA, nor does it explain how the proposed approach is similar or dissimilar to those used in ELECTRA. Without detailed comparisons or references, the claim lacks sufficient support, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential limitation in the novelty of the proposed approach to pretraining, noting that it follows the strategies used in ELECTRA. While this observation highlights a potential issue, it does not provide specific guidance or suggestions on how the authors might address this limitation or differentiate their approach. The comment lacks actionable feedback or detailed advice on how to enhance the novelty or innovation of the proposed approach. As a result, it offers limited value to the authors in terms of improving their draft. Therefore, the comment is rated as 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function. It also points out that even a basic bisecting line search will converge linearly, questioning the impact of quadratic convergence on runtime. The reviewer suggests that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is concrete but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of motivation or need for the Newton algorithm and the suggestion to conduct experiments to motivate the analysis/algorithm. The comment provides a clear direction for improvement by suggesting experiments that could help justify the use of the Newton algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function and that even a basic bisecting line search will converge linearly. The reviewer argues that while quadratic convergence is better than linear convergence, the impact on runtime is unclear. The comment suggests conducting experiments to motivate the need for the analysis/algorithm. This claim is 3 as it provides a logical reasoning for questioning the necessity of the Newton algorithm, but it lacks specific examples or references to support the argument about the impact on runtime. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function. It questions the significance of the analysis/algorithm, noting that even a basic bisecting line search will converge linearly. The reviewer suggests that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment highlights a potential weakness in the paper, it does not provide specific guidance on how to address this issue or what experiments to conduct. The feedback is 3 as it points out a potential area for improvement, but it lacks detailed suggestions or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results appear to indicate that \"better NMT systems are also better at idiomatic translations.\" However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. It lacks concrete steps or detailed advice on how to make the methods more idiomspecific or how to improve the results. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed upweighing and KNN methods\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the methods appear to be similar for idiomatic and random data, suggesting that the results indicate that \"better NMT systems are also better at idiomatic translations.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods are not idiomspecific, as the impact on idiomatic and random data appears similar. The reviewer supports this claim by referencing Figure 3, which presumably shows the results of the methods on different language and score combinations. However, the comment lacks specific details or examples from the figure to fully substantiate the claim. While the reference to Figure 3 provides some context, the comment could be strengthened by including more detailed analysis or specific observations from the figure. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results appear to indicate that \"better NMT systems are also better at idiomatic translations.\" This feedback highlights a potential weakness in the methodology and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue, such as proposing alternative methods or suggesting ways to tailor the methods to idiomatic data. While it identifies a critical area for improvement, the lack of actionable guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the volume calculation and the number of biases, suggesting that the authors should clarify the volume as WxHx1 and the bias as a scalar. It also notes the confusion regarding the number of biases and the fact that the authors only found this hyperparameter for feedforward models in section 3.4. While the comment provides explicit actions to take, such as clarifying the volume and bias, it does not specify how to address the confusion regarding the number of biases or the fact that only feedforward models are mentioned. The authors are left to infer that they need to clarify these points, but the feedback lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the volume calculation and the number of biases, suggesting that the volume should be WxHx1 and the bias as a scalar. The comment also points out the confusion regarding the number of biases and the fact that only feedforward models are mentioned, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the volume should be WxHx1 and the bias should be a scalar, based on the belief that the authors want to have several kernels and biases. The reviewer supports this claim by pointing out that the authors only found this hyperparameter for feedforward models in section 3.4, which creates confusion regarding the number of biases. However, the comment lacks specific examples or references to support the claim that the volume should be WxHx1 or the confusion regarding the number of biases. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the volume calculation and the number of biases in the paper. It points out that the volume should be WxHx1 and the bias should be a scalar, based on the authors\" intention to have several kernels and biases. The reviewer also highlights the confusion regarding the number of biases and the fact that only feedforward models are mentioned, suggesting that this needs clarification. While the comment provides clear and actionable feedback, it could be more helpful if it offered suggestions on how to address the confusion or provided examples of how other papers have handled similar issues. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the equation. The comment lacks actionable details, such as suggesting alternative approaches or methods to mitigate the loss of dynamic information. As a result, the authors are left without a clear understanding of how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equation, noting that subtracting s from the dynamic information could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting s from the dynamic information in Equation 8 could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. This is a valuable observation that could help the authors improve the clarity and accuracy of their equations. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending alternative approaches or methods to mitigate the loss of dynamic information. While it points out a potential problem, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses two questions about the impact of the number of MC samples and the network structure on performance. While it does not explicitly instruct the authors to conduct experiments or provide specific guidance on how to address these questions, the questions themselves are clear and actionable. The authors can infer that they need to conduct experiments to investigate the impact of these factors on performance and potentially include this analysis in their paper. Therefore, the comment is 3, as it provides a clear direction for the authors to follow but lacks explicit instructions.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of MC samples and the network structure on performance, but it does not specify which part of the paper these questions pertain to. The authors may infer that it relates to the experimental section, but this inference is not direct. The comment is specific in its request for empirical evidence and analysis, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions asking for empirical evidence and analysis regarding the impact of the number of MC samples and network structure on performance. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises two important questions about the impact of the number of MC samples and the network structure on performance, prompting the authors to conduct empirical investigations. By asking for empirical evidence and analysis, the comment highlights areas where the authors could enhance their work by providing more detailed explanations and results. However, the comment does not offer specific guidance or suggestions on how to conduct these experiments or what specific aspects to focus on. While it points out a potential gap in the paper, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the smoothed GT shapes should be shown in Figures 3 and 5 to enhance the understanding of the reconstruction quality. This is a clear and direct action for the authors to take, as it provides a specific request for visual clarity. The comment also mentions a minor concern, which could be addressed by providing additional context or explanation. Overall, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include the smoothed GT shapes, but without full grounding, the authors may struggle to identify the exact figures being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the understanding of the reconstruction. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to enhance the clarity of the paper by showing the smoothed GT shapes in Figures 3 and 5. This suggestion directly addresses a potential issue in the presentation of the results, which could help readers better understand the quality of the reconstruction. Additionally, the comment acknowledges a minor concern, which could be further elaborated upon to provide even more detailed guidance. Overall, the comment is clear and offers a concrete way for the authors to improve their draft, making it 4. However, it could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, particularly in the language and vision tasks used for evaluation. It notes that while there is a comparison of training loss and a comparison of the rank of possible solutions, there is no direct comparison of test accuracy. The comment implies that the authors should include direct comparisons of test accuracy to demonstrate the improvement over the baseline. However, it does not explicitly instruct the authors to make these comparisons, leaving the action implicit. The comment is 3 as it provides a clear direction for improvement but lacks concrete guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prior approach PRANC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of direct comparisons with PRANC in the language and vision tasks used to evaluate the proposed approach. The comment provides a clear direction for improvement by suggesting the inclusion of direct comparisons of test accuracy. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in the language or vision tasks used to evaluate the proposed approach. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. The comment suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline that it directly modifies. This claim is 3 as it logically points out the need for direct comparisons to substantiate the claims of improvement. However, it lacks specific examples or references to similar studies that might provide a more robust basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, noting the lack of direct comparisons with the prior approach PRANC in the language or vision tasks used to assess the proposed approach. It highlights the importance of including direct comparisons of test accuracy to demonstrate the improvement over the baseline that is directly modified by the authors. This feedback is clear and actionable, providing the authors with a specific area to address in order to strengthen their evaluation and substantiate their claims. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or provided examples of similar studies that have successfully demonstrated such comparisons. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear direction for enhancing the evaluation section."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It explicitly asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and providing more details on the coverage. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the selection of 21 event types from Freebase and asking about their coverage on the 33 event types in the ACE data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the selection process is problematic. The authors would need to make a significant effort to understand and address the concern, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and their coverage on the 33 event types in the ACE data. This is an important point that could impact the applicability and robustness of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the generalizability of their work. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. While the comment implies that these tasks should be included, it does not explicitly instruct the authors to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to include additional tasks to demonstrate the language modeling capabilities, but the comment lacks concrete guidance on which tasks to include or how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the language modeling capability is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not conduct experiments on generation tasks that require a wellperforming language model, specifically mentioning word similarity and SquAD in section 5.3. The reviewer suggests that these tasks do not adequately reflect the language modeling capability. However, the comment lacks specific examples or references to other tasks that would better demonstrate the language modeling capability. While the claim is logical, it is not fully substantiated by detailed evidence or examples, making it 3. The authors would need to make a significant effort to understand and address the critique, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the experiments on word similarity and SquAD in section 5.3 do not adequately reflect the language modeling capability. It suggests that the authors should include additional tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their evaluation of the language modeling capability. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully demonstrated the importance of these tasks. Overall, the comment is 4 as it guides the authors toward a more comprehensive evaluation of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to cite and discuss important references for domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for references and discussions on domain adaptation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely references and discussions on domain adaptation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact references that are missing. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of important references for domain adaptation. This feedback is clear and actionable, as it directly instructs the authors to include these references and discussions in the revised manuscript. By addressing this issue, the authors can significantly enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided specific examples or references of what is missing, which would guide the authors in selecting and integrating these references effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps to take. It lacks concrete details on how to verify the suspicion or improve the model. As a result, the authors are left without clear instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the hyperparameters and the potential issue with the model\"s performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the suspicion. As a result, the claim is 3, as it requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. This is a relevant observation that could impact the validity of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or verify the suspicion. It does not provide actionable steps or detailed feedback on how to improve the presentation or analysis of the results. As a result, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. The comment lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of what needs to be addressed or how to address it. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"w.r.t. to corpora and datasets,\" indicating that it pertains to the experimental setup. However, it does not specify which part of the paper this pertains to, such as a particular section or table where these aspects are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects are unclear or poorly motivated, making it difficult for the authors to understand the exact issues that need to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, it does not provide any specific examples or details about what is unclear or poorly motivated, making it difficult for the authors to understand the exact issues that need to be addressed. Without concrete examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that some aspects regarding corpora and datasets are unclear or poorly motivated. However, it does not provide any details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be addressed or how to address it. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the proposed method does not show significant improvement over existing RL methods, but it does not provide any specific guidance or suggestions on how the authors could address this issue. There is no explicit or implicit action for the authors to take, such as suggesting ways to improve the method or providing examples of existing RL methods that could be benchmarked. Without actionable advice, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed method does not show significant improvement over existing RL methods, but it does not specify which part of the paper discusses this improvement or where the comparison is made. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of the method are lacking or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method does not show significant improvement over existing RL methods. However, it does not provide any specific examples, comparisons, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the proposed method does not show significant improvement over existing RL methods, which is a critical observation that could impact the paper\"s contribution. However, it lacks specificity and does not provide any guidance on how the authors might address this issue or improve the method\"s performance. Without actionable feedback or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the model size. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"size of the model\" and the \"hourglass modules,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the model size to competing approaches and the details on the size of each hourglass module. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\"s analysis or conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, noting that the authors do not provide details on the size of each hourglass module. This feedback is clear and actionable, as it prompts the authors to include this information in their paper. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, it does not provide explicit guidance on how the authors should address this issue or clarify their claim. The comment lacks concrete suggestions on how to improve the clarity or accuracy of the claim, leaving the authors uncertain about what specific actions to take. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that prior work, such as ClimateBench or ClimateSet, already does this, providing clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, the comment does not provide specific examples or references to these works, nor does it explain how the authors\" claim differs from what has already been done. Without detailed evidence or reasoning, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential misleading claim in the paper regarding the novelty of treating climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already does this, which could undermine the authors\" argument. This feedback is 3 as it highlights a potential issue with the clarity and originality of the claim. However, it lacks specific suggestions on how the authors might address this issue or clarify their claim, such as referencing the prior work or providing additional context. While it provides some insight, the comment could be more actionable with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"metric learning theory\" and \"generalization theory of neural networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide specific suggestions on how to address this issue or improve the results. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, the comment lacks specific references to the theoretical results mentioned or the existing content of the paper, making it difficult for the authors to verify the claim. Without detailed evidence or references, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the metric learning theory is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. This is a clear and actionable observation that highlights a potential weakness in the paper. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or improve their analysis. While it points out a problem, it does not offer guidance on how to resolve it, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should move some visual results from the supplementary to the main paper. It also points out that there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The reviewer suggests condensing the illustration of the proposed network architecture from three figures to two, and using the extra space for visual results. This feedback provides clear and concrete actions for the authors to take, such as selecting specific visual results to include and condensing the figures. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the main paper and the supplementary material, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that some visual results should be moved from the supplementary to the main paper, and it provides a specific suggestion to condense the illustration of the proposed network architecture from three figures to two. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that visual results should be moved from the supplementary to the main paper, as there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The comment provides a logical reasoning by pointing out the lack of visual results in the main paper and suggesting that condensing the illustration of the proposed network architecture could make room for visual results. However, the comment lacks specific examples or references to support the claim that visual results are necessary or how they would enhance the paper. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors move some visual results from the supplementary to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment of the paper, and recommends condensing the illustration of the proposed network architecture from three figures to two. This suggestion is clear and constructive, as it offers a concrete way for the authors to enhance the visual presentation of their work and improve the flow of their paper. By addressing these points, the authors can significantly improve the clarity and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should change the notation, provide additional clarification, or revise the terminology. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, which is confusing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the confusion caused by using the same notation for different concepts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable observation that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending alternative notations or explaining the context in which these terms are used. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether a test example is crucially different, such as a patient being \"British\" versus \"American,\" and whether this can be detected using the corpus residual value. While the comment implies that the authors should consider this issue, it does not provide explicit guidance on how to address it or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in its question about detecting crucial differences, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a relevant concern or how it could be addressed. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a thoughtprovoking question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. This question highlights an important consideration for the authors regarding the potential impact of different cultural contexts on their analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific steps they could take to ensure the validity of their results. While it prompts the authors to consider a relevant aspect of their analysis, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. It provides a rationale for this suggestion, noting that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. While the comment explicitly states the action to take, it does not provide specific guidance on how to implement this change or what additional considerations might be necessary. The action is clear but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"WebQuestionsSP\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of dataset, suggesting that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. The reviewer provides a logical reasoning by explaining that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. However, the comment lacks specific references or examples to support the claim that WebQuestions is more suitable for the task. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3, as it requires further elaboration to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using a more popular dataset, WebQuestions, instead of WebQuestionsSP for their testbed. It offers a logical reasoning that using WebQuestions would be more intuitive and straightforward, and could facilitate direct comparison with mainstream QA research. This feedback is valuable as it encourages the authors to make a change that could enhance the clarity and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to support the claim that WebQuestions is a better choice. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the need for making claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity, and that any potential training speed increases or cost savings must be demonstrated. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or examples to substantiate their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It mentions that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence or demonstrations are needed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claims and the need for evidence, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. The reviewer provides a logical reasoning by pointing out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment lacks specific examples or references to support the claim that sparsity is not beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. While the comment identifies a potential weakness in the paper\"s claims, it lacks specific suggestions or guidance on how the authors might address this issue or provide evidence to support their claims. The feedback is 3 as it highlights a potential area for improvement, but it could be more beneficial with additional guidance or examples on how to substantiate the claims. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to differentiate their design or what aspects could be improved to enhance novelty. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of novelty, specifically mentioning that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the novelty, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the paper, specifically noting that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets and suggests that these results should be presented in the main paper. This feedback provides a clear and concrete action for the authors to take, making it 5. The authors know exactly what additional analysis or results are needed and how to present them in the main paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, specifically ImageNet derivatives. This allows the authors to accurately identify the part of the paper being addressed, which is the analysis or results section. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on ImageNet1k or ImageNet100. This provides clear guidance on what additional analysis is needed to strengthen the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, specifically ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets and recommends presenting these results in the main paper. However, the comment does not provide specific examples or references to support why these datasets are important or how they would impact the paper\"s conclusions. While the suggestion is logical, the lack of detailed justification or evidence makes it 3. The authors would need to make a significant effort to understand and address the suggestion, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include analysis or results on other datasets, such as ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets, which is crucial for broader applicability and credibility. The comment provides a clear and actionable suggestion for the authors to enhance their work by including additional results, which can significantly impact the paper\"s impact and contribution. However, the comment could be more helpful if it offered specific guidance on how to present these results or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the model design, specifically mentioning that the architecture and learning details are fragmented or missing. It provides a clear suggestion for the authors to address this issue by either providing a plot of model illustration, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the novelty of the Neurochaos Learning method. The explicit action and concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model design\" and \"model architecture and learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the fragmented or missing details of the model design, and provides a concrete suggestion to address this issue by providing a plot, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the novelty of the Neurochaos Learning method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details, specifically mentioning the importance of demonstrating integrated details to facilitate reproducibility. The comment suggests providing a plot, pseudocode table, or code repository to address this issue. However, the comment lacks specific examples or references to support the claim that the model design is unclear or that Neurochaos Learning is not wellknown. This makes the claim 3, as the authors would need to infer the importance of these details and the need for demonstration themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides a clear and actionable suggestion for the authors to address this by either providing a plot of model illustration, pseudocode table, or code repository. This feedback is valuable as it guides the authors on how to improve the clarity and reproducibility of their work. However, the comment could be more helpful if it explained why these details are important or provided specific examples of what should be included in the plot or table. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is explicit and provides a clear action for the authors to take, which is to update the paper to reflect the correct usage of these models. The suggestion is concrete, as it specifies the exact change needed in the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between how BigFive and MBTI are described in the abstract and introduction sections as models to be extended, versus their usage as datasets in the experiments. The comment provides a clear suggestion to correct this discrepancy by stating the models as datasets throughout the paper, unless there is a specific reason to extend the explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are stated as models to be extended in the abstract and introduction sections, while they are used as datasets in the experiments. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. The comment is 3 as it logically points out a discrepancy in the paper\"s description of these models. However, it lacks specific examples or references to support the claim that the models should be considered datasets rather than models. This makes the claim 3, as the authors would need to make a logical inference to address the issue.", "helpfulness_rationale": "The review comment identifies a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be more appropriate to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is clear and actionable, as it directs the authors to correct the discrepancy in their description of these models. By following this suggestion, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided additional guidance on how to present the extended explanation or why the models are being extended. Overall, the comment is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include rejection rates or consider misclassifications as rejections in their experiments. This is a clear and direct action, as it specifies exactly what needs to be added or changed in the paper. The comment provides concrete guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rejection rate\" and \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of rejection rates or the consideration of misclassifications as rejections in the results. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests that one could view a misclassification as a rejection. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it affects the paper\"s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that one could view a misclassification as a rejection, and recommends including rejection rates or considering misclassifications as rejections in the results. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this point, the authors can enhance the transparency and completeness of their experimental results. However, the comment could be more helpful if it explained why the inclusion of rejection rates is important or how it would impact the interpretation of the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the generalization gaps in their work, specifically regarding the finetuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of generalization to the TSP instances, particularly the finetuning step in DIMES. It also specifies what needs to be clarified, namely, the difference between DIMES and other methods on TSP100 indistribution testing performance with/without metalearning. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the generalization gaps in their work, specifically regarding the finetuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment identifies a potential issue with the generalization of DIMES, it lacks specific examples or references to support the claim that these gaps need clarification. The suggestion to compare DIMES with other methods is logical but not fully substantiated. Therefore, the claim is 3, as it provides a direction for improvement but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the generalization of the finetuning step in DIMES and suggests that the authors should clarify the difference between DIMES and other methods on TSP100 indistribution testing performance with/without metalearning. This feedback is clear and actionable, as it provides a specific area for improvement and offers a direction for comparison with other methods. By addressing these points, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This provides clear and direct actions for the authors to take, ensuring they know exactly what information is needed to improve their draft. The request for the hyperparameters is specific, and the mention of reproducibility highlights the importance of sharing these details. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what information is needed to improve the reproducibility of the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for information, specifically asking for the final thresholds used for the results and the full set of hyperparameters. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for a claim.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by requesting the final thresholds used for the results and the full set of hyperparameters. This information is crucial for reproducibility and understanding the methodology. However, the comment could be more helpful if it provided guidance on how to present this information or why it is important for reproducibility. Despite this, the feedback is clear and actionable, which makes it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. However, it does not provide any explicit or implicit actions for the authors to take. The comment implies that the authors should clarify their methodology or consider alternative methods for answer detection, but it does not specify how to do so or what specific changes should be made. Without concrete guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the potential inconsistency in the authors\" claim and suggesting that it depends on the method/features used for answer detection, such as POS/dependency parse features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. It suggests that the authors\" claim is dependent on the method/features used for answer detection, such as POS/dependency parse features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. It points out that the authors\" claim is dependent on the method/features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it highlights a potential weakness in the authors\" argument and suggests a direction for clarification or further exploration. However, the comment could be more helpful if it provided specific suggestions on how to address this inconsistency or how to better substantiate the claim. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly instructs the authors to optimize Figure 1 to use less whitespace. This is a clear and direct action, providing the authors with a specific task to improve the visual presentation of their data. The comment is concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the optimization of Figure 1 to use less whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests optimizing Figure 1 to use less whitespace. However, it does not provide any reasoning, evidence, or examples to support why this optimization is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment provides a specific and actionable suggestion to optimize Figure 1 by using less whitespace. This feedback is clear and direct, offering the authors a concrete way to improve the visual presentation of their data. By addressing the issue of excessive whitespace, the authors can enhance the clarity and readability of their figure, which is a valuable improvement for the overall quality of their work. However, the comment could be more helpful if it provided additional guidance on how to achieve this optimization, such as suggesting alternative layouts or techniques. Overall, the comment is 4 as it identifies a specific area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. While the comment implies that the authors should conduct some form of analysis or provide evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis or provide evidence to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vector space where morphological variants are just close together,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the resulting space is meaningful and suggests providing evidence or analysis to support the claim. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. The reviewer does not provide specific examples or references to support their claim, making it 3. The authors would need to infer the need for additional analysis or evidence to address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. This feedback is valuable as it prompts the authors to consider the significance of their results beyond just improved embeddings. However, the comment could be more helpful if it provided specific suggestions on how to conduct the analysis or what kind of evidence would be most relevant. While it identifies an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper needs improvement, specifically noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the comment lacks concrete details on how to achieve these improvements. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying areas for improvement, such as the uneven distribution of space and the missing related work sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment lacks specific examples or references to support the claim that the writing is uneven or that the related work section is incomplete. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some indication but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing quality of the paper, noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. This feedback is 3 as it highlights areas where the paper could be improved in terms of balance and comprehensiveness. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending which sections should be prioritized or how to incorporate additional related work. While it provides some direction, the lack of detailed advice limits its utility for the authors. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific line (Line 140) and raises a concern about the first column of Qo being replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their assumptions and possibly revise the paper accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo by vo to form P\"o, which results in the first state not being reachable anymore. The comment further assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment lacks specific reasoning or evidence to support these assumptions, making it difficult for the authors to understand the basis of the claim. The lack of detailed explanation or references makes the claim 3, as it requires further elaboration to be fully understood and actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. While the comment highlights a potential problem, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what implications it might have for their work. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of the recurrent model, suggesting that the sequential relationship might be easier to model. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these areas to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not specify which part of the paper discusses FLOPs or inference time, making it weakly grounded. The suggestion to explore accuracy or specific properties is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks specific examples or references to support the claim that exploring accuracy or specific properties would lead to improvements. The suggestion is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for the authors to explore if there are improvements in accuracy or specific properties if they did not find improvements in FLOPs or inference time. It offers an example of the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is actionable and provides a clear direction for the authors to consider when evaluating their results. However, the comment could be more helpful if it included specific examples or references to support the claim about the sequential relationship. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should address this assumption, it does not explicitly instruct them to do so. The comment is 3 as it highlights a potential gap in the paper, but it lacks concrete guidance on how to test this assumption or what specific tests should be conducted. The authors can infer that they need to address this assumption, but the lack of detailed instructions makes the action somewhat vague.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption that \"d_e are good replacements for entity embeddings,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks whether this assumption has been tested, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper\"s findings. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. This is an important point that could impact the validity and reliability of the paper\"s findings. However, the comment lacks depth and does not provide specific guidance on how the authors might test this assumption or what kind of evidence would be needed to support it. While it identifies a potential weakness, it does not offer actionable steps for the authors to address it. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the components of the \"scoring function\" and the different threshold values/ranges. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included to clarify the methodology. The action is implicit and vague, as the authors are left to infer that they need to provide more information about the scoring function and threshold values. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"scoring function\" and the different components and threshold values/ranges, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the components and threshold values/ranges. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"scoring function\" and different threshold values/ranges are unclear, but it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specificity and does not offer any evidence or references to substantiate the claim. As a result, the authors may find it challenging to understand and address the issue without further guidance. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the components of the \"scoring function\" and the different threshold values/ranges. It highlights a lack of clarity in the methodology, which is an important aspect for readers to understand. However, the comment does not provide actionable suggestions or guidance on how the authors might clarify these aspects in their paper. While it points out a potential weakness, it lacks depth and specificity, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the table or what specific changes could be made to enhance the information presented. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the factors in a table do not effectively convey more messages than pure text, and there is no additional information. However, it does not specify which table or part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity regarding what information is missing or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to support the assertion, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the presentation of information in the paper, specifically the use of factors in a table that do not effectively convey more messages than pure text. It points out the lack of additional information and suggests that the table may not be contributing to the overall understanding of the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the presentation of their findings. Without specific advice or examples, the feedback is limited in its usefulness to the authors. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the simulation should be considered. The comment lacks actionable details, such as recommending ways to categorize or analyze the different physical interactions, or suggesting methods for evaluating the simulation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what kind of physical interactions are being considered or how they might impact the simulation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it highlights an area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the simulation should be considered. Without actionable feedback or context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. The comment provides explicit actions for the authors to take: to include more datasets with categorical features and to employ one hot encoding for the dataset with categorical features. These actions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Model Comparison\" and the \"wide range\" of datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features and that the authors do not employ one hot encoding for this dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model comparison in the paper is inadequate due to the selection of datasets, which lacks categorical features. The reviewer supports this claim by explaining that categorical features are generally more challenging for deep learning and that the omission of one hot encoding for the dataset with categorical features could negatively affect performance. This reasoning is logical and based on common knowledge, making the claim 4. However, the comment could be strengthened by providing specific examples or references to studies that support the importance of categorical features in deep learning. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their model comparison by including more datasets with categorical features and employing one hot encoding for the dataset with categorical features. By addressing these issues, the authors can significantly enhance the robustness and generalizability of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. While the comment identifies a potential issue with the choice of datasets, it does not provide explicit guidance on how to address this issue or what specific datasets would be better options. The authors are left to infer that they should consider alternative datasets, but the comment lacks concrete suggestions or detailed reasoning on how to make these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of two unpopular IoT datasets for benchmarking is a strange and unhelpful choice, as they are not widely followed or used. The reviewer supports this claim by referencing the specific datasets and their publication dates, which provides some context for the unpopularity of these datasets. However, the comment lacks detailed reasoning or examples of alternative datasets that could have been used, which would strengthen the verifiability of the claim. Therefore, the comment is 3, as it provides some evidence but could be more fully substantiated with additional details or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of datasets for benchmarking, specifically the two unpopular IoT datasets mentioned. It provides a logical reasoning for why these choices might be considered unusual, noting that the datasets are relatively recent but not widely followed, and that one of them was published in 2004 and is no longer used much. The comment suggests that there should have been better options for benchmarking, such as wearable health or mobile activity recognition data, or even some sets in UCI. This feedback is 3 as it points out a potential weakness in the paper\"s methodology and suggests alternative datasets that could be considered. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to select better datasets. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"pruning\" and \"distributed settings,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients. This is a logical claim based on the observation that pruning is often used with large networks and that distributed settings are common for training. However, the comment lacks specific examples or references to support the claim that finding global top Q values is necessary to avoid breaking acceleration techniques like quantization and sparsification. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. This feedback is valuable as it highlights a potential gap in the authors\" discussion of pruning techniques and their impact on distributed settings. However, the comment could be more helpful if it provided specific examples or references to support the claim about the necessity of global top Q values. Overall, the comment is 3 as it directs the authors\" attention to an important aspect of their work that requires further consideration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether some subfigures in Figures 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures and potentially correct any errors, it does not provide explicit instructions on how to do so or what specific subfigures might be affected. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking whether some subfigures in Figures 1 and 2 have been swapped by mistake. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the possibility of subfigures in Figures 1 and 2 being swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or verify the accuracy of the figures. The comment lacks actionable feedback or detailed analysis, making it 3 as it points out a potential problem but does not assist the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss the potential increase in false positives due to the dropout probe improving sensitivity. While it implies that this should be a substantial part of the discussion, it does not explicitly instruct the authors to include this in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue in their discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe\" and its impact on sensitivity, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should discuss the potential increase in false positives due to the improvement in sensitivity. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dropout probe improves sensitivity and finds a causal role for syntactic representations that previous approaches might have missed. However, it also suggests that this improvement could lead to an increase in false positives, which is a valid concern. The comment provides a logical reasoning for the potential increase in false positives but lacks specific examples or references to substantiate the claim. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific improvement in the sensitivity of the dropout probe and its potential impact on finding causal roles for syntactic representations. It acknowledges the positive aspect of the improvement but also highlights a potential risk of increased false positives. The comment suggests that this should be a substantial part of the discussion, which is a valuable point for the authors to consider. However, the comment could be more helpful by providing specific suggestions on how to address this issue or discussing potential mitigation strategies. Overall, the comment is 4 as it directs the authors to consider an important aspect of their work that could impact the validity of their findings."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer explicitly states that they could not find the regret bound in the supplementary, which implies that the authors should include it. However, the comment does not provide specific guidance on how to present the regret bound or where it should be located in the paper. While the action is clear, the lack of detailed instructions on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed minibatch method being cast to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the regret bound is not provided in the supplementary material and references a specific work for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support the claim. This reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support their claim. This feedback is clear and actionable, as it directs the authors to include the missing regret bound in the supplementary material. However, the comment could be more helpful if it provided additional guidance on how to present the regret bound or why it is important for the paper. Overall, the comment is 4 as it highlights a critical oversight in the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the paper formatting does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the paper style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as adjusting the formatting style to conform to the NeurIPS guidelines and reorganizing the content accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper formatting, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the formatting, such as the font size of the abstract and the bottom page margins, and suggests that these issues could be addressed by following the NeurIPS formatting style. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that following the NeurIPS formatting style could improve the paper. While the comment identifies specific formatting issues, it lacks detailed reasoning or references to justify why the current formatting is problematic or how following NeurIPS guidelines would improve the paper. This makes the claim 3, as the authors would need to make an effort to understand and address the issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out issues with the font size of the abstract and the bottom page margins, suggesting that these could be improved by following the NeurIPS guidelines. The comment also suggests that this change could gain some space and allow the NLP experiments to be included in the main body of the paper. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the formatting and layout of their paper. However, it could be more helpful if it included examples of how the NeurIPS formatting style should be applied to the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear path for enhancing the presentation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND and ICM). However, it does not provide any explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or comparison of these methods, but it lacks concrete instructions on how to structure this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on these methods but are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"exploration methods in RL literature, such as countbased methods and intrinsic motivations (RND, ICM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being referred to. Without detailed explanations or references, the claim is not 5, as it relies on general knowledge of RL literature rather than specific examples or evidence. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). This is a critical observation that could significantly impact the paper\"s contribution and relevance. However, the comment lacks depth and does not provide specific suggestions on how the authors might address this issue, such as which methods to discuss or how to structure the comparison. While it points out a significant gap, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it implies that the authors should make the annotations larger, it does not provide specific guidance on how to achieve this or what size would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should make the annotations larger but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the enlargement of annotations for better visibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 could be enlarged for better visibility. However, it does not provide any supporting evidence, reasoning, or examples to justify why the annotations are currently too small or how enlarging them would improve visibility. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it provides a specific suggestion for improvement, it lacks depth and does not explain why the current annotations are too small or how enlarging them would impact the figure\"s readability. The comment could be more helpful if it included additional context or examples to guide the authors on how to implement this suggestion effectively. As it stands, the feedback is 3, as it points out a potential issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes should be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the claim regarding the existence of multiple entities in both sentences and documents, including relation classification. The comment provides a clear critique of the claim and suggests that the authors should clarify or reconsider their statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. This is a relevant observation that could impact the validity of the paper\"s claims. However, the comment lacks specificity and does not provide any guidance on how the authors might address this issue or what changes could be made to improve the paper. Without actionable feedback or suggestions, the authors are left without a clear path forward. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 4, noting that one of the labels on the color bar should say \"worse\" instead of \"better.\" This comment provides a clear and direct action for the authors to take, ensuring that the label is corrected. The action is concrete, as it specifies exactly what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, noting that one of the labels should say \"worse\" instead of \"better.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a specific figure, Figure 4, noting that one of the labels on the color bar is incorrect. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that one of the labels on the color bar is incorrect. This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and clarity of their visual presentation. By pointing out this mistake, the comment provides a straightforward way for the authors to enhance the quality of their draft. However, it could be more helpful if it offered suggestions on how to improve the figure or explained why the label is incorrect. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely, changing \"training/validation/test\" to \"training/validation/test sets.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, noting a typographical error in the text. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific typographical error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and actionable suggestion that can help improve the accuracy and clarity of the paper. By correcting this error, the authors can ensure that their manuscript is more precise and professional in its presentation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and concerns about the paper, but it does not provide explicit or implicit actions for the authors to take. It asks for clarification on the inference process and the coefficient of the p(L, E | X) term in line 307, but it does not instruct the authors on how to address these questions. The comment also mentions the lack of hyperparameter details, the need for baseline tuning, and the writing style, but it does not provide specific guidance on how to improve these aspects. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, but it does not specify which part of the paper these issues pertain to. It mentions \"line 307\" but does not provide context or details about what is being referred to in that line. The comment also mentions \"hyperparameter details,\" \"baselines,\" and \"writing style,\" but these references are not specific enough to guide the authors in identifying the relevant sections of the paper. Without clear grounding, the authors cannot effectively address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, hyperparameter details, and the writing style. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions and concerns are presented as statements, rather than as claims that require verification. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas of concern in the paper, including the inference process, the coefficient of the p(L, E | X) term, hyperparameter details, and the writing style. It raises questions about the inference process and the coefficient of the p(L, E | X) term, which are important for understanding the model\"s behavior. The comment also points out the lack of hyperparameter details and the need for baseline tuning, which are crucial for assessing the model\"s performance. Additionally, it critiques the writing style, suggesting that it is not careful and often impedes understanding. While the comment provides some valuable insights, it lacks specific suggestions or guidance on how the authors might address these issues. Therefore, it is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and recommends adding extra brackets around the term or defining the bracketed term separately if space allows. This provides a clear and explicit action for the authors to take, which is to clarify the definition by adding brackets or defining the bracketed term. The comment is specific and provides concrete guidance on how to improve the clarity of the definition. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to clarify the definition by adding extra brackets or defining the bracketed term separately if space allows. This level of detail provides the authors with clear guidance on how to improve the clarity of the definition. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and provides a specific suggestion to clarify it by adding extra brackets or defining the bracketed term separately. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks detailed explanation or examples to fully substantiate the claim. The authors might need to infer the exact impact of the suggested changes, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the definition of the quantile, which is described as \"a little confusing.\" It provides a clear and actionable suggestion to improve the clarity of the definition by adding extra brackets or defining the bracketed term separately if space allows. This feedback is valuable as it directly addresses a potential source of confusion and offers a concrete way to enhance the clarity of the paper. However, the comment could be more helpful if it explained why the current definition is confusing or provided examples of how the suggested changes might improve clarity. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model mentioned in Line 152 is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. This feedback is explicit and provides a clear action for the authors to take, specifying the exact change needed to update the text. The suggestion is concrete, as it provides a specific alternative phrase to use, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the outdated nature of the model mentioned and the suggestion to replace it with a more current description. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model mentioned in Line 152 is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model mentioned in Line 152 is no longer stateoftheart. It provides a clear and actionable suggestion to replace the outdated reference with a more appropriate description, such as \"very high performing model\" or similar. This feedback is valuable as it helps the authors maintain the accuracy and relevance of their work by updating references to current models. However, the comment could be more helpful if it included a rationale or explanation for why the original reference is no longer relevant. Despite this, the suggestion is 4 as it guides the authors on how to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is identified as the main weakness of the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the performance or suggestions for potential modifications to the method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed compression\" and \"PQ,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is the performance of the proposed compression method compared to PQ when a small code length is allowed, highlighting this as the main weakness of the method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional details or data, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is considered the main weakness of the method, as it is relevant to practical applications. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their method. Without specific recommendations or examples, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment explicitly instructs the authors to provide a detailed explanation to verify these statements. While the action is clear, it is somewhat vague in terms of how to present the explanation, as it does not specify the exact format or content of the explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references, and the laborintensive nature of designing effective architectures. It also mentions the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. However, the comment does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for proofs and references, and the need for a detailed explanation of the statements. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims and suggestions, including the need for proofs and references to support subjective statements, the laborintensive nature of designing effective architectures, and the uncertainty regarding when to fuse multiscale features. The reviewer also suggests that models with skip connections could be considered implicit multiscale methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or examples makes the claims 3, as the authors would need to make a significant effort to understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment provides clear and actionable feedback by suggesting that the authors should provide detailed explanations to verify these statements and address the issues raised. This guidance is valuable for the authors to improve their draft, making the comment 4. However, it could be more comprehensive by offering specific examples or suggestions on how to present the explanations. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how the proposed method compares with prior art. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so or offer guidance on how to conduct this comparison. The action is implicit and somewhat vague, as the authors can infer that they need to address this issue but may not be entirely sure of the specifics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the comparison with prior art is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison with prior art. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about how the proposed method compares with prior art. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the comparison of the proposed method with prior art. While it highlights an important area for clarification, it does not provide any guidance or suggestions on how the authors might address this comparison or what specific aspects should be considered. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it identifies an area for improvement but does not offer sufficient guidance for the authors to act upon."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that the authors should explore potential biases in the data and compare them across different languages/nationalities. While the comment does not explicitly instruct the authors to conduct this analysis, it provides a clear direction for improvement by highlighting a specific area that could be expanded upon. The action is implicit but concrete, as it points to a specific aspect of the analysis that could be enhanced. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring potential biases in the data and comparing them across different languages/nationalities. This provides clear guidance on what the authors could address to improve their analysis. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that there might be interesting observations to be made about biases towards different languages/nationalities. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such observations would be interesting or valuable. Without additional context or evidence, the claim remains somewhat vague, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the analysis, suggesting that the \"language/nationality\" section could be more detailed by exploring potential biases across different languages/nationalities. It implies that there might be interesting observations to be made about these biases, which could enhance the analysis and contribute to the paper\"s overall quality. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what specific observations might be interesting. This limits the comment\"s helpfulness, as it points out an area for improvement but does not provide detailed guidance on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this could be necessary and helpful for the approach design. However, it does not provide any explicit guidance or suggestions on what other properties could be considered or how to incorporate them into the approach. The action is implicit and vague, as the authors are left to infer that they should explore other feature properties but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this could be necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this discussion might be relevant. The authors can infer that it relates to the methodology or approach sections, but this inference is not direct. The comment is specific in its suggestion to consider other properties, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this could be necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is important or how it could be beneficial. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment raises a relevant question about the use of other properties of features in addition to norm, suggesting that this could be necessary and helpful for the approach design. This is a valuable point as it prompts the authors to consider alternative ways to enhance their methodology. However, the comment lacks specificity and does not provide guidance on which properties might be beneficial or how to incorporate them into the approach. While it identifies a potential area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. However, it does not provide explicit guidance on how to address these weaknesses or suggest specific changes. The authors are left to infer that they should make changes to the method, but without detailed instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. The comment also questions why two SIRENs are used for f and d, suggesting that the d should be a simpler network. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the method is mostly constructed on top of previous methods, lacks network changes or losses, and questions the use of two SIRENs for f and d. The reviewer also questions why the d should not be a simpler network. While the comment identifies specific weaknesses, it lacks detailed reasoning or examples to fully substantiate the claims. The authors would need to infer the basis of the critique and determine how to address it. Therefore, the comment is 3, as it provides a starting point for the authors to explore but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies several weaknesses in the method, including the lack of network changes or losses and the use of two SIRENs for f and d. It questions why the d should not be a simpler network and highlights the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. While the comment provides some insight into potential areas for improvement, it lacks depth and does not offer specific suggestions or guidance on how to address these weaknesses. The authors are left with a general understanding of the issues but without actionable steps to improve their draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the RQ1 mentioned in the paper is redundant and does not provide additional information. It also proposes an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a specific reference to a related work that could guide the authors in conducting this analysis. While the comment implies that the authors should reconsider their RQ1 and explore the proposed analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1\" and \"RQ2\" and \"RQ3 tsne plots,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the redundancy of RQ1 and the potential analysis on the effect of explicit hate information on implicit hate speech detection performance. The comment provides a reference to a related work, which is helpful in guiding the authors on how to proceed with their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information. It suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a reference to a related work, which supports the claim by offering a potential direction for analysis. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore the reference and consider the suggestion to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the RQ1 mentioned in the paper and suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance. It also proposes an exploration of how this effect impacts RQ2 and RQ3 tsne plots. The comment provides a specific reference to a related work, which could guide the authors in conducting their analysis. This feedback is clear and actionable, offering a concrete direction for improvement that could enhance the paper\"s contribution. However, it could be more helpful if it included more detailed suggestions on how to conduct the analysis or what specific aspects of the analysis should be prioritized. Overall, the comment is 4 as it provides a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any specific guidance on what these tasks might be or how the authors should address this expectation. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the importance of PE in tasks beyond link prediction. Without concrete instructions or examples, the authors may find it challenging to know how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion where this topic could be addressed. The authors can infer that it relates to the broader context of the paper, but without explicit references, the comment lacks full grounding. It is specific in suggesting a topic for expansion but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this expectation or how it relates to their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. While it identifies a potential area for expansion, it lacks specificity and does not provide guidance on how the authors might address this suggestion or what specific tasks should be considered. The comment is 3 as it points out a potential gap in the paper\"s discussion, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. While it implies that the authors should provide a comparison or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the difference between the authors\" work and other works focusing on semantic face editing. However, it does not specify which part of the paper this comparison should be made, nor does it provide details on what aspects of the work need to be compared. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a valid point by asking the authors to elaborate on the difference between their work and other works focusing on semantic face editing. This is a constructive suggestion that could help the authors better position their contribution in the context of existing research. However, the comment lacks specific guidance on how to address this difference or what aspects of the work should be compared. While it identifies an important area for improvement, it does not provide detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to reduce the use of footnotes and move important content into the main body of the paper. It provides a specific example by suggesting moving details around parameter settings to the appendix. This feedback is clear and concrete, giving the authors a direct action to take to improve the draft. The suggestion to move content to the appendix is also detailed, providing specific guidance on how to structure the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of excessive use of footnotes and suggests moving important content into the main body of the paper. The comment provides a specific example by suggesting moving details around parameter settings to the appendix. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively in the paper, which is distracting. It suggests that much of the content is important and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting moving details around parameter settings to the appendix. This suggestion is based on a logical observation that footnotes are not necessary for the main content of the paper. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the suggestion is 3, it could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that footnotes are used excessively and distract from the main content. It suggests that much of the important content should be moved into the main body of the paper. The comment provides a clear and actionable suggestion by providing an example of where to move content, such as parameter settings, to the appendix. This feedback is valuable as it directs the authors to improve the organization and readability of their paper, making it more accessible to readers. However, the comment could be more helpful if it explained why the use of footnotes is distracting or provided additional guidance on how to balance footnotes and main content. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts. It also mentions that the inclusion of zeroshot generation results seems strange and might satisfy general curiosity about the capabilities of the LLM in this setting. However, the comment does not provide explicit instructions on how to incorporate these suggestions or what specific aspects of the discussion should be included. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts. It also mentions the inclusion of zeroshot generation results, which seems strange in the context of the paper. However, the comment does not specify which part of the paper these suggestions pertain to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a discussion about fewshot demonstrations and the inclusion of zeroshot generation results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results seems strange and might satisfy general curiosity about the capabilities of the LLM in the setting. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to substantiate the claim that the inclusion of zeroshot generation results is unusual or unnecessary. As a result, the claim is not 5, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment provides a constructive critique by suggesting that the inclusion of zeroshot generation results might be unusual or unnecessary in the context of the paper. It also suggests that a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts, would be beneficial. While the comment identifies areas for improvement, it lacks specific guidance on how to incorporate these suggestions or what aspects of the discussion should be included. This limits the comment\"s helpfulness, as it provides insight but does not offer detailed instructions for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific problem, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to update the caption or add references to the body text, but the comment lacks concrete details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that \"OAA\" is never referenced in the body text and suggesting that there might be more content in the appendix that is missing or that the caption is out of date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"OAA\" is never referenced in the body text of Figure 3, suggesting that there might be more content in the appendix that is missing or that the caption is out of date. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment highlights a specific problem, it lacks depth and does not provide actionable guidance or suggestions on how to address the issue. The authors are left with a clear indication of a problem but without detailed instructions on how to resolve it. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to clarify in the introduction that the proposed solution is a fix of [12], rather than a new PIC approach. It provides a specific suggestion to make this clarification by mentioning the reference in lines 2930. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (2930) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of whether the proposed solution is a fix of [12] or a new PIC approach. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors need to clarify in the introduction that the proposed solution is a fix of [12], rather than a new PIC approach. The reviewer supports this claim by referencing specific lines in the paper (2930) where the proposed solution is introduced as a new PIC approach. This provides a clear and specific example of the issue, making the claim 4. However, the comment could be strengthened by referencing [12] directly or providing more context on why this clarification is important. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the introduction of the paper, namely, the lack of clarity regarding whether the proposed solution is a fix of [12] or a new PIC approach. By pointing out the confusion in lines 2930, the reviewer provides clear guidance on how to improve the clarity of the introduction. This feedback is actionable and constructive, as it directs the authors to make a precise and necessary correction that can enhance the readability and understanding of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. However, it does not provide explicit instructions or suggestions on how the authors should address this question or investigate the impact of the GS module on the effective receptive field. The comment lacks concrete guidance on what specific analyses or experiments the authors should conduct to answer this question. As a result, the authors are left without clear direction on how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module\" and suggests that the effective receptive field can be computed from a reference [2]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks a question about the effectiveness of the GS module and suggests that the authors investigate how the effective receptive field changed after applying it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the effectiveness of the GS module in propagating context information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. This is an interesting point that could lead to further exploration and analysis. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might investigate or address this question. While it points out a potential area for improvement, it does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network computing the value functions for the states during the finetuning stage. While the comment provides a clear action\u2014adding another head to the network\u2014it does not specify how to implement this addition or what specific changes are needed in the code or methodology. The authors are left to infer the details of execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the objective for the LSTM part, specifically mentioning the probabilities of actions and the finetuning stage. However, it does not specify which part of the paper this pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the objective and the potential approach for finetuning, but it lacks grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the objective of the LSTM part, suggesting that it is the same for pretraining and finetuning. It also provides a possible solution by suggesting that the authors may add another head to the network during the finetuning stage to compute the value functions for the states. This feedback is 3 as it points out a potential weakness and offers a direction for improvement. However, it could be more helpful if it provided more detailed guidance on how to implement this suggestion or what specific changes are needed. Overall, the comment offers some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC and asks if G4RL requires HRAC\"s regularization in the latent space. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HRACG4RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind combining G4RL with HRAC and asks if G4RL requires HRAC\"s regularization in the latent space. This is a relevant question that could help the authors understand the basis of their method and its potential limitations. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works related to supervised, multilingual systems. While the comment implies that the authors should include this acknowledgment, it does not provide specific guidance on which works to mention or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works related to supervised, multilingual systems, providing clear guidance on what needs to be addressed in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works related to supervised, multilingual systems. However, it does not provide specific examples or references to these older works, nor does it explain why acknowledging them is important. Without additional context or reasoning, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works related to supervised, multilingual systems. While it identifies a potential gap in the literature review, it does not provide specific examples of older works to consider or explain why acknowledging them would be beneficial. The comment is 3 as it points out an area for improvement, but it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer points out that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their results. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the results in Table 2, particularly the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The comment further explains the potential reasoning behind this observation, suggesting that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is rather close. This feedback is 3 as it points out a potential issue with the results and suggests a possible explanation for why the linear/exponentialdecay sampling may not perform well. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or test their hypothesis. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the time complexity of the proposed method, including the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the time complexity. The comment lacks concrete details on how to implement these improvements, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the time complexity, such as the potential for many users associated with a typical item and the larger number of hidden units compared to matrix factorizationbased methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. While the comment provides some reasoning by mentioning these factors, it lacks specific examples or detailed explanations to fully substantiate the claim. The authors would need to infer the exact impact of these factors on the time complexity, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. It highlights that these factors could contribute to a high time complexity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the time complexity. While it points out a potential weakness, it lacks actionable advice or detailed feedback that would help the authors make meaningful improvements to their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the figures would be clearer if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a specific action for the authors to take, which is to add this information to the figures to enhance clarity. The comment is explicit and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment suggests that many of the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting what needs to be clarified, namely the types of autoencoders used in the figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figures. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that many of the figures would be more clear if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is 3 as it identifies a specific area for improvement in the clarity of the figures, which could enhance the readers\" understanding of the content. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it is important. Additionally, it does not address other aspects of the paper, such as the content or methodology. Therefore, the comment is 3, as it points out a specific area for improvement but lacks comprehensive guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison with a NeRFbased method, specifically mentioning the recent Zero1to3 and pointe. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides explicit actions to include comparisons and question the relevance, it lacks concrete details on how to implement these suggestions. The authors are given a clear direction but may need to infer the specifics of how to conduct these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment does not specify which part of the paper these comparisons should be included in or how the relevance of the occlusion experiment should be addressed. While the authors can infer that the suggestions relate to the experimental section, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting comparisons and questioning the relevance, but it lacks detailed guidance on implementation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe, is missing. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment lacks specific examples or detailed reasoning to support these claims. The mention of Zero1to3 and pointe provides some context, but the lack of detailed justification or references makes the claim 3. The authors would need to infer the relevance and potential benefits of these comparisons, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of comparisons with NeRFbased methods, such as Zero1to3 and pointe. This suggestion is clear and can help the authors enhance the comprehensiveness and relevance of their evaluation. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment identifies areas for improvement, it could be more helpful if it provided additional context or examples of how these comparisons could be conducted. Overall, the comment is 4 as it offers clear and actionable suggestions for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the use of subscripts s and t in Figure 1. While the comment implies that the authors should provide an explanation for \"multiaspect\" and clarify the subscripts in Figure 1, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and clarify the subscripts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (14 and 47) and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a brief explanation of \"multiaspect\" and the use of subscripts s and t in Figure 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the use of subscripts s and t in Figure 1. However, it does not provide any reasoning or evidence to support why these elements are unclear or problematic. The comment lacks specific examples or references to justify the need for an explanation or clarification. As a result, the claim is not verifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement, namely the need for a brief explanation of the term \"multiaspect\" and the use of subscripts s and t in Figure 1. While it highlights these issues, the comment lacks depth and does not provide detailed guidance on how to address them. It does not offer suggestions on what kind of explanation or clarification would be helpful or how to improve the figure. As a result, the feedback is 3, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It explicitly requests a more detailed analysis of these aspects. While the comment identifies areas for improvement, it does not provide specific guidance on how to conduct the analysis or what aspects should be emphasized. The authors are left to infer that they need to provide more detailed information, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p,\" which likely refers to a specific parameter or value used in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis of these aspects, which could significantly enhance the paper\"s clarity and rigor. While the comment identifies areas for improvement, it lacks specific guidance on how to conduct the analysis or what aspects should be emphasized. This makes the feedback 3, as it points out potential weaknesses but does not provide detailed instructions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks for information about the computational requirements and runtime of the experiments, specifically mentioning the type of hardware used. This is an explicit request for additional details that the authors need to provide to improve the clarity of their draft. The action is clear and concrete, as it specifies exactly what information is needed and how it should be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional details are needed to improve the clarity of the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for additional information about the computational requirements and runtime of the experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by asking for information about the computational requirements and runtime of the experiments. This is important as it can help the authors understand the feasibility and scalability of their experiments. However, the comment could be more helpful if it provided guidance on how to present this information or what specific details should be included. Overall, the feedback is actionable and offers a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors only apply the meta sampler in a decoupled way, specifically when the features are fixed, and asks for more discussion on this. It also requests clarification on when the authors start applying the meta sampler. While the comment implies that the authors should provide more information on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta sampler\" and the \"linear classifier,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether the meta sampler is applied in a decoupled way and requests more discussion on this topic. Additionally, it asks for clarification on when the meta sampler is applied, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It also asks for clarification on when the authors start applying the meta sampler. This feedback is 3 as it identifies a potential area for improvement by prompting the authors to provide more detailed information about the application of the meta sampler. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have discussed this topic. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and encourages them to follow a cited AAAI paper on fairnessaware metrics like Equality Odds (EO). While the comment provides a specific recommendation to conduct more experiments and mentions a relevant paper, it does not explicitly instruct the authors on how to implement these suggestions or what specific aspects of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a vanilla metric and suggests conducting more experiments on datasets like COMPAS and Drug Consumption. It also references a specific paper, \"Exacerbating Algorithmic Bias through Fairness Attacks,\" which provides a clear context for the authors to understand the feedback. However, the comment lacks specificity regarding what aspects of the paper need improvement or how the authors should conduct these experiments. While it provides a clear direction, the lack of detailed guidance on execution makes it fully grounded but underspecific. Therefore, this comment is categorized as 4, aligning with category 4.", "verifiability_rationale": "The review point suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and mentions a specific paper for reference. However, the comment does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would improve the paper. The mention of the cited paper suggests that the reviewer believes it could be relevant, but without further explanation or justification, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors use their own defined vanilla metric and lack related fairnessaware metrics like Equality Odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption, and references a specific paper for guidance. While the comment provides a clear direction for improvement, it lacks detailed guidance on how to implement these suggestions or what specific aspects of the paper should be revised. The feedback is 3 as it points out a gap in the paper but could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to either state the content as a remark or move it to a Discussion section or remove it altogether. This provides a clear and direct action for the authors to take, ensuring that the content is either revised or removed as needed. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L107114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the content seems speculative or overly opinionated and suggests it should be stated as a remark or moved to a Discussion section. This provides clear guidance on how to revise the content. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"L107114 seems speculative or overly opinionated\" and suggests it should be stated as a remark or moved to a Discussion section or removed. However, the comment does not provide any specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (L107114) that is deemed speculative or overly opinionated. It suggests that this content should be stated as a remark or moved to a Discussion section or removed. This feedback is clear and actionable, providing the authors with a concrete direction to address the issue. By suggesting a specific approach to handling the content, the comment offers valuable guidance on how to improve the clarity and objectivity of the paper. However, it could be more helpful if it provided additional context or examples to support the claim of speculation or overly opinionated content. Overall, the comment is 4 as it effectively directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is concrete, as it specifies the baselines to consider, but it is somewhat vague because it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the evaluation or experimental sections, but this inference is not direct. The comment is specific in suggesting the inclusion of these baselines, but it lacks grounding as it does not explicitly mention the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these baselines are relevant or how they would impact the evaluation. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why these specific baselines are relevant. While it points out a potential enhancement, it could be more helpful if it included more detailed reasoning or examples of how these baselines could be integrated into the evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies two missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness across different neighborhood sizes is essential. Additionally, it questions the use of different hyperparameter sets per dataset and recommends providing insights into how performance varies with a constant set of parameters. The comment is clear and provides specific actions for the authors to take, such as conducting an analysis of h and its influence on performance, and standardizing hyperparameter sets across datasets. The explicit nature of the suggestions and the concrete details on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for an analysis of the robustness of the method with respect to different neighborhood sizes and the use of different hyperparameter sets per dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the value of the neighborhood size h and its influence on the model\"s performance are missing elements in the paper. It suggests that this is a key parameter of the proposed strategy and that providing insights into its value and robustness is essential. The comment also questions the use of different hyperparameter sets per dataset, suggesting that standardizing these parameters would be beneficial. While the comment provides logical reasoning and highlights important aspects that need to be addressed, it lacks specific examples or references to support the claim about the influence of h on performance. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two important missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness across different neighborhood sizes is essential, as this is a key parameter of the proposed strategy. Additionally, it questions the use of different hyperparameter sets per dataset, recommending that authors provide insights into how performance varies with a constant set of parameters. This feedback is clear and actionable, as it directs the authors to address specific gaps in their analysis and provide more comprehensive information to enhance the understanding and robustness of their method. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment implies that the authors should consider these questions and potentially address them in their paper, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects of the model. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the model\"s performance or analysis. The comment is specific in its inquiry about the impact of missing modalities and the potential for leveraging additional modalities. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point poses a question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities affect the model\"s ability to construct higherorder interactions and polynomial tensors. The comment does not make a claim or express an opinion but rather seeks clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it prompts the authors to consider a critical aspect of their model\"s robustness and generalizability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or explore the impact of missing modalities. Overall, the comment is 3 as it directs the authors to consider an important aspect of their model but lacks detailed guidance on how to implement the suggested exploration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides specific examples of what to analyze, such as the frequency of \"nothing\" and its impact on context polarity. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. The action is clear and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which are questions and suggestions about the use of the SST dataset and the analysis of negation or intensity words. The comment provides detailed guidance on what statistics to analyze, such as the frequency of \"nothing\" and its impact on context polarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides specific examples of what to analyze, such as the frequency of \"nothing\" and its impact on context polarity. This claim is 3 as it logically suggests that analyzing these statistics could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks detailed justification or references to support the importance of these analyses, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should analyze the statistics of negation and intensity words in the SST dataset. It offers examples of what to analyze, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is clear and provides the authors with a concrete direction for improving their draft. By addressing these suggestions, the authors can enhance the clarity and depth of their analysis, which is highly beneficial for improving the paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, specifically mentioning DrugOOD. It suggests that the authors should verify the stability of their model on this benchmark, which is a clear and explicit action. However, the comment does not provide specific guidance on how to conduct this verification or what metrics to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OGEAug\" and \"DrugOOD\" datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of stability verification on OOD benchmarks, such as DrugOOD, where SPE is validated. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, specifically mentioning DrugOOD. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, such as DrugOOD. It points out that the SPE model is validated on this dataset, highlighting a potential gap in the paper\"s evaluation. This feedback is clear and actionable, as it directs the authors to verify the stability of their model on OOD benchmarks, which could strengthen the paper\"s claims. However, the comment could be more helpful if it provided additional guidance on how to conduct this verification or what specific metrics to use. Overall, the comment is 4 as it effectively identifies a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider freezing some layers of the model while only training a few layers or using parameterefficient methods like LoRA. These suggestions are explicit and provide clear actions for the authors to take, such as considering these methods for experimental comparison. The comment also specifies the potential benefits of these approaches, making it clear what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests considering freezing some layers of the model while only training a few layers or using parameterefficient methods like LoRA. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the model training or parameter efficiency sections, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors consider alternative methods, such as freezing some layers of the model or using LoRA, for parameterefficient model training. While the comment provides a logical reasoning for considering these methods, it lacks specific examples or references to support the claim that these methods are \"natural to think about\" or \"valuable for experimental comparison.\" This makes the claim 3, as the authors would need to infer the benefits and applicability of these methods themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors consider alternative methods for model training, such as freezing some layers or using LoRA, which could provide a valuable basis for experimental comparison. This feedback is actionable and offers a clear direction for the authors to explore and potentially improve their work. By considering these methods, the authors could enhance the scope and depth of their analysis, leading to a more comprehensive and valuable contribution. However, the comment could be more helpful if it provided specific examples or references to these methods, which would guide the authors more directly. Overall, the comment is 4 as it identifies a potential area for improvement and offers a clear suggestion for enhancing the study."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to expand the related work section and compare their work to strong baselines that use coordinates. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The suggestion is concrete, as it specifies the exact content that needs to be included, making it 5.", "grounding_specificity_rationale": "The comment suggests expanding the related work section and comparing the work to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is currently located in, making it weakly grounded. The comment is specific in its request to expand the related work section and compare to strong baselines, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing the work to strong baselines that use coordinates. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests expanding the related work section and comparing the work to strong baselines that use coordinates. This feedback is 3 as it identifies a specific area for improvement, namely the need to provide a more comprehensive comparison with existing work. However, the comment lacks depth and does not offer detailed guidance on how to effectively expand the related work section or what specific aspects of the comparison should be addressed. While it points out a potential weakness, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the experiments should be expanded to include multiple seed experiments. This provides a clear and direct action for the authors to take, as it specifies a specific improvement that would enhance the robustness and significance of the evaluation. The comment is specific in detailing what needs to be added to the experiments, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Single Seed Experiments\" and suggests expanding the experiments to include multiple seeds. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for multiple seed experiments to provide a more robust evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment recommends conducting multiple seed experiments to provide a more robust evaluation. While the claim is logical and based on common sense, it lacks specific examples or references to support the need for multiple seed experiments. This makes the claim 3, as the authors would need to infer the importance of multiple seed experiments themselves.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s experiments, specifically the use of a single seed for training. It suggests that conducting multiple seed experiments would provide a more robust evaluation of the proposed method. This feedback is clear and actionable, as it directly suggests an improvement that could enhance the paper\"s robustness and significance. However, the comment could be more helpful if it provided specific guidance on how to conduct multiple seed experiments or why this is crucial for the evaluation. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, asking for clarification on the motivation behind this choice. While the comment implies that the authors should provide a clearer explanation or justification for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, indicating a lack of clarity in the motivation behind this choice. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, suggesting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It highlights a potential lack of clarity in the paper regarding the rationale behind this choice. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify their methodology. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional guidance on how to improve the explanation or justification for the choice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, making it less accessible for many potential users. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more accessible or suggestions for alternative approaches. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, which makes it less accessible for many potential users. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this requirement affects the accessibility of the method. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible for many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the accessibility of the method. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the accessibility of the proposed method, noting that an entire multiGPU setup is required for optimizations. This is a relevant point that could impact the practicality and adoption of the method by users who may not have access to such a setup. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting ways to make the method more accessible. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing citation for the public skipgram data set in L425. This is a clear and direct action for the authors to take, as it specifies the exact part of the paper that needs to be revised. The comment provides concrete guidance on what needs to be added, making it 5. Authors know exactly what to do to address this issue, ensuring that the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing citation for the public skipgram data set. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing citation for the public skipgram data set in L425. This is a factual statement that does not require any verification or justification. It is a request for clarification or correction, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the missing citation for the public skipgram data set in L425. This is a clear and actionable piece of feedback that the authors can easily address by adding the missing citation. By pointing out this oversight, the comment helps the authors improve the accuracy and completeness of their work. However, it could be more helpful if it provided additional context or explanation about the significance of the data set or its relevance to the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. It provides a clear and concrete action for the authors to take, which is to compare their system with another that captures semantics. However, it does not specify which aspects of the current system should be compared or how to implement the comparison. While the suggestion is explicit, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that captures semantics, potentially using Ref[2] as a baseline. However, it does not specify which part of the paper this comparison should be made, such as a specific section or experiment. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not direct. The comment is specific in suggesting a comparison with Ref[2] as a baseline, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the current system with another system that captures semantics, potentially using Ref[2] as a baseline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered actionable. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. This is a clear and actionable suggestion that could help the authors improve the evaluation of their system by providing a more comprehensive comparison. However, the comment could be more helpful if it provided specific guidance on how to implement this comparison or what aspects of the current system should be compared to the baseline. Overall, the comment is 4 as it identifies a potential area for improvement and offers a concrete suggestion for enhancing the evaluation of the system."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the data used for training, validating, and testing. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should clarify the data sources, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the quantitative results and the need for clarity regarding the data used for training, validating, and testing. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what specific data sources or methods are unclear or how they could be clarified. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point questions the clarity of the quantitative results, specifically asking for more information on the data used for training, validating, and testing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the results are unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the quantitative results, specifically questioning the clarity of the data used for training, validating, and testing. This is a relevant point that could impact the reproducibility and interpretability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not provide specific guidance on how the authors should address these issues or what steps to take to improve the model. The comment lacks concrete actions or detailed suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of model performance and suggesting that assumptions might not be satisfied or that there could be learning difficulties. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that assumptions are not satisfied or that learning difficulties exist. Without such evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. It prompts the authors to consider whether the model is encountering difficulties in learning or if assumptions are not being met. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern. The feedback is 3 as it points out a potential problem but does not offer detailed guidance on how to resolve it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment requests that the authors provide a rationale for why their SE framework can help improve the system and how it does so. It suggests that the authors should not just present their achievements but also explain why and how they managed to achieve them. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not explicitly instruct the authors to use this reference or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their approach and its benefits. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a rationale and explanation of how the SE framework can help improve the system. The reference to [1] Luo, et al. provides additional context and guidance for the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale and explanation behind the SE framework\"s ability to improve the system. It suggests that the authors should provide a detailed explanation of why and how the framework can help, rather than just presenting results. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not provide specific examples or detailed reasoning from the referenced work to support the claim. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of a clear rationale and explanation for why the SE framework can help improve the system. It suggests that the authors should not just present their achievements but also provide a detailed explanation of why and how they managed to achieve them. The comment references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. This reference could be useful for the authors to consider in their response. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested ways to improve the explanation. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific steps to take to improve the generalization of the system. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion that the system should be able to generalize to more views, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it could be addressed. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. While it identifies a potential weakness in the approach, it lacks specificity and does not provide actionable guidance or suggestions on how to address this limitation. The comment is 3 as it points out an area for improvement, but it does not offer detailed advice or examples on how to enhance the generalization of the system. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the metrics used for evaluating continual learning, specifically noting that they are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to adapt the metrics or suggest alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. However, it does not specify which part of the paper these metrics are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment also notes that these metrics may not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable, but it does not provide specific guidance on how to address this issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This claim is 3 as it provides a logical reasoning based on the nature of the metrics and their applicability to different scenarios. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue, which would further substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically noting that they are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This is a relevant observation that highlights a potential weakness in the paper\"s methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or adapt their metrics to different settings. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. While the comment identifies an area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind the user decoder\"s information usage but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"user decoder\" and \"agent decoder,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the user decoder only uses information up to time step t and does not consider information from all time steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind the user decoder\"s use of information from the agent decoder, specifically questioning why it only uses information up to time step t and does not consider information from all time steps. This feedback identifies a potential area of confusion or inconsistency in the paper, prompting the authors to clarify their methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional information might be needed to clarify the rationale. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing discussion on arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on \"arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice and the sensitivity analysis of this hyperparameter. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on arbitrary hyperparameter \u03b3 is missing, including how to set it in practice and analyzing its sensitivity. This claim is 3 as it highlights a specific omission in the paper, but it lacks detailed justification or examples to fully substantiate the importance of including this discussion. The authors may need to infer the significance of this omission themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the lack of discussion on the arbitrary hyperparameter \u03b3, including how to set it in practice and analyzing its sensitivity. This feedback is clear and actionable, as it points out a critical area that needs to be addressed in the paper to ensure that the research is accessible and understandable. By providing a concrete suggestion for improvement, the comment empowers the authors to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it included specific examples or references to similar discussions in related literature, which would further guide the authors in their analysis and presentation. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider a controlled baseline that ablates heads at different locations in the model to address the confounding factor of head location in the induction and FV heads. This feedback provides a clear and explicit action for the authors to take, which is to implement a controlled baseline that can help isolate the impact of head location on ICL performance. The suggestion is concrete and provides a specific direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head location within the model. It suggests that a controlled baseline should be considered to isolate the impact of head location. However, the comment does not specify which part of the paper discusses the induction and FV heads or where the controlled baseline should be implemented. While the authors might have an idea of where these elements are discussed, the comment lacks full grounding. It is specific about the need for a controlled baseline but does not provide detailed guidance on how to implement it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head location within the model. The reviewer proposes a controlled baseline to isolate the impact of head location. However, the comment lacks specific examples or references to support the claim that head location is a significant confounding factor. Without detailed evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the difference in ICL performance when ablating induction heads versus FV heads, suggesting that the location of these heads within the model could be a contributing factor. It provides a clear and actionable suggestion by recommending the inclusion of a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it offers a specific direction for the authors to address the issue and improve their analysis. However, the comment could be more helpful if it provided additional context or examples of how this controlled baseline might be implemented or what specific locations should be considered. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a section on synonym identification under similarity measurement, which is a clear and direct action for the authors to take. It specifies the missing section and provides a specific suggestion for what should be included, namely a description of how the multiplechoice task is approached. This level of detail makes the action explicit and concrete, allowing the authors to know exactly what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a section on synonym identification, and provides a clear direction for improvement by suggesting a description of how the multiplechoice task is approached. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their draft. By adding this section, the authors can provide a more comprehensive explanation of their approach to the multiplechoice task, which could enhance the understanding and applicability of their work. However, the comment could be more helpful if it offered suggestions on how to structure or present this section, or if it highlighted other areas where similar information might be relevant. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the action is implicit, it is concrete because it specifies what needs to be added (an overview of the workflow and the model). This provides the authors with a clear direction on how to enhance their draft, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, nor does it provide details on what aspects of the workflow and model should be covered. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in suggesting the need for an overview but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning or examples to support why this overview is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. This feedback is 3 as it identifies a potential area for improvement in presenting the key components of the paper. However, the comment lacks specific guidance on what aspects of the workflow and model should be covered or how this overview should be structured. While it points out a need for clarity, it does not provide detailed suggestions on how to achieve it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It also mentions that this information cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to discuss this issue but are not given clear instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to know the statistical dimension d_lambda of the design matrix A and the issue with computing it accurately without the same runtime as ridge regression. It also mentions a similar issue with the surrogate sketch. This allows the authors to accurately identify the parts of the paper being addressed, such as the sections discussing debiasing and surrogate sketch computation. The comment is specific because it clearly outlines the problem with the approach and suggests that it may not achieve its intended purpose due to the computational requirements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the debiasing approach requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without the same runtime as ridge regression. The reviewer suggests that this issue may defeat the purpose of the approach and points out that it is not discussed in the paper. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to substantiate the claim fully. The authors would need to further explore the issue and provide evidence to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It points out that this information cannot be computed accurately without the same runtime as required for ridge regression, which could lead to bias and defeat the purpose of the approach. The comment also notes that this issue is not discussed in the paper. While the comment highlights a significant concern, it lacks specific suggestions or guidance on how the authors might address this issue or discuss it in the paper. The feedback is 3 as it alerts the authors to a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3 as the expected quantities are scalars but shown as a vector. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is 5 as it clearly specifies what needs to be done to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, redefining the figure to accurately represent the expected quantities as scalars. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figure should be redefined as the expected quantities are scalars but shown as a vector. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific issue with Figure 3, noting that the expected quantities are scalars but shown as a vector. This feedback is clear and actionable, as it directs the authors to redefine the figure to accurately represent the expected quantities. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why the current representation is misleading or offering guidance on how to present the data more accurately. Overall, the comment is valuable for directing the authors to make a specific improvement, but it could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance on how to improve the experiment setup or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions on how to enhance the experiment setup, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not specify which part of the paper this pertains to, such as the experimental section or the results section. The authors cannot confidently determine which part of the paper is being addressed, making this comment 1. Additionally, the comment lacks specificity as it does not detail what questions arise or how the experiment setup could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the ablations deserve better experiment setup due to the many questions that arise. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance or examples on what aspects of the experiment setup need improvement or how to address the questions that arise. Without actionable advice or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful, as it lacks depth and specificity, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. While the comment implies that the authors should conduct additional experiments, it does not specify which experiments to conduct or how to conduct them. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed models\" and the \"hypothesis\" related to learning representations for lowfrequency words. It also specifies the issue of the lack of empirical evidence to support the argument, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed models are particularly useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. It suggests that the authors should explore this aspect further by providing empirical evidence. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to make a significant effort to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. This feedback is clear and actionable, as it directs the authors to a specific area where their work could be strengthened. However, the comment could be more helpful if it provided suggestions on which types of experiments or data sets would be most appropriate for testing the hypothesis. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. It specifically mentions that the resolution of the 3D voxel should be considered and that the study should be included in Sec4.2. The comment provides a clear and explicit action for the authors to take, which is to conduct a study comparing the global feature with different voxel resolutions. The suggestion is concrete and provides a specific direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of the global feature and its resolution, and suggests comparing it with different resolutions of voxel features. This provides clear guidance on what the authors should consider in their analysis. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the study of global features should consider the resolution of the 3D voxel and compare it with different resolutions of voxel features. The reviewer provides a logical reasoning by explaining that the high computational and memory cost of voxellike features might be a reason for avoiding them. However, the comment lacks specific examples or references to support the claim about the overhead introduced by the resolution. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to study the importance of the global feature by comparing it with different resolutions of voxel features. It highlights the potential issue of high computational and memory cost associated with voxellike features and suggests that the resolution of the 3D voxel should be considered. By making this suggestion, the reviewer empowers the authors to enhance their analysis and provide a more comprehensive understanding of the global feature. However, the comment could be more helpful if it included specific examples or references to support the claim about the overhead introduced by the resolution. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the error analysis on the movie dataset is missing and highlights the need for other researchers to understand the cases where the model fails. This provides a clear and direct action for the authors to include an error analysis section in their paper. The comment is specific and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the error analysis on the movie dataset, and why it is important for other researchers to understand the cases where the model fails. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper\"s contribution. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this omission. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers to understand the cases where the model fails. This feedback is clear and actionable, as it directly points out a critical area that needs to be addressed in the paper. However, the comment could be more helpful if it provided specific suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests that it would be interesting to see development set trends with respect to these hyperparameters. While the comment implies that the authors should explore this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the trends in Table 3 and the impact of hyperparameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the table, noting that it is difficult to see trends, particularly regarding the behavior of PM+CL compared to PM or CL alone. The comment suggests exploring development set trends with respect to these hyperparameters, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests that exploring development set trends with respect to these hyperparameters would be interesting. However, the comment lacks specific examples or detailed reasoning to support why this exploration is necessary or how it would improve the paper. Without additional context or evidence, the claim is 3, as it provides a suggestion but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests that exploring development set trends with respect to these hyperparameters would be interesting. This feedback is 3 as it points out a potential area for improvement in the presentation of results, but it lacks detailed guidance on how to address the issue or what specific trends should be explored. While it provides a direction for improvement, the comment could be more actionable with additional suggestions or examples. Therefore, it is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of Figure 5, noting that there are many lines on top of each other, making it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added or clarified, but it is somewhat vague in terms of how to implement these changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the difficulty in understanding the figure due to the overlapping lines and suggests reporting additional metrics like flops or model size to provide a more concrete understanding of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the overlapping lines and suggests that the authors could report additional metrics like flops or model size to provide a more concrete understanding of the results. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is unclear or how the suggested metrics would improve clarity. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 5, noting that the overlapping lines make it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensiveness of their figures and metrics reporting. However, the comment could be more helpful if it provided specific guidance on how to present these additional metrics or how to improve the figure\"s clarity. Overall, the comment is 4 as it offers concrete suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific guidance on what details are missing or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment mentions the \"questions section below,\" which implies that it is referring to a specific part of the paper. However, without explicit mention of a section or table, the authors cannot confidently determine the exact part being addressed. The comment also lacks specificity as it does not detail what specific details are missing or how they should be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide specific examples or reasoning to support this claim. The mention of the \"questions section below\" suggests that the reviewer is referring to a specific part of the paper, but without further elaboration, it is difficult for the authors to understand which details are missing or how to address them. The lack of detailed justification or examples makes the claim 1, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any further explanation or guidance on what details are missing or how they could be addressed. Without specific examples or suggestions, the authors are left without actionable feedback to improve their draft. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends simplifying the description and explaining the architecture and computations better. It also suggests reducing Figure 7, Section 8, and specific lines (3964) to gain more space. These explicit actions provide clear guidance on what the authors need to do to improve the draft. The comment is concrete, as it specifies which parts of the paper need simplification and reduction, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the paper being too dense and difficult to follow, suggesting that it needs simplification and better explanation of the architecture and computations. It provides specific examples of sections and lines that could be reduced to gain more space. However, it does not explicitly mention which sections or lines should be reduced, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as simplifying the description and explaining the architecture and computations better. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to understand the concepts and contributions. It suggests simplifying the description and explaining the architecture and computations better. The comment provides specific examples of sections and lines that could be reduced to gain more space. This claim is 3 as it offers a logical reasoning for simplifying the paper, but it lacks detailed justification or references to support the claim that the paper is too dense. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is too dense and difficult to follow. It suggests simplifying the description and explaining the architecture and computations better, which is a crucial improvement for the clarity and accessibility of the paper. The comment provides specific examples of sections and lines that could be reduced to gain more space, offering actionable guidance for the authors. However, the comment could be more helpful if it provided additional suggestions on how to simplify the description or explained why these sections are particularly challenging to understand. Overall, the comment is 4 as it effectively points out a significant weakness and offers concrete steps for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of comparison to be made, but it is somewhat vague in terms of how to implement it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests a specific comparison to be made regarding the evaluation of oversmoothing, particularly with respect to the EIGNN model and variants that focus on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this evaluation is currently included in, making it weakly grounded. The comment is specific in suggesting a particular comparison to be made, but without explicit references to sections or figures, the authors may struggle to identify the exact location of the evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the evaluation. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests a specific comparison that could be made in the evaluation of oversmoothing, specifically by comparing the EIGNN model with variants that focus on dealing with oversmoothing, such as GCNII. This feedback is actionable as it provides a clear direction for the authors to enhance their evaluation by including a comparison that could offer insights into the performance of the EIGNN model under standard settings on realworld datasets. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted or what specific aspects to focus on. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to add a separate section or subsection to introduce the inference strategy, but the comment lacks concrete details on what this section should include or how to implement it. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment explicitly mentions the \"approach method\" and the \"inference strategy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly the use of multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting the absence of a separate part or subsection to introduce the inference strategy, particularly the use of multiple prompts in the test stage. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by providing a dedicated section to explain the inference strategy. However, the comment could be more helpful if it offered suggestions on how to structure this section or what specific aspects to cover. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Figure 4 is confusing and notes that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in the figure and its caption. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure and the lack of explanation in the text or caption. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The comment claims that Figure 4 is confusing and points out that the columns are not explained in the text or caption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing and that the columns are not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns and provide explanations in the text or caption. By addressing this issue, the authors can improve the clarity and accessibility of their figure, making it more understandable for readers. However, the comment could be more helpful if it provided suggestions on how to clarify the columns or offered examples of how similar figures have been effectively explained. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results could be discussed more, specifically questioning whether the MaxGapTop2UCB algorithm is better than others based on the Streetview experiment. It also points out the lack of clarity regarding the realworld applications of the problem setting and the computational complexity of the proposed algorithms. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects should be discussed in the paper. The authors are left to infer that they need to provide more detailed discussions and address the computational complexity, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Streetview experiment\" and the \"realworld applications of this new problem setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the conclusion from the Streetview experiment and asking about the computational complexity of the proposed algorithms in the context of ranking problems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the conclusions drawn from the Streetview experiment and the realworld applications of the problem setting. It suggests that the authors should discuss the results more and questions whether MaxGapTop2UCB is better than other algorithms. The reviewer also points out the complexity of the proposed algorithms in the context of ranking problems, which is a valid concern. However, the comment lacks specific examples or references to support the claim about the complexity or the need for more discussion on the results. This makes the claim 3, as it provides some reasoning but requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable critique of the paper, identifying areas where the authors could improve the discussion and clarity of their results. It questions the conclusion drawn from the Streetview experiment and suggests that the authors should discuss the results more thoroughly. Additionally, it points out the lack of clarity regarding the realworld applications of the problem setting and the computational complexity of the proposed algorithms in the context of ranking problems. While the comment highlights important areas for improvement, it could be more helpful if it provided specific suggestions on how to address these issues or what aspects of the discussion should be expanded upon. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their analysis and discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. The reviewer implies that more explanations are needed to understand the discrepancy. However, the comment does not provide explicit guidance on what specific explanations should be given or how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given concrete steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for more explanations, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the low results obtained using only ML in the ablation experiments, suggesting that they are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these results are unexpected or problematic. Without specific examples or comparisons, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that they are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. This prompts the authors to consider providing more explanations for the discrepancy. However, the comment does not offer specific suggestions or guidance on what kind of explanations might be helpful or how the authors might address this issue. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. However, it does not provide explicit guidance on how to include ablation analysis or what specific components should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include ablation analysis but without clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper lacks this analysis, such as the specific sections or experiments where it should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue of lacking ablation analysis, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. This is a critical observation that highlights a gap in the experimental analysis, which could be crucial for understanding the impact of different components on the overall performance. However, the comment does not provide specific suggestions on how to address this issue, such as which components should be analyzed or how to conduct the ablation analysis. While it points out a significant weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it identifies a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any guidance or suggestions on how the authors should address this observation or what implications it might have for their work. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" which likely refers to a specific figure or table in the paper. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not detail what aspect of the noise rate of similarity labels compared to class labels is problematic or how it affects the paper. Without additional context or suggestions for improvement, the authors may find it challenging to address the issue effectively. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand or verify the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any actionable feedback or suggestions for the authors to address this observation or how it might impact their work. Without additional context or guidance, the authors are left without a clear understanding of how to proceed or what improvements could be made. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a concern about the verification of the hypothesis, specifically noting that the experiment is not welldesigned. It suggests that the base model should be trained on the original dataset along with the adversarial set to better highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to modify the experimental design to include the comparison between the original dataset and the mixture. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the hypothesis through an experiment that compares the base model trained on the original dataset with that trained on the mixture of original and adversarial examples. This provides clear guidance on how to improve the experimental design to better highlight the impact of the augmented adversarial examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is interesting but not wellverified by the designed experiment. It references Section 3.1 to support this claim, specifically mentioning that models in conventional methods are trained on the original training set in addition to the generated adversarial examples, while the base model is trained on the adversarial set only. The reviewer suggests that comparing the model trained on the original dataset with that trained on the mixture would highlight the impact of the augmented adversarial examples. This claim is 3 as it provides a logical reasoning for the need to compare the models, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the verification of the hypothesis, specifically noting that the experiment is not welldesigned. It points out that the base model is trained on the adversarial set only, while conventional methods train on the original training set in addition to the generated adversarial examples. The comment suggests that comparing the model trained on the original dataset with that trained on the mixture would highlight the impact of the augmented adversarial examples. This feedback is clear and actionable, providing the authors with a specific and direct way to improve the experimental design and make the hypothesis more convincing. By addressing this issue, the authors can enhance the credibility and robustness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. There is no guidance on what aspects of the experiments are lacking or how they could be improved. Without explicit or implicit suggestions for improvement, the authors are left without a clear understanding of what changes are needed to enhance the convincingness of their results. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the CNN experiments, but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what aspects of the experiments are not convincing or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without additional context or reasoning, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of supporting evidence or justification makes the claim 1, as it does not provide sufficient information for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment mentions that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without further explanation or guidance, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of actionable feedback limits the usefulness of the comment, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly points out that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper and suggests that if the authors computed these results themselves, they should mention it. This provides a clear and direct action for the authors to take, ensuring that they either report the results from the original paper or acknowledge their selfcomputation. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"model (3) (Chung et al. 2016) for CsEn,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the results were taken from the original paper or computed by the authors themselves. This provides clear guidance on what needs to be corrected or clarified in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper, suggesting that the authors should mention if they computed these results themselves. The comment is 3 as it provides a specific reference to the original paper, which could help the authors verify the claim. However, the comment lacks detailed reasoning or explanation about why the results should be reported or how they might impact the paper. This makes it 3, as the authors would need to follow up with additional research or clarification to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper. It suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, as it provides a direct and specific suggestion for the authors to either report the results from the original paper or acknowledge their selfcomputation. By addressing this issue, the authors can improve the accuracy and transparency of their work. However, the comment could be more helpful if it provided additional context or explanation about why this issue is important or how it affects the overall paper. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer implies that discussing how to design prompts effectively is crucial. However, the comment does not provide specific guidance on how to achieve this or what aspects of prompt design should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to focus on prompt design but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper discusses these prompting methods or where the authors should focus their attention. The authors can infer that it relates to the sections discussing prompt design, but this inference is not direct. The comment is specific in its suggestion to discuss prompt design effectively, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer argues that different prompts may result in varying performance outcomes, emphasizing the importance of discussing how to design prompts effectively. However, the comment lacks specific examples or references to support the claim that different prompts lead to varying performance outcomes. This makes the claim 3, as the authors would need to infer the importance of prompt design and the potential impact on performance outcomes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer highlights the importance of discussing how to design prompts effectively, given that different prompts may result in varying performance outcomes. This feedback is clear and actionable, as it directs the authors to focus on a critical aspect of their work that could significantly impact its impact and effectiveness. However, the comment could be more helpful if it provided specific suggestions or examples of effective prompt design strategies. Overall, the comment is 4 as it identifies a key area for improvement and offers a direction for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the comment implies that the authors should include such comparisons, it does not provide explicit instructions or detailed guidance on how to conduct these comparisons or what specific aspects to focus on. The action is clear but somewhat vague, as the authors know they need to compare their results but may not be entirely sure of the exact steps to take. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be included in, such as the results or discussion sections. The authors can infer that it relates to the results or evaluation sections, but this inference is not direct. The comment is specific in suggesting a comparison with SoTA approaches, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific improvement by recommending the authors compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is actionable as it provides a clear direction for enhancing the paper by demonstrating the relevance and impact of the proposed method in the context of existing work. However, the comment could be more helpful if it included additional guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it identifies a meaningful area for improvement but could be more comprehensive with further details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they should clarify the rationale behind the use of freezing and consider using an adaptive method for subset selection. Without concrete steps or examples, the authors may find it challenging to implement the suggested changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MLS selection,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of freezing in MLS selection and suggesting that adaptive methods could be used instead. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests that adaptive methods could be used instead. However, the comment lacks specific reasoning or evidence to support why the use of freezing is unclear or ineffective. It does not provide examples or references to similar studies or methods that have successfully used adaptive methods for subset selection. As a result, the claim is not 5, as it relies on a general suggestion without detailed justification or evidence. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a valid question about the use of freezing in MLS selection and suggests that adaptive methods could be a better approach. This feedback prompts the authors to reconsider their methodology and potentially improve their draft by exploring alternative methods. However, the comment lacks specific guidance or examples on how to implement the suggested change or why it might be beneficial. While it identifies a potential area for improvement, it does not provide detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This is a clear and direct action that the authors can take to improve their draft. The comment is specific in its request for a detailed plan, which provides a concrete direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations mentioned in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more detailed plan on how to address the limitations in future work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they intend to address the limitations mentioned in the paper. However, the comment does not provide any specific examples or reasoning to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive approach to addressing the drawbacks. However, the comment could be more helpful if it offered specific suggestions on what elements of the plan should include or how to prioritize these limitations. Overall, the comment is 4 as it guides the authors toward a more comprehensive approach to addressing the limitations, but it could be more detailed to be fully beneficial."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should perform a similar analysis on the proposed knowledgeCLIP model as done in existing work that combines text and KGs. This feedback implies that the authors should conduct an experiment to test the robustness of their model in handling negation or changes in entities in the text. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear direction for further investigation. The action is explicit and concrete, as it specifies the type of analysis to be conducted, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed knowledgeCLIP model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting an analysis similar to existing work that combines text and KGs, providing a clear direction for improvement. This feedback is detailed and actionable, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the issue is not resolved in the proposed knowledgeCLIP model and recommends conducting an analysis similar to existing work that combines text and KGs. The comment provides a reference to an external work that has performed similar analyses, which adds some level of verification to the claim. However, the comment lacks specific examples or detailed reasoning from the existing work to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or explanation to be fully convincing.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct an analysis similar to existing work that combines text and KGs to test the robustness of their proposed knowledgeCLIP model. By referencing an external work that has performed similar analyses, the comment highlights a specific area for improvement and offers a concrete direction for the authors to enhance their draft. This feedback is valuable as it encourages the authors to conduct a meaningful experiment that could strengthen their model\"s robustness. However, the comment could be more helpful if it provided specific guidance on how to implement this analysis or what aspects of the existing work should be emulated. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, and questions the reason for this choice. It also suggests that the authors consider adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides explicit actions for the authors to take, such as clarifying the reason for the choice and considering adding variance. Additionally, it offers specific guidance on how to improve the draft by suggesting a change in notation. The actions are concrete and detailed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of p m in the numerator and p c in the denominator, suggesting that the authors clarify the reason for this choice. Additionally, it recommends adding the variance for further improvement and suggests using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, questioning the reason for this choice. It suggests that the authors consider adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides logical reasoning by suggesting that using \u03bc g instead of \u03bc f would be consistent with the equation. However, it lacks specific examples or references to support the claim that using variance would improve the results. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the use of p m in the numerator and p c in the denominator in Eq. 3. It questions the reason for this choice and suggests that the authors consider adding the variance for further improvement. Additionally, it recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. This feedback is clear and actionable, as it provides specific guidance on how to clarify the notation and improve the paper. By addressing these points, the authors can enhance the clarity and coherence of their work. However, the comment could be more helpful if it included examples or detailed explanations of how the variance could be incorporated or why \u03bc g is preferred over \u03bc f. Overall, the comment is 4 as it offers valuable insights and suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should provide a more comprehensive discussion about the computational complexity of the proposal and raises a question about whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed discussion and address the computational cost issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"additional cost\" and the \"computational complexity of the proposal,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the computational cost and its potential impact on the approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the computational cost of the proposed approach and questions whether it becomes prohibitive in certain settings. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It suggests that the paper should provide a more comprehensive discussion about the computational complexity and raises a question about whether the approach becomes prohibitive in certain settings. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to address the computational cost issue or what aspects of the approach might be problematic. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to clarify how novel values in the test set are handled for clarity. This is a direct and concrete action, as it specifies exactly what needs to be addressed. The authors know exactly what information is missing and how to provide it, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how novel values in the test set are handled. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors clarify how novel values in the test set are handled for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where clarity is needed, specifically regarding how novel values in the test set are handled. By pointing out this gap, the comment provides the authors with a clear direction for improving the draft. However, the comment could be more helpful if it offered suggestions on how to clarify this aspect or provided examples of how other studies handle similar issues. While it highlights an important area for improvement, the feedback could be more comprehensive to be fully beneficial. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that similar methods have already been proposed for multitask learning and were not discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a discussion of related work or a comparison with existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Similar methods have already been proposed for multitask learning and has not been discussed in this paper [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on similar methods for multitask learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar methods have already been proposed for multitask learning and were not discussed in the paper. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by pointing out that similar methods for multitask learning have already been proposed and were not discussed. This is a relevant observation that could prompt the authors to include a discussion of related work or to address the limitations of their approach in comparison to existing methods. However, the comment lacks specific suggestions or guidance on how to incorporate this information into the paper. While it highlights an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FedMITR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the amount of computation required for FedMITR compared to other methods, indicating a potential area for improvement or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment poses a question about the expected computation of FedMITR compared to other methods, suggesting that this might be an area for comparison. While it highlights a potential weakness or area for improvement, it does not provide specific guidance or suggestions on how to address this issue or what specific comparisons should be made. The comment is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it unclear whether this suggestion is being implemented. The comment provides a specific action\u2014using a generic external knowledge base\u2014but lacks concrete guidance on how to implement it or address the confusion in the writing. The authors are left with a clear action but without detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests avoiding \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, it acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment references \"1) and 2)\" and Figure 3, it does not specify which parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting the use of a generic external knowledge base, but without detailed guidance on how to address the confusion in the writing, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using a generic external knowledge base (as shown in Figure 3) can avoid \"1) and 2)\" and that the writing is confusing. However, the comment lacks specific examples or detailed reasoning to support the claim that the external knowledge base would be beneficial or how it would address the confusion in the writing. Without additional context or evidence, the authors may find it challenging to understand and implement the suggestion. Therefore, the claim is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment provides a specific actionable suggestion, it lacks depth and does not offer detailed guidance on how to effectively implement the external knowledge base or address the confusion in the writing. The feedback is 3 as it points out a potential solution but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of the choice, and whether other influential losses have been considered. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The comment implies that the authors should provide more detailed information about their methodology, but it does not specify exactly what aspects need to be clarified or how to implement the changes. Therefore, the action is explicit but somewhat vague, making this comment 4.", "grounding_specificity_rationale": "The comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of this choice, and whether other influential losses have been considered. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the methodology and the potential impact of the choice, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and requests for clarification regarding the methodology used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also asks whether other influential losses have been considered, such as replacing the min with a mean or NDCG. These questions are relevant and could prompt the authors to reconsider their methodology and potentially improve the robustness of their results. However, the comment lacks specific guidance or suggestions on how to address these issues, making it 3. The authors are given direction but may need to infer the exact steps to take. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of indepth analysis on experimental results, specifically questioning why improvements are limited on one dataset and significant on another. This provides a clear and direct action for the authors to take, which is to conduct a more detailed analysis of the experimental results. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for an indepth analysis on the improvements of models, particularly on the offense detection dataset and the coarse stereotype set. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited improvements of models on the offense detection dataset and the significant improvements on the coarse stereotype set. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of indepth analysis on experimental results. It points out that the improvements of models are limited on one dataset (offense detection) and significant on another (coarse stereotype set). This feedback is clear and actionable, as it directs the authors to provide a more detailed analysis of their experimental results to better understand the underlying reasons for the observed trends. By addressing this issue, the authors can enhance the comprehensiveness and robustness of their study. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests several actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. The reviewer also mentions that the current method might not work due to the small number of conv layers. However, the comment does not provide specific guidance on how to implement these suggestions or what specific changes should be made to the method. The action is implicit and somewhat vague, as the authors need to infer the details of how to apply these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the method of training on labeled data and incorporating input mask explanation annotations, as well as the use of modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. It suggests that the current method might not work due to the small number of conv layers. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the number of examples and the use of modern baselines. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method might not work due to the small number of conv layers and the use of modern backbone baselines like Resnet50 or DenseNet121. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to similar interventions that have failed, making it difficult for the authors to understand the basis of the skepticism. As a result, the claim is 3, as it provides a logical argument but lacks sufficient evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical analysis of the proposed method, suggesting that the current approach might not work due to the small number of conv layers and the use of modern backbone baselines like Resnet50 or DenseNet121. The reviewer also recommends incorporating input mask explanation annotations for a few examples and using modern backbone baselines for the feature extraction layer. While the comment identifies potential weaknesses and offers suggestions for improvement, it lacks specific guidance on how to implement these changes or what specific aspects of the method need to be addressed. The feedback is 3 as it points out areas for improvement but could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method. This implies that the authors should make a comparable effort to optimize the baseline as they do for their proposed method. However, the comment does not provide specific guidance on how to achieve this or what steps to take to ensure a fair comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of multiple hyperparameters and the extensive hyperparameter search, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of ensuring that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment highlights the extensive hyperparameter search, it lacks specific examples or references to support the claim that this is necessary. The reasoning is based on a general assumption that ensuring fairness is important, but it does not provide detailed evidence or justification for why this is crucial. Therefore, the claim is 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the need to ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is a relevant point that could impact the validity and fairness of the results. However, the comment lacks specific guidance on how to achieve this or what steps the authors should take to ensure a fair comparison. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not provide actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. While the comment provides explicit guidance on what needs to be corrected, it does not offer specific suggestions on how to revise the definition or equation to ensure accuracy. The action is clear but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is incorrect about the definition of perplexity and the equation mentioned, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. The reviewer also notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the paper regarding the definition of perplexity, noting that it is not correctly defined. It also points out that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. This feedback is clear and actionable, as it provides the authors with specific guidance on how to correct the errors in their work. By addressing these issues, the authors can improve the accuracy and clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to revise the definition or equation to ensure correctness. Overall, the comment is 4 as it directs the authors to a critical area needing correction, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action for the authors to take, as it specifies the exact improvement needed and provides a concrete direction for testing. The comment is specific and provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and the \"compared baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing baselines, such as MVGRL[4] and gptgnn[5], and suggests adding more baselines of graph contrastive learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL[4] and gptgnn[5]. However, the comment does not provide any supporting evidence or reasoning to justify why these baselines are necessary or how their inclusion would improve the study. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficiency of the baseline for the graph classification task. It points out the absence of certain baselines, such as MVGRL[4] and gptgnn[5], and suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting specific additions and tests that could enhance the robustness and comprehensiveness of the study. However, the comment could be more helpful if it explained why these additional baselines are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern with the evaluation of the proposed strategies, specifically mentioning the need to test the defense against an adversarial attack. It suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. However, the comment does not provide specific guidance on how to implement this evaluation or what specific adversarial examples should be used. The action is implicit and somewhat vague, as the authors can infer the need for an adversarial evaluation but may not know exactly how to conduct it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation of the proposed strategies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern about the defense against an adversarial attack, including the need to evaluate against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of the proposed strategies is insufficient, specifically mentioning the need to test against adversarial attacks that produce minimal structural alterations to the edge map but mislead the model predictions. The comment provides a logical reasoning by highlighting the potential vulnerability of the defense against such attacks. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the need for adversarial testing themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the evaluation of the proposed strategies, specifically the need to test against adversarial attacks that produce minimal structural alterations to the edge map but mislead the model predictions. This is a crucial point that could significantly impact the effectiveness of the defense strategies. However, the comment lacks specific guidance on how to implement this evaluation or what specific adversarial examples should be used. While it highlights an important area for improvement, the lack of actionable details limits its helpfulness. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for the authors to address the concern effectively."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the legends for tables 1, 2, and 3 longer and clarify whether the numbers are percent errors or percent correct. This feedback provides clear and direct guidance on what changes need to be made to improve the clarity of the tables. The action is explicit and concrete, as it specifies exactly what needs to be done to enhance the legends. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the legends for these tables, and it provides guidance on what should be clarified, such as whether the numbers are percent errors or percent correct. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a factual observation and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a clear and direct suggestion that can help improve the clarity and readability of the tables, making the comment 5. By addressing this issue, the authors can enhance the comprehensibility of their results, which is crucial for effective communication of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental results lack standard deviations, making it difficult to assess the significance of the results. This is a clear and direct action for the authors to take, as it instructs them to include standard deviations in their results. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the inclusion of standard deviations\u2014and why this is important for assessing the significance of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, making it difficult to assess the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why standard deviations are necessary or how their absence affects the interpretation of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting the absence of standard deviations and its impact on assessing the significance of the results. This feedback is clear and actionable, as it directs the authors to include standard deviations in their results to enhance the credibility and interpretability of their findings. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a standard deviation threshold or discussing the implications of not including them. Overall, the comment is 4 as it highlights a critical aspect of the experimental results that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the provided analysis seems weak in light of theoretical work on sampling and particlebased optimization methods. It specifically highlights the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps for the authors to address these issues. The authors are left to infer that they need to provide more detailed information about the solution and discretization, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the theoretical work on sampling and particlebased optimization methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the analysis, specifically pointing out the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is \"somewhat weak\" due to the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This claim is 3 as it references theoretical work on sampling and particlebased optimization methods, which provides a basis for the expectation of detailed analysis. However, the comment lacks specific references to that theoretical work or examples of what should be included in the analysis. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper\"s analysis is considered weak, namely the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This is a critical point, as it highlights a gap in the theoretical foundation of the work. The comment provides a clear direction for improvement by suggesting that the authors should address these gaps in their analysis. However, it could be more helpful if it offered specific suggestions on how to provide these guarantees or what kind of information should be included. Overall, the comment is 4 as it points out a significant weakness and provides a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the realism of the generated images or suggestions for potential improvements. As a result, the authors are left without any clear direction on how to enhance the quality of their results. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of limited realism in the generated images, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it highlights an area for improvement, but it lacks specific suggestions or guidance on how to address the issue. The authors are informed of a potential weakness but are not provided with actionable steps to enhance the realism of their generated images. Therefore, the comment is 3, as it points out a problem but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to describe the size and elements of G, which is the graph used in the DGCN model. It also suggests adding the dimensions of G, X, and W to provide a better understanding of the model. These actions are clear and concrete, as they specify exactly what needs to be added or clarified in the paper. The authors know exactly what steps to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of G, the size and elements of G, and the dimensions of G, X, and W. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of G in Section 3.3 and suggests that it would be better to describe the size and elements of G. It also recommends adding the dimensions of G, X, and W to enhance understanding. While the comment identifies a potential gap in the explanation, it does not provide specific examples or references to support the claim that these details are necessary. The suggestion is logical but lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where additional clarity is needed, specifically regarding the construction of G in Section 3.3. It suggests that the authors should describe the size and elements of G and provide the dimensions of G, X, and W to enhance understanding. This feedback is clear and actionable, as it directs the authors to add specific details that could improve the clarity and comprehensibility of their work. By addressing these points, the authors can significantly enhance the reader\"s ability to understand the DGCN model and its components. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this discrepancy or improve their draft. As a result, the authors are left without any guidance on how to respond to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding Cycle Consistency loss is not entirely true, as it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific discrepancy in the paper regarding the Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify or correct this discrepancy. Overall, the comment is 4 as it points out a critical issue that the authors can address to enhance the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer suggests that the authors should clarify or replace the term with a more appropriate one. While the comment provides a clear suggestion for improvement, it does not offer specific guidance on how to address the issue, such as recommending alternative terms or explaining the context in which the term is used. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and not standard in the field of hyperspectral imaging. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer provides a definition of hyperspectral imaging to support the claim, which is a logical and accurate explanation. However, the comment could be strengthened by providing specific examples or references to other works that use the term \"hyperspectral\" in a different context or with a different meaning. This additional context would further substantiate the claim and make it more 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper by pointing out that the term \"hyperspectral\" is not a standard term in the field of hyperspectral imaging. It provides a clear and concise explanation of what hyperspectral imaging is, which helps the authors understand the issue and make a correction. The comment is actionable as it suggests that the authors should clarify or replace the term with a more appropriate one, which is a straightforward suggestion that can improve the clarity and accuracy of the paper. However, the comment could be more helpful if it offered suggestions on how to address the issue, such as recommending alternative terms or explaining the context in which the term is used. Overall, the comment is 4 as it provides clear guidance on a specific area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also mentions that the concept of peak in Figure 5 is not described. While the comment provides explicit actions to take, such as revisiting the energy concept and clarifying the peak concept, it does not specify how to implement these actions or what specific details should be included in the refreshed explanation. The authors are given clear guidance on what needs to be addressed, but the execution of these actions is somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing a possible interpretation of high energy on a character. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and that it should be refreshed in Section 5.2, where it is used several times. The reviewer also questions the interpretation of high energy on a character, suggesting it might indicate that the current morpheme should be split at that point. Additionally, the reviewer points out that the concept of peak in Figure 5 is not described. While the comment provides a logical suggestion for clarifying the energy concept, it lacks specific examples or references to support the claim that the current explanation is insufficient. Therefore, the claim is 3, as it provides a reasonable basis for improvement but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also points out that the concept of peak in Figure 5 is not described, which is a clear area for improvement. This feedback is valuable as it directs the authors to clarify and enhance the explanations of key concepts, ensuring that the paper is more comprehensible and accurate. However, the comment could be more helpful if it included examples or additional guidance on how to interpret the energy concept or what specific details should be included in the explanation of the peak. Overall, the comment is 4 as it identifies important areas for improvement and provides clear direction for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. It specifically mentions that ablation studies in Sections 3 and 4 demonstrate the effectiveness of each component, but the comment implies that a more detailed explanation is needed. While the action is implicit, it is concrete because it specifies what additional information is needed (e.g., how the performance of combining the Linformer and window attention in Big Bird is improved). Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the contribution of each component to the final performance improvements. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. While it mentions ablation studies in Sections 3 and 4, it does not provide specific examples or detailed reasoning to support why this additional information is necessary. The claim is 3 as it highlights a potential gap in the paper, but it lacks the necessary evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about how each component contributes to the final performance improvements. It references ablation studies in Sections 3 and 4, which is a clear indication of where the authors can enhance their explanation. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to present this information. While it highlights a critical area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific gaps in the paper regarding the details of the models, particularly the grammar over kernels and the probabilities associated with it. It explicitly asks for clarification on how the approach is applied in practice, including inference. This feedback provides clear and concrete actions for the authors to take, such as explaining the grammar over kernels and the probabilities associated with it, and detailing the inference process. The explicit nature of the questions and the request for clarification makes the comment 5, as the authors know exactly what needs to be addressed to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the models\" and \"the grammar over kernels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail in the explanation of the grammar over kernels and the probabilities associated with it, as well as the inference process. This provides clear guidance on what needs to be clarified or expanded in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of detail in the explanation of the grammar over kernels and the probabilities associated with it, making it difficult to understand how the approach is applied in practice. The reviewer questions how inference is performed and suggests that these details are missing. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the missing details themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors have not provided sufficient detail, namely the explanation of the grammar over kernels and the probabilities associated with it. It questions how inference is performed and points out that these details are missing, making it difficult for readers to understand the practical application of the approach. The comment is clear and actionable, as it provides a direct request for clarification and guidance on how to improve the paper. By addressing these points, the authors can enhance the clarity and comprehensibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the role of visual information, verify the effectiveness of the ablation study, and ensure that the experiment results are significant. The lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10\" and \"w/o perception module and w perception,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out the lack of explicit verification in the ablation study, the questionable significance of the experiment results due to the sample size, and the need to clarify the role of visual information. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown, questioning the effectiveness of the ablation study and the significance of the experiment results due to the sample size. The comment provides some support by mentioning that the implementation detail of \"w/o perception\" is unknown and that the improvements are unlikely to be significant. However, the comment lacks specific examples or references to substantiate the claim about the effectiveness of the ablation study or the significance of the experiment results. This makes the claim 3, as the authors would need to further explore and substantiate the claims themselves.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. It highlights specific areas that need attention, such as the implementation detail of \"w/o perception\" and the need to clarify the role of visual information. While the comment provides some guidance on what needs to be addressed, it could be more helpful if it offered specific suggestions or examples on how to improve these areas. Overall, the comment is 3 as it points out important weaknesses but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This implies that the authors should include references to these works to provide a more comprehensive comparison. The comment is explicit in its request for inclusion of these references, making it clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the end of Section 4.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of references to previous works on Lasso screening, such as Ren et al. (2017), which should be included for a more comprehensive comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This claim is 3 as it highlights a specific omission in the paper, but it lacks detailed references or examples to fully substantiate the claim. The authors would need to conduct additional research to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This feedback is clear and actionable, as it points out a gap in the literature review that the authors should address to provide a more comprehensive and accurate assessment of their work. By addressing this issue, the authors can enhance the credibility and depth of their analysis. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the documentation. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed information about the hyperparameters. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the model, noting that many components have hyperparameters that are not fully provided. However, it does not specify which components or hyperparameters are in question, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors should improve the documentation. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model, noting that many components have hyperparameters that are not fully provided. This is a relevant observation that could impact the reproducibility and clarity of the paper. However, the comment lacks depth and does not provide actionable guidance or suggestions on how the authors might address this issue, such as recommending specific improvements or providing examples of how to better document the hyperparameters. As a result, the comment is 3, as it points out a potential problem but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This feedback implies that the authors should clarify the meaning of \"%p\" in their results notation. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a possible explanation or alternative notation. While the action is implicit, it is clear that the authors need to clarify the notation, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This provides clear guidance on what needs to be addressed to improve the clarity of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This claim is 3 as it highlights a potential issue with the clarity of the results notation. However, it lacks specific examples or references to similar notation in the literature, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the results notation, particularly regarding the claim of an improvement for CIFAR10 of 3%p. By pointing out the lack of clarity regarding the \"%p\" notation, the comment highlights an area where the authors need to improve the presentation of their results. However, the comment does not provide suggestions or guidance on how to clarify the notation or what alternative notation might be used. While it identifies a clear issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be beneficial to include qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it does not specify which specific qualitative results or failure cases should be included or how to present them. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests including qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. However, the comment does not specify which part of the paper these results should be included in, nor does it provide detailed guidance on how to present them. While the authors might have an idea of where these results could be added, the lack of explicit grounding makes it difficult for them to pinpoint the exact sections that need revision. The suggestion is specific in terms of what is needed, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that including these results would be beneficial. The absence of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of these additions themselves.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also suggests showing some failure cases and analyzing the limitations. This feedback is valuable as it offers a concrete way for the authors to enhance the presentation of their results, which could help demonstrate the effectiveness of their method. However, the comment could be more helpful if it provided specific examples of what qualitative results or failure cases should be included, or if it offered guidance on how to present these results effectively. Overall, the comment is 4 as it provides clear and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. This feedback provides a clear and explicit action for the authors to take, which is to clarify the title to avoid confusion. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the ambiguity in the title regarding whether it refers to human reading comprehension or machine comprehension of text. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. The comment provides a logical reasoning by explaining the common understanding of \"reading comprehension\" and \"readability\" in the context of human reading. However, it lacks specific examples or references to support the claim that the title is ambiguous. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the title of the paper, noting that it is ambiguous and could be misinterpreted as referring to human reading comprehension rather than machine comprehension of text. It provides a clear and actionable suggestion to clarify the title to avoid confusion. This feedback is valuable as it helps the authors ensure that their title accurately reflects the focus of their work, which is important for clarity and effective communication. However, the comment could be more helpful if it offered additional guidance on how to clarify the title or suggested alternative wording. Overall, the comment is 4 as it provides a specific and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific claim made by the authors on line 238, which is incorrect according to the Central Limit Theorem (CLT). It highlights that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment explicitly identifies the issue with the claim and provides a clear explanation of why it is incorrect. However, it does not offer any guidance on how the authors should address this issue or suggest alternative statements to correct the claim. The action is explicit but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made by the authors regarding the Central Limit Theorem (CLT) and why it is incorrect. The comment provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement regarding the Central Limit Theorem (CLT) is incorrect. The reviewer provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This logical reasoning and specific examples make the claim verifiable, as it provides a clear understanding of the issue and the basis for the critique. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and points out multiple incorrect assertions. It provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it guides the authors to correct their claim and ensure the accuracy of their statements. However, the comment could be more helpful if it suggested alternative formulations or references to support the correct understanding of the CLT. Overall, the comment is 4 as it effectively highlights a critical issue and offers a constructive path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors need to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area to focus on, making it 5. The authors know exactly what needs to be done to address the reviewer\"s concern, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the time complexity of the proposed policies mentioned in Section 4. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the proposed policies should be analyzed. However, it does not provide any supporting evidence, reasoning, or examples to justify why this analysis is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment is clear and actionable, as it explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This feedback is specific and directs the authors to a particular area of the paper that needs further attention and analysis. By addressing this suggestion, the authors can enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the analysis or what specific aspects of time complexity should be considered. Overall, the comment is 4 as it identifies a clear area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the evaluation is discussed, the comment lacks full grounding. It is specific in its critique of the use of an automatic metric, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) in the human evaluation, suggesting that it weakens the convincingness of human evaluation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an automatic metric is less convincing than a human metric. Without such justification, the claim remains 1, as it lacks the necessary information to support the claim. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. This feedback highlights a potential weakness in the evaluation methodology, which could impact the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative human metrics could be used. While it identifies a potential problem, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be strengthened by including experiments across more diverse domains, specifically mentioning those in TDMPC 2. While the comment implies that the authors should expand their experiments to include more diverse domains, it does not provide specific guidance on how to do so or which domains to consider. The action is implicit and somewhat vague, as the authors need to infer the need for more diverse domains and determine which ones to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments prove the point made by the authors and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more diverse domains, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments prove the authors\" point and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional domains would be beneficial or how they would strengthen the paper. Without such details, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the experiments effectively prove the point made by the authors and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional experiments to enhance the paper\"s diversity and strengthen the results. However, the comment lacks specific guidance on how to implement this suggestion or which domains to consider, making it 3 but not fully actionable. The authors are given a direction but need more detailed guidance to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should show confidence intervals and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. The comment provides explicit actions for the authors to take, such as including confidence intervals and expanding the evaluation to more datasets. However, it does not specify which datasets should be used or how to calculate the confidence intervals. While the actions are clear, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results and the limited evaluation on two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of not showing confidence intervals and the need to evaluate on more datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. The reviewer supports this claim by referencing external works that discuss the importance of confidence intervals and the need for more datasets to evaluate robustness. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of confidence intervals or by explaining why the two datasets used are insufficient. Despite this, the claim is 4 due to the references to external works, which provide a solid foundation for the critique.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should include confidence intervals to demonstrate statistical significance and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the robustness and credibility of their results. However, the comment could be more helpful if it offered suggestions on how to calculate confidence intervals or which datasets to consider. Overall, the comment is 4 as it effectively directs the authors toward improving their draft, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on what specific aspects of the interpretability tax should be evaluated or how the evaluation should be conducted. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the interpretability tax should be evaluated or how it should be measured. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper could be improved, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This is a relevant point that could enhance the paper\"s comprehensiveness and rigor. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable advice or detailed feedback, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is 3, as it points out an area for improvement but lacks the depth and specificity needed for full utility."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the main contribution of the paper is not in proposing novel techniques but rather in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There are no suggestions for how to enhance the novelty or innovation of the proposed techniques, nor are there any guidance on how to present the results or discuss the findings. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment discusses the simplicity of the LUQ design and the standard approaches in Section 5, suggesting that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not specify which part of the paper this discussion pertains to, such as the sections on the LUQ design or the approaches in Section 5. Additionally, it lacks specificity regarding what aspects of the existing techniques are combined or how this combination leads to surprisingly good accuracy. Without clear references to specific sections or detailed suggestions for improvement, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the LUQ design is straightforward and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel techniques. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment acknowledges the simplicity of the LUQ design and the standard nature of the approaches presented in Section 5, suggesting that the main contribution of the paper is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not provide specific suggestions or guidance on how the authors could enhance the novelty or innovation of their work. The comment lacks actionable feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it identifies a limitation but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it implies that the authors should provide evidence or analysis to address this concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide training losses to substantiate their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it identifies a potential area of concern, it does not provide any specific guidance or suggestions on how the authors might address this issue or what kind of training losses might be relevant. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as being the same concept. The reviewer suggests that these are actually different perspectives on applying stronger constraints for samples with higher popularity. While the comment identifies a potential issue with the paper\"s claims, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims and provide a more nuanced explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper overclaims the strength of the proposed BC loss by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as the same concept. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as the same concept. The reviewer supports this claim by explaining that these elements are actually different perspectives on applying stronger constraints for samples with higher popularity. However, the comment lacks specific examples or references to substantiate the claim fully. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims regarding the strength of the proposed BC loss in the theoretical analysis. It points out that the paper overclaims by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as the same concept. The reviewer explains that these elements are actually different perspectives on applying stronger constraints for samples with higher popularity. This feedback is 3 as it highlights a potential misrepresentation in the paper\"s claims, but it could be more beneficial if it provided specific suggestions on how the authors might clarify or adjust their claims to be more accurate. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer suggests that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to improve the evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the relevance and effectiveness of their method in the context of scorebased evaluation systems. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also mentions the framework FFAEVAL and similar frameworks like Chatbot Arena, suggesting that these arenabased evaluation systems may not be suitable for evaluating a single dialogue system. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the relevance and effectiveness of the proposed method in the context of scorebased evaluation systems. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer provides logical reasoning by explaining that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. However, the comment lacks specific examples or references to support the claim that arenabased evaluation systems are not effective for single dialogue systems. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. This feedback is valuable as it highlights a potential limitation in the applicability of the proposed method, which could impact the authors\" ability to evaluate their work effectively. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these concerns or what alternative evaluation methods might be considered. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed compared to other methods. The reviewer suggests that this could result in unfair comparisons. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their training approach or provide additional context to justify the use of 2x samples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed and unfair comparisons. The comment provides a clear direction for the authors to address this issue by suggesting that they might need to reconsider their training approach or provide additional context to justify the use of 2x samples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to slower running speed and unfair comparisons. The reviewer supports this claim by referencing the authors\" claim of 1.5x slower running speed compared to other methods. However, the comment lacks specific examples or references to other methods or studies that could substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed and unfair comparisons. This is a relevant observation that could impact the fairness and validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a different training approach or justifying the use of 2x samples. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of focal loss in regression tasks and points out that it may not be appropriate for this task due to its lower gradients on easy samples. It suggests that the authors may have overlooked the difference between classification and regression tasks. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their approach. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the use of focal loss in their regression tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks and suggests that the authors may have overlooked the difference between classification and regression tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the use of focal loss in regression tasks and its potential impact on accuracy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its lower gradients on easy samples. The reviewer provides a logical reasoning that focal loss is more suitable for classification tasks where class imbalance is an issue. However, the comment lacks specific examples or references to support the claim that using focal loss in regression tasks could lead to inaccurate results. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its lower gradients on easy samples. It points out that focal loss is more suitable for classification tasks where class imbalance is an issue. The comment highlights a potential oversight in the paper, noting that the authors may have overlooked the difference between classification and regression tasks. While the comment identifies a significant issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. Therefore, the comment is 3, as it provides insight into a potential weakness but does not offer actionable advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of scalability should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of scalability should be considered or how the authors might address this question. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback that could help the authors improve their draft. Therefore, the comment is 3, as it identifies an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to verify whether the improvements of the proposed model over the RL without feedback model are statistically significant. This is a clear and direct action for the authors to take, as it provides a specific task to ensure the robustness of their findings. The comment is concrete in its request for statistical verification, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the proposed model\"s improvements over the RL without feedback model. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed model\"s improvements over the RL without feedback model are not statistically significant, specifically mentioning the comparison between rows 3 and 4 in Table 6. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed model\"s improvements over the RL without feedback model, noting that the improvements are not statistically significant as evidenced by the comparison between rows 3 and 4 in Table 6. The comment suggests that the authors verify if these improvements are statistically significant, providing a clear and actionable piece of feedback. This guidance is valuable as it directs the authors to a specific area that needs further investigation, ensuring that their findings are robust and reliable. However, the comment could be more helpful if it included additional context or examples of how to conduct the statistical verification. Overall, the comment is 4 as it effectively points out a potential weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. However, it does not provide explicit guidance or suggestions on how to address this issue or what specific actions the authors should take. The comment is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"In continuation to the above remark,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how to relax the need to visit all ballaction pairs with each iteration and what would happen if partial coverage is considered. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification or suggestions regarding relaxing the need to visit all ballaction pairs with each iteration and exploring partial coverage. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. While it raises an interesting point, it lacks specific guidance or suggestions on how to address this issue or what specific assumptions or approaches could be considered. The comment is 3 as it prompts the authors to consider alternative approaches, but it does not provide actionable steps or detailed feedback. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. While it does not explicitly instruct the authors to use RoBERTabase, the implication is clear that they should consider this option. The comment is 3 as it provides a concrete suggestion for improvement but lacks explicit guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"encoder\" and compares it to \"RoBERTabase,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the observed improvement could be achieved with a better encoder, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTabase might be a better choice. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the potential improvement in the observed results with a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. While it does not provide specific guidance or suggestions for improvement, it does prompt the authors to consider alternative encoders that could enhance their results. This feedback is 3 as it points out a potential area for exploration, but it lacks depth and actionable steps for the authors to follow. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. While the action is explicit, it lacks concrete details on which specific datasets should be included or how to integrate them into the paper. The authors are given a clear direction to expand their dataset selection, but the lack of detailed guidance on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment suggests adding more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results discussion. The authors can infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of additional datasets, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific datasets are important or how they would contribute to the paper\"s claims. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a specific area for improvement by recommending the inclusion of additional datasets. However, the comment lacks depth and does not provide detailed guidance on how to integrate these datasets or why they are important for the paper\"s claims. While it points out a potential gap in the paper\"s evidence, it does not offer specific suggestions on how to address it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to use these methods or explain how to incorporate them into their evaluation. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the choice of baseline methods could be improved, specifically mentioning RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. However, it does not specify which part of the paper these suggestions pertain to, such as a specific section or experiment where these baselines could be applied. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved by comparing with other existing methods, specifically mentioning RefNeRF and MipNerf as potential baselines. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or detailed justification for why these methods are particularly suitable for the evaluation. This makes the claim 3, as the authors would need to infer the reasoning behind the suggestion and potentially conduct additional research to fully understand the rationale. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. This suggestion is based on the rationale that these methods contain appearance decomposition, which is relevant to the evaluation of the paper. By providing these examples, the comment offers a clear direction for the authors to enhance their evaluation and comparison with existing methods. However, the comment could be more helpful if it explained why these specific methods were chosen or how they might be integrated into the evaluation. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" While the action is implicit, it is clear that the authors need to provide a method for achieving fair policy learning without negatively impacting the predictive model\"s performance. However, the comment does not specify how to achieve this or what specific steps to take, leaving some ambiguity. Therefore, the comment is 3, as it provides a direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request to demonstrate fair policy learning without negatively impacting performance, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" This feedback is 3 as it identifies a potential weakness in the paper, specifically the impact of the proposed method on the predictive model\"s performance. However, the comment lacks specific guidance or examples on how to achieve this goal or what aspects of the method might be causing performance degradation. While it points out an area for improvement, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. This provides a clear and direct action for the authors to take, specifying where the details should be added and what needs to be included. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of implementation details of the proposed methods, which is a critical aspect of the paper. It suggests that these details should be included in Section 4.1, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area that needs attention and guidance on how to enhance the clarity and completeness of their work. However, the comment could be more helpful if it offered additional insights or examples of what kind of implementation details would be beneficial. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a concrete direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contribution. The comment is explicit in its request for empirical evaluation and comparison, providing concrete guidance on what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that there is no practical value demonstrated and that the theoretical contributions may be significant but not adequately presented. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, which is a subjective claim. The reviewer supports this claim by stating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. However, the comment does not provide specific examples or references to support the claim that the theoretical contributions are significant or that the lack of empirical evaluation is a significant issue. This makes the claim 3, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of empirical evaluation and comparison with other methods. It highlights that the theoretical contributions may be significant but are not adequately demonstrated in the paper, making it unclear what the practical value of the contribution could be. The comment suggests that even a theoretical paper should attempt to argue for its significance, and it concludes that the current submission is not suitable for publication at NeurIPS. This feedback is clear and actionable, providing the authors with a specific direction to enhance the empirical evaluation and comparison sections of their paper. However, it could be more helpful if it offered suggestions on how to conduct the empirical evaluation or what specific comparisons should be made. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback implies that the authors should clarify the use of P in these instances to avoid confusion. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a change in notation or clarifying the context in which P is used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the clarity of their manuscript. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the manuscript, including \"P mostly represents a probability but sometimes for a cumulative distribution function (e.g., Eqs. (3) and (4) and L44, all in Appendix), which leads to confusion.\" This allows the authors to accurately identify the parts of the manuscript being addressed. The comment is also specific because it clearly specifies the issue of using P for both probability and cumulative distribution functions, which leads to confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of P in the manuscript is confusing because it is used to represent both a probability and a cumulative distribution function. This claim is 3 as it provides a specific example (P used in Eqs. (3) and (4) and L44) to illustrate the confusion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why this confusion is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 3, as it provides some support but could be strengthened with additional justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that P is used to represent both a probability and a cumulative distribution function, which leads to confusion. This feedback is clear and actionable, as it points out a specific area where the manuscript could be improved by clarifying the use of P. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a change in notation or explaining the context in which P is used. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or explore more general tasks. The authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the paper\"s applicability to more general tasks, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited in its application to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL. However, the comment does not provide specific references or examples from PRMRL to substantiate this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s applicability to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL. It points out that the paper could be more interesting if it explored more general tasks. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this limitation or expand their work. While it highlights an area for improvement, the feedback is incomplete and does not offer detailed direction for the authors to enhance their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider whether all feature spaces are wellsuited for 1NN and warns that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends standardizing feature dimensions to avoid this issue. While the comment provides a clear action\u2014to evaluate the suitability of feature spaces and standardize dimensions\u2014it does not offer specific guidance on how to implement this suggestion or what metrics to use for evaluation. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suitability of feature spaces for 1NN and the potential issue with nonspherical Gaussian feature spaces. The comment provides a clear suggestion to standardize feature dimensions to avoid this issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes a claim about the suitability of feature spaces for 1NN and suggests that nonspherical Gaussian feature spaces may perform poorly. The comment provides a logical reasoning by explaining that standardizing feature dimensions can avoid this issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not as robust as it could be. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the suitability of feature spaces for 1NN, noting that nonspherical Gaussian feature spaces may perform poorly. It provides a clear and actionable suggestion to standardize feature dimensions to avoid this issue. This feedback is valuable as it directs the authors to a specific area that could impact the performance of their model, offering a concrete step to improve the draft. However, the comment could be more helpful if it included examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed \"contrastive gap\" is a central concept in the work but has not been clearly defined. It provides an example of an intuitive demonstration but notes that the setting is less convincing. The reviewer explicitly states that a clear, formal definition is needed. This feedback is clear and provides a direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is central to the work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear, formal definition for the contrastive gap. The comment provides detailed feedback on the example given and the setting, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" is central to the work but has not been clearly defined. It provides an example of an intuitive demonstration but notes that the setting is less convincing. The reviewer suggests that a clear, formal definition is needed. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the setting is less convincing. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It provides an example of an intuitive demonstration but notes that the setting is less convincing. The comment highlights the need for a formal definition, which is a crucial aspect of the paper. This feedback is clear and actionable, as it directs the authors to address a specific area that could significantly impact the clarity and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to formalize the definition or examples of how it could be presented more effectively. Overall, the comment is 4 as it points out a significant gap in the paper that the authors can address to improve its clarity and rigor."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov Decision Process (MDP). It suggests that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it does not provide explicit guidance on how to clarify the description or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description, but it is concrete in that it points to specific lines that need attention. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inaccuracy of the statement regarding rewards in standard MDP formulations and suggests clarifying the description of each action. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it lacks detailed reasoning or references to standard MDP formulations or examples to fully substantiate the claim. This makes the claim 3, as the authors would need to further explore the topic to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov Decision Process (MDP). It points out that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. This feedback is 3 as it highlights a potential misconception in the paper and provides a specific area for clarification. However, the comment could be more helpful if it offered suggestions on how to clarify the description or provided examples of standard MDP formulations. Overall, the comment is 3 as it directs the authors to a specific area needing improvement, but it lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. The reviewer provides a specific suggestion to include the explanation of why the chosen baseline makes the most sense. However, the comment does not explicitly instruct the authors to add this explanation or provide guidance on how to integrate it into the paper. While the action is implied, it is not as concrete as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of other baselines and providing a rationale for why they are relevant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, such as those mentioned in related work [29, 5, 6]. However, it does not provide any specific reasoning or evidence to support why these baselines are necessary or how they would enhance the study. The comment also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered, but it does not elaborate on these responses. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of including these baselines and the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks specific guidance on how to integrate these baselines into the paper or why they are particularly relevant. While it points out a potential enhancement, it does not provide detailed instructions or examples on how to implement this suggestion. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the meaning of \u03b4 in the statement of Lemma 5. While it does not explicitly instruct the authors to clarify this term, it implies that the authors should provide a definition or explanation for \u03b4. The action is implicit but concrete, as the authors can infer that they need to address this question to improve the clarity of their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \u03b4 in the statement of Lemma 5. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the meaning of \u03b4 in the statement of Lemma 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the meaning of \u03b4 in the statement of Lemma 5. While it identifies a potential area of confusion or ambiguity in the paper, it does not provide any guidance or suggestions for clarification or improvement. The comment lacks actionable feedback or context that would help the authors address the issue. As a result, it is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the uniform setting of \u03b1_m in line 113, noting that this implies the contributions from all modalities are the same. It suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider dynamically weighting the modalities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform setting of \u03b1_m and suggests that dynamically weighting the modalities is important in multimodal fusion. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that setting \u03b1_m uniformly to 1/M implies that the contributions from all modalities are the same, which is not accurate. The reviewer supports this claim by referencing works in multimodal fusion that demonstrate the importance of dynamically weighting modalities. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to these works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the uniform setting of \u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. It suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. This feedback is 3 as it points out a potential weakness in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples or references to multimodal fusion works that demonstrate the importance of weighting modalities. As it stands, the authors are left with a general suggestion to explore this further, which may not be immediately actionable without additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. However, it does not provide any guidance on how the authors should address this issue or suggest alternative phrasing. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the pervasive use of the phrase \"to meet\" and how it is difficult to understand. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. This feedback is clear and actionable, as it points out a specific area where the language could be improved for clarity. However, the comment could be more helpful if it provided suggestions for alternative phrasing or clarified the intended meaning of the phrase. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a clear and explicit observation that the authors can easily address by correcting the labeling in the figure. The comment provides concrete guidance on what needs to be done to ensure consistency in the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L_task\" and \"L_class,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the task loss being labeled inconsistently in the text and figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a factual observation that does not require any subjective interpretation or opinion. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor but important discrepancy between the labeling of the task loss in the text and the figure. This is a clear and actionable observation that the authors can easily address to ensure consistency in their paper. By pointing out this inconsistency, the comment provides valuable feedback that can help the authors improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to resolve the issue or explained the potential impact of this inconsistency. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the method should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the network depth is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\"s limitations should be addressed or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. This is a relevant point that could prompt the authors to consider the depth of their network and its implications for the method\"s effectiveness. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the method should be considered. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work should be evaluated in machine translation, which is seen as a more convincing approach due to its lower uncertainty per word. While the comment implies that the authors should consider this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider machine translation as an additional evaluation method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work should be evaluated in machine translation, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work only uses answer generation and summarization, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the proposed method in machine translation would be more convincing due to its lower uncertainty per word. The comment provides a logical reasoning for why machine translation might be a more appropriate evaluation method, but it lacks specific examples or references to support the claim that machine translation is indeed a more convincing approach. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation, which exhibits lower uncertainties per word, would be more convincing. This feedback is 3 as it points out a potential weakness in the evaluation approach and suggests an alternative method for demonstrating the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific examples or references to support the claim that machine translation is a more appropriate evaluation method. Overall, the comment offers a valuable suggestion for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout method used in the paper, specifically regarding the dropping rate and the number of masks generated. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the dropout\" and \"multiple stochastic masks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the dropout method used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dropout method used in the paper, asking for clarification on the dropping rate and the number of masks generated. This feedback is 3 as it prompts the authors to provide additional information that could enhance the clarity and understanding of their method. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how it might be incorporated into the paper. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to demonstrate the effectiveness. This feedback provides clear and concrete actions for the authors to take, such as including comparisons and benchmarks to support their claims. The explicit nature of the suggestions and the detailed guidance on what needs to be added make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further justifications, comparisons with other singlestage attacks, and benchmarks with SOTA algorithms to demonstrate the effectiveness of the technical contributions. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification, suggesting that showing performance drop on fusion models alone is insufficient. The reviewer suggests that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to justify the technical contributions. This claim is 3 as it provides a logical reasoning for the need for additional comparisons and benchmarks. However, it lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the need for further justification of the proposed twostage optimization approach. It suggests that showing performance drop on fusion models alone is insufficient and that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to demonstrate the effectiveness. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their paper by including additional comparisons and benchmarks. By addressing these points, the authors can significantly improve the clarity and credibility of their technical contributions. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not specify the type of GPUs used for testing or the inference time. This is an explicit observation that the authors can directly address by including this information in their draft. The comment provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be added to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the absence of information about the type of GPUs used for testing and the inference time, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be added, namely the type of GPUs and inference time, providing clear guidance on what needs to be included in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used for testing or the inference time. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting the lack of information about the type of GPUs used for testing and the inference time. This is a clear and actionable point that the authors can address to improve the transparency and reproducibility of their results. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is 3 as it highlights an important area for improvement but lacks depth in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including a comment on the monotonic increase of RSD4PG performance with respect to \u03bb values in Table 1 and missing symbols in the text. However, it does not provide explicit instructions or suggestions on how the authors should address these issues. The comment lacks actionable guidance, such as recommending specific experiments or corrections to make or suggesting ways to clarify the missing symbols. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"paragraph D4PG,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the monotonic increase of RSD4PG performance with respect to \u03bb values in Table 1 and the missing symbols in the text. Additionally, it points out the missing symbols in the bracket on Page 3, Line 2, and the missing symbols in the bracket on Line 4 at paragraph D4PG. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual observations and requests for clarification. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including a monotonic increase in performance with respect to \u03bb values in Table 1 and missing symbols in the text. It also points out missing symbols in the bracket on Page 3, Line 2, and in the bracket on Line 4 at paragraph D4PG. While the comment highlights these issues, it does not provide actionable guidance or suggestions on how the authors might address them. The feedback is 3 as it directs the authors\" attention to specific areas needing clarification or correction, but it lacks depth and does not offer detailed advice on how to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. While the comment identifies a specific area of concern, it does not provide explicit instructions on how to address this issue or what changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to make a correction but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, noting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, as it points out a potential error or inconsistency in the presentation of the data. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why this distinction is important or offering guidance on how to correct the mistake. Overall, the comment is 3 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that a specific sentence is confusing and suggests that the authors should clarify it. However, it does not provide any explicit guidance on how to improve the sentence or what specific changes should be made to make it clearer. The authors are left to infer that they need to revise the sentence, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, which is that it is confusing and lacks immediate clarity. However, the comment does not provide specific suggestions on how to improve the clarity or what aspects of the sentence are confusing. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and lacks immediate clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why the sentence is confusing or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific sentence that is confusing and lacks clarity. It acknowledges that the reviewer understood the sentence after rereading it, but notes that it is not immediately obvious what is meant. This feedback is valuable as it highlights a potential issue with the clarity of the writing, which the authors can address to improve the readability and comprehension of their paper. However, the comment could be more helpful if it provided suggestions on how to clarify the sentence or offered alternative wordings that might improve understanding. Overall, the comment is 3 as it points out a specific area for improvement, but it lacks detailed guidance for the authors to fully address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several instances where citations are missing or needed, specifically in lines 7879, 129130, 156158, and 217218. While it identifies these areas, it does not provide explicit instructions on how to include the missing citations or what specific references should be used. The actions are implicit and somewhat vague, as the authors need to infer that they should include citations but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for citations in lines 7879, 129130, 156158, and 217218. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of claims that require specific citations to support the assertions. For example, the claim about diffusion models outperforming generative adversarial networks is not substantiated with a reference. Similarly, the claim about previous work having limited success is also unsupported. The reviewer requests citations for these claims, which would provide the necessary evidence to support the claims. Therefore, the comment is considered 1 due to the lack of supporting evidence or references.", "helpfulness_rationale": "The review comment identifies specific areas where citations are missing or needed, which is a clear and actionable piece of feedback. It highlights specific lines in the paper where references should be included, providing the authors with a concrete list of places to improve their draft. However, the comment could be more helpful if it offered suggestions on which specific works or references might be relevant for each of these citations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between Figures 1 and 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback implies that the authors should reconcile these figures to ensure consistency. However, the comment does not provide explicit instructions on how to address this issue, such as suggesting specific changes or clarifications. While the action is implied, it lacks concrete guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the figures, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This claim is 3 as it highlights a discrepancy between the figures, but it lacks detailed explanation or references to support the assertion that this inconsistency is problematic. The authors might need to further investigate the implications of this discrepancy and determine if it affects the validity or interpretation of the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between Figures 1 and 2, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback highlights an inconsistency in the figures, which could impact the clarity and coherence of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending changes to the figures or explaining the rationale behind the discrepancy. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify or modify the description of N_l^(s) to ensure that each node can attend to its own lowerlevel representation, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the ability of each node to attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This is a relevant point that could impact the understanding and interpretation of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the description. While it identifies a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify how Lemma 7 is applied to this inequality. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the inequality after line 433 follows from Lemma 7, and it suggests that the authors should clarify how Lemma 7 is applied in this context. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how an inequality follows from a lemma. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the derivation of an inequality after line 433, asking how it follows from Lemma 7. This is a clear and actionable feedback that prompts the authors to clarify their reasoning and provide additional explanation to facilitate understanding. By addressing this question, the authors can improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided suggestions on how to present this explanation or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the paper\"s main contribution is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to clarify the main contribution. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations and evidence to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of the main idea and the automation process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. The reviewer suggests that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of specific evidence or references makes the claim 3, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, noting that the novel properties of the proposed method and its ability to cope with dynamic largescale multitasking are unclear. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. This feedback is valuable as it highlights specific areas where the authors need to provide more detailed explanations and evidence to support their claims. However, the comment could be more helpful if it offered suggestions on how to clarify these aspects or provided examples of how similar methods have been effectively communicated. Overall, the comment is 4 as it directs the authors to critical areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the bottomup method [9] in their tables and evaluate its performance on the standard MS COCO dataset to see if there is a drop in performance in easy (non occluded) settings. While the comment explicitly states what needs to be done, it does not provide detailed guidance on how to implement these changes or what specific aspects of the method should be included in the tables. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bottomup method [9] and its performance on the crowdpose dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is to include the bottomup method in the tables and evaluate its performance on the MS COCO dataset. This provides clear guidance on what changes need to be made to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method [9] has reported results on the crowdpose dataset outperforming all methods, including the paper\"s own method, with a ResNet50. The comment also recommends evaluating the method on the standard MS COCO dataset to see if there is a drop in performance in easy settings. While the claim is based on a specific external work, it lacks detailed justification or references to support the claim that the bottomup method outperforms all methods, including the paper\"s own method. The suggestion to evaluate on the MS COCO dataset is logical, but the claim about the bottomup method\"s performance is not fully substantiated. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include the bottomup method [9] in their tables and evaluate its performance on the standard MS COCO dataset. This suggestion is based on the reported results of the bottomup method on the crowdpose dataset, which could help the authors demonstrate the robustness and generalizability of their method. By including this information, the authors can enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided additional context or analysis on why this evaluation is important or how it might impact the paper\"s conclusions. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. It provides an example from TACRED slot filling guidelines to illustrate the depth of understanding required. While the comment highlights a potential overstatement, it does not explicitly instruct the authors to revise their claim or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claim and provide more detailed information about their understanding of annotation guidelines. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim of using \"annotation guideline\" and provides a specific example of the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to identify the exact part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the overstatement of using annotation guidelines and the need to provide more detailed information about the understanding of annotation guidelines. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. The reviewer provides an example from TACRED slot filling guidelines to illustrate the depth of understanding required. This example is specific and provides a clear rationale for the claim, making the comment 4. However, the comment could be strengthened by referencing additional examples or sources to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper regarding the use of \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. The reviewer provides a specific example from TACRED slot filling guidelines to illustrate the depth of understanding required, which is a valuable contribution to the authors. This feedback is clear and actionable, as it prompts the authors to reconsider their claim and provide more detailed information about their understanding of annotation guidelines. However, the comment could be more helpful if it suggested specific ways to address this issue or provided additional guidance on how to better align the paper with the complexity of annotation guidelines. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the BERTbaseline. This provides a clear and concrete action for the authors to take, specifying exactly what additional comparisons are needed to strengthen the experiment comparison. The comment is specific and direct, giving the authors a clear path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment comparison\" and the need to compare the method to token pruning and token combination baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional baselines for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because it only compares the method to the BERTbaseline. It suggests that the authors should compare their method to token pruning and token combination baselines. While the comment identifies a potential issue with the experiment comparison, it does not provide specific reasoning or evidence to support why the current comparison is insufficient. The suggestion to include additional baselines is logical, but the lack of detailed justification or examples makes the claim 3. The authors would need to further explore the rationale behind the need for these additional comparisons to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experiment comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should also compare their method to token pruning and token combination baselines. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental evaluation by including additional baselines. By addressing this suggestion, the authors can strengthen their analysis and provide a more comprehensive comparison of their method. Therefore, the comment is 4, as it offers a clear and constructive path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison to these methods. The comment is specific in identifying the missing comparison and offers concrete guidance on how to enhance the experimental section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This provides clear guidance on how to enhance the experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This claim is 3 as it logically suggests that including such comparisons would provide a more comprehensive evaluation of the methods. However, the comment lacks specific examples or references to these methods, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, suggesting that a comparison to coordinateaware methods, such as TFN or SchNet, would be beneficial. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental evaluation by including a broader range of methods. By addressing this point, the authors can enhance the comprehensiveness and relevance of their experimental analysis. However, the comment could be more helpful if it explained why these methods are particularly relevant or how they might impact the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any specific guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending which weaknesses should be explored or how they could be demonstrated. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the authors did not show the possible weaknesses of the proposed model, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what weaknesses should be explored or how they could be demonstrated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific weaknesses should be explored. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of related work and experimentation with other extractthengenerate methodologies in the paper. It implies that the authors should include a related work section and experiment with other methods to demonstrate the novelty and effectiveness of their proposed system. While the comment does not explicitly instruct the authors to add a related work section or conduct additional experiments, it provides a clear direction for improvement. The action is implicit but concrete, as the authors can infer the need to address these gaps in their work. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the idea of long document summarization and questions the novelty of the proposed system compared to previous methodologies. It specifically mentions the absence of a related work section and the lack of experimentation with other extractthengenerate methodologies. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. While the authors can infer that it relates to the sections discussing the methodology and results, the comment is not fully grounded as it does not explicitly mention these sections. The comment is specific in detailing what is missing, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the novelty and effectiveness of the proposed system compared to previous methodologies in the area of long document summarization. It questions the absence of a related work section and the lack of experimentation with other extractthengenerate methodologies. However, the comment does not provide specific examples or references to support the claim that the system does not offer any novelty or improvement over existing methods. Without such evidence or comparisons, the claim remains 1, as it lacks the necessary justification to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a related work section and the lack of experimentation with other extractthengenerate methodologies. It questions the novelty and effectiveness of the proposed system compared to previous methodologies in the area of long document summarization. While the comment highlights an important area for improvement, it does not provide specific suggestions or guidance on how the authors might address this gap. The feedback is 3 as it points out a critical issue, but it could be more beneficial with additional details or actionable advice on how to improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The authors are left to infer that they should consider these alternatives, but without specific guidance on how to integrate them into their work, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in suggesting alternative approaches, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints. However, it does not provide any supporting evidence, reasoning, or references to justify why these alternatives might be more appealing or effective. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, and the authors may find it challenging to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. While these suggestions are interesting and could potentially improve the paper, the comment lacks specific guidance or examples on how to implement these alternatives. It does not provide detailed instructions or explain why these directions might be more effective or how they could be integrated into the existing work. As a result, the comment offers some insight but lacks depth and actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is not sufficient and recommends providing more information on the advantages or differences of the proposed method, specifically in comparison to BGLN. While the comment implies that additional work on GLN is needed, it does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about GLN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction of related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the introduction of related work and the need for more work on GLN to reflect the advantages or differences of the proposed method, such as the difference from BGLN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN is needed to reflect the advantages or differences of the proposed method, specifically in comparison to BGLN. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and recommends providing more information on the advantages or differences of the proposed method, particularly in comparison to BGLN. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided examples or detailed guidance on how to present this additional information. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks actionable guidance or recommendations on how the authors might improve their draft in response to this observation. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Moon\"s approach\" and \"Variational dropout,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of hyperparameters in Moon\"s approach, particularly the use of only one dropout rate compared to Variational dropout, which has inputoutput and recurrent dropout parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of hyperparameters in Moon\"s approach, specifically noting that Variational dropout has inputoutput and recurrent dropout parameters, while Moon\"s approach only uses one dropout rate. This observation highlights a potential inconsistency in the choice of hyperparameters, prompting the reviewer to ask for clarification. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this inconsistency is problematic or how it affects the paper\"s results. As a result, the claim is considered 2, as it lacks detailed justification or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. This observation highlights a potential inconsistency in the choice of hyperparameters, which could impact the results and conclusions of the paper. However, the comment does not provide any actionable feedback or suggestions for the authors to address this issue. It lacks depth and does not guide the authors on how to improve their draft or what specific changes might be necessary to clarify the choice of hyperparameters. As a result, the comment is 2, as it identifies a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a clear and specific action for the authors to take, which is to conduct these experiments and compare their results against other approaches. The comment is explicit and provides concrete details on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. This provides clear guidance on what aspects of the paper need to be addressed. The comment is also specific in detailing what kind of experiments should be conducted and how they could be conducted, such as using publicly available simulators and comparing against other approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks experiments with larger stateaction spaces and nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. The reviewer questions whether this is due to a lack of time or severe scalability issues. The comment provides a logical reasoning by suggesting that conducting experiments on simple videogame domains would be more convincing, as they naturally have a lowcardinality discrete state and actionspace. However, the comment lacks specific examples or references to support the claim that these experiments would be more convincing. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The comment highlights the importance of these experiments to address scalability issues and provide more convincing evidence. By suggesting specific domains and methods for conducting these experiments, the comment offers detailed guidance that can help the authors improve their draft. However, it could be more helpful if it provided examples of how these experiments could be conducted or what specific metrics should be used to evaluate the results. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be further enhanced with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not provide any guidance on what specific quantitative measurement should be used or how to implement it. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without clear direction on how to address this issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where this measurement is discussed. The authors can infer that it relates to the discussion of occupation bias, but this inference is not direct. The comment is specific in detailing what is missing, but it is weakly grounded because it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided quantitative measurements to assess the extent of occupation bias relative to real distributions in society. This is a relevant point that could impact the validity and generalizability of the study. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific quantitative measurements could be used. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete suggestions on how to address this issue. The authors are left to infer that they should explore the potential impact of using adaptive gradient methods, but the comment lacks specific guidance on how to conduct this exploration or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue might be relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the potential impact, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. The comment does not present any claims or opinions but rather seeks clarification or additional information. It is a request for further exploration rather than a statement that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. This is a valuable observation that could lead to a deeper understanding of the results and their robustness. However, the comment lacks specific guidance or suggestions on how the authors might explore this aspect or what specific experiments or analyses could be conducted to address it. While it points out an important area for consideration, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it provides a direction for further exploration but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to expand the types of teacher architectures and consider more recent methods, but the comment lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of insufficient experiments, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the issues with the experiments, such as the limited types of teacher architectures and the age of the compared methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. While it highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The comment lacks depth and actionable advice, leaving the authors with a general understanding of the problem but without clear steps to improve their draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to include information from 2hop neighbors or how to clarify the effectiveness of the method. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of information and the need to clarify the effectiveness of the method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"no information from 2hop neighbors is included\" and questions the effectiveness of the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the lack of information from 2hop neighbors and questioning the effectiveness of the method. However, it does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the clarity of their work. Without specific advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends using the real DICOM image as experiment data instead of the PNG image and suggests using the FastMRI challenge dataset for this purpose. It also advises comparing inference speeds between different methods. This feedback provides clear and concrete actions for the authors to take, such as changing the image format and including a specific dataset for evaluation. The suggestions are direct and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"real dicom image\" and suggests using the FastMRI challenge dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, recommending the use of the real DICOM image and suggesting the FastMRI challenge dataset for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using the real DICOM image as experiment data instead of the PNG image and recommends using the FastMRI challenge dataset for comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the DICOM image is preferred or how it would impact the results. This lack of justification makes the claim 1, as the authors are left without clear guidance on how to address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending the use of the real DICOM image as experiment data instead of the PNG image. It also suggests using the FastMRI challenge dataset for comparison, which is a clear and concrete suggestion that can help improve the quality and relevance of the paper\"s experiments. Additionally, the comment advises comparing inference speeds between different methods, which is a valuable suggestion for enhancing the paper\"s methodological rigor. Overall, this feedback is 5 as it guides the authors on how to enhance their experimental setup and improve the quality of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the binder design needs further optimization and validation, specifically mentioning that ProtPainter only provides empirical conformation estimation. However, it does not provide any explicit guidance on how to optimize or validate the binder design or what specific aspects need attention. The action is implied but not clearly stated, leaving the authors to infer the necessary steps to take. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ProtPainter\" and \"binder design,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further optimization and validation of the binder design. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ProtPainter only provides empirical conformation estimation for binder design, suggesting that further optimization and validation are required. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the binder design, noting that ProtPainter only provides empirical conformation estimation and that further optimization and validation are required. This feedback is clear and actionable, as it points out a gap in the current work and suggests specific areas for enhancement. However, the comment could be more helpful if it provided examples or guidance on how to optimize or validate the binder design. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the model in Figure 7 was trained, specifically inquiring about the stimulus used and the duration of the cycle. It also raises a question about whether the time scale of adaptation would shorten if the duration of the cycle changes, referencing a specific study. The comment provides clear and direct actions for the authors to take, such as clarifying the training process and addressing the potential implications of time scale changes. The explicit nature of the request and the concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the training process and the potential implications of changes in the duration of the cycle. The comment provides a clear direction for the authors to address the issue by asking for clarification on the training process and its potential impact on the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training process of the model in Figure 7, specifically inquiring about the stimulus used and the duration of the cycle. It also references a specific study by Smirnakis et al. (Nature 1997) to support the claim that the time scale of adaptation might change with changes in the duration of the cycle. However, the comment does not provide detailed reasoning or evidence to substantiate the claim that the model cannot handle longer time scales. While it references a specific study, the lack of detailed explanation or examples makes the claim 3, as the authors would need to further explore the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of the paper that requires clarification regarding the training process of the model in Figure 7. It asks for clarification on the stimulus used and the duration of the cycle, which are crucial details for understanding the methodology. Additionally, it raises a relevant question about the potential implications of changes in the duration of the cycle on the time scale of adaptation, referencing a specific study. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and completeness of their methodology section. However, the comment could be more helpful if it offered suggestions on how to address the potential implications or provided additional references to support the claim. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about what happens if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what potential implications it might have for their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the potential consequences of this association, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment poses a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. While it highlights an area of interest, it does not provide any guidance or suggestions for the authors to address this question or explore its potential implications. Without actionable feedback or direction, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. While the comment implies that additional evaluation is needed, it does not provide specific guidance on what aspects of the evaluation should be conducted or how to conduct it. The authors are left to infer that they should conduct more evaluations, but without concrete instructions on what to evaluate or how to do it, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting what kind of evaluation is needed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify why this additional evaluation is necessary or how it would improve the paper. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. This feedback is 3 as it identifies a potential area for improvement in the evaluation section of the paper. However, the comment lacks specific guidance on what aspects of the evaluation should be conducted or how it could be integrated into the existing work. While it points out a potential gap, it does not provide detailed suggestions or examples on how to address it, which would make the feedback more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and ensure they are using the same amount of data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparisons made in the table, suggesting that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. The comment also points out that H>N>H and H>N>H use less data than H>N+B>H. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. The reviewer suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, the comment points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies a potential issue with the comparisons, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for these comparisons and the specific data amounts involved, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This feedback is clear and actionable, as it provides specific guidance on how to improve the comparisons in the table. By addressing these points, the authors can ensure that their comparisons are more meaningful and accurate. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add references or reconsider the placement of Alg 1, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it highlights areas for improvement but does not offer detailed instructions on how to achieve them.", "grounding_specificity_rationale": "The comment addresses several issues, including the placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specificity by mentioning the line number and the introduction, it lacks full grounding as it does not explicitly mention the sections where these issues are discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. These points highlight areas where the paper could be improved by providing more context and references to relevant literature. However, the comment does not offer specific suggestions or guidance on how to address these issues, such as recommending the inclusion of additional references or explaining the rationale behind the placement of Alg 1. While the feedback points out areas for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and provide more motivation for the CBN approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the section and provide more motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of Section 2.1 is problematic or where the ResNet architecture is discussed, making it weakly grounded. The comment is specific in suggesting that the time spent on the ResNet architecture could be better used, but it lacks grounding in the original text. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. The reviewer argues that Batch Normalization is a general technique and that the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or references to support the claim that the inclusion of Section 2.1 is unnecessary or that the ResNet architecture could be better utilized. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the critique without additional guidance.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors focus on the ResNet architecture to provide more context and motivation for the proposed methodology. However, the comment could be more helpful if it provided specific suggestions on how to enhance the motivation and intuition sections or how to better integrate the ResNet architecture into the paper. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to clarify the explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the expected outcome of multiplying in equation (1) by a dense projection matrix, suggesting that the resulting matrix should be sparse. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the expected outcome of multiplying in equation (1) by a dense projection matrix, suggesting that the resulting matrix should be sparse. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the expected outcome of multiplying in equation (1) by a dense projection matrix, suggesting that the resulting matrix should be sparse. This feedback highlights a potential confusion in the explanation and provides a clear direction for the authors to clarify their reasoning. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context to help the authors understand the implications of their argument. Overall, the comment is 3 as it points out a specific area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This is a clear and concrete action that the authors can take to address the issue of lacking direct evidence for the motivation. The comment provides a specific suggestion for how to present the evidence, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of direct evidence for the motivation and suggests plotting a figure to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct, as the problem is stated as \"a predictor suffers from accuracy decline due to longterm and continuous usage.\" The reviewer suggests that the authors should plot a figure showing the decline in accuracy over time (search steps) in different settings to support their claim. This claim is 3 as it provides a logical suggestion for addressing the issue, but it lacks specific examples or references to similar studies that have successfully used such figures to demonstrate the decline in accuracy. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of direct evidence for the motivation of the study. It suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This feedback is clear and actionable, providing the authors with a concrete step to address the identified weakness. However, the comment could be more helpful if it explained why this figure is necessary or how it would strengthen the paper. Overall, the comment is 4 as it guides the authors toward a specific improvement that can enhance the clarity and credibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions about the definition and calculation of excessive risk in the context of the paper. It suggests that the authors should provide more explanation about the concept and its practical application, particularly in terms of expectation. The reviewer also points out that the optimal solution \u03b8 \u2217 is not the optimal solution for the loss function w.r.t. data of group a, and that negative values might be possible. Additionally, the reviewer questions whether excessive risk values are comparable among different groups and whether it is a good representation for fairness. While the comment identifies areas for clarification and potential issues, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanation and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of excessive risk and how it is calculated in practice, particularly in terms of expectation. The comment also raises questions about the comparability of excessive risk values among different groups and the representation of fairness. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the definition and calculation of excessive risk, particularly in the context of the paper. It suggests that the authors should provide more explanation about the concept and its practical application, including how it is calculated in terms of expectation. The reviewer also questions the comparability of excessive risk values among different groups and the representation of fairness. While the comment identifies areas for clarification and potential issues, it lacks specific examples or references to support the claims. The authors would need to make a significant effort to address these points, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the definition and calculation of excessive risk in the paper. It questions the practical application of the concept and its comparability among different groups. The reviewer also points out that the optimal solution \u03b8 \u2217 is not the optimal solution for the loss function w.r.t. data of group a, which could lead to negative values. This feedback is valuable as it prompts the authors to clarify and potentially reconsider their approach to fairness representation. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of how similar concepts have been handled in related literature. Overall, the comment is 3 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It also references a specific paper ([1] Kunstner et al., 2019) to provide context and guidance on how to better present the initialization aspect. While the comment implies that the authors should reconsider their statement about initialization, it does not explicitly instruct them to do so or provide detailed guidance on how to improve the statement. The reference to the external work is helpful, but the action is implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more careful statement about initialization and references a specific paper ([1] Kunstner et al., 2019) to provide context and guidance on how to better present the initialization aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in natural gradient descent (NGD) and suggests that it should be considered as pretraining. The reviewer supports this claim by referencing a specific paper ([1] Kunstner et al., 2019) that discusses the limitations of empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how initialization affects NGD. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It provides a specific reference to a relevant paper ([1] Kunstner et al., 2019) to support the claim that initialization plays a role in natural gradient descent (NGD). This feedback is valuable as it highlights a specific area where the authors need to clarify their statement, which could improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered additional guidance on how to rephrase the statement or what specific aspects of initialization should be emphasized. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a relevant reference to support the claim."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the lack of clarity regarding how named entities were extracted from datasets and the need for an Englishproofreading to improve the readability of the paper. While the first point is explicit in asking for clarification on the extraction process, the second point is more implicit in suggesting an improvement. However, both points are concrete in their request for clarification and improvement, respectively. The authors know exactly what needs to be done to address both issues, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for clarification on how named entities were extracted from datasets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for an Englishproofreading to improve the readability of the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding how named entities were extracted from datasets and suggests that an Englishproofreading would significantly improve the readability of the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: clarity regarding the extraction of named entities from datasets and the need for an Englishproofreading to enhance the readability of the paper. While the comment highlights these issues, it does not provide detailed guidance or suggestions on how to address them. The authors are informed of the need for clarity and readability improvements but are left without specific steps or examples to follow. This limits the comment\"s helpfulness, as it points out areas for improvement but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which would improve the condition slightly. This feedback is explicit and provides a concrete action for the authors to take, as it clearly specifies what change to make and why it might be beneficial. The authors know exactly what to do to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L200\" and \"L303,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement \"for every arm a,\" suggesting that it implies a single optimistic parameter, and provides a specific alternative suggestion for improving the condition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a critique of the statement \"for every arm a\" and a suggestion for improvement. The first part questions the implication of a single optimistic parameter, which is a logical observation. However, the second part provides a specific suggestion for improvement by proposing an alternative condition. This suggestion is based on a logical reasoning that could potentially improve the condition, but it lacks detailed justification or references to support the claim. Therefore, the comment is 3, as it provides a logical basis for the critique but requires more detailed explanation or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement \"for every arm a\" in the paper, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which could improve the condition slightly. This feedback is clear and actionable, as it points out a potential weakness in the paper and offers a specific improvement that the authors can consider. However, the comment could be more helpful if it provided additional context or explanation about why this change might be beneficial or how it would impact the overall analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the terms \"L\" and \"E\" should be defined in the immediate vicinity and highlights the inconsistency in whether they are italicized or not. This provides a clear and direct action for the authors to take, ensuring that the terms are consistently defined and styled throughout the paper. The comment is specific and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the definition and styling of the terms \"L\" and \"E.\" This provides clear guidance on how to improve the clarity and consistency of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the inconsistency in the definition and styling of the terms \"L\" and \"E\" in the paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting and consistency of the terms \"L\" and \"E\" in the paper. It points out that sometimes these terms are italicized and sometimes not, which can lead to confusion and inconsistency. This feedback is clear and actionable, as it provides the authors with a concrete step to improve the clarity and consistency of their paper. By addressing this issue, the authors can enhance the readability and professionalism of their draft. However, the comment could be more helpful if it offered suggestions on how to standardize the formatting or provided examples of how to apply the changes. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the experimental section is weak and suggests that more experiments are required. However, it does not provide specific guidance on what additional experiments should be conducted or how they should be structured. The authors are left to infer that they need to expand their experimental section, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and needs more experiments. However, it does not specify which part of the experimental section is considered weak or what specific experiments are needed. Without explicit references to sections, figures, or experiments, the authors cannot confidently determine which parts of the paper need improvement. The comment lacks specificity and is 1, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand why the experimental section is considered weak and what specific experiments are needed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a weakness in the experimental section, suggesting that more experiments are required. However, it lacks specificity and does not provide any guidance on what additional experiments should be conducted or how they could enhance the paper. Without specific suggestions or examples, the authors are left without actionable feedback on how to improve their experimental section. Therefore, the comment is not helpful, as it does not provide the authors with a clear path to address the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript should include more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that additional comparisons are needed, it does not specify which models or techniques should be included or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparisons but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which models or techniques should be included. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support the claim that these comparisons are necessary or how they would enhance the manuscript. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies an area where the manuscript could be strengthened by expanding its comparisons. However, the comment lacks specificity and does not provide guidance on which models or techniques should be included or how to conduct these comparisons. While it points out a potential improvement, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies four specific errors in the text, including incorrect grammar and spelling. It provides explicit corrections for each error, such as \"Despite being compact\" and \"We refer to multiway arrays.\" Additionally, it points out that \"HPFN to a even deeper ConAC\" should be corrected to \"HPFN to an even deeper ConAC.\" The reviewer also notes that \"Effect of the modelling mixed temporalmodality features\" is not grammatically correct and is unclear. These corrections are direct and concrete, providing the authors with clear guidance on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections to errors in the text, such as incorrect grammar and spelling. It explicitly mentions lines 2, 56, 158, and 265, allowing the authors to accurately identify the parts of the paper being addressed. Additionally, the comment provides specific guidance on how to correct these errors, such as changing \"Despite of being compact\" to \"Despite being compact\" and \"We refer multiway arrays\" to \"We refer to multiway arrays.\" This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of corrections to errors in grammar and spelling, which are factual statements. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific errors in the text, such as incorrect grammar and spelling, and provides clear and actionable feedback to correct them. It also points out that the phrasing \"Effect of the modelling mixed temporalmodality features\" is not grammatically correct, which is a valuable observation that can help the authors improve the clarity and coherence of their writing. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or coherence of the text beyond these specific corrections. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of Eqs. The reviewer does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or correct the issue. Without any guidance or direction, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the context of the equations, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the context of Eqs. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. This question highlights a potential confusion in the paper, which could be clarified to improve the understanding of the authors\" work. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to make the work more innovative or differentiate it from existing work. As a result, the authors are left without any clear direction on how to enhance their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the model extension are considered incremental or straightforward. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assessment and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve their work. Without actionable guidance or constructive criticism, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While the comment implies that the authors should conduct a comparison between the two designs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison between sequential and combinational designs, but without explicit references to sections or figures, the authors may struggle to identify where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the method may perform better in combinational logic. The comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to conduct this comparison or what specific aspects to focus on. The comment is 3 as it points out a potential area for further exploration, but it does not offer detailed suggestions or examples to guide the authors in conducting the comparison. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a discussion of the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is concrete, as it specifies the metric to be analyzed and provides a clear direction for improvement, but it is somewhat vague because it does not provide detailed guidance on how to conduct the analysis or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides clear guidance on what aspect of the experiment needs further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline combining LDA and LSTM (LDA+LSTM) can capture sequential information and provide topic assignment for each word. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and how it relates to the experiment section. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by discussing the performance of a baseline combining LDA and LSTM (LDA+LSTM) in terms of the topic switch percent metric. This feedback is clear and actionable, as it prompts the authors to include a discussion of the baseline\"s performance in their experiment section. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or analyze the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide more information about the motivation and potential applications of their work, but the comment lacks specific suggestions on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the motivation and potential applications of the work, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the motivation is unclear or that the task is difficult to predict. The comment is 3 as it highlights potential gaps in the paper, but it does not provide detailed reasoning or evidence to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the motivation and potential applications of the task, which are crucial for understanding the significance and impact of the work. It highlights the difficulty in predicting the state of an object when it is occluded and questions the quality of predictions when the real state is unknown. The comment also asks about the potential downstream applications or benefits of amodal tracking and how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider the broader implications and applications of their work, but it could be more beneficial with additional direction or examples. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is explicit and provides a clear action for the authors to take, which is to include experiments with GPT3.5. The comment is concrete because it specifies the exact change needed to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of the proposed approach. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not direct. The comment is specific in suggesting the inclusion of GPT3.5 experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. However, the comment does not provide any supporting evidence or reasoning to justify why GPT3.5 is a better option or why it would provide a more comprehensive evaluation. Without additional context or comparisons, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly advises the authors to include a more costeffective option in their experiments. However, the comment could be more helpful if it provided additional context or justification for why GPT3.5 is a better choice or how it might impact the evaluation. Despite this, the suggestion is valuable as it encourages the authors to consider a broader range of options for their experiments. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. This is a clear and direct action for the authors to take, as it provides a specific and concrete step to improve the presentation of their results. The comment is 5 because it clearly specifies what needs to be done to enhance the clarity and accuracy of the table.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of bold numbers for the baselines of previous work, particularly for WMT17WIKT. This provides clear guidance on how to improve the presentation of results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 4 should include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or how it would improve the clarity or accuracy of the table. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with the presentation of results in Table 4, specifically regarding the inclusion of bold numbers for the baselines of previous work, such as WMT17WIKT. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accuracy of the table. By including bold numbers, the authors can better highlight the baselines and their performance, which is crucial for understanding the context and significance of their results. However, the comment could be more helpful if it explained why this change is important or how it would enhance the overall presentation of the results. Overall, the comment is valuable for guiding the authors in improving their draft, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take by asking for examples. The comment is concrete because it specifies the exact part of the paper where the examples should be provided, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors\" mentioned in those lines. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for verifiability.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area in the paper where examples of \"unreliable neighbors\" are mentioned. By asking for examples, the reviewer prompts the authors to provide more detailed explanations or examples to support their claims. However, the comment could be more helpful if it offered suggestions on how to present these examples or what specific aspects to focus on. While it provides a clear direction for improvement, it lacks depth and could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of support for the claim about the synergies between DQD and PPO, specifically mentioning the absence of reference to the TD3GA algorithm in the main paper. It also suggests that the comparison to TD3GA should be central to the paper. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include references to the TD3GA algorithm and emphasize the comparison to TD3GA, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of reference to the TD3GA algorithm and the need for a central comparison to TD3GA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the synergies between DQD and PPO are insufficiently supported, specifically mentioning the absence of reference to the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA should be central to understanding these synergies. This claim is 3 as it highlights a gap in the paper\"s discussion of the TD3GA algorithm, which is crucial for understanding the synergies. However, the comment lacks specific examples or references to the TD3GA algorithm or its relevance to the synergies, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the paper. This feedback is clear and actionable, as it points out a specific omission and provides a direction for improvement. By addressing these issues, the authors can enhance the clarity and robustness of their claims. However, the comment could be more helpful if it offered suggestions on how to incorporate the TD3GA algorithm or provided examples of how it could be integrated into the paper. Overall, the comment is 4 as it effectively guides the authors on how to strengthen their claims and improve the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why the treesliced Wasserstein distance outperforms the original optimal transport distance, as observed in Sections 6.1 and 6.2. This request is clear and provides a specific action for the authors to take, which is to provide an explanation for this observation. The comment is concrete in its request for clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for an explanation of why the treesliced Wasserstein distance outperforms the original optimal transport distance, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the observation that the treesliced Wasserstein distance outperforms the original optimal transport distance, suggesting that an explanation is needed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation in the paper regarding the treesliced Wasserstein distance outperforming the original optimal transport distance. It prompts the authors to explain this observation, which is a clear and actionable suggestion for improvement. By asking for an explanation, the comment encourages the authors to clarify their findings and provide a deeper understanding of their results. However, the comment could be more helpful if it offered additional guidance on how to present this explanation or what aspects of the results are particularly surprising or noteworthy. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the word \"confident\" in the sentence is unclear and suggests rephrasing it to clarify whether it pertains to model confidence or human interpretability. While the comment implies that the authors should rephrase the sentence to improve clarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should revise the sentence to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence containing the word \"confident,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, suggesting that the word \"confident\" should be rephrased to clarify whether it pertains to model confidence or human interpretability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the word \"confident\" in the sentence, suggesting that it may refer to model confidence or human interpretability. The reviewer provides a logical reasoning by questioning the word choice, which is a common practice in academic writing. However, the comment lacks specific examples or references to support the claim that the word is unclear or misleading. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the word \"confident\" in the sentence, suggesting that it may be unclear whether it pertains to model confidence or human interpretability. While the comment highlights a potential source of confusion, it does not provide specific suggestions for rephrasing the sentence to improve clarity. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable guidance on how to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the practicality of the proposed work, specifically regarding the use of known causal relationships between features. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the practicality of their work or what specific steps they could take to ensure the validity of their causal relationships. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s proposal to use known causal relationships between features, noting that prior knowledge might not always be available or accurate for specific subpopulations. It raises a concern about the practicality of the work and suggests that researchers focus on mining causal relationships from data automatically. However, the comment does not specify which part of the paper this critique is based on, such as specific sections or examples where the proposed method is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the concern about the practicality of the work, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed work relies on known causal relationships between features, which might not always be available or accurate for specific subpopulations. The reviewer supports this claim by noting that most researchers focus on mining causal relationships from data automatically. However, the comment lacks specific examples or references to substantiate the claim about the inaccuracy of prior knowledge or the practicality of the proposed approach. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3, as it requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s proposal, noting that the use of known causal relationships between features might not always be available or accurate for specific subpopulations. It highlights a practical concern by suggesting that most researchers focus on mining causal relationships from data automatically. This feedback is 3 as it points out a potential limitation in the applicability of the proposed method, prompting the authors to consider the practicality of their work. However, the comment could be more helpful if it provided suggestions on how to address this concern or examples of how others have addressed similar issues. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of polishing in figures and empirical results, which affects clarity and confidence in empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. However, the comment does not explicitly instruct the authors on how to address these issues or provide guidance on how to improve the clarity and polish of the figures and results. The action is implicit and somewhat vague, as the authors can infer that they need to improve the presentation of their results but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the lack of polishing in figures and empirical results, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. This provides clear guidance on what needs to be addressed to improve the clarity and confidence in empirical findings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks polishing in figures and empirical results, which affects clarity and confidence in empirical findings. The comment provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in the literature, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and confidence in the empirical findings of the paper. It points out specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These observations highlight areas where the paper could be improved to enhance its credibility and impact. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending standard practices for figure presentation or offering guidance on how to improve the robustness of the empirical results. Despite this, the feedback is 4 as it directs the authors\" attention to critical areas needing improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to enhance the generalizability of the findings or suggestions for further exploration. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. However, it does not specify which part of the paper this observation is based on, such as specific sections, tables, or figures. The authors can infer that it relates to the results or findings section, but this inference is not direct. The comment is specific in detailing the expected outcome of taskspecific finetuning, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited due to the expected outcome of taskspecific finetuning, which generally increases confidence for a specific task while potentially reducing generalizability. This claim is 3 as it provides a logical reasoning based on the general understanding of taskspecific finetuning. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. It suggests that this expected outcome reduces the novelty of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their findings. While it identifies a potential issue, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. It explicitly states that this would further test the conjecture and provide valuable insights, even if the phenomenon weakens in this setting. The comment is clear and provides a direct action for the authors to take, which is to include these numbers in their report. The action is concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, which would further test the conjecture. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting that reporting these numbers would strengthen the case, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this additional information would be beneficial or how it would impact the paper\"s conclusions. Without such justification, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. It provides a clear and actionable suggestion that could enhance the paper\"s robustness and credibility by further testing the conjecture. This feedback is valuable as it offers a specific and meaningful improvement that the authors can consider, even if it does not directly address all aspects of the paper. However, the comment could be more helpful if it provided additional context or explanation on why this additional data is important or how it would impact the paper\"s conclusions. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of using the number of weight updates as a metric over the number of network updates, given that the brain operates in parallel. It suggests providing additional feedback to improve the paper. However, the comment does not specify what additional feedback is needed or how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information or justification for their choice of metrics, but the comment lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of metrics used in the paper, specifically questioning why the number of weight updates is preferred over the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where this metric is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its question about the choice of metrics, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of metrics used in the paper, specifically questioning why the number of weight updates is preferred over the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unsuitable. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of metrics used in the paper, specifically questioning why the number of weight updates is preferred over the number of network updates, given that the brain operates in parallel. This is an important point that could impact the interpretation and understanding of the results. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it does not offer guidance on how to resolve it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the objective should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the objective, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification, which is factual in nature. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. This is a relevant point that could help the authors clarify their methodology and provide a more comprehensive understanding of their approach. However, the comment lacks specific guidance or suggestions on how the authors might address this question or what aspects of the objective should be clarified. While it identifies an area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It also points out the need to explore the effects of varying the number of InContext Examples. While the comment provides a clear list of areas that need improvement, it does not offer specific guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the experiment setup and explore different scenarios, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of incontent examples used and the need to explore the effects of varying the number of InContext Examples. The comment also highlights the reliance on a single dataset, which could limit the generalizability of the results. While the comment identifies some issues, it lacks specific examples or references to support the claim that the evaluation is insufficient or lacks transparency. This makes the claim 3, as the authors would need to further explore and address these points to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It also points out the need to explore the effects of varying the number of InContext Examples. These are all valid observations that could significantly improve the paper by providing more detailed information and addressing potential limitations. However, the comment could be more helpful if it offered specific suggestions on how to improve the evaluation or provided examples of how other studies have addressed similar issues. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance on execution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the contrastive learning framework used in the paper is the same as SimCLR, which is a direct observation. However, it does not provide any guidance or suggestions on how the authors should address this observation or what changes they should make to their framework. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the contrastive learning framework used in the paper is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the comparison to SimCLR. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which could be a potential issue or a point of comparison. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this observation or differentiate their work from SimCLR. Without actionable feedback or constructive advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This implies that the authors should include these comparisons in Section 4.3 to showcase the unique advantages or potential shortcomings of their proposed method in a broader context. The comment is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests that including these comparisons would provide a broader context for the proposed method. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these comparisons and determine how they would enhance the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback highlights the importance of including such comparisons to showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By suggesting these comparisons, the comment provides clear and actionable guidance for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully included such comparisons. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so or provide guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these references. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the references to include, but it is 1 in the context of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or explanation as to why these references are relevant or how they could enhance the paper. Without additional context or justification, the claim lacks verifiability, as it does not provide sufficient evidence or guidance for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While this feedback identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to integrate these references into the paper or why they are relevant. The comment does not offer suggestions on how to effectively incorporate the references or how they might enhance the paper. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should include comparisons with existing text GANs and test SeqGAN with a pretrained version, but the comment lacks specific guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The comment is specific in detailing what is missing, namely the comparison with existing GANs and the testing of SeqGAN with a pretrained version. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. However, the comment lacks specific examples or references to existing GANs or SeqGAN implementations to support the claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a comparison against existing text GANs, many of which have opensource implementations. It also points out that SeqGAN is mentioned but not tested with a pretrained version. This feedback is clear and actionable, as it highlights specific areas where the paper could be strengthened by including comparisons with existing models and testing SeqGAN with a pretrained version. However, the comment could be more helpful if it provided examples of existing GANs or suggested specific ways to implement these comparisons and tests. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. While the comment implies that the paper lacks depth in this area, it does not provide specific guidance on how to address this issue or what aspects of the algorithmic aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to expand on the algorithmic aspects but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing the algorithmic aspects or the introduction of the Blackwell winner. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithmic aspects should be addressed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This claim is based on the observation that the novelty of the paper seems limited after introducing the Blackwell winner. However, the comment lacks specific examples or detailed reasoning to support why the algorithmic aspects are crucial or how they could enhance the paper\"s contribution. The lack of specific evidence or detailed justification makes the claim 3, as it provides a logical basis but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This feedback is 3 as it identifies a potential area for improvement by suggesting that the paper could provide more depth on the algorithmic aspects. However, the comment lacks specific guidance on what aspects of the algorithmic aspects should be covered or how they could be integrated into the paper. While it points out a potential weakness, it does not offer detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that Table 4 and 5 should be split into two tables each, with one table per measure. This provides a clear and concrete action for the authors to take, as it specifies the exact change needed to improve the readability of the tables. The suggestion is specific and actionable, leaving no ambiguity about what the authors should do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of the tables by splitting them into two tables each, with one table per measure. This gives the authors a clear idea of what needs to be addressed to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that splitting tables 4 and 5 into two tables each would improve their readability. This claim is based on a logical reasoning that separating the columns by measure would make the tables more organized and easier to understand. However, the comment does not provide specific examples or references to support this claim, such as how other papers or studies have successfully implemented this structure. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, with one table per measure. This is a clear and constructive piece of feedback that can help the authors enhance the clarity and organization of their tables. By following this suggestion, the authors can significantly improve the presentation of their data, making it easier for readers to understand and interpret the results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. This is a direct and concrete action for the authors to take, as it clearly identifies a specific aspect of the figure that needs clarification. The comment provides a clear and specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of \"valid\" and \"orig\" in the context of Fig. 5. This provides clear guidance on what the authors need to do to improve the clarity of their figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the understanding of the figure. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Fig. 5, noting that the terms \"valid\" and \"orig\" are used without explanation. This feedback is clear and actionable, as it directs the authors to provide a brief explanation of what these terms mean in the context of the figure. By addressing this point, the authors can improve the clarity and accessibility of their figure, which is valuable for enhancing the overall understanding and impact of their work. However, the comment could be more helpful if it suggested how to present this explanation or provided examples of how similar terms have been clarified in similar figures. Overall, the comment is 4 as it effectively guides the authors on a specific area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons with the most closely related work more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. The comment is explicit in its suggestion and offers a specific improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely making comparisons more systematic with respect to the tuning of each method. This provides clear guidance on how to enhance the originality and comparative analysis of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s originality is improved by comparing it to the most closely related work of Zemel et al. (2013) and explaining how it differs. The comment suggests that the comparisons could be made more systematic by comparing the best performance of each method. This claim is 3 as it provides a logical reasoning for improvement, but it lacks specific examples or references to the original work or the current paper\"s comparisons. The authors would need to infer the specifics of the comparisons and the need for systematic analysis, making the claim 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the comparisons with the most closely related work. It suggests that the paper could be more original by making these comparisons more systematic, specifically by comparing the best performance of each method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the originality and depth of the paper. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or provided examples of how other studies have approached this task. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not provide specific guidance on which method to compare or how to adapt it to language tasks. The action is implicit and somewhat vague, as the authors need to infer the specific method and adaptation steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to one of the methods mentioned in the computer vision setting, specifically mentioning lossbased sampling as an example. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison could be included. While the authors might infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in suggesting a potential improvement by including a comparison to computer vision methods, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some could be adapted to language tasks relatively easily. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to infer the specific methods and adaptations themselves, making the comment 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This feedback is 3 as it provides a specific suggestion for enhancing the paper by including a comparison that could offer insights into the applicability of computer vision methods to language tasks. However, the comment could be more helpful if it included specific examples of methods that could be adapted or how to adapt them. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion for how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need to estimate the time complexity of the learning algorithm to prove its scalability properties, which provides full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the estimation of time complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a clear and actionable suggestion that can help the authors strengthen their claims about the algorithm\"s performance. By addressing this point, the authors can provide more robust evidence to support their conclusions. However, the comment could be more helpful if it included examples or guidance on how to estimate the time complexity effectively. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that there may be a connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, it does not provide explicit instructions or guidance on how the authors should explore or incorporate this connection. The comment implies that the authors should investigate the relationship but lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential connection to properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, the comment does not provide any detailed reasoning or explanation of why this connection is relevant or how it could be explored. Without further context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. This is a valuable suggestion that could lead to a deeper understanding of the topic and potentially enhance the paper\"s contribution. However, the comment lacks specific guidance on how to explore this connection or what aspects of the universal kernel properties might be relevant to the paper. While it points to a potentially interesting direction, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit actions for the authors to take to improve the discussion. There is no guidance on what aspects of the discussion need to be expanded or clarified, nor are there suggestions for how to present the information more effectively. As a result, the authors are left without any actionable steps to follow in order to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the discussion is lacking or how it could be improved, leaving the authors with a general understanding of the issue but without detailed guidance on how to address it. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and not \"very clearly explained.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. However, it does not provide any suggestions or guidance on how the authors might improve the clarity or depth of this discussion. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a weakness but lacks depth and specificity in its feedback."}
